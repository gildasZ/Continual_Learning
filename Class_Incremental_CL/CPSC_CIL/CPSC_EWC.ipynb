{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07af288c",
   "metadata": {},
   "source": [
    "## __Check first before starting__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f00b1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /mnt/mydisk/Continual_Learning_JL/Continual_Learning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "Working_directory = os.path.normpath(\"/mnt/mydisk/Continual_Learning_JL/Continual_Learning/\")\n",
    "os.chdir(Working_directory)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97bdf56",
   "metadata": {},
   "source": [
    "## __All imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b85d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating system and file management\n",
    "import os\n",
    "import shutil\n",
    "import contextlib\n",
    "import traceback\n",
    "import gc\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import subprocess\n",
    "import time\n",
    "import re, pickle\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "from glob import glob\n",
    "from math import ceil\n",
    "\n",
    "# Jupyter notebook widgets and display\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_interactions import zoom_factory, panhandler\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from ta import trend, momentum, volatility, volume\n",
    "\n",
    "# Mathematical and scientific computing\n",
    "import math\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# Type hinting\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "# Deep learning with PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a496fe70",
   "metadata": {},
   "source": [
    "## __üìÅ Path Settings and Constants__\n",
    "This cell defines essential paths and constants for the CPSC2018 ECG dataset processing:\n",
    "- `BASE_DIR`: Root directory of the project.\n",
    "- `save_dir`: Path to the preprocessed `.npy` files (one for each continual learning period).\n",
    "- `ECG_PATH`: Directory containing original `.mat` and `.hea` files.\n",
    "- `MAX_LEN`: Length of each ECG sample, fixed to 5000 time steps (i.e., 10 seconds at 500Hz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7748e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL\"\n",
    "save_dir = os.path.join(BASE_DIR, \"processed\")\n",
    "ECG_PATH = os.path.join(BASE_DIR, \"datas\")\n",
    "MAX_LEN = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba7249f",
   "metadata": {},
   "source": [
    "## __üè∑Ô∏è Label Mapping and Period Configuration__\n",
    "\n",
    "This section defines:\n",
    "- `snomed_map`: Mapping from SNOMED CT codes to readable class names for 9 major ECG conditions.\n",
    "- `period_label_map`: Incremental learning task structure across four periods.  \n",
    "  Class `1` is reserved for \"OTHER\" abnormalities until Period 4 when all 9 classes are explicitly categorized.\n",
    "- `print_class_distribution()`: Helper function to show class-wise data distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "103ca271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNOMED CT to readable names\n",
    "snomed_map = {\n",
    "    \"426783006\": \"NSR\",    # Ê≠£Â∏∏Á´áÊÄßÂøÉÂæã\n",
    "    \"270492004\": \"I-AVB\",  # ‰∏ÄÂ∫¶ÊàøÂÆ§ÂÇ≥Â∞éÈòªÊªØ\n",
    "    \"164889003\": \"AF\",     # ÂøÉÊàøÁ∫ñÁ∂≠È°´Âãï\n",
    "    \"164909002\": \"LBBB\",   # Â∑¶ÊùüÊîØÂÇ≥Â∞éÈòªÊªØ\n",
    "    \"59118001\":  \"RBBB\",   # Âè≥ÊùüÊîØÂÇ≥Â∞éÈòªÊªØ\n",
    "    \"284470004\": \"PAC\",    # ÂøÉÊàøÊó©ÊúüÊêèÂãï\n",
    "    \"164884008\": \"PVC\",    # ÂÆ§ÊÄßÊó©ÊúüÊêèÂãï\n",
    "    \"429622005\": \"STD\",    # ST ÊÆµÂ£ì‰Ωé\n",
    "    \"164931005\": \"STE\"     # ST ÊÆµÊä¨È´ò\n",
    "}\n",
    "\n",
    "# Period class mapping (Âõ∫ÂÆö class 1 ÊòØ„ÄåÂÖ∂‰ªñÁï∞Â∏∏„ÄçÁõ¥Âà∞ P4 ÁßªÈô§)\n",
    "period_label_map = {\n",
    "    1: {\"NSR\": 0, \"OTHER\": 1},\n",
    "    2: {\"NSR\": 0, \"I-AVB\": 2, \"AF\": 3, \"OTHER\": 1},\n",
    "    3: {\"NSR\": 0, \"I-AVB\": 2, \"AF\": 3, \"LBBB\": 4, \"RBBB\": 5, \"OTHER\": 1},\n",
    "    4: {\"NSR\": 0, \"I-AVB\": 2, \"AF\": 3, \"LBBB\": 4, \"RBBB\": 5, \"PAC\": 6, \"PVC\": 7, \"STD\": 8, \"STE\": 9}\n",
    "}\n",
    "\n",
    "def print_class_distribution(y, label_map):\n",
    "    y = np.array(y).flatten()\n",
    "    total = len(y)\n",
    "    all_labels = sorted(label_map.values())\n",
    "    print(\"\\nüìä Class Distribution\")\n",
    "    for lbl in all_labels:\n",
    "        count = np.sum(y == lbl)\n",
    "        label = [k for k, v in label_map.items() if v == lbl]\n",
    "        name = label[0] if label else str(lbl)\n",
    "        print(f\"  ‚îú‚îÄ Label {lbl:<2} ({name:<10}) ‚Üí {count:>5} samples ({(count/total)*100:5.2f}%)\")\n",
    "\n",
    "def ensure_folder(folder_path: str) -> None:\n",
    "    \"\"\"Ensure the given folder exists, create it if not.\"\"\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f95af3",
   "metadata": {},
   "source": [
    "## üì¶ EX. Load Example (Period 4) Data and View Format\n",
    "\n",
    "This example demonstrates how to load preprocessed `.npy` data for **Period 4**, and inspect the dataset shapes and label distribution.  \n",
    "Use this format as a reference when loading data in other methods (e.g., EWC, PNN, DynEx-CLoRA).\n",
    "\n",
    "Each ECG sample:\n",
    "- Has shape `(5000, 12)` ‚Üí represents 10 seconds (at 500Hz) across 12-lead channels.\n",
    "- Corresponding label is an integer ID (e.g., 0‚Äì9) defined by `period_label_map[4]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a401dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ÁØÑ‰æã:ËºâÂÖ• period 4\n",
    "# save_dir = os.path.join(BASE_DIR, \"processed\")\n",
    "# X_train = np.load(os.path.join(save_dir, \"X_train_p4.npy\"))\n",
    "# y_train = np.load(os.path.join(save_dir, \"y_train_p4.npy\"))\n",
    "# X_test = np.load(os.path.join(save_dir, \"X_test_p4.npy\"))\n",
    "# y_test = np.load(os.path.join(save_dir, \"y_test_p4.npy\"))\n",
    "\n",
    "# print(\"‚úÖ Loaded\")\n",
    "# print(\"X_train shape:\", X_train.shape)\n",
    "# print(\"y_train shape:\", y_train.shape)\n",
    "# print(\"X_test shape:\", X_test.shape)\n",
    "# print(\"y_test shape:\", y_test.shape)\n",
    "# print_class_distribution(y_train, period_label_map[4])\n",
    "# print_class_distribution(y_test, period_label_map[4])\n",
    "\n",
    "# del X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d4b54b",
   "metadata": {},
   "source": [
    "## __Check GPU, CUDA, Pytorch__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50a987a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 10 15:10:28 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off |   00000000:2A:00.0 Off |                  Off |\n",
      "| 30%   43C    P2             80W /  300W |    1435MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000               Off |   00000000:3D:00.0 Off |                  Off |\n",
      "| 30%   51C    P2             97W /  300W |   45337MiB /  49140MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000               Off |   00000000:AB:00.0 Off |                  Off |\n",
      "| 30%   45C    P2             95W /  300W |   45335MiB /  49140MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2845      G   /usr/lib/xorg/Xorg                        4MiB |\n",
      "|    0   N/A  N/A         2314326      C   python                                  766MiB |\n",
      "|    0   N/A  N/A         2514160      C   python                                  640MiB |\n",
      "|    1   N/A  N/A            2845      G   /usr/lib/xorg/Xorg                        4MiB |\n",
      "|    1   N/A  N/A           11816      C   python                                45198MiB |\n",
      "|    2   N/A  N/A            2845      G   /usr/lib/xorg/Xorg                        4MiB |\n",
      "|    2   N/A  N/A           12293      C   python                                45196MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f78325",
   "metadata": {},
   "source": [
    "### CUDA Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00875f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "             GPU Configuration Check              \n",
      "==================================================\n",
      "PyTorch Version          : 2.5.1\n",
      "GPU Available            : Yes\n",
      "--------------------------------------------------\n",
      "                   GPU Details                    \n",
      "--------------------------------------------------\n",
      "Device Name              : NVIDIA RTX A6000\n",
      "Number of GPUs           : 3\n",
      "Current Device Index     : 0\n",
      "Compute Capability       : 8.6\n",
      "Total CUDA Cores         : 10752\n",
      "Total Memory (GB)        : 47.41\n",
      "Allocated Memory (GB)    : 0.00\n",
      "Reserved Memory (GB)     : 0.00\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def check_gpu_config():\n",
    "    \"\"\"\n",
    "    Check GPU availability and display detailed configuration information.\n",
    "    \"\"\"\n",
    "    # Check if GPU is available\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    \n",
    "    # Print header\n",
    "    print(\"=\" * 50)\n",
    "    print(\"GPU Configuration Check\".center(50))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic GPU availability\n",
    "    print(f\"{'PyTorch Version':<25}: {torch.__version__}\")\n",
    "    print(f\"{'GPU Available':<25}: {'Yes' if gpu_available else 'No'}\")\n",
    "    \n",
    "    # If GPU is available, print detailed info\n",
    "    if gpu_available:\n",
    "        print(\"-\" * 50)\n",
    "        print(\"GPU Details\".center(50))\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Device info\n",
    "        print(f\"{'Device Name':<25}: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"{'Number of GPUs':<25}: {torch.cuda.device_count()}\")\n",
    "        print(f\"{'Current Device Index':<25}: {torch.cuda.current_device()}\")\n",
    "        \n",
    "        # Compute capability and CUDA cores\n",
    "        props = torch.cuda.get_device_properties(0)\n",
    "        print(f\"{'Compute Capability':<25}: {props.major}.{props.minor}\")\n",
    "        print(f\"{'Total CUDA Cores':<25}: {props.multi_processor_count * 128}\")  # Approx. 128 cores per SM\n",
    "        \n",
    "        # Memory info\n",
    "        total_memory = props.total_memory / (1024 ** 3)  # Convert to GB\n",
    "        memory_allocated = torch.cuda.memory_allocated(0) / (1024 ** 3)\n",
    "        memory_reserved = torch.cuda.memory_reserved(0) / (1024 ** 3)\n",
    "        print(f\"{'Total Memory (GB)':<25}: {total_memory:.2f}\")\n",
    "        print(f\"{'Allocated Memory (GB)':<25}: {memory_allocated:.2f}\")\n",
    "        print(f\"{'Reserved Memory (GB)':<25}: {memory_reserved:.2f}\")\n",
    "    else:\n",
    "        print(\"-\" * 50)\n",
    "        print(\"No GPU detected. Running on CPU.\".center(50))\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_gpu_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a868ff5",
   "metadata": {},
   "source": [
    "### PyTorch Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d153a6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "              PyTorch Configuration               \n",
      "==================================================\n",
      "PyTorch Version          : 2.5.1\n",
      "CUDA Compiled Version    : 12.1\n",
      "CUDA Available           : Yes\n",
      "Number of GPUs           : 3\n",
      "GPU Name                 : NVIDIA RTX A6000\n",
      "--------------------------------------------------\n",
      "Random Seed              : 42 (Seeding successful!)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def print_torch_config():\n",
    "    \"\"\"Print PyTorch and CUDA configuration in a formatted manner.\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"PyTorch Configuration\".center(50))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic PyTorch and CUDA info\n",
    "    print(f\"{'PyTorch Version':<25}: {torch.__version__}\")\n",
    "    print(f\"{'CUDA Compiled Version':<25}: {torch.version.cuda}\")\n",
    "    print(f\"{'CUDA Available':<25}: {'Yes' if torch.cuda.is_available() else 'No'}\")\n",
    "    print(f\"{'Number of GPUs':<25}: {torch.cuda.device_count()}\")\n",
    "\n",
    "    # GPU details if available\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"{'GPU Name':<25}: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Seed setting\n",
    "    torch.manual_seed(42)\n",
    "    print(f\"{'Random Seed':<25}: 42 (Seeding successful!)\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print_torch_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbab549",
   "metadata": {},
   "source": [
    "## __‚öôÔ∏è GPU Selection ‚Äî Auto-select the least loaded GPU__\n",
    "This code automatically scans available GPUs and selects the one with the lowest current memory usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4ffdd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Automatically selected GPU:\n",
      "    - CUDA Device ID : 0\n",
      "    - Memory Used    : 1435 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "def auto_select_cuda_device(verbose=True):\n",
    "    \"\"\"\n",
    "    Automatically selects the CUDA GPU with the least memory usage.\n",
    "    Falls back to CPU if no GPU is available.\n",
    "    \"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"üö´ No CUDA GPU available. Using CPU.\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    try:\n",
    "        # Run nvidia-smi to get memory usage of each GPU\n",
    "        smi_output = subprocess.check_output(\n",
    "            ['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'],\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        memory_used = [int(x) for x in smi_output.strip().split('\\n')]\n",
    "        best_gpu = int(np.argmin(memory_used))\n",
    "\n",
    "        if verbose:\n",
    "            print(\"üéØ Automatically selected GPU:\")\n",
    "            print(f\"    - CUDA Device ID : {best_gpu}\")\n",
    "            print(f\"    - Memory Used    : {memory_used[best_gpu]} MiB\")\n",
    "            print(f\"    - Device Name    : {torch.cuda.get_device_name(best_gpu)}\")\n",
    "        return torch.device(f\"cuda:{best_gpu}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to auto-detect GPU. Falling back to cuda:0. ({e})\")\n",
    "        return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Execute and assign\n",
    "device = auto_select_cuda_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfae7c5a",
   "metadata": {},
   "source": [
    "## __Model__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b4707e",
   "metadata": {},
   "source": [
    "### ResNet 18 - 1D (ResNet18_1D_big_inplane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cab8843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock1d(nn.Module):\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock1d, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ResNet18_1D(nn.Module):\n",
    "    def __init__(self, input_channels=12, output_size=9, inplanes=64):\n",
    "        super(ResNet18_1D, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        \n",
    "        # Initial conv layer\n",
    "        self.conv1 = nn.Conv1d(input_channels, self.inplanes, kernel_size=15, stride=2, padding=7, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Residual layers\n",
    "        self.layer1 = self._make_layer(BasicBlock1d, 64, 2)\n",
    "        self.layer2 = self._make_layer(BasicBlock1d, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock1d, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock1d, 512, 2, stride=2)\n",
    "        \n",
    "        # Adaptive pooling (both avg and max)\n",
    "        self.adaptiveavgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.adaptivemaxpool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        # Fully connected layer with dropout\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(512 * BasicBlock1d.expansion * 2, output_size)\n",
    "    \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Expect input shape: (batch_size, time_steps, channels)\n",
    "        x = x.permute(0, 2, 1)  # ‚Üí (batch_size, channels, time_steps)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # Apply both avg and max pooling\n",
    "        x1 = self.adaptiveavgpool(x)\n",
    "        x2 = self.adaptivemaxpool(x)\n",
    "        \n",
    "        # Concatenate pooling results\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Apply dropout\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Final classification\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebc8c6",
   "metadata": {},
   "source": [
    "## __Training and validation function__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616acb4",
   "metadata": {},
   "source": [
    "### Extra Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3ce00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classwise_accuracy(student_logits_flat, y_batch, class_correct, class_total):\n",
    "    \"\"\"\n",
    "    Computes per-class accuracy by accumulating correct and total samples for each class using vectorized operations.\n",
    "    \n",
    "    Args:\n",
    "        student_logits_flat (torch.Tensor): Model predictions (logits) in shape [batch_size * seq_len, output_size]\n",
    "        y_batch (torch.Tensor): True labels in shape [batch_size * seq_len]\n",
    "        class_correct (dict): Dictionary to store correct predictions per class\n",
    "        class_total (dict): Dictionary to store total samples per class\n",
    "    \"\"\"\n",
    "    # Ensure inputs are on the same device\n",
    "    if student_logits_flat.device != y_batch.device:\n",
    "        raise ValueError(\"student_logits_flat and y_batch must be on the same device\")\n",
    "\n",
    "    # Convert logits to predicted class indices\n",
    "    predictions = torch.argmax(student_logits_flat, dim=-1)  # Shape: [batch_size * seq_len]\n",
    "\n",
    "    # Compute correct predictions mask\n",
    "    correct_mask = (predictions == y_batch)  # Shape: [batch_size * seq_len], boolean\n",
    "\n",
    "    # Get unique labels in this batch\n",
    "    unique_labels = torch.unique(y_batch)\n",
    "\n",
    "    # Update class_total and class_correct using vectorized operations\n",
    "    for label in unique_labels:\n",
    "        label = label.item()  # Convert tensor to scalar\n",
    "        if label not in class_total:\n",
    "            class_total[label] = 0\n",
    "            class_correct[label] = 0\n",
    "        \n",
    "        # Count total samples for this label\n",
    "        label_mask = (y_batch == label)\n",
    "        class_total[label] += label_mask.sum().item()\n",
    "        \n",
    "        # Count correct predictions for this label\n",
    "        class_correct[label] += (label_mask & correct_mask).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "724647c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_parameter_info(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    param_size_bytes = total_params * 4\n",
    "    param_size_MB = param_size_bytes / (1024**2)\n",
    "    return total_params, param_size_MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b7f0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(y: np.ndarray, num_classes: int, exclude_classes: list = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Ë®àÁÆó class weightsÔºàinverse frequencyÔºâÈÅøÂÖç class imbalance„ÄÇ\n",
    "    ÂèØÊéíÈô§Êüê‰∫õÈ°ûÂà•ÔºàÂ¶Ç‰∏çÂ≠òÂú®ÁöÑÈ°ûÂà•ÔºâÔºåÈÄô‰∫õÈ°ûÂà•ÁöÑÊ¨äÈáçÂ∞áË®≠ÁÇ∫ 0„ÄÇ\n",
    "    \"\"\"\n",
    "    exclude_classes = set(exclude_classes or [])\n",
    "    class_sample_counts = np.bincount(y, minlength=num_classes)\n",
    "    total_samples = len(y)\n",
    "\n",
    "    weights = np.zeros(num_classes, dtype=np.float32)\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        if cls in exclude_classes:\n",
    "            weights[cls] = 0.0\n",
    "        else:\n",
    "            count = class_sample_counts[cls]\n",
    "            weights[cls] = total_samples / (count + 1e-6)\n",
    "\n",
    "    # Normalize only non-excluded weights\n",
    "    valid_mask = np.array([cls not in exclude_classes for cls in range(num_classes)])\n",
    "    norm_sum = weights[valid_mask].sum()\n",
    "    if norm_sum > 0:\n",
    "        weights[valid_mask] /= norm_sum\n",
    "\n",
    "    print(\"\\nüìä Class Weights (normalized):\")\n",
    "    for i, w in enumerate(weights):\n",
    "        status = \" (excluded)\" if i in exclude_classes else \"\"\n",
    "        print(f\"  - Class {i}: {w:.4f}{status}\")\n",
    "    \n",
    "    return torch.tensor(weights, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed6d807",
   "metadata": {},
   "source": [
    "### EWC Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ec320fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWC:\n",
    "    def __init__(self, fisher: dict, params: dict):\n",
    "        self.fisher = {k: v.cpu() for k, v in fisher.items()}\n",
    "        self.params = {k: v.cpu() for k, v in params.items()}\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_fisher_and_params(model, dataloader, criterion, device, sample_size=None):\n",
    "        model.train()\n",
    "        fisher = {n: torch.zeros_like(p, device=device) for n, p in model.named_parameters() if p.requires_grad}\n",
    "        params = {n: p.clone().detach().cpu() for n, p in model.named_parameters() if p.requires_grad}\n",
    "\n",
    "        total_samples = 0\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            if sample_size and total_samples >= sample_size:\n",
    "                break\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            model.zero_grad()\n",
    "            outputs = model(x)\n",
    "            # ÂèØË¶ñÊ®°ÂûãËº∏Âá∫ÊòØÂê¶ÈúÄÂ±ïÂπ≥ËÄåÈÅ∏ÊìáÂä†‰∏ä outputs.view(-1, ...)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            for n, p in model.named_parameters():\n",
    "                if p.grad is not None:\n",
    "                    fisher[n] += (p.grad ** 2) * x.size(0)\n",
    "            total_samples += x.size(0)\n",
    "\n",
    "        fisher = {n: f / total_samples for n, f in fisher.items()}\n",
    "        return {n: f.cpu() for n, f in fisher.items()}, params\n",
    "\n",
    "    def penalty(self, model):\n",
    "        loss = 0.0\n",
    "        for n, p in model.named_parameters():\n",
    "            if n in self.fisher:\n",
    "                _loss = self.fisher[n].to(p.device) * (p - self.params[n].to(p.device)) ** 2\n",
    "                loss += _loss.sum()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe5f03",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7836ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_ewc_ecg(model, output_size, criterion, optimizer,\n",
    "                       X_train, y_train, X_val, y_val,\n",
    "                       scheduler=None, num_epochs=10, batch_size=64,\n",
    "                       model_saving_folder=None, model_name=None,\n",
    "                       stop_signal_file=None, ewc=None, lambda_ewc=0.4,\n",
    "                       device=None):\n",
    "\n",
    "    print(\"\\nüöÄ 'train_with_ewc_ecg' started.\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    device = device or auto_select_cuda_device()\n",
    "    model_name = model_name or 'model'\n",
    "    model_saving_folder = model_saving_folder or './saved_models'\n",
    "\n",
    "    if os.path.exists(model_saving_folder):\n",
    "        shutil.rmtree(model_saving_folder)\n",
    "        print(f\"‚úÖ Removed existing folder: {model_saving_folder}\")\n",
    "    os.makedirs(model_saving_folder, exist_ok=True)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(\"\\n‚úÖ Data Overview:\")\n",
    "    print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "\n",
    "    best_results = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if stop_signal_file and os.path.exists(stop_signal_file):\n",
    "            print(\"\\nüõë Stop signal detected. Exiting training loop.\")\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        class_correct, class_total = {}, {}\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            if ewc:\n",
    "                loss += (lambda_ewc / 2) * ewc.penalty(model)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * X_batch.size(0)\n",
    "            compute_classwise_accuracy(outputs, y_batch, class_correct, class_total)\n",
    "\n",
    "        train_loss = epoch_loss / len(train_loader.dataset)\n",
    "        train_acc = {int(c): f\"{(class_correct[c] / class_total[c]) * 100:.2f}%\" if class_total[c] > 0 else \"0.00%\"\n",
    "                     for c in sorted(class_total.keys())}\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        val_class_correct, val_class_total = {}, {}\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                outputs = model(X_batch)\n",
    "                val_loss += criterion(outputs, y_batch).item() * X_batch.size(0)\n",
    "                predictions = torch.argmax(outputs, dim=-1)\n",
    "                val_correct += (predictions == y_batch).sum().item()\n",
    "                val_total += y_batch.size(0)\n",
    "                compute_classwise_accuracy(outputs, y_batch, val_class_correct, val_class_total)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_acc_cls = {int(c): f\"{(val_class_correct[c] / val_class_total[c]) * 100:.2f}%\" if val_class_total[c] > 0 else \"0.00%\"\n",
    "                       for c in sorted(val_class_total.keys())}\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}, Train-Class-Acc: {train_acc}\")\n",
    "        print(f\"Val Loss: {val_loss:.6f}, Val Acc: {val_acc * 100:.2f}%, Val-Class-Acc: {val_acc_cls}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        model_path = os.path.join(model_saving_folder, f\"{model_name}_epoch_{epoch+1}.pth\")\n",
    "        current = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_acc,\n",
    "            'train_classwise_accuracy': train_acc,\n",
    "            'val_classwise_accuracy': val_acc_cls,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'learning_rate': optimizer.param_groups[0]['lr'],\n",
    "            'model_path': model_path\n",
    "        }\n",
    "\n",
    "        if len(best_results) < 5 or val_acc > best_results[-1]['val_accuracy']:\n",
    "            if len(best_results) == 5:\n",
    "                to_remove = best_results.pop()\n",
    "                if os.path.exists(to_remove['model_path']):\n",
    "                    os.remove(to_remove['model_path'])\n",
    "                    print(f\"üóë Removed: {to_remove['model_path']}\")\n",
    "            best_results.append(current)\n",
    "            best_results.sort(key=lambda x: (x['val_accuracy'], x['epoch']), reverse=True)\n",
    "            torch.save(current, model_path)\n",
    "            print(f\"‚úÖ Saved model: {model_path}\")\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "    # End of training\n",
    "    training_time = time.time() - start_time\n",
    "    total_params, param_size_MB = get_model_parameter_info(model)\n",
    "\n",
    "    if best_results:\n",
    "        best = best_results[0]\n",
    "        best_model_path = os.path.join(model_saving_folder, f\"{model_name}_best.pth\")\n",
    "        torch.save(best, best_model_path)\n",
    "        print(f\"\\nüèÜ Best model saved as: {best_model_path} (Val Accuracy: {best['val_accuracy'] * 100:.2f}%)\")\n",
    "\n",
    "    final_model_path = os.path.join(model_saving_folder, f\"{model_name}_final.pth\")\n",
    "    torch.save(current, final_model_path)\n",
    "    print(f\"\\nüìå Final model saved as: {final_model_path}\")\n",
    "\n",
    "    print(\"\\nüéØ Top 5 Best Models:\")\n",
    "    for res in best_results:\n",
    "        print(f\"Epoch {res['epoch']}, Train Loss: {res['train_loss']:.6f}, Train-Acc: {res['train_classwise_accuracy']},\\n\"\n",
    "              f\"Val Loss: {res['val_loss']:.6f}, Val Acc: {res['val_accuracy']*100:.2f}%, Val-Acc: {res['val_classwise_accuracy']},\"\n",
    "              f\" Model Path: {res['model_path']}\")\n",
    "\n",
    "    print(f\"\\nüß† Model Summary:\")\n",
    "    print(f\"Total Parameters: {total_params:,}\")\n",
    "    print(f\"Model Size (float32): {param_size_MB:.2f} MB\")\n",
    "    print(f\"Total Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "    # Markdown output\n",
    "    match = re.search(r'Period_(\\d+)', model_saving_folder)\n",
    "    period_label = match.group(1) if match else \"?\"\n",
    "    model_name_str = model.__class__.__name__\n",
    "\n",
    "    print(f\"\"\"\n",
    "---\n",
    "### Period {period_label}\n",
    "+ ##### Total training time: {training_time:.2f} seconds\n",
    "+ ##### Model: {model_name_str}\n",
    "+ ##### Training and saving in *'{model_saving_folder}'*\n",
    "+ ##### Best Epoch: {best['epoch']}\n",
    "#### __Val Accuracy: {best['val_accuracy'] * 100:.2f}%__\n",
    "#### __Val-Class-Acc: {best['val_classwise_accuracy']}__\n",
    "#### __Total Parameters: {total_params:,}__\n",
    "#### __Model Size (float32): {param_size_MB:.2f} MB__\n",
    "\"\"\".strip())\n",
    "\n",
    "    del X_train, y_train, X_val, y_val, train_loader, val_loader, current, outputs, predictions\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1085b2",
   "metadata": {},
   "source": [
    "## __Training__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8ee5f8",
   "metadata": {},
   "source": [
    "### Period 1 Summary\n",
    "+ **Epoch:** 63\n",
    "+ **Train Loss:** 0.0076635455248283595\n",
    "+ **Val Loss:** 0.800983331773592\n",
    "+ **Val Accuracy:** 88.86%\n",
    "+ **Learning Rate:** 0.0006561000000000001\n",
    "+ **Stored Model Path:** `Class_Incremental_CL/CPSC_CIL/ResNet18_Selection/ResNet18_big_inplane_v1/ResNet18_big_inplane_1D_epoch_63.pth`\n",
    "+ **Train-Class-Acc:** {0: '99.86%', 1: '99.59%'}\n",
    "+ **Val-Class-Acc:** {0: '91.85%', 1: '85.87%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c948b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Model Summary from: Class_Incremental_CL/CPSC_CIL/ResNet18_Selection/ResNet18_big_inplane_v1/ResNet18_big_inplane_1D_best.pth\n",
      "üìå Epoch: 63\n",
      "üßÆ Train Loss: 0.007664\n",
      "üéØ Val Loss: 0.800983\n",
      "‚úÖ Val Accuracy: 88.86%\n",
      "üìé Learning Rate: 0.0006561000000000001\n",
      "üìÅ Stored Model Path: Class_Incremental_CL/CPSC_CIL/ResNet18_Selection/ResNet18_big_inplane_v1/ResNet18_big_inplane_1D_epoch_63.pth\n",
      "üß† Total Parameters: 3,857,026\n",
      "üìè Model Size (float32): 14.71 MB\n",
      "\n",
      "üìä Train Class-wise Accuracy:\n",
      "  ‚îî‚îÄ Class 0 : 99.86%\n",
      "  ‚îî‚îÄ Class 1 : 99.59%\n",
      "\n",
      "üìä Val Class-wise Accuracy:\n",
      "  ‚îî‚îÄ Class 0 : 91.85%\n",
      "  ‚îî‚îÄ Class 1 : 85.87%\n",
      "\n",
      "---\n",
      "### Period 1 Summary (Markdown Format)\n",
      "+ **Epoch:** 63\n",
      "+ **Train Loss:** 0.0076635455248283595\n",
      "+ **Val Loss:** 0.800983331773592\n",
      "+ **Val Accuracy:** 88.86%\n",
      "+ **Learning Rate:** 0.0006561000000000001\n",
      "+ **Stored Model Path:** `Class_Incremental_CL/CPSC_CIL/ResNet18_Selection/ResNet18_big_inplane_v1/ResNet18_big_inplane_1D_epoch_63.pth`\n",
      "+ **Total Parameters:** 3,857,026\n",
      "+ **Model Size (float32):** 14.71 MB\n",
      "+ **Train-Class-Acc:** {0: '99.86%', 1: '99.59%'}\n",
      "+ **Val-Class-Acc:** {0: '91.85%', 1: '85.87%'}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_321925/3192502623.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "def display_model_summary_with_params(model_folder, model_filename=\"ResNet18_big_inplane_1D_best.pth\", input_channels=12, output_size=10):\n",
    "    model_path = os.path.join(model_folder, model_filename)\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå File not found: {model_path}\")\n",
    "        return\n",
    "\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "    # === ÈÇÑÂéüÊ®°Âûã‰∏¶ËºâÂÖ•ÂèÉÊï∏ ===\n",
    "    model = ResNet18_1D(input_channels=input_channels, output_size=output_size)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    total_params, param_size_MB = get_model_parameter_info(model)\n",
    "\n",
    "    # === È°ØÁ§∫ÊëòË¶Å ===\n",
    "    epoch = checkpoint.get(\"epoch\", \"?\")\n",
    "    train_loss = checkpoint.get(\"train_loss\", \"?\")\n",
    "    val_loss = checkpoint.get(\"val_loss\", \"?\")\n",
    "    val_acc = checkpoint.get(\"val_accuracy\", \"?\")\n",
    "    train_acc_dict = checkpoint.get(\"train_classwise_accuracy\", {})\n",
    "    val_acc_dict = checkpoint.get(\"val_classwise_accuracy\", {})\n",
    "    lr = checkpoint.get(\"learning_rate\", \"?\")\n",
    "    stored_path = checkpoint.get(\"model_path\", \"N/A\")\n",
    "\n",
    "    print(f\"\\nüì¶ Model Summary from: {model_path}\")\n",
    "    print(f\"üìå Epoch: {epoch}\")\n",
    "    print(f\"üßÆ Train Loss: {train_loss:.6f}\" if isinstance(train_loss, float) else f\"üßÆ Train Loss: {train_loss}\")\n",
    "    print(f\"üéØ Val Loss: {val_loss:.6f}\" if isinstance(val_loss, float) else f\"üéØ Val Loss: {val_loss}\")\n",
    "    print(f\"‚úÖ Val Accuracy: {val_acc*100:.2f}%\" if isinstance(val_acc, float) else f\"‚úÖ Val Accuracy: {val_acc}\")\n",
    "    print(f\"üìé Learning Rate: {lr}\")\n",
    "    print(f\"üìÅ Stored Model Path: {stored_path}\")\n",
    "    print(f\"üß† Total Parameters: {total_params:,}\")\n",
    "    print(f\"üìè Model Size (float32): {param_size_MB:.2f} MB\")\n",
    "\n",
    "    print(\"\\nüìä Train Class-wise Accuracy:\")\n",
    "    for c, acc in train_acc_dict.items():\n",
    "        print(f\"  ‚îî‚îÄ Class {c:<2}: {acc}\")\n",
    "\n",
    "    print(\"\\nüìä Val Class-wise Accuracy:\")\n",
    "    for c, acc in val_acc_dict.items():\n",
    "        print(f\"  ‚îî‚îÄ Class {c:<2}: {acc}\")\n",
    "\n",
    "    print(\"\\n---\\n### Period 1 Summary (Markdown Format)\")\n",
    "    print(f\"+ **Epoch:** {epoch}\")\n",
    "    print(f\"+ **Train Loss:** {train_loss}\")\n",
    "    print(f\"+ **Val Loss:** {val_loss}\")\n",
    "    print(f\"+ **Val Accuracy:** {val_acc*100:.2f}%\" if isinstance(val_acc, float) else f\"+ **Val Accuracy:** {val_acc}\")\n",
    "    print(f\"+ **Learning Rate:** {lr}\")\n",
    "    print(f\"+ **Stored Model Path:** `{stored_path}`\")\n",
    "    print(f\"+ **Total Parameters:** {total_params:,}\")\n",
    "    print(f\"+ **Model Size (float32):** {param_size_MB:.2f} MB\")\n",
    "    print(f\"+ **Train-Class-Acc:** {train_acc_dict}\")\n",
    "    print(f\"+ **Val-Class-Acc:** {val_acc_dict}\")\n",
    "    print(\"---\")\n",
    "\n",
    "# Example call:\n",
    "display_model_summary_with_params(\n",
    "    model_folder=os.path.join(\"Class_Incremental_CL\", \"CPSC_CIL\", \"ResNet18_Selection\", \"ResNet18_big_inplane_v1\"),\n",
    "    input_channels=12,\n",
    "    output_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e2f418",
   "metadata": {},
   "source": [
    "### Period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f583d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Automatically selected GPU:\n",
      "    - CUDA Device ID : 2\n",
      "    - Memory Used    : 18 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "‚úÖ Loaded Period 1 weights (except FC mismatch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_321925/3757884289.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  prev_checkpoint = torch.load(prev_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Fisher information computed from Period 1\n",
      "\n",
      "üöÄ 'train_with_ewc_ecg' started.\n",
      "‚úÖ Removed existing folder: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2\n",
      "\n",
      "‚úÖ Data Overview:\n",
      "X_train: torch.Size([3263, 5000, 12]), y_train: torch.Size([3263])\n",
      "X_val: torch.Size([816, 5000, 12]), y_val: torch.Size([816])\n",
      "Epoch 1/200, Train Loss: 1.063499, Train-Class-Acc: {0: '75.61%', 1: '58.20%', 2: '61.87%', 3: '70.49%'}\n",
      "Val Loss: 0.526914, Val Acc: 81.62%, Val-Class-Acc: {0: '68.48%', 1: '89.34%', 2: '77.08%', 3: '86.48%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.515939, Train-Class-Acc: {0: '78.34%', 1: '73.57%', 2: '83.88%', 3: '89.75%'}\n",
      "Val Loss: 0.437184, Val Acc: 82.72%, Val-Class-Acc: {0: '75.54%', 1: '83.61%', 2: '86.11%', 3: '85.25%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.429473, Train-Class-Acc: {0: '83.24%', 1: '78.18%', 2: '88.04%', 3: '91.60%'}\n",
      "Val Loss: 0.430890, Val Acc: 81.86%, Val-Class-Acc: {0: '59.78%', 1: '84.43%', 2: '88.19%', 3: '92.21%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.393702, Train-Class-Acc: {0: '84.20%', 1: '81.15%', 2: '87.18%', 3: '92.42%'}\n",
      "Val Loss: 0.371012, Val Acc: 87.50%, Val-Class-Acc: {0: '90.76%', 1: '77.87%', 2: '86.11%', 3: '95.49%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.342323, Train-Class-Acc: {0: '85.15%', 1: '83.09%', 2: '88.39%', 3: '94.16%'}\n",
      "Val Loss: 0.386236, Val Acc: 87.75%, Val-Class-Acc: {0: '83.70%', 1: '81.15%', 2: '89.58%', 3: '96.31%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.331913, Train-Class-Acc: {0: '87.60%', 1: '82.99%', 2: '90.99%', 3: '93.65%'}\n",
      "Val Loss: 0.462193, Val Acc: 84.80%, Val-Class-Acc: {0: '94.02%', 1: '67.21%', 2: '81.94%', 3: '97.13%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_1.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_6.pth\n",
      "Epoch 7/200, Train Loss: 0.307860, Train-Class-Acc: {0: '85.56%', 1: '84.84%', 2: '91.16%', 3: '94.98%'}\n",
      "Val Loss: 0.414755, Val Acc: 85.05%, Val-Class-Acc: {0: '90.76%', 1: '67.21%', 2: '94.44%', 3: '93.03%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_3.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.282414, Train-Class-Acc: {0: '87.60%', 1: '86.37%', 2: '90.81%', 3: '95.49%'}\n",
      "Val Loss: 0.412467, Val Acc: 85.78%, Val-Class-Acc: {0: '75.00%', 1: '84.43%', 2: '89.58%', 3: '93.03%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_2.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_8.pth\n",
      "Epoch 9/200, Train Loss: 0.268671, Train-Class-Acc: {0: '90.33%', 1: '86.89%', 2: '91.33%', 3: '94.47%'}\n",
      "Val Loss: 0.407960, Val Acc: 86.64%, Val-Class-Acc: {0: '88.04%', 1: '75.82%', 2: '87.50%', 3: '95.90%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_6.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.238604, Train-Class-Acc: {0: '89.51%', 1: '86.58%', 2: '92.55%', 3: '95.70%'}\n",
      "Val Loss: 0.520245, Val Acc: 84.19%, Val-Class-Acc: {0: '77.17%', 1: '79.92%', 2: '79.17%', 3: '96.72%'}, LR: 0.001000\n",
      "Epoch 11/200, Train Loss: 0.215114, Train-Class-Acc: {0: '89.92%', 1: '88.83%', 2: '93.93%', 3: '96.82%'}\n",
      "Val Loss: 0.380153, Val Acc: 87.87%, Val-Class-Acc: {0: '91.85%', 1: '78.28%', 2: '84.03%', 3: '96.72%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_7.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_11.pth\n",
      "Epoch 12/200, Train Loss: 0.196858, Train-Class-Acc: {0: '91.01%', 1: '90.88%', 2: '94.11%', 3: '97.64%'}\n",
      "Val Loss: 0.457537, Val Acc: 87.50%, Val-Class-Acc: {0: '86.96%', 1: '83.61%', 2: '80.56%', 3: '95.90%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_8.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_12.pth\n",
      "Epoch 13/200, Train Loss: 0.207852, Train-Class-Acc: {0: '92.10%', 1: '88.32%', 2: '93.24%', 3: '96.52%'}\n",
      "Val Loss: 0.482368, Val Acc: 87.38%, Val-Class-Acc: {0: '90.76%', 1: '70.08%', 2: '93.06%', 3: '98.77%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_9.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_13.pth\n",
      "Epoch 14/200, Train Loss: 0.199862, Train-Class-Acc: {0: '91.28%', 1: '90.27%', 2: '94.45%', 3: '97.23%'}\n",
      "Val Loss: 0.444246, Val Acc: 86.89%, Val-Class-Acc: {0: '90.76%', 1: '79.10%', 2: '81.25%', 3: '95.08%'}, LR: 0.001000\n",
      "Epoch 15/200, Train Loss: 0.145653, Train-Class-Acc: {0: '93.87%', 1: '93.44%', 2: '95.84%', 3: '97.75%'}\n",
      "Val Loss: 0.461164, Val Acc: 87.13%, Val-Class-Acc: {0: '79.89%', 1: '90.16%', 2: '81.25%', 3: '93.03%'}, LR: 0.001000\n",
      "Epoch 16/200, Train Loss: 0.125633, Train-Class-Acc: {0: '93.73%', 1: '93.44%', 2: '97.05%', 3: '97.95%'}\n",
      "Val Loss: 0.423882, Val Acc: 86.89%, Val-Class-Acc: {0: '74.46%', 1: '87.70%', 2: '86.81%', 3: '95.49%'}, LR: 0.000900\n",
      "Epoch 17/200, Train Loss: 0.149446, Train-Class-Acc: {0: '93.87%', 1: '93.03%', 2: '96.53%', 3: '97.23%'}\n",
      "Val Loss: 0.475525, Val Acc: 87.75%, Val-Class-Acc: {0: '78.80%', 1: '84.84%', 2: '91.67%', 3: '95.08%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_13.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_17.pth\n",
      "Epoch 18/200, Train Loss: 0.100774, Train-Class-Acc: {0: '96.59%', 1: '95.70%', 2: '97.40%', 3: '98.77%'}\n",
      "Val Loss: 0.532463, Val Acc: 85.29%, Val-Class-Acc: {0: '77.72%', 1: '84.84%', 2: '91.67%', 3: '87.70%'}, LR: 0.000900\n",
      "Epoch 19/200, Train Loss: 0.089417, Train-Class-Acc: {0: '96.32%', 1: '96.62%', 2: '97.23%', 3: '98.16%'}\n",
      "Val Loss: 0.441256, Val Acc: 88.36%, Val-Class-Acc: {0: '95.65%', 1: '78.28%', 2: '85.42%', 3: '94.67%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_4.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_19.pth\n",
      "Epoch 20/200, Train Loss: 0.074224, Train-Class-Acc: {0: '96.73%', 1: '96.82%', 2: '98.09%', 3: '99.08%'}\n",
      "Val Loss: 0.553094, Val Acc: 85.54%, Val-Class-Acc: {0: '67.39%', 1: '88.11%', 2: '86.81%', 3: '95.90%'}, LR: 0.000900\n",
      "Epoch 21/200, Train Loss: 0.058666, Train-Class-Acc: {0: '98.37%', 1: '97.44%', 2: '98.79%', 3: '99.08%'}\n",
      "Val Loss: 0.574494, Val Acc: 86.40%, Val-Class-Acc: {0: '89.13%', 1: '77.87%', 2: '78.47%', 3: '97.54%'}, LR: 0.000900\n",
      "Epoch 22/200, Train Loss: 0.065814, Train-Class-Acc: {0: '97.00%', 1: '97.54%', 2: '98.44%', 3: '99.08%'}\n",
      "Val Loss: 0.589748, Val Acc: 87.62%, Val-Class-Acc: {0: '90.76%', 1: '75.82%', 2: '86.11%', 3: '97.95%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_12.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_22.pth\n",
      "Epoch 23/200, Train Loss: 0.076662, Train-Class-Acc: {0: '96.05%', 1: '96.82%', 2: '98.96%', 3: '98.87%'}\n",
      "Val Loss: 0.622536, Val Acc: 84.56%, Val-Class-Acc: {0: '76.63%', 1: '76.64%', 2: '90.28%', 3: '95.08%'}, LR: 0.000900\n",
      "Epoch 24/200, Train Loss: 0.096832, Train-Class-Acc: {0: '94.69%', 1: '95.59%', 2: '97.23%', 3: '98.77%'}\n",
      "Val Loss: 0.502618, Val Acc: 86.64%, Val-Class-Acc: {0: '83.15%', 1: '79.51%', 2: '90.28%', 3: '94.26%'}, LR: 0.000900\n",
      "Epoch 25/200, Train Loss: 0.078489, Train-Class-Acc: {0: '97.28%', 1: '96.72%', 2: '97.05%', 3: '98.98%'}\n",
      "Val Loss: 0.636479, Val Acc: 85.05%, Val-Class-Acc: {0: '71.74%', 1: '81.56%', 2: '93.75%', 3: '93.44%'}, LR: 0.000900\n",
      "Epoch 26/200, Train Loss: 0.108299, Train-Class-Acc: {0: '95.91%', 1: '94.26%', 2: '96.88%', 3: '98.67%'}\n",
      "Val Loss: 0.610741, Val Acc: 85.66%, Val-Class-Acc: {0: '82.07%', 1: '80.33%', 2: '81.94%', 3: '95.90%'}, LR: 0.000900\n",
      "Epoch 27/200, Train Loss: 0.050061, Train-Class-Acc: {0: '98.64%', 1: '98.77%', 2: '98.79%', 3: '99.08%'}\n",
      "Val Loss: 0.550673, Val Acc: 87.38%, Val-Class-Acc: {0: '89.13%', 1: '81.97%', 2: '82.64%', 3: '94.26%'}, LR: 0.000810\n",
      "Epoch 28/200, Train Loss: 0.033203, Train-Class-Acc: {0: '99.18%', 1: '98.67%', 2: '98.96%', 3: '99.59%'}\n",
      "Val Loss: 0.645691, Val Acc: 86.27%, Val-Class-Acc: {0: '76.63%', 1: '89.34%', 2: '81.25%', 3: '93.44%'}, LR: 0.000810\n",
      "Epoch 29/200, Train Loss: 0.023908, Train-Class-Acc: {0: '99.86%', 1: '99.18%', 2: '99.48%', 3: '100.00%'}\n",
      "Val Loss: 0.574753, Val Acc: 87.25%, Val-Class-Acc: {0: '90.76%', 1: '77.87%', 2: '86.81%', 3: '94.26%'}, LR: 0.000810\n",
      "Epoch 30/200, Train Loss: 0.022416, Train-Class-Acc: {0: '99.86%', 1: '99.49%', 2: '99.48%', 3: '99.69%'}\n",
      "Val Loss: 0.620214, Val Acc: 88.60%, Val-Class-Acc: {0: '89.13%', 1: '80.33%', 2: '88.89%', 3: '96.31%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_22.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_30.pth\n",
      "Epoch 31/200, Train Loss: 0.011735, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '99.83%', 3: '100.00%'}\n",
      "Val Loss: 0.596732, Val Acc: 87.62%, Val-Class-Acc: {0: '84.24%', 1: '83.20%', 2: '85.42%', 3: '95.90%'}, LR: 0.000810\n",
      "Epoch 32/200, Train Loss: 0.021776, Train-Class-Acc: {0: '99.46%', 1: '98.87%', 2: '100.00%', 3: '99.90%'}\n",
      "Val Loss: 0.595456, Val Acc: 88.48%, Val-Class-Acc: {0: '82.61%', 1: '85.25%', 2: '90.28%', 3: '95.08%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_5.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_32.pth\n",
      "Epoch 33/200, Train Loss: 0.072915, Train-Class-Acc: {0: '96.32%', 1: '96.72%', 2: '99.31%', 3: '99.18%'}\n",
      "Val Loss: 0.714563, Val Acc: 86.89%, Val-Class-Acc: {0: '92.93%', 1: '75.41%', 2: '86.11%', 3: '94.26%'}, LR: 0.000810\n",
      "Epoch 34/200, Train Loss: 0.071351, Train-Class-Acc: {0: '96.59%', 1: '96.82%', 2: '99.48%', 3: '99.59%'}\n",
      "Val Loss: 0.536654, Val Acc: 86.52%, Val-Class-Acc: {0: '92.93%', 1: '77.87%', 2: '86.81%', 3: '90.16%'}, LR: 0.000810\n",
      "Epoch 35/200, Train Loss: 0.031058, Train-Class-Acc: {0: '99.05%', 1: '99.08%', 2: '99.31%', 3: '99.49%'}\n",
      "Val Loss: 0.685696, Val Acc: 86.64%, Val-Class-Acc: {0: '84.78%', 1: '74.18%', 2: '91.67%', 3: '97.54%'}, LR: 0.000810\n",
      "Epoch 36/200, Train Loss: 0.046931, Train-Class-Acc: {0: '98.09%', 1: '98.87%', 2: '98.27%', 3: '99.69%'}\n",
      "Val Loss: 0.609549, Val Acc: 86.89%, Val-Class-Acc: {0: '86.96%', 1: '76.64%', 2: '87.50%', 3: '96.72%'}, LR: 0.000810\n",
      "Epoch 37/200, Train Loss: 0.039707, Train-Class-Acc: {0: '98.64%', 1: '98.67%', 2: '99.13%', 3: '99.69%'}\n",
      "Val Loss: 0.654985, Val Acc: 86.52%, Val-Class-Acc: {0: '91.85%', 1: '70.90%', 2: '90.97%', 3: '95.49%'}, LR: 0.000810\n",
      "Epoch 38/200, Train Loss: 0.029712, Train-Class-Acc: {0: '99.59%', 1: '98.77%', 2: '99.48%', 3: '99.80%'}\n",
      "Val Loss: 0.787314, Val Acc: 83.70%, Val-Class-Acc: {0: '65.76%', 1: '88.52%', 2: '88.19%', 3: '89.75%'}, LR: 0.000729\n",
      "Epoch 39/200, Train Loss: 0.040338, Train-Class-Acc: {0: '98.64%', 1: '98.67%', 2: '98.61%', 3: '99.18%'}\n",
      "Val Loss: 0.720068, Val Acc: 85.78%, Val-Class-Acc: {0: '83.70%', 1: '77.05%', 2: '90.97%', 3: '93.03%'}, LR: 0.000729\n",
      "Epoch 40/200, Train Loss: 0.030176, Train-Class-Acc: {0: '99.18%', 1: '98.98%', 2: '99.48%', 3: '99.69%'}\n",
      "Val Loss: 0.642460, Val Acc: 86.76%, Val-Class-Acc: {0: '88.59%', 1: '78.28%', 2: '86.11%', 3: '94.26%'}, LR: 0.000729\n",
      "Epoch 41/200, Train Loss: 0.020570, Train-Class-Acc: {0: '99.73%', 1: '99.39%', 2: '99.48%', 3: '100.00%'}\n",
      "Val Loss: 0.647271, Val Acc: 87.25%, Val-Class-Acc: {0: '78.26%', 1: '83.61%', 2: '90.28%', 3: '95.90%'}, LR: 0.000729\n",
      "Epoch 42/200, Train Loss: 0.019407, Train-Class-Acc: {0: '99.46%', 1: '99.39%', 2: '99.83%', 3: '100.00%'}\n",
      "Val Loss: 0.655708, Val Acc: 87.13%, Val-Class-Acc: {0: '84.78%', 1: '83.20%', 2: '84.72%', 3: '94.26%'}, LR: 0.000729\n",
      "Epoch 43/200, Train Loss: 0.030490, Train-Class-Acc: {0: '98.37%', 1: '99.08%', 2: '100.00%', 3: '99.90%'}\n",
      "Val Loss: 0.667755, Val Acc: 87.01%, Val-Class-Acc: {0: '77.17%', 1: '85.66%', 2: '90.28%', 3: '93.85%'}, LR: 0.000729\n",
      "Epoch 44/200, Train Loss: 0.023345, Train-Class-Acc: {0: '99.18%', 1: '98.98%', 2: '99.83%', 3: '99.90%'}\n",
      "Val Loss: 0.654107, Val Acc: 87.50%, Val-Class-Acc: {0: '91.85%', 1: '79.92%', 2: '82.64%', 3: '94.67%'}, LR: 0.000729\n",
      "Epoch 45/200, Train Loss: 0.011288, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.633116, Val Acc: 86.76%, Val-Class-Acc: {0: '80.98%', 1: '81.56%', 2: '89.58%', 3: '94.67%'}, LR: 0.000729\n",
      "Epoch 46/200, Train Loss: 0.012515, Train-Class-Acc: {0: '99.73%', 1: '99.80%', 2: '99.83%', 3: '100.00%'}\n",
      "Val Loss: 0.726673, Val Acc: 87.13%, Val-Class-Acc: {0: '88.59%', 1: '78.28%', 2: '88.19%', 3: '94.26%'}, LR: 0.000729\n",
      "Epoch 47/200, Train Loss: 0.019167, Train-Class-Acc: {0: '99.73%', 1: '99.69%', 2: '99.31%', 3: '99.59%'}\n",
      "Val Loss: 0.697948, Val Acc: 85.78%, Val-Class-Acc: {0: '81.52%', 1: '84.43%', 2: '87.50%', 3: '89.34%'}, LR: 0.000729\n",
      "Epoch 48/200, Train Loss: 0.039060, Train-Class-Acc: {0: '98.91%', 1: '98.98%', 2: '99.13%', 3: '99.18%'}\n",
      "Val Loss: 0.775050, Val Acc: 86.27%, Val-Class-Acc: {0: '89.67%', 1: '79.10%', 2: '80.56%', 3: '94.26%'}, LR: 0.000729\n",
      "Epoch 49/200, Train Loss: 0.041665, Train-Class-Acc: {0: '98.64%', 1: '99.18%', 2: '98.44%', 3: '99.39%'}\n",
      "Val Loss: 0.710914, Val Acc: 86.27%, Val-Class-Acc: {0: '85.87%', 1: '79.51%', 2: '87.50%', 3: '92.62%'}, LR: 0.000656\n",
      "Epoch 50/200, Train Loss: 0.057924, Train-Class-Acc: {0: '98.64%', 1: '97.54%', 2: '97.75%', 3: '99.18%'}\n",
      "Val Loss: 0.732223, Val Acc: 86.76%, Val-Class-Acc: {0: '90.76%', 1: '73.77%', 2: '90.97%', 3: '94.26%'}, LR: 0.000656\n",
      "Epoch 51/200, Train Loss: 0.051013, Train-Class-Acc: {0: '98.09%', 1: '97.95%', 2: '98.44%', 3: '99.08%'}\n",
      "Val Loss: 0.801635, Val Acc: 84.80%, Val-Class-Acc: {0: '69.02%', 1: '84.43%', 2: '87.50%', 3: '95.49%'}, LR: 0.000656\n",
      "Epoch 52/200, Train Loss: 0.060228, Train-Class-Acc: {0: '97.55%', 1: '97.85%', 2: '98.61%', 3: '98.98%'}\n",
      "Val Loss: 0.665272, Val Acc: 86.03%, Val-Class-Acc: {0: '85.33%', 1: '81.56%', 2: '80.56%', 3: '94.26%'}, LR: 0.000656\n",
      "Epoch 53/200, Train Loss: 0.051462, Train-Class-Acc: {0: '98.09%', 1: '98.36%', 2: '97.92%', 3: '99.08%'}\n",
      "Val Loss: 0.611675, Val Acc: 86.27%, Val-Class-Acc: {0: '84.24%', 1: '79.92%', 2: '89.58%', 3: '92.21%'}, LR: 0.000656\n",
      "Epoch 54/200, Train Loss: 0.030894, Train-Class-Acc: {0: '99.18%', 1: '99.08%', 2: '99.31%', 3: '99.90%'}\n",
      "Val Loss: 0.661435, Val Acc: 87.62%, Val-Class-Acc: {0: '91.30%', 1: '77.05%', 2: '88.19%', 3: '95.08%'}, LR: 0.000656\n",
      "Epoch 55/200, Train Loss: 0.024200, Train-Class-Acc: {0: '99.18%', 1: '99.18%', 2: '99.65%', 3: '100.00%'}\n",
      "Val Loss: 0.607970, Val Acc: 86.40%, Val-Class-Acc: {0: '79.89%', 1: '83.61%', 2: '84.72%', 3: '95.08%'}, LR: 0.000656\n",
      "Epoch 56/200, Train Loss: 0.022024, Train-Class-Acc: {0: '99.46%', 1: '99.39%', 2: '99.48%', 3: '99.80%'}\n",
      "Val Loss: 0.628500, Val Acc: 86.89%, Val-Class-Acc: {0: '80.43%', 1: '83.20%', 2: '89.58%', 3: '93.85%'}, LR: 0.000656\n",
      "Epoch 57/200, Train Loss: 0.013252, Train-Class-Acc: {0: '99.73%', 1: '100.00%', 2: '100.00%', 3: '99.90%'}\n",
      "Val Loss: 0.686270, Val Acc: 88.36%, Val-Class-Acc: {0: '90.22%', 1: '79.92%', 2: '88.19%', 3: '95.49%'}, LR: 0.000656\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_17.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_57.pth\n",
      "Epoch 58/200, Train Loss: 0.009846, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.667993, Val Acc: 87.99%, Val-Class-Acc: {0: '86.41%', 1: '82.79%', 2: '87.50%', 3: '94.67%'}, LR: 0.000656\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_11.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_58.pth\n",
      "Epoch 59/200, Train Loss: 0.008959, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.666198, Val Acc: 87.75%, Val-Class-Acc: {0: '84.78%', 1: '82.38%', 2: '87.50%', 3: '95.49%'}, LR: 0.000656\n",
      "Epoch 60/200, Train Loss: 0.008328, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.687186, Val Acc: 87.99%, Val-Class-Acc: {0: '88.04%', 1: '82.38%', 2: '84.72%', 3: '95.49%'}, LR: 0.000590\n",
      "Epoch 61/200, Train Loss: 0.007929, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.690402, Val Acc: 88.11%, Val-Class-Acc: {0: '88.04%', 1: '82.38%', 2: '84.72%', 3: '95.90%'}, LR: 0.000590\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_58.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_61.pth\n",
      "Epoch 62/200, Train Loss: 0.007974, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.679511, Val Acc: 87.99%, Val-Class-Acc: {0: '87.50%', 1: '82.38%', 2: '84.72%', 3: '95.90%'}, LR: 0.000590\n",
      "Epoch 63/200, Train Loss: 0.007591, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.673922, Val Acc: 88.36%, Val-Class-Acc: {0: '89.67%', 1: '82.38%', 2: '84.72%', 3: '95.49%'}, LR: 0.000590\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_61.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_63.pth\n",
      "Epoch 64/200, Train Loss: 0.007427, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.674502, Val Acc: 88.11%, Val-Class-Acc: {0: '86.41%', 1: '82.79%', 2: '86.81%', 3: '95.49%'}, LR: 0.000590\n",
      "Epoch 65/200, Train Loss: 0.007305, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.684664, Val Acc: 88.24%, Val-Class-Acc: {0: '89.13%', 1: '81.97%', 2: '84.72%', 3: '95.90%'}, LR: 0.000590\n",
      "Epoch 66/200, Train Loss: 0.007206, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.688255, Val Acc: 88.36%, Val-Class-Acc: {0: '89.13%', 1: '81.97%', 2: '85.42%', 3: '95.90%'}, LR: 0.000590\n",
      "Epoch 67/200, Train Loss: 0.007151, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.687433, Val Acc: 87.75%, Val-Class-Acc: {0: '87.50%', 1: '81.97%', 2: '84.72%', 3: '95.49%'}, LR: 0.000590\n",
      "Epoch 68/200, Train Loss: 0.007226, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.724635, Val Acc: 88.11%, Val-Class-Acc: {0: '89.67%', 1: '81.15%', 2: '84.72%', 3: '95.90%'}, LR: 0.000590\n",
      "Epoch 69/200, Train Loss: 0.007165, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.738472, Val Acc: 88.24%, Val-Class-Acc: {0: '92.39%', 1: '79.92%', 2: '84.72%', 3: '95.49%'}, LR: 0.000590\n",
      "Epoch 70/200, Train Loss: 0.006754, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.708459, Val Acc: 88.11%, Val-Class-Acc: {0: '88.59%', 1: '82.38%', 2: '84.72%', 3: '95.49%'}, LR: 0.000590\n",
      "Epoch 71/200, Train Loss: 0.006704, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.717101, Val Acc: 88.60%, Val-Class-Acc: {0: '91.30%', 1: '81.97%', 2: '84.72%', 3: '95.49%'}, LR: 0.000531\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_19.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_71.pth\n",
      "Epoch 72/200, Train Loss: 0.006650, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.709724, Val Acc: 88.24%, Val-Class-Acc: {0: '88.04%', 1: '83.20%', 2: '84.72%', 3: '95.49%'}, LR: 0.000531\n",
      "Epoch 73/200, Train Loss: 0.006499, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.703504, Val Acc: 88.60%, Val-Class-Acc: {0: '89.67%', 1: '83.20%', 2: '84.72%', 3: '95.49%'}, LR: 0.000531\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_57.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_73.pth\n",
      "Epoch 74/200, Train Loss: 0.006436, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.724218, Val Acc: 88.11%, Val-Class-Acc: {0: '90.22%', 1: '81.15%', 2: '84.72%', 3: '95.49%'}, LR: 0.000531\n",
      "Epoch 75/200, Train Loss: 0.006386, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.712949, Val Acc: 87.87%, Val-Class-Acc: {0: '86.41%', 1: '82.79%', 2: '85.42%', 3: '95.49%'}, LR: 0.000531\n",
      "Epoch 76/200, Train Loss: 0.006290, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.729605, Val Acc: 88.48%, Val-Class-Acc: {0: '90.22%', 1: '81.97%', 2: '85.42%', 3: '95.49%'}, LR: 0.000531\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_63.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_76.pth\n",
      "Epoch 77/200, Train Loss: 0.006164, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.726742, Val Acc: 87.62%, Val-Class-Acc: {0: '85.87%', 1: '82.38%', 2: '85.42%', 3: '95.49%'}, LR: 0.000531\n",
      "Epoch 78/200, Train Loss: 0.006119, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.722392, Val Acc: 87.38%, Val-Class-Acc: {0: '84.78%', 1: '81.97%', 2: '86.11%', 3: '95.49%'}, LR: 0.000531\n",
      "Epoch 79/200, Train Loss: 0.006099, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.730975, Val Acc: 88.60%, Val-Class-Acc: {0: '91.85%', 1: '81.56%', 2: '85.42%', 3: '95.08%'}, LR: 0.000531\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_32.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_79.pth\n",
      "Epoch 80/200, Train Loss: 0.005935, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.734964, Val Acc: 88.48%, Val-Class-Acc: {0: '90.76%', 1: '81.97%', 2: '84.72%', 3: '95.49%'}, LR: 0.000531\n",
      "Epoch 81/200, Train Loss: 0.005849, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.732212, Val Acc: 88.24%, Val-Class-Acc: {0: '89.67%', 1: '81.97%', 2: '84.72%', 3: '95.49%'}, LR: 0.000531\n",
      "Epoch 82/200, Train Loss: 0.005778, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.734119, Val Acc: 88.24%, Val-Class-Acc: {0: '89.13%', 1: '82.38%', 2: '84.72%', 3: '95.49%'}, LR: 0.000478\n",
      "Epoch 83/200, Train Loss: 0.005707, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.731666, Val Acc: 88.60%, Val-Class-Acc: {0: '90.76%', 1: '81.97%', 2: '85.42%', 3: '95.49%'}, LR: 0.000478\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_76.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_83.pth\n",
      "Epoch 84/200, Train Loss: 0.005631, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.727018, Val Acc: 88.48%, Val-Class-Acc: {0: '90.22%', 1: '81.97%', 2: '85.42%', 3: '95.49%'}, LR: 0.000478\n",
      "Epoch 85/200, Train Loss: 0.005560, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.745489, Val Acc: 88.48%, Val-Class-Acc: {0: '91.30%', 1: '81.56%', 2: '84.72%', 3: '95.49%'}, LR: 0.000478\n",
      "Epoch 86/200, Train Loss: 0.005497, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.736343, Val Acc: 88.36%, Val-Class-Acc: {0: '89.67%', 1: '82.38%', 2: '84.72%', 3: '95.49%'}, LR: 0.000478\n",
      "Epoch 87/200, Train Loss: 0.005449, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.753168, Val Acc: 88.73%, Val-Class-Acc: {0: '92.39%', 1: '81.56%', 2: '84.72%', 3: '95.49%'}, LR: 0.000478\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_30.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_87.pth\n",
      "Epoch 88/200, Train Loss: 0.005384, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.758584, Val Acc: 87.87%, Val-Class-Acc: {0: '88.59%', 1: '81.56%', 2: '84.72%', 3: '95.49%'}, LR: 0.000478\n",
      "Epoch 89/200, Train Loss: 0.005319, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.754497, Val Acc: 88.36%, Val-Class-Acc: {0: '89.13%', 1: '82.79%', 2: '84.72%', 3: '95.49%'}, LR: 0.000478\n",
      "Epoch 90/200, Train Loss: 0.005292, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.762392, Val Acc: 88.11%, Val-Class-Acc: {0: '90.76%', 1: '80.74%', 2: '84.72%', 3: '95.49%'}, LR: 0.000478\n",
      "Epoch 91/200, Train Loss: 0.005225, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.736993, Val Acc: 87.99%, Val-Class-Acc: {0: '89.13%', 1: '81.56%', 2: '86.11%', 3: '94.67%'}, LR: 0.000478\n",
      "Epoch 92/200, Train Loss: 0.005142, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.736684, Val Acc: 87.87%, Val-Class-Acc: {0: '89.13%', 1: '81.15%', 2: '85.42%', 3: '95.08%'}, LR: 0.000478\n",
      "Epoch 93/200, Train Loss: 0.005083, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.747855, Val Acc: 88.36%, Val-Class-Acc: {0: '90.22%', 1: '81.97%', 2: '85.42%', 3: '95.08%'}, LR: 0.000430\n",
      "Epoch 94/200, Train Loss: 0.005084, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.767534, Val Acc: 88.24%, Val-Class-Acc: {0: '88.59%', 1: '82.79%', 2: '84.72%', 3: '95.49%'}, LR: 0.000430\n",
      "Epoch 95/200, Train Loss: 0.005100, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.805332, Val Acc: 87.75%, Val-Class-Acc: {0: '88.04%', 1: '81.97%', 2: '83.33%', 3: '95.90%'}, LR: 0.000430\n",
      "Epoch 96/200, Train Loss: 0.060214, Train-Class-Acc: {0: '98.23%', 1: '98.36%', 2: '97.05%', 3: '99.18%'}\n",
      "Val Loss: 1.077683, Val Acc: 83.46%, Val-Class-Acc: {0: '63.59%', 1: '81.97%', 2: '87.50%', 3: '97.54%'}, LR: 0.000430\n",
      "Epoch 97/200, Train Loss: 0.326383, Train-Class-Acc: {0: '89.51%', 1: '88.63%', 2: '93.24%', 3: '95.29%'}\n",
      "Val Loss: 0.523503, Val Acc: 85.54%, Val-Class-Acc: {0: '84.78%', 1: '78.28%', 2: '90.97%', 3: '90.16%'}, LR: 0.000430\n",
      "Epoch 98/200, Train Loss: 0.092010, Train-Class-Acc: {0: '97.82%', 1: '96.21%', 2: '97.05%', 3: '98.36%'}\n",
      "Val Loss: 0.576339, Val Acc: 84.93%, Val-Class-Acc: {0: '80.98%', 1: '86.07%', 2: '83.33%', 3: '87.70%'}, LR: 0.000430\n",
      "Epoch 99/200, Train Loss: 0.043579, Train-Class-Acc: {0: '99.18%', 1: '98.36%', 2: '98.79%', 3: '99.59%'}\n",
      "Val Loss: 0.716763, Val Acc: 85.29%, Val-Class-Acc: {0: '77.72%', 1: '82.38%', 2: '83.33%', 3: '95.08%'}, LR: 0.000430\n",
      "Epoch 100/200, Train Loss: 0.021417, Train-Class-Acc: {0: '99.46%', 1: '99.59%', 2: '99.65%', 3: '99.90%'}\n",
      "Val Loss: 0.629400, Val Acc: 87.13%, Val-Class-Acc: {0: '85.87%', 1: '82.79%', 2: '81.94%', 3: '95.49%'}, LR: 0.000430\n",
      "Epoch 101/200, Train Loss: 0.014302, Train-Class-Acc: {0: '99.73%', 1: '99.80%', 2: '99.83%', 3: '100.00%'}\n",
      "Val Loss: 0.638824, Val Acc: 88.11%, Val-Class-Acc: {0: '87.50%', 1: '82.38%', 2: '86.11%', 3: '95.49%'}, LR: 0.000430\n",
      "Epoch 102/200, Train Loss: 0.009846, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.661961, Val Acc: 88.11%, Val-Class-Acc: {0: '88.59%', 1: '81.97%', 2: '84.72%', 3: '95.90%'}, LR: 0.000430\n",
      "Epoch 103/200, Train Loss: 0.011144, Train-Class-Acc: {0: '99.86%', 1: '99.90%', 2: '100.00%', 3: '99.90%'}\n",
      "Val Loss: 0.679977, Val Acc: 88.11%, Val-Class-Acc: {0: '89.13%', 1: '80.74%', 2: '88.19%', 3: '94.67%'}, LR: 0.000430\n",
      "Epoch 104/200, Train Loss: 0.013101, Train-Class-Acc: {0: '100.00%', 1: '99.80%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.702616, Val Acc: 87.87%, Val-Class-Acc: {0: '88.04%', 1: '82.38%', 2: '85.42%', 3: '94.67%'}, LR: 0.000387\n",
      "Epoch 105/200, Train Loss: 0.013009, Train-Class-Acc: {0: '99.86%', 1: '99.90%', 2: '99.83%', 3: '100.00%'}\n",
      "Val Loss: 0.717574, Val Acc: 87.99%, Val-Class-Acc: {0: '92.39%', 1: '77.46%', 2: '86.81%', 3: '95.90%'}, LR: 0.000387\n",
      "Epoch 106/200, Train Loss: 0.009996, Train-Class-Acc: {0: '100.00%', 1: '99.90%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.702325, Val Acc: 87.75%, Val-Class-Acc: {0: '83.70%', 1: '84.84%', 2: '86.11%', 3: '94.67%'}, LR: 0.000387\n",
      "Epoch 107/200, Train Loss: 0.008468, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '99.90%'}\n",
      "Val Loss: 0.688731, Val Acc: 87.87%, Val-Class-Acc: {0: '88.04%', 1: '80.33%', 2: '86.81%', 3: '95.90%'}, LR: 0.000387\n",
      "Epoch 108/200, Train Loss: 0.009141, Train-Class-Acc: {0: '100.00%', 1: '99.90%', 2: '99.83%', 3: '100.00%'}\n",
      "Val Loss: 0.728377, Val Acc: 87.99%, Val-Class-Acc: {0: '88.59%', 1: '79.92%', 2: '88.89%', 3: '95.08%'}, LR: 0.000387\n",
      "Epoch 109/200, Train Loss: 0.007706, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.734186, Val Acc: 87.50%, Val-Class-Acc: {0: '86.96%', 1: '80.33%', 2: '86.81%', 3: '95.49%'}, LR: 0.000387\n",
      "Epoch 110/200, Train Loss: 0.007587, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.733757, Val Acc: 86.76%, Val-Class-Acc: {0: '83.70%', 1: '79.10%', 2: '86.81%', 3: '96.72%'}, LR: 0.000387\n",
      "Epoch 111/200, Train Loss: 0.008554, Train-Class-Acc: {0: '100.00%', 1: '99.90%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.756296, Val Acc: 86.89%, Val-Class-Acc: {0: '83.70%', 1: '83.20%', 2: '84.03%', 3: '94.67%'}, LR: 0.000387\n",
      "Epoch 112/200, Train Loss: 0.008290, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.723327, Val Acc: 87.38%, Val-Class-Acc: {0: '85.87%', 1: '82.79%', 2: '84.72%', 3: '94.67%'}, LR: 0.000387\n",
      "Epoch 113/200, Train Loss: 0.008141, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.802119, Val Acc: 87.87%, Val-Class-Acc: {0: '93.48%', 1: '77.05%', 2: '86.11%', 3: '95.49%'}, LR: 0.000387\n",
      "Epoch 114/200, Train Loss: 0.007302, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.761178, Val Acc: 87.13%, Val-Class-Acc: {0: '90.22%', 1: '77.87%', 2: '85.42%', 3: '95.08%'}, LR: 0.000387\n",
      "Epoch 115/200, Train Loss: 0.006849, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.756639, Val Acc: 87.25%, Val-Class-Acc: {0: '87.50%', 1: '78.69%', 2: '87.50%', 3: '95.49%'}, LR: 0.000349\n",
      "Epoch 116/200, Train Loss: 0.006752, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.748443, Val Acc: 87.75%, Val-Class-Acc: {0: '87.50%', 1: '80.33%', 2: '87.50%', 3: '95.49%'}, LR: 0.000349\n",
      "Epoch 117/200, Train Loss: 0.006659, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.742161, Val Acc: 87.50%, Val-Class-Acc: {0: '86.96%', 1: '80.33%', 2: '86.81%', 3: '95.49%'}, LR: 0.000349\n",
      "Epoch 118/200, Train Loss: 0.006575, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.752480, Val Acc: 87.25%, Val-Class-Acc: {0: '86.41%', 1: '80.74%', 2: '85.42%', 3: '95.49%'}, LR: 0.000349\n",
      "Epoch 119/200, Train Loss: 0.006471, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.749626, Val Acc: 87.87%, Val-Class-Acc: {0: '88.04%', 1: '81.15%', 2: '86.11%', 3: '95.49%'}, LR: 0.000349\n",
      "Epoch 120/200, Train Loss: 0.006411, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.764691, Val Acc: 87.75%, Val-Class-Acc: {0: '86.41%', 1: '81.56%', 2: '85.42%', 3: '96.31%'}, LR: 0.000349\n",
      "Epoch 121/200, Train Loss: 0.006300, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.762718, Val Acc: 87.62%, Val-Class-Acc: {0: '86.96%', 1: '80.74%', 2: '86.81%', 3: '95.49%'}, LR: 0.000349\n",
      "Epoch 122/200, Train Loss: 0.006225, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.757027, Val Acc: 87.87%, Val-Class-Acc: {0: '87.50%', 1: '80.74%', 2: '87.50%', 3: '95.49%'}, LR: 0.000349\n",
      "Epoch 123/200, Train Loss: 0.006182, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.760645, Val Acc: 87.87%, Val-Class-Acc: {0: '86.41%', 1: '81.97%', 2: '86.11%', 3: '95.90%'}, LR: 0.000349\n",
      "Epoch 124/200, Train Loss: 0.006160, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.757256, Val Acc: 88.11%, Val-Class-Acc: {0: '87.50%', 1: '82.38%', 2: '86.81%', 3: '95.08%'}, LR: 0.000349\n",
      "Epoch 125/200, Train Loss: 0.006032, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.772726, Val Acc: 87.87%, Val-Class-Acc: {0: '88.04%', 1: '80.74%', 2: '86.11%', 3: '95.90%'}, LR: 0.000349\n",
      "Epoch 126/200, Train Loss: 0.006020, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.757774, Val Acc: 87.99%, Val-Class-Acc: {0: '85.87%', 1: '82.79%', 2: '86.81%', 3: '95.49%'}, LR: 0.000314\n",
      "Epoch 127/200, Train Loss: 0.005986, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.760249, Val Acc: 87.87%, Val-Class-Acc: {0: '88.59%', 1: '81.15%', 2: '86.81%', 3: '94.67%'}, LR: 0.000314\n",
      "Epoch 128/200, Train Loss: 0.005904, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.769579, Val Acc: 87.38%, Val-Class-Acc: {0: '86.96%', 1: '80.33%', 2: '85.42%', 3: '95.90%'}, LR: 0.000314\n",
      "Epoch 129/200, Train Loss: 0.005837, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.774362, Val Acc: 87.50%, Val-Class-Acc: {0: '87.50%', 1: '80.74%', 2: '85.42%', 3: '95.49%'}, LR: 0.000314\n",
      "Epoch 130/200, Train Loss: 0.005753, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.776716, Val Acc: 87.13%, Val-Class-Acc: {0: '87.50%', 1: '79.51%', 2: '84.72%', 3: '95.90%'}, LR: 0.000314\n",
      "Epoch 131/200, Train Loss: 0.005681, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.785391, Val Acc: 87.25%, Val-Class-Acc: {0: '85.87%', 1: '81.15%', 2: '84.72%', 3: '95.90%'}, LR: 0.000314\n",
      "Epoch 132/200, Train Loss: 0.005690, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.781996, Val Acc: 87.25%, Val-Class-Acc: {0: '85.87%', 1: '81.15%', 2: '85.42%', 3: '95.49%'}, LR: 0.000314\n",
      "Epoch 133/200, Train Loss: 0.005620, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.799807, Val Acc: 87.01%, Val-Class-Acc: {0: '87.50%', 1: '80.33%', 2: '84.03%', 3: '95.08%'}, LR: 0.000314\n",
      "Epoch 134/200, Train Loss: 0.005573, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.772902, Val Acc: 87.38%, Val-Class-Acc: {0: '86.41%', 1: '80.33%', 2: '86.81%', 3: '95.49%'}, LR: 0.000314\n",
      "Epoch 135/200, Train Loss: 0.005472, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.773238, Val Acc: 87.62%, Val-Class-Acc: {0: '85.87%', 1: '80.74%', 2: '87.50%', 3: '95.90%'}, LR: 0.000314\n",
      "Epoch 136/200, Train Loss: 0.005438, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.792215, Val Acc: 86.89%, Val-Class-Acc: {0: '86.41%', 1: '79.10%', 2: '86.81%', 3: '95.08%'}, LR: 0.000314\n",
      "Epoch 137/200, Train Loss: 0.005380, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.789853, Val Acc: 86.89%, Val-Class-Acc: {0: '86.41%', 1: '80.33%', 2: '86.11%', 3: '94.26%'}, LR: 0.000282\n",
      "Epoch 138/200, Train Loss: 0.005335, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.787150, Val Acc: 86.76%, Val-Class-Acc: {0: '86.41%', 1: '79.51%', 2: '86.11%', 3: '94.67%'}, LR: 0.000282\n",
      "Epoch 139/200, Train Loss: 0.005290, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.802858, Val Acc: 86.64%, Val-Class-Acc: {0: '85.87%', 1: '80.33%', 2: '85.42%', 3: '94.26%'}, LR: 0.000282\n",
      "Epoch 140/200, Train Loss: 0.005241, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.796295, Val Acc: 86.89%, Val-Class-Acc: {0: '85.87%', 1: '80.74%', 2: '86.11%', 3: '94.26%'}, LR: 0.000282\n",
      "Epoch 141/200, Train Loss: 0.005210, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.809078, Val Acc: 86.52%, Val-Class-Acc: {0: '84.24%', 1: '80.74%', 2: '86.11%', 3: '94.26%'}, LR: 0.000282\n",
      "Epoch 142/200, Train Loss: 0.005131, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.798920, Val Acc: 86.76%, Val-Class-Acc: {0: '84.78%', 1: '81.15%', 2: '86.11%', 3: '94.26%'}, LR: 0.000282\n",
      "Epoch 143/200, Train Loss: 0.005087, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.808078, Val Acc: 86.52%, Val-Class-Acc: {0: '84.78%', 1: '80.33%', 2: '86.11%', 3: '94.26%'}, LR: 0.000282\n",
      "Epoch 144/200, Train Loss: 0.005055, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.819781, Val Acc: 86.76%, Val-Class-Acc: {0: '84.24%', 1: '81.15%', 2: '85.42%', 3: '95.08%'}, LR: 0.000282\n",
      "Epoch 145/200, Train Loss: 0.004989, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.805160, Val Acc: 86.52%, Val-Class-Acc: {0: '85.87%', 1: '79.51%', 2: '86.11%', 3: '94.26%'}, LR: 0.000282\n",
      "Epoch 146/200, Train Loss: 0.004932, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.807024, Val Acc: 86.40%, Val-Class-Acc: {0: '84.78%', 1: '79.10%', 2: '86.11%', 3: '95.08%'}, LR: 0.000282\n",
      "Epoch 147/200, Train Loss: 0.004947, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.806711, Val Acc: 86.52%, Val-Class-Acc: {0: '80.98%', 1: '82.79%', 2: '86.11%', 3: '94.67%'}, LR: 0.000282\n",
      "Epoch 148/200, Train Loss: 0.004870, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.808017, Val Acc: 86.76%, Val-Class-Acc: {0: '84.78%', 1: '81.15%', 2: '85.42%', 3: '94.67%'}, LR: 0.000254\n",
      "Epoch 149/200, Train Loss: 0.004833, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.806618, Val Acc: 86.76%, Val-Class-Acc: {0: '86.41%', 1: '79.92%', 2: '85.42%', 3: '94.67%'}, LR: 0.000254\n",
      "Epoch 150/200, Train Loss: 0.004809, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.827059, Val Acc: 86.40%, Val-Class-Acc: {0: '84.24%', 1: '79.10%', 2: '85.42%', 3: '95.90%'}, LR: 0.000254\n",
      "Epoch 151/200, Train Loss: 0.004812, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.798581, Val Acc: 86.76%, Val-Class-Acc: {0: '84.24%', 1: '79.92%', 2: '88.19%', 3: '94.67%'}, LR: 0.000254\n",
      "Epoch 152/200, Train Loss: 0.004721, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.804006, Val Acc: 87.13%, Val-Class-Acc: {0: '85.33%', 1: '80.33%', 2: '86.81%', 3: '95.49%'}, LR: 0.000254\n",
      "Epoch 153/200, Train Loss: 0.004676, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.805359, Val Acc: 86.76%, Val-Class-Acc: {0: '85.33%', 1: '80.74%', 2: '86.11%', 3: '94.26%'}, LR: 0.000254\n",
      "Epoch 154/200, Train Loss: 0.004827, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.819246, Val Acc: 87.38%, Val-Class-Acc: {0: '89.67%', 1: '77.87%', 2: '86.81%', 3: '95.49%'}, LR: 0.000254\n",
      "Epoch 155/200, Train Loss: 0.004690, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.827475, Val Acc: 86.76%, Val-Class-Acc: {0: '85.87%', 1: '80.74%', 2: '84.03%', 3: '95.08%'}, LR: 0.000254\n",
      "Epoch 156/200, Train Loss: 0.004598, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.837566, Val Acc: 86.76%, Val-Class-Acc: {0: '87.50%', 1: '78.28%', 2: '85.42%', 3: '95.49%'}, LR: 0.000254\n",
      "Epoch 157/200, Train Loss: 0.004502, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.824248, Val Acc: 87.13%, Val-Class-Acc: {0: '86.96%', 1: '79.92%', 2: '85.42%', 3: '95.49%'}, LR: 0.000254\n",
      "Epoch 158/200, Train Loss: 0.004508, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.828183, Val Acc: 87.01%, Val-Class-Acc: {0: '85.87%', 1: '80.33%', 2: '86.11%', 3: '95.08%'}, LR: 0.000254\n",
      "Epoch 159/200, Train Loss: 0.004415, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.839923, Val Acc: 87.13%, Val-Class-Acc: {0: '86.96%', 1: '79.92%', 2: '85.42%', 3: '95.49%'}, LR: 0.000229\n",
      "Epoch 160/200, Train Loss: 0.004381, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.831641, Val Acc: 86.64%, Val-Class-Acc: {0: '86.41%', 1: '78.69%', 2: '86.11%', 3: '95.08%'}, LR: 0.000229\n",
      "Epoch 161/200, Train Loss: 0.005817, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '99.90%'}\n",
      "Val Loss: 0.873937, Val Acc: 86.15%, Val-Class-Acc: {0: '79.35%', 1: '82.38%', 2: '83.33%', 3: '96.72%'}, LR: 0.000229\n",
      "Epoch 162/200, Train Loss: 0.142924, Train-Class-Acc: {0: '95.91%', 1: '94.67%', 2: '97.23%', 3: '96.93%'}\n",
      "Val Loss: 0.780283, Val Acc: 84.31%, Val-Class-Acc: {0: '89.13%', 1: '74.18%', 2: '87.50%', 3: '88.93%'}, LR: 0.000229\n",
      "Epoch 163/200, Train Loss: 0.061888, Train-Class-Acc: {0: '98.23%', 1: '98.05%', 2: '97.92%', 3: '98.98%'}\n",
      "Val Loss: 0.666620, Val Acc: 85.91%, Val-Class-Acc: {0: '80.43%', 1: '82.38%', 2: '84.72%', 3: '94.26%'}, LR: 0.000229\n",
      "Epoch 164/200, Train Loss: 0.021162, Train-Class-Acc: {0: '99.46%', 1: '99.18%', 2: '99.65%', 3: '100.00%'}\n",
      "Val Loss: 0.762422, Val Acc: 86.76%, Val-Class-Acc: {0: '88.59%', 1: '79.92%', 2: '81.25%', 3: '95.49%'}, LR: 0.000229\n",
      "Epoch 165/200, Train Loss: 0.013944, Train-Class-Acc: {0: '99.73%', 1: '99.80%', 2: '99.83%', 3: '99.90%'}\n",
      "Val Loss: 0.703412, Val Acc: 86.40%, Val-Class-Acc: {0: '85.87%', 1: '78.69%', 2: '86.11%', 3: '94.67%'}, LR: 0.000229\n",
      "Epoch 166/200, Train Loss: 0.008920, Train-Class-Acc: {0: '99.86%', 1: '99.90%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.733935, Val Acc: 87.38%, Val-Class-Acc: {0: '90.76%', 1: '78.28%', 2: '86.11%', 3: '94.67%'}, LR: 0.000229\n",
      "Epoch 167/200, Train Loss: 0.007206, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.712340, Val Acc: 87.75%, Val-Class-Acc: {0: '88.04%', 1: '81.15%', 2: '86.81%', 3: '94.67%'}, LR: 0.000229\n",
      "Epoch 168/200, Train Loss: 0.006962, Train-Class-Acc: {0: '100.00%', 1: '99.90%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.728488, Val Acc: 87.13%, Val-Class-Acc: {0: '87.50%', 1: '80.74%', 2: '86.81%', 3: '93.44%'}, LR: 0.000229\n",
      "Epoch 169/200, Train Loss: 0.006144, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.732830, Val Acc: 87.75%, Val-Class-Acc: {0: '88.04%', 1: '80.33%', 2: '86.81%', 3: '95.49%'}, LR: 0.000229\n",
      "Epoch 170/200, Train Loss: 0.006071, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.752736, Val Acc: 87.99%, Val-Class-Acc: {0: '91.85%', 1: '78.28%', 2: '86.81%', 3: '95.49%'}, LR: 0.000206\n",
      "Epoch 171/200, Train Loss: 0.005906, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.744954, Val Acc: 87.87%, Val-Class-Acc: {0: '90.22%', 1: '80.33%', 2: '86.11%', 3: '94.67%'}, LR: 0.000206\n",
      "Epoch 172/200, Train Loss: 0.005724, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.749033, Val Acc: 87.75%, Val-Class-Acc: {0: '88.59%', 1: '81.15%', 2: '86.11%', 3: '94.67%'}, LR: 0.000206\n",
      "Epoch 173/200, Train Loss: 0.005525, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.753290, Val Acc: 87.99%, Val-Class-Acc: {0: '88.59%', 1: '81.56%', 2: '86.81%', 3: '94.67%'}, LR: 0.000206\n",
      "Epoch 174/200, Train Loss: 0.005608, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.760667, Val Acc: 87.87%, Val-Class-Acc: {0: '88.04%', 1: '81.15%', 2: '86.81%', 3: '95.08%'}, LR: 0.000206\n",
      "Epoch 175/200, Train Loss: 0.005488, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.756131, Val Acc: 87.38%, Val-Class-Acc: {0: '84.78%', 1: '81.97%', 2: '86.81%', 3: '95.08%'}, LR: 0.000206\n",
      "Epoch 176/200, Train Loss: 0.005421, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.774438, Val Acc: 87.38%, Val-Class-Acc: {0: '86.41%', 1: '81.56%', 2: '86.81%', 3: '94.26%'}, LR: 0.000206\n",
      "Epoch 177/200, Train Loss: 0.005330, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.776662, Val Acc: 87.38%, Val-Class-Acc: {0: '86.41%', 1: '81.56%', 2: '86.81%', 3: '94.26%'}, LR: 0.000206\n",
      "Epoch 178/200, Train Loss: 0.005325, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.773122, Val Acc: 87.25%, Val-Class-Acc: {0: '85.87%', 1: '81.56%', 2: '86.81%', 3: '94.26%'}, LR: 0.000206\n",
      "Epoch 179/200, Train Loss: 0.005226, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.792670, Val Acc: 86.76%, Val-Class-Acc: {0: '84.78%', 1: '80.74%', 2: '86.81%', 3: '94.26%'}, LR: 0.000206\n",
      "Epoch 180/200, Train Loss: 0.005284, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.784327, Val Acc: 86.64%, Val-Class-Acc: {0: '83.70%', 1: '81.15%', 2: '86.81%', 3: '94.26%'}, LR: 0.000206\n",
      "Epoch 181/200, Train Loss: 0.005204, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.792289, Val Acc: 87.25%, Val-Class-Acc: {0: '86.96%', 1: '80.74%', 2: '86.81%', 3: '94.26%'}, LR: 0.000185\n",
      "Epoch 182/200, Train Loss: 0.005135, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.792124, Val Acc: 87.25%, Val-Class-Acc: {0: '86.96%', 1: '80.74%', 2: '86.81%', 3: '94.26%'}, LR: 0.000185\n",
      "Epoch 183/200, Train Loss: 0.005055, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.801241, Val Acc: 87.50%, Val-Class-Acc: {0: '87.50%', 1: '79.92%', 2: '86.81%', 3: '95.49%'}, LR: 0.000185\n",
      "Epoch 184/200, Train Loss: 0.005099, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.804018, Val Acc: 86.89%, Val-Class-Acc: {0: '83.70%', 1: '80.74%', 2: '86.81%', 3: '95.49%'}, LR: 0.000185\n",
      "Epoch 185/200, Train Loss: 0.005028, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.801334, Val Acc: 87.62%, Val-Class-Acc: {0: '88.04%', 1: '81.15%', 2: '86.81%', 3: '94.26%'}, LR: 0.000185\n",
      "Epoch 186/200, Train Loss: 0.005236, Train-Class-Acc: {0: '100.00%', 1: '99.90%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.877887, Val Acc: 86.76%, Val-Class-Acc: {0: '84.78%', 1: '82.79%', 2: '84.03%', 3: '93.85%'}, LR: 0.000185\n",
      "Epoch 187/200, Train Loss: 0.005606, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '99.83%', 3: '100.00%'}\n",
      "Val Loss: 0.847285, Val Acc: 86.64%, Val-Class-Acc: {0: '89.13%', 1: '78.28%', 2: '84.72%', 3: '94.26%'}, LR: 0.000185\n",
      "Epoch 188/200, Train Loss: 0.005275, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.795347, Val Acc: 87.25%, Val-Class-Acc: {0: '88.04%', 1: '78.28%', 2: '86.81%', 3: '95.90%'}, LR: 0.000185\n",
      "Epoch 189/200, Train Loss: 0.005222, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.805491, Val Acc: 87.13%, Val-Class-Acc: {0: '87.50%', 1: '78.69%', 2: '86.81%', 3: '95.49%'}, LR: 0.000185\n",
      "Epoch 190/200, Train Loss: 0.005237, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '99.90%'}\n",
      "Val Loss: 0.820226, Val Acc: 87.25%, Val-Class-Acc: {0: '87.50%', 1: '79.51%', 2: '85.42%', 3: '95.90%'}, LR: 0.000185\n",
      "Epoch 191/200, Train Loss: 0.005071, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.809947, Val Acc: 87.50%, Val-Class-Acc: {0: '86.41%', 1: '81.56%', 2: '86.11%', 3: '95.08%'}, LR: 0.000185\n",
      "Epoch 192/200, Train Loss: 0.004873, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.811922, Val Acc: 87.50%, Val-Class-Acc: {0: '89.67%', 1: '79.51%', 2: '86.81%', 3: '94.26%'}, LR: 0.000167\n",
      "Epoch 193/200, Train Loss: 0.004856, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.811895, Val Acc: 87.38%, Val-Class-Acc: {0: '85.33%', 1: '81.97%', 2: '87.50%', 3: '94.26%'}, LR: 0.000167\n",
      "Epoch 194/200, Train Loss: 0.004778, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.816206, Val Acc: 87.75%, Val-Class-Acc: {0: '86.96%', 1: '81.97%', 2: '87.50%', 3: '94.26%'}, LR: 0.000167\n",
      "Epoch 195/200, Train Loss: 0.004888, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.847965, Val Acc: 87.62%, Val-Class-Acc: {0: '89.67%', 1: '78.69%', 2: '86.11%', 3: '95.90%'}, LR: 0.000167\n",
      "Epoch 196/200, Train Loss: 0.004821, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.850591, Val Acc: 87.13%, Val-Class-Acc: {0: '86.96%', 1: '80.33%', 2: '86.11%', 3: '94.67%'}, LR: 0.000167\n",
      "Epoch 197/200, Train Loss: 0.004718, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.839049, Val Acc: 87.75%, Val-Class-Acc: {0: '89.13%', 1: '80.74%', 2: '86.81%', 3: '94.26%'}, LR: 0.000167\n",
      "Epoch 198/200, Train Loss: 0.004809, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.851955, Val Acc: 86.89%, Val-Class-Acc: {0: '85.33%', 1: '79.92%', 2: '87.50%', 3: '94.67%'}, LR: 0.000167\n",
      "Epoch 199/200, Train Loss: 0.004629, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.861710, Val Acc: 87.01%, Val-Class-Acc: {0: '85.33%', 1: '79.92%', 2: '87.50%', 3: '95.08%'}, LR: 0.000167\n",
      "Epoch 200/200, Train Loss: 0.004604, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'}\n",
      "Val Loss: 0.868867, Val Acc: 87.25%, Val-Class-Acc: {0: '86.41%', 1: '80.74%', 2: '86.81%', 3: '94.67%'}, LR: 0.000167\n",
      "\n",
      "üèÜ Best model saved as: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_best.pth (Val Accuracy: 88.73%)\n",
      "\n",
      "üìå Final model saved as: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_final.pth\n",
      "\n",
      "üéØ Top 5 Best Models:\n",
      "Epoch 87, Train Loss: 0.005449, Train-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'},\n",
      "Val Loss: 0.753168, Val Acc: 88.73%, Val-Acc: {0: '92.39%', 1: '81.56%', 2: '84.72%', 3: '95.49%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_87.pth\n",
      "Epoch 83, Train Loss: 0.005707, Train-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'},\n",
      "Val Loss: 0.731666, Val Acc: 88.60%, Val-Acc: {0: '90.76%', 1: '81.97%', 2: '85.42%', 3: '95.49%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_83.pth\n",
      "Epoch 79, Train Loss: 0.006099, Train-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'},\n",
      "Val Loss: 0.730975, Val Acc: 88.60%, Val-Acc: {0: '91.85%', 1: '81.56%', 2: '85.42%', 3: '95.08%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_79.pth\n",
      "Epoch 73, Train Loss: 0.006499, Train-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'},\n",
      "Val Loss: 0.703504, Val Acc: 88.60%, Val-Acc: {0: '89.67%', 1: '83.20%', 2: '84.72%', 3: '95.49%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_73.pth\n",
      "Epoch 71, Train Loss: 0.006704, Train-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%'},\n",
      "Val Loss: 0.717101, Val Acc: 88.60%, Val-Acc: {0: '91.30%', 1: '81.97%', 2: '84.72%', 3: '95.49%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2/ResNet18_1D_epoch_71.pth\n",
      "\n",
      "üß† Model Summary:\n",
      "Total Parameters: 3,859,076\n",
      "Model Size (float32): 14.72 MB\n",
      "Total Training Time: 439.15 seconds\n",
      "---\n",
      "### Period 2\n",
      "+ ##### Total training time: 439.15 seconds\n",
      "+ ##### Model: ResNet18_1D\n",
      "+ ##### Training and saving in *'/mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_2'*\n",
      "+ ##### Best Epoch: 87\n",
      "#### __Val Accuracy: 88.73%__\n",
      "#### __Val-Class-Acc: {0: '92.39%', 1: '81.56%', 2: '84.72%', 3: '95.49%'}__\n",
      "#### __Total Parameters: 3,859,076__\n",
      "#### __Model Size (float32): 14.72 MB__\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# üìå Period 2: EWC Training (Protect Period 2)\n",
    "# ================================\n",
    "period = 2\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.join(BASE_DIR, \"stop_training.txt\")\n",
    "model_saving_folder = os.path.join(BASE_DIR, \"Trained_models\", \"EWC_CIL_v1\", f\"Period_{period}\")\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Load Period 2 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, f\"X_train_p{period}.npy\"))\n",
    "y_train = np.load(os.path.join(save_dir, f\"y_train_p{period}.npy\"))\n",
    "X_val   = np.load(os.path.join(save_dir, f\"X_test_p{period}.npy\"))\n",
    "y_val   = np.load(os.path.join(save_dir, f\"y_test_p{period}.npy\"))\n",
    "\n",
    "# ==== Device ====\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "# ==== Model Configuration ====\n",
    "input_channels = X_train.shape[2]  # ECG 12-lead\n",
    "output_size = len(np.unique(y_train))  # New class count in Period 2\n",
    "model = ResNet18_1D(input_channels=input_channels, output_size=output_size).to(device)\n",
    "\n",
    "# ==== Load Period 1 Best Model ====\n",
    "prev_model_path = os.path.join(BASE_DIR, \"ResNet18_Selection\", \"ResNet18_big_inplane_v1\", \"ResNet18_big_inplane_1D_best.pth\")\n",
    "prev_checkpoint = torch.load(prev_model_path, map_location=device)\n",
    "state_dict = prev_checkpoint[\"model_state_dict\"]\n",
    "model_dict = model.state_dict()\n",
    "filtered_dict = {k: v for k, v in state_dict.items() if k in model_dict and model_dict[k].shape == v.shape}\n",
    "model.load_state_dict(filtered_dict, strict=False)\n",
    "for k in model_dict:\n",
    "    if k not in filtered_dict:\n",
    "        print(f\"üîç Not loaded: {k}, shape={model_dict[k].shape}\")\n",
    "print(\"‚úÖ Loaded Period 1 weights (except FC mismatch)\")\n",
    "\n",
    "# ==== Prepare EWC (Compute Fisher Info from Period 1 Data) ====\n",
    "X_prev = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))\n",
    "y_prev = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "train_loader_prev = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_prev, dtype=torch.float32), torch.tensor(y_prev, dtype=torch.long)),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fisher_dict, params_dict = EWC.compute_fisher_and_params(model, train_loader_prev, criterion, device=device)\n",
    "ewc_state = EWC(fisher=fisher_dict, params=params_dict)\n",
    "print(\"üìà Fisher information computed from Period 1\")\n",
    "\n",
    "# ==== Optimizer / Scheduler ====\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "lambda_ewc = 1.0\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_with_ewc_ecg(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name=\"ResNet18_1D\",\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    ewc=ewc_state,\n",
    "    lambda_ewc=lambda_ewc,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# ‚úÖ Cleanup\n",
    "# ================================\n",
    "del X_train, y_train, X_val, y_val, X_prev, y_prev\n",
    "del prev_model_path, prev_checkpoint, state_dict, model_dict, filtered_dict\n",
    "del model, train_loader_prev, fisher_dict, params_dict, ewc_state\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad6ab5d",
   "metadata": {},
   "source": [
    "### Period 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90039f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Automatically selected GPU:\n",
      "    - CUDA Device ID : 0\n",
      "    - Memory Used    : 283 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "‚úÖ Loaded Period 2 weights (except FC mismatch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_321925/3804802245.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  prev_checkpoint = torch.load(prev_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Fisher information computed from Period 2\n",
      "\n",
      "üöÄ 'train_with_ewc_ecg' started.\n",
      "‚úÖ Removed existing folder: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3\n",
      "\n",
      "‚úÖ Data Overview:\n",
      "X_train: torch.Size([5120, 5000, 12]), y_train: torch.Size([5120])\n",
      "X_val: torch.Size([1281, 5000, 12]), y_val: torch.Size([1281])\n",
      "Epoch 1/200, Train Loss: 0.722560, Train-Class-Acc: {0: '71.80%', 1: '72.48%', 2: '81.46%', 3: '88.93%', 4: '48.10%', 5: '85.50%'}\n",
      "Val Loss: 0.394099, Val Acc: 86.81%, Val-Class-Acc: {0: '88.59%', 1: '76.72%', 2: '91.67%', 3: '91.39%', 4: '85.00%', 5: '90.72%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.376974, Train-Class-Acc: {0: '82.43%', 1: '81.75%', 2: '89.25%', 3: '94.47%', 4: '78.48%', 5: '92.53%'}\n",
      "Val Loss: 0.433739, Val Acc: 86.49%, Val-Class-Acc: {0: '84.78%', 1: '82.39%', 2: '93.06%', 3: '95.08%', 4: '80.00%', 5: '83.23%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.300842, Train-Class-Acc: {0: '85.01%', 1: '85.04%', 2: '93.24%', 3: '94.57%', 4: '84.81%', 5: '93.65%'}\n",
      "Val Loss: 0.586977, Val Acc: 84.54%, Val-Class-Acc: {0: '68.48%', 1: '84.78%', 2: '79.86%', 3: '97.13%', 4: '77.50%', 5: '86.83%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.279925, Train-Class-Acc: {0: '88.28%', 1: '87.58%', 2: '93.07%', 3: '94.77%', 4: '84.18%', 5: '93.87%'}\n",
      "Val Loss: 0.432607, Val Acc: 87.67%, Val-Class-Acc: {0: '88.59%', 1: '76.72%', 2: '87.50%', 3: '90.57%', 4: '82.50%', 5: '96.71%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.215030, Train-Class-Acc: {0: '90.33%', 1: '89.60%', 2: '94.63%', 3: '96.52%', 4: '89.24%', 5: '95.37%'}\n",
      "Val Loss: 0.427990, Val Acc: 87.82%, Val-Class-Acc: {0: '88.59%', 1: '78.21%', 2: '93.75%', 3: '94.26%', 4: '85.00%', 5: '90.12%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.197179, Train-Class-Acc: {0: '90.33%', 1: '90.73%', 2: '93.76%', 3: '97.95%', 4: '82.91%', 5: '96.41%'}\n",
      "Val Loss: 0.485477, Val Acc: 86.73%, Val-Class-Acc: {0: '78.80%', 1: '85.07%', 2: '83.33%', 3: '93.44%', 4: '67.50%', 5: '91.62%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_3.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_6.pth\n",
      "Epoch 7/200, Train Loss: 0.185850, Train-Class-Acc: {0: '91.55%', 1: '91.77%', 2: '96.19%', 3: '97.13%', 4: '85.44%', 5: '96.04%'}\n",
      "Val Loss: 0.612852, Val Acc: 86.65%, Val-Class-Acc: {0: '82.07%', 1: '78.81%', 2: '81.94%', 3: '90.16%', 4: '82.50%', 5: '97.01%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_2.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.173763, Train-Class-Acc: {0: '91.42%', 1: '91.10%', 2: '96.01%', 3: '96.31%', 4: '93.04%', 5: '96.71%'}\n",
      "Val Loss: 0.489252, Val Acc: 87.35%, Val-Class-Acc: {0: '88.59%', 1: '74.93%', 2: '90.97%', 3: '93.85%', 4: '82.50%', 5: '93.41%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_7.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_8.pth\n",
      "Epoch 9/200, Train Loss: 0.180382, Train-Class-Acc: {0: '92.37%', 1: '91.62%', 2: '94.28%', 3: '96.21%', 4: '89.24%', 5: '96.34%'}\n",
      "Val Loss: 0.591092, Val Acc: 84.70%, Val-Class-Acc: {0: '55.43%', 1: '90.75%', 2: '86.11%', 3: '90.98%', 4: '82.50%', 5: '89.82%'}, LR: 0.001000\n",
      "Epoch 10/200, Train Loss: 0.117452, Train-Class-Acc: {0: '93.19%', 1: '94.47%', 2: '97.40%', 3: '98.67%', 4: '94.94%', 5: '98.13%'}\n",
      "Val Loss: 0.569116, Val Acc: 86.34%, Val-Class-Acc: {0: '84.78%', 1: '80.60%', 2: '84.72%', 3: '90.57%', 4: '82.50%', 5: '91.02%'}, LR: 0.001000\n",
      "Epoch 11/200, Train Loss: 0.106447, Train-Class-Acc: {0: '93.19%', 1: '94.54%', 2: '97.23%', 3: '98.36%', 4: '96.20%', 5: '98.21%'}\n",
      "Val Loss: 0.582559, Val Acc: 86.49%, Val-Class-Acc: {0: '91.85%', 1: '70.45%', 2: '89.58%', 3: '93.85%', 4: '82.50%', 5: '93.41%'}, LR: 0.001000\n",
      "Epoch 12/200, Train Loss: 0.108031, Train-Class-Acc: {0: '96.05%', 1: '95.59%', 2: '98.61%', 3: '97.95%', 4: '93.04%', 5: '97.61%'}\n",
      "Val Loss: 0.652801, Val Acc: 85.25%, Val-Class-Acc: {0: '63.04%', 1: '85.97%', 2: '88.89%', 3: '90.16%', 4: '82.50%', 5: '91.92%'}, LR: 0.001000\n",
      "Epoch 13/200, Train Loss: 0.074839, Train-Class-Acc: {0: '96.32%', 1: '96.78%', 2: '97.75%', 3: '98.87%', 4: '94.94%', 5: '98.88%'}\n",
      "Val Loss: 0.551723, Val Acc: 87.04%, Val-Class-Acc: {0: '75.00%', 1: '83.88%', 2: '86.11%', 3: '93.85%', 4: '85.00%', 5: '92.51%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_6.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_13.pth\n",
      "Epoch 14/200, Train Loss: 0.055114, Train-Class-Acc: {0: '97.00%', 1: '97.83%', 2: '99.31%', 3: '98.98%', 4: '98.73%', 5: '98.80%'}\n",
      "Val Loss: 0.595295, Val Acc: 87.04%, Val-Class-Acc: {0: '72.28%', 1: '81.79%', 2: '86.81%', 3: '94.26%', 4: '82.50%', 5: '95.81%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_1.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_14.pth\n",
      "Epoch 15/200, Train Loss: 0.068057, Train-Class-Acc: {0: '98.50%', 1: '97.01%', 2: '99.13%', 3: '98.46%', 4: '99.37%', 5: '98.65%'}\n",
      "Val Loss: 0.619665, Val Acc: 86.89%, Val-Class-Acc: {0: '74.46%', 1: '85.37%', 2: '86.11%', 3: '90.98%', 4: '85.00%', 5: '92.81%'}, LR: 0.000900\n",
      "Epoch 16/200, Train Loss: 0.072302, Train-Class-Acc: {0: '96.46%', 1: '96.71%', 2: '98.44%', 3: '99.28%', 4: '97.47%', 5: '98.73%'}\n",
      "Val Loss: 0.651242, Val Acc: 86.89%, Val-Class-Acc: {0: '89.67%', 1: '78.51%', 2: '84.03%', 3: '93.03%', 4: '82.50%', 5: '91.02%'}, LR: 0.000900\n",
      "Epoch 17/200, Train Loss: 0.055401, Train-Class-Acc: {0: '97.28%', 1: '97.98%', 2: '98.09%', 3: '98.98%', 4: '95.57%', 5: '99.10%'}\n",
      "Val Loss: 0.799752, Val Acc: 84.39%, Val-Class-Acc: {0: '80.98%', 1: '73.13%', 2: '94.44%', 3: '83.20%', 4: '85.00%', 5: '94.01%'}, LR: 0.000900\n",
      "Epoch 18/200, Train Loss: 0.091632, Train-Class-Acc: {0: '94.69%', 1: '96.11%', 2: '97.05%', 3: '98.67%', 4: '94.30%', 5: '98.51%'}\n",
      "Val Loss: 0.582735, Val Acc: 87.35%, Val-Class-Acc: {0: '88.59%', 1: '80.90%', 2: '86.81%', 3: '93.85%', 4: '82.50%', 5: '89.22%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_13.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_18.pth\n",
      "Epoch 19/200, Train Loss: 0.069856, Train-Class-Acc: {0: '96.19%', 1: '96.78%', 2: '98.79%', 3: '99.18%', 4: '97.47%', 5: '98.36%'}\n",
      "Val Loss: 0.737588, Val Acc: 84.70%, Val-Class-Acc: {0: '85.33%', 1: '79.40%', 2: '88.89%', 3: '87.70%', 4: '80.00%', 5: '86.23%'}, LR: 0.000900\n",
      "Epoch 20/200, Train Loss: 0.063475, Train-Class-Acc: {0: '97.82%', 1: '98.20%', 2: '98.09%', 3: '98.98%', 4: '96.20%', 5: '98.51%'}\n",
      "Val Loss: 0.642462, Val Acc: 86.42%, Val-Class-Acc: {0: '74.46%', 1: '79.40%', 2: '86.81%', 3: '93.85%', 4: '82.50%', 5: '94.91%'}, LR: 0.000900\n",
      "Epoch 21/200, Train Loss: 0.039843, Train-Class-Acc: {0: '97.14%', 1: '98.20%', 2: '99.48%', 3: '99.28%', 4: '100.00%', 5: '99.63%'}\n",
      "Val Loss: 0.640503, Val Acc: 87.35%, Val-Class-Acc: {0: '78.26%', 1: '83.28%', 2: '86.11%', 3: '93.85%', 4: '82.50%', 5: '92.81%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_14.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_21.pth\n",
      "Epoch 22/200, Train Loss: 0.021814, Train-Class-Acc: {0: '98.77%', 1: '99.18%', 2: '99.65%', 3: '99.80%', 4: '100.00%', 5: '99.78%'}\n",
      "Val Loss: 0.740962, Val Acc: 86.73%, Val-Class-Acc: {0: '90.76%', 1: '71.04%', 2: '88.19%', 3: '93.44%', 4: '82.50%', 5: '95.21%'}, LR: 0.000900\n",
      "Epoch 23/200, Train Loss: 0.026478, Train-Class-Acc: {0: '98.91%', 1: '98.95%', 2: '99.31%', 3: '99.59%', 4: '98.73%', 5: '99.70%'}\n",
      "Val Loss: 0.636669, Val Acc: 88.06%, Val-Class-Acc: {0: '89.13%', 1: '80.60%', 2: '87.50%', 3: '92.62%', 4: '80.00%', 5: '92.81%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_8.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_23.pth\n",
      "Epoch 24/200, Train Loss: 0.021567, Train-Class-Acc: {0: '99.05%', 1: '99.55%', 2: '99.65%', 3: '99.69%', 4: '98.10%', 5: '100.00%'}\n",
      "Val Loss: 0.671013, Val Acc: 86.96%, Val-Class-Acc: {0: '84.24%', 1: '76.42%', 2: '93.06%', 3: '90.57%', 4: '82.50%', 5: '94.31%'}, LR: 0.000810\n",
      "Epoch 25/200, Train Loss: 0.019739, Train-Class-Acc: {0: '99.46%', 1: '99.33%', 2: '100.00%', 3: '99.69%', 4: '99.37%', 5: '99.70%'}\n",
      "Val Loss: 0.728606, Val Acc: 86.96%, Val-Class-Acc: {0: '72.83%', 1: '85.37%', 2: '83.33%', 3: '92.62%', 4: '82.50%', 5: '94.31%'}, LR: 0.000810\n",
      "Epoch 26/200, Train Loss: 0.015136, Train-Class-Acc: {0: '99.59%', 1: '99.78%', 2: '99.83%', 3: '99.90%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.755574, Val Acc: 87.43%, Val-Class-Acc: {0: '85.87%', 1: '77.91%', 2: '81.25%', 3: '92.21%', 4: '82.50%', 5: '97.60%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_18.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_26.pth\n",
      "Epoch 27/200, Train Loss: 0.037553, Train-Class-Acc: {0: '98.77%', 1: '98.88%', 2: '98.61%', 3: '99.39%', 4: '98.73%', 5: '99.33%'}\n",
      "Val Loss: 0.870225, Val Acc: 84.00%, Val-Class-Acc: {0: '65.76%', 1: '79.70%', 2: '87.50%', 3: '95.90%', 4: '75.00%', 5: '89.22%'}, LR: 0.000810\n",
      "Epoch 28/200, Train Loss: 0.110540, Train-Class-Acc: {0: '95.37%', 1: '95.59%', 2: '96.01%', 3: '97.85%', 4: '91.77%', 5: '98.51%'}\n",
      "Val Loss: 0.800085, Val Acc: 82.67%, Val-Class-Acc: {0: '56.52%', 1: '85.07%', 2: '93.06%', 3: '83.61%', 4: '90.00%', 5: '88.62%'}, LR: 0.000810\n",
      "Epoch 29/200, Train Loss: 0.098926, Train-Class-Acc: {0: '97.28%', 1: '96.63%', 2: '96.53%', 3: '98.16%', 4: '94.94%', 5: '97.98%'}\n",
      "Val Loss: 0.659012, Val Acc: 85.56%, Val-Class-Acc: {0: '72.28%', 1: '77.91%', 2: '90.97%', 3: '94.67%', 4: '82.50%', 5: '91.92%'}, LR: 0.000810\n",
      "Epoch 30/200, Train Loss: 0.045705, Train-Class-Acc: {0: '97.28%', 1: '97.91%', 2: '98.96%', 3: '99.39%', 4: '97.47%', 5: '99.33%'}\n",
      "Val Loss: 0.679311, Val Acc: 86.81%, Val-Class-Acc: {0: '86.41%', 1: '77.31%', 2: '84.03%', 3: '94.67%', 4: '85.00%', 5: '92.22%'}, LR: 0.000810\n",
      "Epoch 31/200, Train Loss: 0.030209, Train-Class-Acc: {0: '98.64%', 1: '98.80%', 2: '99.65%', 3: '99.59%', 4: '98.10%', 5: '99.55%'}\n",
      "Val Loss: 0.669468, Val Acc: 86.73%, Val-Class-Acc: {0: '91.30%', 1: '72.54%', 2: '87.50%', 3: '95.08%', 4: '85.00%', 5: '92.22%'}, LR: 0.000810\n",
      "Epoch 32/200, Train Loss: 0.021410, Train-Class-Acc: {0: '99.32%', 1: '99.33%', 2: '99.83%', 3: '99.80%', 4: '100.00%', 5: '99.85%'}\n",
      "Val Loss: 0.616755, Val Acc: 87.74%, Val-Class-Acc: {0: '86.41%', 1: '80.00%', 2: '88.89%', 3: '93.44%', 4: '85.00%', 5: '91.92%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_21.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_32.pth\n",
      "Epoch 33/200, Train Loss: 0.017017, Train-Class-Acc: {0: '99.59%', 1: '99.48%', 2: '99.65%', 3: '99.90%', 4: '100.00%', 5: '99.78%'}\n",
      "Val Loss: 0.665613, Val Acc: 87.74%, Val-Class-Acc: {0: '78.80%', 1: '81.19%', 2: '94.44%', 3: '92.62%', 4: '82.50%', 5: '93.41%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_26.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_33.pth\n",
      "Epoch 34/200, Train Loss: 0.029925, Train-Class-Acc: {0: '98.77%', 1: '99.25%', 2: '98.96%', 3: '99.80%', 4: '98.10%', 5: '99.48%'}\n",
      "Val Loss: 0.768848, Val Acc: 86.65%, Val-Class-Acc: {0: '83.15%', 1: '74.93%', 2: '88.19%', 3: '95.08%', 4: '87.50%', 5: '93.41%'}, LR: 0.000810\n",
      "Epoch 35/200, Train Loss: 0.061834, Train-Class-Acc: {0: '96.32%', 1: '97.01%', 2: '98.09%', 3: '99.28%', 4: '99.37%', 5: '99.33%'}\n",
      "Val Loss: 0.755557, Val Acc: 86.73%, Val-Class-Acc: {0: '79.89%', 1: '84.78%', 2: '85.42%', 3: '89.75%', 4: '87.50%', 5: '90.72%'}, LR: 0.000729\n",
      "Epoch 36/200, Train Loss: 0.048040, Train-Class-Acc: {0: '97.68%', 1: '98.06%', 2: '99.48%', 3: '99.39%', 4: '99.37%', 5: '99.33%'}\n",
      "Val Loss: 0.762734, Val Acc: 85.71%, Val-Class-Acc: {0: '83.70%', 1: '78.51%', 2: '87.50%', 3: '91.39%', 4: '85.00%', 5: '89.22%'}, LR: 0.000729\n",
      "Epoch 37/200, Train Loss: 0.024241, Train-Class-Acc: {0: '99.46%', 1: '99.18%', 2: '99.31%', 3: '99.49%', 4: '100.00%', 5: '99.70%'}\n",
      "Val Loss: 0.710727, Val Acc: 87.35%, Val-Class-Acc: {0: '84.78%', 1: '77.01%', 2: '91.67%', 3: '93.03%', 4: '82.50%', 5: '93.71%'}, LR: 0.000729\n",
      "Epoch 38/200, Train Loss: 0.011700, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '99.80%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.712769, Val Acc: 86.65%, Val-Class-Acc: {0: '79.35%', 1: '80.30%', 2: '86.11%', 3: '93.44%', 4: '82.50%', 5: '92.81%'}, LR: 0.000729\n",
      "Epoch 39/200, Train Loss: 0.007166, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.716317, Val Acc: 87.12%, Val-Class-Acc: {0: '80.43%', 1: '81.19%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '94.31%'}, LR: 0.000729\n",
      "Epoch 40/200, Train Loss: 0.007698, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.766308, Val Acc: 86.42%, Val-Class-Acc: {0: '73.91%', 1: '86.27%', 2: '82.64%', 3: '89.34%', 4: '82.50%', 5: '93.41%'}, LR: 0.000729\n",
      "Epoch 41/200, Train Loss: 0.007694, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.724950, Val Acc: 87.12%, Val-Class-Acc: {0: '73.37%', 1: '83.58%', 2: '86.11%', 3: '93.85%', 4: '82.50%', 5: '94.31%'}, LR: 0.000729\n",
      "Epoch 42/200, Train Loss: 0.009118, Train-Class-Acc: {0: '100.00%', 1: '99.78%', 2: '99.83%', 3: '100.00%', 4: '99.37%', 5: '100.00%'}\n",
      "Val Loss: 0.748067, Val Acc: 86.65%, Val-Class-Acc: {0: '76.63%', 1: '82.69%', 2: '77.78%', 3: '92.62%', 4: '82.50%', 5: '96.11%'}, LR: 0.000729\n",
      "Epoch 43/200, Train Loss: 0.049231, Train-Class-Acc: {0: '99.18%', 1: '98.80%', 2: '98.79%', 3: '98.87%', 4: '99.37%', 5: '99.03%'}\n",
      "Val Loss: 0.862096, Val Acc: 86.49%, Val-Class-Acc: {0: '77.72%', 1: '82.39%', 2: '81.94%', 3: '90.98%', 4: '82.50%', 5: '94.61%'}, LR: 0.000729\n",
      "Epoch 44/200, Train Loss: 0.106165, Train-Class-Acc: {0: '96.19%', 1: '96.48%', 2: '97.57%', 3: '97.75%', 4: '97.47%', 5: '98.06%'}\n",
      "Val Loss: 0.812740, Val Acc: 85.01%, Val-Class-Acc: {0: '80.43%', 1: '75.22%', 2: '84.72%', 3: '93.85%', 4: '82.50%', 5: '91.32%'}, LR: 0.000729\n",
      "Epoch 45/200, Train Loss: 0.066786, Train-Class-Acc: {0: '96.46%', 1: '97.23%', 2: '98.61%', 3: '99.59%', 4: '96.84%', 5: '99.10%'}\n",
      "Val Loss: 0.768672, Val Acc: 85.17%, Val-Class-Acc: {0: '86.41%', 1: '72.54%', 2: '87.50%', 3: '93.85%', 4: '82.50%', 5: '90.12%'}, LR: 0.000729\n",
      "Epoch 46/200, Train Loss: 0.025681, Train-Class-Acc: {0: '98.64%', 1: '99.33%', 2: '99.65%', 3: '99.80%', 4: '99.37%', 5: '99.78%'}\n",
      "Val Loss: 0.671761, Val Acc: 87.04%, Val-Class-Acc: {0: '79.89%', 1: '81.49%', 2: '85.42%', 3: '93.03%', 4: '82.50%', 5: '93.41%'}, LR: 0.000656\n",
      "Epoch 47/200, Train Loss: 0.012426, Train-Class-Acc: {0: '100.00%', 1: '99.55%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.685636, Val Acc: 87.82%, Val-Class-Acc: {0: '79.89%', 1: '83.28%', 2: '90.28%', 3: '91.39%', 4: '85.00%', 5: '93.41%'}, LR: 0.000656\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_4.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_47.pth\n",
      "Epoch 48/200, Train Loss: 0.008357, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '99.83%', 3: '99.90%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.674486, Val Acc: 87.67%, Val-Class-Acc: {0: '78.80%', 1: '82.09%', 2: '90.28%', 3: '93.44%', 4: '82.50%', 5: '93.41%'}, LR: 0.000656\n",
      "Epoch 49/200, Train Loss: 0.009581, Train-Class-Acc: {0: '100.00%', 1: '99.85%', 2: '99.83%', 3: '99.90%', 4: '100.00%', 5: '99.85%'}\n",
      "Val Loss: 0.713484, Val Acc: 87.12%, Val-Class-Acc: {0: '80.98%', 1: '82.39%', 2: '85.42%', 3: '91.80%', 4: '85.00%', 5: '92.81%'}, LR: 0.000656\n",
      "Epoch 50/200, Train Loss: 0.008079, Train-Class-Acc: {0: '99.86%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.745121, Val Acc: 87.28%, Val-Class-Acc: {0: '85.33%', 1: '79.10%', 2: '84.03%', 3: '91.80%', 4: '82.50%', 5: '95.21%'}, LR: 0.000656\n",
      "Epoch 51/200, Train Loss: 0.006517, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.730150, Val Acc: 86.73%, Val-Class-Acc: {0: '78.80%', 1: '80.30%', 2: '86.11%', 3: '93.44%', 4: '82.50%', 5: '93.41%'}, LR: 0.000656\n",
      "Epoch 52/200, Train Loss: 0.005875, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.725159, Val Acc: 86.81%, Val-Class-Acc: {0: '80.98%', 1: '80.30%', 2: '85.42%', 3: '91.39%', 4: '82.50%', 5: '94.31%'}, LR: 0.000656\n",
      "Epoch 53/200, Train Loss: 0.005502, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.712275, Val Acc: 87.20%, Val-Class-Acc: {0: '80.43%', 1: '81.19%', 2: '85.42%', 3: '92.21%', 4: '85.00%', 5: '94.31%'}, LR: 0.000656\n",
      "Epoch 54/200, Train Loss: 0.005339, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.717055, Val Acc: 87.28%, Val-Class-Acc: {0: '79.35%', 1: '81.19%', 2: '88.19%', 3: '92.62%', 4: '85.00%', 5: '93.71%'}, LR: 0.000656\n",
      "Epoch 55/200, Train Loss: 0.005147, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.729611, Val Acc: 87.04%, Val-Class-Acc: {0: '79.35%', 1: '80.30%', 2: '87.50%', 3: '92.62%', 4: '85.00%', 5: '94.01%'}, LR: 0.000656\n",
      "Epoch 56/200, Train Loss: 0.004983, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.737366, Val Acc: 86.96%, Val-Class-Acc: {0: '80.98%', 1: '79.40%', 2: '86.81%', 3: '93.03%', 4: '85.00%', 5: '93.71%'}, LR: 0.000656\n",
      "Epoch 57/200, Train Loss: 0.005107, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.729228, Val Acc: 87.12%, Val-Class-Acc: {0: '82.61%', 1: '80.30%', 2: '84.72%', 3: '93.03%', 4: '85.00%', 5: '93.41%'}, LR: 0.000590\n",
      "Epoch 58/200, Train Loss: 0.004690, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.732286, Val Acc: 86.81%, Val-Class-Acc: {0: '78.26%', 1: '81.79%', 2: '84.72%', 3: '92.21%', 4: '85.00%', 5: '93.71%'}, LR: 0.000590\n",
      "Epoch 59/200, Train Loss: 0.004493, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.737671, Val Acc: 87.04%, Val-Class-Acc: {0: '79.35%', 1: '81.79%', 2: '86.11%', 3: '92.62%', 4: '85.00%', 5: '93.11%'}, LR: 0.000590\n",
      "Epoch 60/200, Train Loss: 0.004460, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.735860, Val Acc: 87.35%, Val-Class-Acc: {0: '80.98%', 1: '81.79%', 2: '86.11%', 3: '92.21%', 4: '82.50%', 5: '94.01%'}, LR: 0.000590\n",
      "Epoch 61/200, Train Loss: 0.004295, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.738035, Val Acc: 87.35%, Val-Class-Acc: {0: '80.98%', 1: '82.39%', 2: '84.72%', 3: '92.62%', 4: '82.50%', 5: '93.71%'}, LR: 0.000590\n",
      "Epoch 62/200, Train Loss: 0.004166, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.744933, Val Acc: 87.74%, Val-Class-Acc: {0: '81.52%', 1: '81.19%', 2: '88.19%', 3: '92.62%', 4: '82.50%', 5: '94.61%'}, LR: 0.000590\n",
      "Epoch 63/200, Train Loss: 0.004072, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.741730, Val Acc: 87.12%, Val-Class-Acc: {0: '78.26%', 1: '82.39%', 2: '86.11%', 3: '92.62%', 4: '82.50%', 5: '93.71%'}, LR: 0.000590\n",
      "Epoch 64/200, Train Loss: 0.004030, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.756318, Val Acc: 87.35%, Val-Class-Acc: {0: '78.26%', 1: '83.58%', 2: '85.42%', 3: '92.62%', 4: '82.50%', 5: '93.71%'}, LR: 0.000590\n",
      "Epoch 65/200, Train Loss: 0.003881, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.750297, Val Acc: 87.12%, Val-Class-Acc: {0: '78.26%', 1: '82.09%', 2: '86.81%', 3: '92.62%', 4: '82.50%', 5: '93.71%'}, LR: 0.000590\n",
      "Epoch 66/200, Train Loss: 0.003814, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.748435, Val Acc: 87.20%, Val-Class-Acc: {0: '80.43%', 1: '81.49%', 2: '85.42%', 3: '92.62%', 4: '82.50%', 5: '94.01%'}, LR: 0.000590\n",
      "Epoch 67/200, Train Loss: 0.003707, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.760338, Val Acc: 87.35%, Val-Class-Acc: {0: '78.80%', 1: '82.69%', 2: '86.11%', 3: '92.62%', 4: '82.50%', 5: '94.01%'}, LR: 0.000590\n",
      "Epoch 68/200, Train Loss: 0.003752, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.746055, Val Acc: 87.43%, Val-Class-Acc: {0: '82.07%', 1: '81.19%', 2: '88.19%', 3: '92.21%', 4: '82.50%', 5: '93.41%'}, LR: 0.000531\n",
      "Epoch 69/200, Train Loss: 0.003556, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.753140, Val Acc: 87.59%, Val-Class-Acc: {0: '80.98%', 1: '81.49%', 2: '88.19%', 3: '91.80%', 4: '82.50%', 5: '94.61%'}, LR: 0.000531\n",
      "Epoch 70/200, Train Loss: 0.003519, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.761019, Val Acc: 87.43%, Val-Class-Acc: {0: '82.07%', 1: '80.90%', 2: '87.50%', 3: '92.62%', 4: '82.50%', 5: '93.71%'}, LR: 0.000531\n",
      "Epoch 71/200, Train Loss: 0.003422, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.770218, Val Acc: 87.51%, Val-Class-Acc: {0: '80.98%', 1: '81.49%', 2: '85.42%', 3: '92.62%', 4: '85.00%', 5: '94.61%'}, LR: 0.000531\n",
      "Epoch 72/200, Train Loss: 0.003360, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.766547, Val Acc: 87.04%, Val-Class-Acc: {0: '77.72%', 1: '82.39%', 2: '85.42%', 3: '92.21%', 4: '85.00%', 5: '94.01%'}, LR: 0.000531\n",
      "Epoch 73/200, Train Loss: 0.003291, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.772166, Val Acc: 87.20%, Val-Class-Acc: {0: '80.43%', 1: '81.19%', 2: '86.11%', 3: '92.62%', 4: '82.50%', 5: '94.01%'}, LR: 0.000531\n",
      "Epoch 74/200, Train Loss: 0.003244, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.761708, Val Acc: 87.20%, Val-Class-Acc: {0: '80.98%', 1: '81.49%', 2: '85.42%', 3: '92.21%', 4: '85.00%', 5: '93.71%'}, LR: 0.000531\n",
      "Epoch 75/200, Train Loss: 0.003225, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.772221, Val Acc: 87.12%, Val-Class-Acc: {0: '80.98%', 1: '81.49%', 2: '87.50%', 3: '90.57%', 4: '85.00%', 5: '93.71%'}, LR: 0.000531\n",
      "Epoch 76/200, Train Loss: 0.003122, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.765441, Val Acc: 87.12%, Val-Class-Acc: {0: '80.43%', 1: '81.79%', 2: '85.42%', 3: '92.62%', 4: '85.00%', 5: '93.11%'}, LR: 0.000531\n",
      "Epoch 77/200, Train Loss: 0.003052, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.789222, Val Acc: 86.73%, Val-Class-Acc: {0: '80.98%', 1: '80.30%', 2: '84.72%', 3: '91.80%', 4: '82.50%', 5: '94.01%'}, LR: 0.000531\n",
      "Epoch 78/200, Train Loss: 0.002982, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.790464, Val Acc: 86.81%, Val-Class-Acc: {0: '80.43%', 1: '80.90%', 2: '84.03%', 3: '92.21%', 4: '82.50%', 5: '94.01%'}, LR: 0.000531\n",
      "Epoch 79/200, Train Loss: 0.002915, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.797164, Val Acc: 86.89%, Val-Class-Acc: {0: '79.35%', 1: '82.09%', 2: '84.72%', 3: '92.21%', 4: '82.50%', 5: '93.41%'}, LR: 0.000478\n",
      "Epoch 80/200, Train Loss: 0.002858, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.794282, Val Acc: 87.20%, Val-Class-Acc: {0: '80.43%', 1: '81.19%', 2: '86.81%', 3: '92.62%', 4: '82.50%', 5: '93.71%'}, LR: 0.000478\n",
      "Epoch 81/200, Train Loss: 0.002830, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.799843, Val Acc: 86.96%, Val-Class-Acc: {0: '80.43%', 1: '81.49%', 2: '83.33%', 3: '92.21%', 4: '82.50%', 5: '94.31%'}, LR: 0.000478\n",
      "Epoch 82/200, Train Loss: 0.002770, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.795618, Val Acc: 87.28%, Val-Class-Acc: {0: '82.07%', 1: '80.90%', 2: '87.50%', 3: '91.80%', 4: '82.50%', 5: '93.71%'}, LR: 0.000478\n",
      "Epoch 83/200, Train Loss: 0.002731, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.801506, Val Acc: 87.35%, Val-Class-Acc: {0: '81.52%', 1: '80.60%', 2: '87.50%', 3: '92.62%', 4: '82.50%', 5: '94.01%'}, LR: 0.000478\n",
      "Epoch 84/200, Train Loss: 0.002741, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.781827, Val Acc: 87.43%, Val-Class-Acc: {0: '86.96%', 1: '80.00%', 2: '86.11%', 3: '92.62%', 4: '82.50%', 5: '92.51%'}, LR: 0.000478\n",
      "Epoch 85/200, Train Loss: 0.002912, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.829355, Val Acc: 86.73%, Val-Class-Acc: {0: '76.09%', 1: '82.69%', 2: '88.89%', 3: '90.16%', 4: '82.50%', 5: '93.71%'}, LR: 0.000478\n",
      "Epoch 86/200, Train Loss: 0.102570, Train-Class-Acc: {0: '96.19%', 1: '97.16%', 2: '97.23%', 3: '97.85%', 4: '95.57%', 5: '99.03%'}\n",
      "Val Loss: 1.031072, Val Acc: 79.31%, Val-Class-Acc: {0: '59.78%', 1: '70.75%', 2: '84.03%', 3: '90.98%', 4: '92.50%', 5: '86.53%'}, LR: 0.000478\n",
      "Epoch 87/200, Train Loss: 0.356210, Train-Class-Acc: {0: '82.83%', 1: '86.84%', 2: '89.60%', 3: '94.57%', 4: '86.71%', 5: '93.80%'}\n",
      "Val Loss: 0.574950, Val Acc: 84.54%, Val-Class-Acc: {0: '84.78%', 1: '82.09%', 2: '86.81%', 3: '85.25%', 4: '82.50%', 5: '85.63%'}, LR: 0.000478\n",
      "Epoch 88/200, Train Loss: 0.081246, Train-Class-Acc: {0: '96.59%', 1: '96.11%', 2: '99.13%', 3: '98.36%', 4: '96.84%', 5: '98.36%'}\n",
      "Val Loss: 0.600382, Val Acc: 86.57%, Val-Class-Acc: {0: '85.87%', 1: '78.51%', 2: '85.42%', 3: '92.21%', 4: '82.50%', 5: '91.92%'}, LR: 0.000478\n",
      "Epoch 89/200, Train Loss: 0.035261, Train-Class-Acc: {0: '98.91%', 1: '98.65%', 2: '98.96%', 3: '99.28%', 4: '99.37%', 5: '99.48%'}\n",
      "Val Loss: 0.761586, Val Acc: 85.09%, Val-Class-Acc: {0: '55.43%', 1: '84.78%', 2: '86.11%', 3: '93.44%', 4: '85.00%', 5: '95.21%'}, LR: 0.000478\n",
      "Epoch 90/200, Train Loss: 0.016164, Train-Class-Acc: {0: '100.00%', 1: '99.78%', 2: '99.83%', 3: '99.90%', 4: '99.37%', 5: '100.00%'}\n",
      "Val Loss: 0.683422, Val Acc: 86.49%, Val-Class-Acc: {0: '76.63%', 1: '82.69%', 2: '88.19%', 3: '88.93%', 4: '85.00%', 5: '93.41%'}, LR: 0.000430\n",
      "Epoch 91/200, Train Loss: 0.010669, Train-Class-Acc: {0: '99.86%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.658250, Val Acc: 87.43%, Val-Class-Acc: {0: '80.43%', 1: '80.90%', 2: '85.42%', 3: '92.62%', 4: '82.50%', 5: '95.51%'}, LR: 0.000430\n",
      "Epoch 92/200, Train Loss: 0.008181, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.687050, Val Acc: 87.59%, Val-Class-Acc: {0: '77.72%', 1: '84.48%', 2: '86.81%', 3: '91.39%', 4: '82.50%', 5: '94.31%'}, LR: 0.000430\n",
      "Epoch 93/200, Train Loss: 0.007392, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '99.37%', 5: '100.00%'}\n",
      "Val Loss: 0.689892, Val Acc: 86.96%, Val-Class-Acc: {0: '71.20%', 1: '85.07%', 2: '86.11%', 3: '91.39%', 4: '82.50%', 5: '95.21%'}, LR: 0.000430\n",
      "Epoch 94/200, Train Loss: 0.007364, Train-Class-Acc: {0: '99.73%', 1: '99.85%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.752445, Val Acc: 87.04%, Val-Class-Acc: {0: '70.65%', 1: '83.88%', 2: '84.03%', 3: '94.67%', 4: '82.50%', 5: '95.51%'}, LR: 0.000430\n",
      "Epoch 95/200, Train Loss: 0.007480, Train-Class-Acc: {0: '99.86%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.692282, Val Acc: 86.65%, Val-Class-Acc: {0: '72.83%', 1: '81.49%', 2: '86.81%', 3: '94.26%', 4: '82.50%', 5: '94.31%'}, LR: 0.000430\n",
      "Epoch 96/200, Train Loss: 0.005893, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.718135, Val Acc: 87.35%, Val-Class-Acc: {0: '76.63%', 1: '81.79%', 2: '85.42%', 3: '93.85%', 4: '82.50%', 5: '95.51%'}, LR: 0.000430\n",
      "Epoch 97/200, Train Loss: 0.005404, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.695226, Val Acc: 87.12%, Val-Class-Acc: {0: '78.26%', 1: '80.90%', 2: '86.11%', 3: '94.26%', 4: '82.50%', 5: '94.01%'}, LR: 0.000430\n",
      "Epoch 98/200, Train Loss: 0.005058, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.707679, Val Acc: 87.12%, Val-Class-Acc: {0: '78.80%', 1: '80.90%', 2: '86.11%', 3: '93.85%', 4: '82.50%', 5: '94.01%'}, LR: 0.000430\n",
      "Epoch 99/200, Train Loss: 0.004748, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.715660, Val Acc: 87.35%, Val-Class-Acc: {0: '79.35%', 1: '81.49%', 2: '86.11%', 3: '93.85%', 4: '82.50%', 5: '94.01%'}, LR: 0.000430\n",
      "Epoch 100/200, Train Loss: 0.004827, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.719008, Val Acc: 87.04%, Val-Class-Acc: {0: '79.35%', 1: '83.28%', 2: '84.72%', 3: '90.16%', 4: '82.50%', 5: '94.31%'}, LR: 0.000430\n",
      "Epoch 101/200, Train Loss: 0.004709, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.735440, Val Acc: 87.12%, Val-Class-Acc: {0: '78.26%', 1: '78.81%', 2: '87.50%', 3: '95.08%', 4: '82.50%', 5: '94.91%'}, LR: 0.000387\n",
      "Epoch 102/200, Train Loss: 0.004425, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.733433, Val Acc: 87.67%, Val-Class-Acc: {0: '76.09%', 1: '82.99%', 2: '86.11%', 3: '95.08%', 4: '82.50%', 5: '94.61%'}, LR: 0.000387\n",
      "Epoch 103/200, Train Loss: 0.004361, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.724813, Val Acc: 87.74%, Val-Class-Acc: {0: '79.35%', 1: '81.79%', 2: '86.11%', 3: '94.67%', 4: '82.50%', 5: '94.61%'}, LR: 0.000387\n",
      "Epoch 104/200, Train Loss: 0.004227, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.732640, Val Acc: 87.43%, Val-Class-Acc: {0: '78.26%', 1: '81.79%', 2: '85.42%', 3: '94.26%', 4: '82.50%', 5: '94.61%'}, LR: 0.000387\n",
      "Epoch 105/200, Train Loss: 0.004161, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.740643, Val Acc: 87.43%, Val-Class-Acc: {0: '76.63%', 1: '82.69%', 2: '84.72%', 3: '94.67%', 4: '82.50%', 5: '94.61%'}, LR: 0.000387\n",
      "Epoch 106/200, Train Loss: 0.004085, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.746210, Val Acc: 87.43%, Val-Class-Acc: {0: '77.72%', 1: '81.79%', 2: '85.42%', 3: '93.44%', 4: '82.50%', 5: '95.51%'}, LR: 0.000387\n",
      "Epoch 107/200, Train Loss: 0.003978, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.742833, Val Acc: 87.51%, Val-Class-Acc: {0: '78.26%', 1: '80.90%', 2: '86.11%', 3: '94.26%', 4: '82.50%', 5: '95.51%'}, LR: 0.000387\n",
      "Epoch 108/200, Train Loss: 0.003976, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.755250, Val Acc: 87.67%, Val-Class-Acc: {0: '77.17%', 1: '81.49%', 2: '86.81%', 3: '94.67%', 4: '82.50%', 5: '95.51%'}, LR: 0.000387\n",
      "Epoch 109/200, Train Loss: 0.003871, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.756936, Val Acc: 87.20%, Val-Class-Acc: {0: '77.17%', 1: '80.90%', 2: '86.81%', 3: '93.85%', 4: '82.50%', 5: '94.91%'}, LR: 0.000387\n",
      "Epoch 110/200, Train Loss: 0.003797, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.759803, Val Acc: 87.43%, Val-Class-Acc: {0: '77.17%', 1: '82.09%', 2: '85.42%', 3: '94.26%', 4: '82.50%', 5: '94.91%'}, LR: 0.000387\n",
      "Epoch 111/200, Train Loss: 0.003771, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.762311, Val Acc: 87.43%, Val-Class-Acc: {0: '75.54%', 1: '82.39%', 2: '86.11%', 3: '94.67%', 4: '82.50%', 5: '94.91%'}, LR: 0.000387\n",
      "Epoch 112/200, Train Loss: 0.003729, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.779922, Val Acc: 87.04%, Val-Class-Acc: {0: '80.98%', 1: '78.51%', 2: '86.11%', 3: '93.85%', 4: '82.50%', 5: '94.91%'}, LR: 0.000349\n",
      "Epoch 113/200, Train Loss: 0.003704, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.795429, Val Acc: 86.65%, Val-Class-Acc: {0: '77.72%', 1: '79.40%', 2: '84.72%', 3: '93.85%', 4: '82.50%', 5: '94.91%'}, LR: 0.000349\n",
      "Epoch 114/200, Train Loss: 0.003580, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.792925, Val Acc: 86.34%, Val-Class-Acc: {0: '75.54%', 1: '80.30%', 2: '85.42%', 3: '92.62%', 4: '82.50%', 5: '94.61%'}, LR: 0.000349\n",
      "Epoch 115/200, Train Loss: 0.003564, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.792517, Val Acc: 86.49%, Val-Class-Acc: {0: '76.09%', 1: '80.00%', 2: '84.72%', 3: '93.03%', 4: '82.50%', 5: '95.21%'}, LR: 0.000349\n",
      "Epoch 116/200, Train Loss: 0.003511, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.808516, Val Acc: 86.42%, Val-Class-Acc: {0: '75.54%', 1: '79.40%', 2: '84.72%', 3: '93.85%', 4: '82.50%', 5: '95.21%'}, LR: 0.000349\n",
      "Epoch 117/200, Train Loss: 0.003453, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.793388, Val Acc: 87.20%, Val-Class-Acc: {0: '77.17%', 1: '81.19%', 2: '85.42%', 3: '93.85%', 4: '82.50%', 5: '95.21%'}, LR: 0.000349\n",
      "Epoch 118/200, Train Loss: 0.003416, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.789234, Val Acc: 87.04%, Val-Class-Acc: {0: '78.26%', 1: '80.00%', 2: '86.81%', 3: '94.26%', 4: '82.50%', 5: '94.31%'}, LR: 0.000349\n",
      "Epoch 119/200, Train Loss: 0.003345, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.796947, Val Acc: 87.04%, Val-Class-Acc: {0: '78.26%', 1: '80.60%', 2: '85.42%', 3: '94.26%', 4: '82.50%', 5: '94.31%'}, LR: 0.000349\n",
      "Epoch 120/200, Train Loss: 0.003288, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.799881, Val Acc: 87.04%, Val-Class-Acc: {0: '76.63%', 1: '81.19%', 2: '85.42%', 3: '94.26%', 4: '82.50%', 5: '94.61%'}, LR: 0.000349\n",
      "Epoch 121/200, Train Loss: 0.003250, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.794412, Val Acc: 86.73%, Val-Class-Acc: {0: '77.17%', 1: '80.60%', 2: '85.42%', 3: '94.26%', 4: '82.50%', 5: '93.71%'}, LR: 0.000349\n",
      "Epoch 122/200, Train Loss: 0.003221, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.802625, Val Acc: 86.81%, Val-Class-Acc: {0: '79.35%', 1: '79.40%', 2: '85.42%', 3: '94.26%', 4: '82.50%', 5: '94.01%'}, LR: 0.000349\n",
      "Epoch 123/200, Train Loss: 0.003181, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.815002, Val Acc: 86.89%, Val-Class-Acc: {0: '75.00%', 1: '81.79%', 2: '84.72%', 3: '94.26%', 4: '82.50%', 5: '94.61%'}, LR: 0.000314\n",
      "Epoch 124/200, Train Loss: 0.003120, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.812009, Val Acc: 86.96%, Val-Class-Acc: {0: '76.63%', 1: '80.90%', 2: '85.42%', 3: '94.26%', 4: '82.50%', 5: '94.61%'}, LR: 0.000314\n",
      "Epoch 125/200, Train Loss: 0.003071, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.814497, Val Acc: 86.89%, Val-Class-Acc: {0: '76.63%', 1: '80.60%', 2: '85.42%', 3: '94.26%', 4: '82.50%', 5: '94.61%'}, LR: 0.000314\n",
      "Epoch 126/200, Train Loss: 0.003033, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.809022, Val Acc: 86.73%, Val-Class-Acc: {0: '76.63%', 1: '80.60%', 2: '84.72%', 3: '93.85%', 4: '82.50%', 5: '94.61%'}, LR: 0.000314\n",
      "Epoch 127/200, Train Loss: 0.002996, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.817383, Val Acc: 86.81%, Val-Class-Acc: {0: '77.17%', 1: '80.90%', 2: '85.42%', 3: '93.03%', 4: '82.50%', 5: '94.61%'}, LR: 0.000314\n",
      "Epoch 128/200, Train Loss: 0.002960, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.820681, Val Acc: 86.73%, Val-Class-Acc: {0: '77.72%', 1: '80.00%', 2: '85.42%', 3: '93.85%', 4: '82.50%', 5: '94.31%'}, LR: 0.000314\n",
      "Epoch 129/200, Train Loss: 0.002929, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.833995, Val Acc: 86.49%, Val-Class-Acc: {0: '73.91%', 1: '81.19%', 2: '86.11%', 3: '93.44%', 4: '82.50%', 5: '94.31%'}, LR: 0.000314\n",
      "Epoch 130/200, Train Loss: 0.002894, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.836619, Val Acc: 86.96%, Val-Class-Acc: {0: '78.26%', 1: '80.00%', 2: '86.11%', 3: '93.44%', 4: '82.50%', 5: '94.91%'}, LR: 0.000314\n",
      "Epoch 131/200, Train Loss: 0.002854, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.827559, Val Acc: 86.18%, Val-Class-Acc: {0: '75.54%', 1: '80.90%', 2: '84.72%', 3: '93.85%', 4: '82.50%', 5: '92.81%'}, LR: 0.000314\n",
      "Epoch 132/200, Train Loss: 0.095341, Train-Class-Acc: {0: '95.10%', 1: '97.01%', 2: '97.75%', 3: '98.05%', 4: '96.84%', 5: '98.43%'}\n",
      "Val Loss: 0.955143, Val Acc: 81.34%, Val-Class-Acc: {0: '85.87%', 1: '62.39%', 2: '84.72%', 3: '94.26%', 4: '82.50%', 5: '86.83%'}, LR: 0.000314\n",
      "Epoch 133/200, Train Loss: 0.193056, Train-Class-Acc: {0: '91.96%', 1: '92.30%', 2: '96.53%', 3: '96.52%', 4: '91.14%', 5: '95.37%'}\n",
      "Val Loss: 0.670743, Val Acc: 85.64%, Val-Class-Acc: {0: '67.93%', 1: '81.79%', 2: '88.19%', 3: '90.57%', 4: '82.50%', 5: '94.91%'}, LR: 0.000314\n",
      "Epoch 134/200, Train Loss: 0.032692, Train-Class-Acc: {0: '99.46%', 1: '99.25%', 2: '99.65%', 3: '99.08%', 4: '98.10%', 5: '99.48%'}\n",
      "Val Loss: 0.688374, Val Acc: 86.81%, Val-Class-Acc: {0: '76.09%', 1: '81.19%', 2: '81.25%', 3: '93.44%', 4: '85.00%', 5: '96.11%'}, LR: 0.000282\n",
      "Epoch 135/200, Train Loss: 0.011860, Train-Class-Acc: {0: '99.86%', 1: '99.93%', 2: '99.65%', 3: '100.00%', 4: '99.37%', 5: '100.00%'}\n",
      "Val Loss: 0.691516, Val Acc: 86.49%, Val-Class-Acc: {0: '75.54%', 1: '80.90%', 2: '86.81%', 3: '92.21%', 4: '85.00%', 5: '94.01%'}, LR: 0.000282\n",
      "Epoch 136/200, Train Loss: 0.007208, Train-Class-Acc: {0: '99.86%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.691357, Val Acc: 86.26%, Val-Class-Acc: {0: '77.72%', 1: '80.30%', 2: '84.72%', 3: '92.21%', 4: '85.00%', 5: '93.41%'}, LR: 0.000282\n",
      "Epoch 137/200, Train Loss: 0.006244, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.716725, Val Acc: 86.57%, Val-Class-Acc: {0: '79.89%', 1: '79.40%', 2: '84.72%', 3: '93.44%', 4: '85.00%', 5: '93.41%'}, LR: 0.000282\n",
      "Epoch 138/200, Train Loss: 0.007639, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '99.48%', 3: '100.00%', 4: '100.00%', 5: '99.85%'}\n",
      "Val Loss: 0.735020, Val Acc: 85.71%, Val-Class-Acc: {0: '75.54%', 1: '77.91%', 2: '92.36%', 3: '93.03%', 4: '85.00%', 5: '91.02%'}, LR: 0.000282\n",
      "Epoch 139/200, Train Loss: 0.006213, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.734598, Val Acc: 86.03%, Val-Class-Acc: {0: '75.54%', 1: '79.10%', 2: '86.11%', 3: '92.62%', 4: '85.00%', 5: '94.01%'}, LR: 0.000282\n",
      "Epoch 140/200, Train Loss: 0.005352, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.748041, Val Acc: 86.34%, Val-Class-Acc: {0: '76.63%', 1: '80.60%', 2: '86.81%', 3: '93.03%', 4: '85.00%', 5: '92.51%'}, LR: 0.000282\n",
      "Epoch 141/200, Train Loss: 0.004667, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.750056, Val Acc: 86.18%, Val-Class-Acc: {0: '77.72%', 1: '79.40%', 2: '82.64%', 3: '93.03%', 4: '85.00%', 5: '94.31%'}, LR: 0.000282\n",
      "Epoch 142/200, Train Loss: 0.004627, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.741521, Val Acc: 86.49%, Val-Class-Acc: {0: '76.09%', 1: '80.90%', 2: '86.81%', 3: '91.80%', 4: '85.00%', 5: '94.01%'}, LR: 0.000282\n",
      "Epoch 143/200, Train Loss: 0.004327, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.753879, Val Acc: 86.42%, Val-Class-Acc: {0: '79.89%', 1: '78.51%', 2: '84.72%', 3: '93.85%', 4: '85.00%', 5: '93.41%'}, LR: 0.000282\n",
      "Epoch 144/200, Train Loss: 0.004244, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.750723, Val Acc: 86.81%, Val-Class-Acc: {0: '81.52%', 1: '78.51%', 2: '86.11%', 3: '93.44%', 4: '85.00%', 5: '93.71%'}, LR: 0.000282\n",
      "Epoch 145/200, Train Loss: 0.004087, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.759745, Val Acc: 86.57%, Val-Class-Acc: {0: '79.35%', 1: '79.10%', 2: '85.42%', 3: '93.44%', 4: '85.00%', 5: '93.71%'}, LR: 0.000254\n",
      "Epoch 146/200, Train Loss: 0.003933, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.762077, Val Acc: 86.42%, Val-Class-Acc: {0: '77.17%', 1: '79.10%', 2: '85.42%', 3: '93.44%', 4: '85.00%', 5: '94.31%'}, LR: 0.000254\n",
      "Epoch 147/200, Train Loss: 0.003918, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.761463, Val Acc: 86.65%, Val-Class-Acc: {0: '75.00%', 1: '80.90%', 2: '86.81%', 3: '93.44%', 4: '85.00%', 5: '94.01%'}, LR: 0.000254\n",
      "Epoch 148/200, Train Loss: 0.004792, Train-Class-Acc: {0: '99.86%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.769721, Val Acc: 86.49%, Val-Class-Acc: {0: '84.78%', 1: '76.12%', 2: '84.03%', 3: '93.03%', 4: '85.00%', 5: '94.31%'}, LR: 0.000254\n",
      "Epoch 149/200, Train Loss: 0.004118, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.766122, Val Acc: 86.10%, Val-Class-Acc: {0: '77.17%', 1: '79.40%', 2: '84.03%', 3: '93.44%', 4: '85.00%', 5: '93.41%'}, LR: 0.000254\n",
      "Epoch 150/200, Train Loss: 0.004072, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.772555, Val Acc: 86.65%, Val-Class-Acc: {0: '76.09%', 1: '81.49%', 2: '85.42%', 3: '92.21%', 4: '82.50%', 5: '94.61%'}, LR: 0.000254\n",
      "Epoch 151/200, Train Loss: 0.004457, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.785930, Val Acc: 86.34%, Val-Class-Acc: {0: '76.09%', 1: '80.90%', 2: '85.42%', 3: '93.03%', 4: '85.00%', 5: '93.11%'}, LR: 0.000254\n",
      "Epoch 152/200, Train Loss: 0.003878, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.788653, Val Acc: 86.73%, Val-Class-Acc: {0: '77.17%', 1: '81.79%', 2: '85.42%', 3: '92.62%', 4: '82.50%', 5: '93.71%'}, LR: 0.000254\n",
      "Epoch 153/200, Train Loss: 0.003812, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.793362, Val Acc: 86.73%, Val-Class-Acc: {0: '78.26%', 1: '81.49%', 2: '84.03%', 3: '93.03%', 4: '82.50%', 5: '93.71%'}, LR: 0.000254\n",
      "Epoch 154/200, Train Loss: 0.003689, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.786854, Val Acc: 86.73%, Val-Class-Acc: {0: '79.35%', 1: '80.90%', 2: '85.42%', 3: '93.03%', 4: '82.50%', 5: '93.11%'}, LR: 0.000254\n",
      "Epoch 155/200, Train Loss: 0.003558, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.800753, Val Acc: 86.42%, Val-Class-Acc: {0: '77.72%', 1: '80.30%', 2: '84.72%', 3: '93.03%', 4: '82.50%', 5: '93.71%'}, LR: 0.000254\n",
      "Epoch 156/200, Train Loss: 0.003600, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.800201, Val Acc: 86.42%, Val-Class-Acc: {0: '78.80%', 1: '80.00%', 2: '84.03%', 3: '93.03%', 4: '82.50%', 5: '93.71%'}, LR: 0.000229\n",
      "Epoch 157/200, Train Loss: 0.003470, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.804371, Val Acc: 86.10%, Val-Class-Acc: {0: '77.72%', 1: '80.00%', 2: '82.64%', 3: '93.03%', 4: '82.50%', 5: '93.71%'}, LR: 0.000229\n",
      "Epoch 158/200, Train Loss: 0.003484, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.813897, Val Acc: 86.03%, Val-Class-Acc: {0: '77.72%', 1: '79.10%', 2: '82.64%', 3: '93.03%', 4: '82.50%', 5: '94.31%'}, LR: 0.000229\n",
      "Epoch 159/200, Train Loss: 0.003447, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.819811, Val Acc: 86.57%, Val-Class-Acc: {0: '78.26%', 1: '81.79%', 2: '84.72%', 3: '91.80%', 4: '82.50%', 5: '93.41%'}, LR: 0.000229\n",
      "Epoch 160/200, Train Loss: 0.003393, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.817222, Val Acc: 86.57%, Val-Class-Acc: {0: '77.72%', 1: '81.19%', 2: '84.03%', 3: '93.03%', 4: '82.50%', 5: '93.71%'}, LR: 0.000229\n",
      "Epoch 161/200, Train Loss: 0.003416, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.822691, Val Acc: 86.49%, Val-Class-Acc: {0: '76.09%', 1: '81.49%', 2: '85.42%', 3: '93.03%', 4: '82.50%', 5: '93.41%'}, LR: 0.000229\n",
      "Epoch 162/200, Train Loss: 0.003366, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.825528, Val Acc: 86.49%, Val-Class-Acc: {0: '75.00%', 1: '82.39%', 2: '84.03%', 3: '93.03%', 4: '82.50%', 5: '93.71%'}, LR: 0.000229\n",
      "Epoch 163/200, Train Loss: 0.003336, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.808655, Val Acc: 85.95%, Val-Class-Acc: {0: '78.26%', 1: '77.91%', 2: '85.42%', 3: '93.03%', 4: '82.50%', 5: '93.71%'}, LR: 0.000229\n",
      "Epoch 164/200, Train Loss: 0.003267, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.820479, Val Acc: 86.34%, Val-Class-Acc: {0: '77.72%', 1: '79.10%', 2: '86.11%', 3: '93.03%', 4: '82.50%', 5: '94.01%'}, LR: 0.000229\n",
      "Epoch 165/200, Train Loss: 0.003246, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.827556, Val Acc: 86.42%, Val-Class-Acc: {0: '77.72%', 1: '80.00%', 2: '84.72%', 3: '93.03%', 4: '85.00%', 5: '93.71%'}, LR: 0.000229\n",
      "Epoch 166/200, Train Loss: 0.003199, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.829577, Val Acc: 86.10%, Val-Class-Acc: {0: '78.26%', 1: '78.81%', 2: '84.03%', 3: '93.03%', 4: '85.00%', 5: '93.71%'}, LR: 0.000229\n",
      "Epoch 167/200, Train Loss: 0.003156, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.820616, Val Acc: 86.65%, Val-Class-Acc: {0: '78.26%', 1: '80.30%', 2: '85.42%', 3: '92.62%', 4: '85.00%', 5: '94.01%'}, LR: 0.000206\n",
      "Epoch 168/200, Train Loss: 0.003171, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.836964, Val Acc: 86.34%, Val-Class-Acc: {0: '77.72%', 1: '79.40%', 2: '87.50%', 3: '92.62%', 4: '85.00%', 5: '93.11%'}, LR: 0.000206\n",
      "Epoch 169/200, Train Loss: 0.003111, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.840588, Val Acc: 86.65%, Val-Class-Acc: {0: '78.26%', 1: '80.00%', 2: '86.81%', 3: '93.03%', 4: '85.00%', 5: '93.41%'}, LR: 0.000206\n",
      "Epoch 170/200, Train Loss: 0.003101, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.849266, Val Acc: 86.42%, Val-Class-Acc: {0: '77.72%', 1: '80.30%', 2: '82.64%', 3: '93.44%', 4: '82.50%', 5: '94.31%'}, LR: 0.000206\n",
      "Epoch 171/200, Train Loss: 0.003070, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.845352, Val Acc: 86.49%, Val-Class-Acc: {0: '78.26%', 1: '79.40%', 2: '85.42%', 3: '93.03%', 4: '82.50%', 5: '94.31%'}, LR: 0.000206\n",
      "Epoch 172/200, Train Loss: 0.003035, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.849613, Val Acc: 86.73%, Val-Class-Acc: {0: '77.17%', 1: '80.60%', 2: '84.03%', 3: '93.85%', 4: '85.00%', 5: '94.31%'}, LR: 0.000206\n",
      "Epoch 173/200, Train Loss: 0.003005, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.844885, Val Acc: 86.49%, Val-Class-Acc: {0: '77.72%', 1: '79.40%', 2: '84.72%', 3: '93.44%', 4: '85.00%', 5: '94.31%'}, LR: 0.000206\n",
      "Epoch 174/200, Train Loss: 0.002974, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.835463, Val Acc: 86.57%, Val-Class-Acc: {0: '77.72%', 1: '79.10%', 2: '86.11%', 3: '93.44%', 4: '85.00%', 5: '94.31%'}, LR: 0.000206\n",
      "Epoch 175/200, Train Loss: 0.002946, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.850196, Val Acc: 86.65%, Val-Class-Acc: {0: '77.72%', 1: '79.70%', 2: '85.42%', 3: '93.44%', 4: '85.00%', 5: '94.31%'}, LR: 0.000206\n",
      "Epoch 176/200, Train Loss: 0.002937, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.858663, Val Acc: 86.26%, Val-Class-Acc: {0: '76.63%', 1: '80.00%', 2: '85.42%', 3: '93.44%', 4: '82.50%', 5: '93.41%'}, LR: 0.000206\n",
      "Epoch 177/200, Train Loss: 0.002923, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.857460, Val Acc: 86.57%, Val-Class-Acc: {0: '77.72%', 1: '80.30%', 2: '85.42%', 3: '93.03%', 4: '82.50%', 5: '94.01%'}, LR: 0.000206\n",
      "Epoch 178/200, Train Loss: 0.002881, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.860846, Val Acc: 86.10%, Val-Class-Acc: {0: '78.80%', 1: '78.81%', 2: '84.72%', 3: '93.44%', 4: '82.50%', 5: '93.11%'}, LR: 0.000185\n",
      "Epoch 179/200, Train Loss: 0.002876, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.864043, Val Acc: 86.34%, Val-Class-Acc: {0: '77.17%', 1: '80.00%', 2: '84.72%', 3: '93.44%', 4: '85.00%', 5: '93.41%'}, LR: 0.000185\n",
      "Epoch 180/200, Train Loss: 0.002842, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.870637, Val Acc: 86.34%, Val-Class-Acc: {0: '78.80%', 1: '78.51%', 2: '85.42%', 3: '93.44%', 4: '85.00%', 5: '93.71%'}, LR: 0.000185\n",
      "Epoch 181/200, Train Loss: 0.002840, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.847514, Val Acc: 86.57%, Val-Class-Acc: {0: '78.26%', 1: '80.00%', 2: '86.11%', 3: '92.62%', 4: '85.00%', 5: '93.71%'}, LR: 0.000185\n",
      "Epoch 182/200, Train Loss: 0.002795, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.858845, Val Acc: 86.73%, Val-Class-Acc: {0: '78.26%', 1: '80.60%', 2: '84.72%', 3: '93.03%', 4: '85.00%', 5: '94.01%'}, LR: 0.000185\n",
      "Epoch 183/200, Train Loss: 0.002789, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.883860, Val Acc: 86.10%, Val-Class-Acc: {0: '78.26%', 1: '79.70%', 2: '81.25%', 3: '93.44%', 4: '82.50%', 5: '94.01%'}, LR: 0.000185\n",
      "Epoch 184/200, Train Loss: 0.002759, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.869098, Val Acc: 86.57%, Val-Class-Acc: {0: '78.26%', 1: '80.00%', 2: '84.03%', 3: '93.44%', 4: '85.00%', 5: '94.01%'}, LR: 0.000185\n",
      "Epoch 185/200, Train Loss: 0.002743, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.870636, Val Acc: 86.42%, Val-Class-Acc: {0: '78.26%', 1: '80.60%', 2: '83.33%', 3: '92.62%', 4: '85.00%', 5: '93.71%'}, LR: 0.000185\n",
      "Epoch 186/200, Train Loss: 0.002724, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.857234, Val Acc: 86.57%, Val-Class-Acc: {0: '77.72%', 1: '80.00%', 2: '85.42%', 3: '93.44%', 4: '85.00%', 5: '93.71%'}, LR: 0.000185\n",
      "Epoch 187/200, Train Loss: 0.002691, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.874481, Val Acc: 86.34%, Val-Class-Acc: {0: '78.26%', 1: '79.10%', 2: '85.42%', 3: '93.44%', 4: '82.50%', 5: '93.71%'}, LR: 0.000185\n",
      "Epoch 188/200, Train Loss: 0.002662, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.902600, Val Acc: 86.65%, Val-Class-Acc: {0: '77.17%', 1: '80.90%', 2: '84.72%', 3: '93.44%', 4: '85.00%', 5: '93.71%'}, LR: 0.000185\n",
      "Epoch 189/200, Train Loss: 0.002659, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.879545, Val Acc: 86.49%, Val-Class-Acc: {0: '78.80%', 1: '78.51%', 2: '86.81%', 3: '93.44%', 4: '85.00%', 5: '93.71%'}, LR: 0.000167\n",
      "Epoch 190/200, Train Loss: 0.002651, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.882067, Val Acc: 86.26%, Val-Class-Acc: {0: '78.26%', 1: '79.10%', 2: '84.03%', 3: '93.44%', 4: '85.00%', 5: '93.71%'}, LR: 0.000167\n",
      "Epoch 191/200, Train Loss: 0.002628, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.883042, Val Acc: 86.42%, Val-Class-Acc: {0: '77.17%', 1: '79.10%', 2: '86.81%', 3: '93.44%', 4: '82.50%', 5: '94.01%'}, LR: 0.000167\n",
      "Epoch 192/200, Train Loss: 0.002592, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.899889, Val Acc: 86.42%, Val-Class-Acc: {0: '78.26%', 1: '79.70%', 2: '84.03%', 3: '93.44%', 4: '85.00%', 5: '93.71%'}, LR: 0.000167\n",
      "Epoch 193/200, Train Loss: 0.002575, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.900947, Val Acc: 86.49%, Val-Class-Acc: {0: '78.80%', 1: '80.00%', 2: '84.03%', 3: '93.44%', 4: '85.00%', 5: '93.41%'}, LR: 0.000167\n",
      "Epoch 194/200, Train Loss: 0.002543, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.916011, Val Acc: 86.18%, Val-Class-Acc: {0: '78.80%', 1: '79.70%', 2: '82.64%', 3: '93.44%', 4: '82.50%', 5: '93.41%'}, LR: 0.000167\n",
      "Epoch 195/200, Train Loss: 0.002531, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.923275, Val Acc: 86.03%, Val-Class-Acc: {0: '78.80%', 1: '78.51%', 2: '84.03%', 3: '93.44%', 4: '82.50%', 5: '93.41%'}, LR: 0.000167\n",
      "Epoch 196/200, Train Loss: 0.002511, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.918534, Val Acc: 86.10%, Val-Class-Acc: {0: '78.80%', 1: '79.10%', 2: '84.72%', 3: '93.44%', 4: '85.00%', 5: '92.51%'}, LR: 0.000167\n",
      "Epoch 197/200, Train Loss: 0.002543, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.925838, Val Acc: 86.34%, Val-Class-Acc: {0: '77.72%', 1: '80.30%', 2: '84.03%', 3: '93.03%', 4: '82.50%', 5: '93.71%'}, LR: 0.000167\n",
      "Epoch 198/200, Train Loss: 0.028562, Train-Class-Acc: {0: '99.05%', 1: '99.18%', 2: '98.61%', 3: '99.69%', 4: '98.73%', 5: '99.48%'}\n",
      "Val Loss: 0.989441, Val Acc: 84.23%, Val-Class-Acc: {0: '73.91%', 1: '72.84%', 2: '82.64%', 3: '95.08%', 4: '82.50%', 5: '94.31%'}, LR: 0.000167\n",
      "Epoch 199/200, Train Loss: 0.076791, Train-Class-Acc: {0: '96.59%', 1: '96.78%', 2: '98.09%', 3: '98.36%', 4: '98.73%', 5: '98.65%'}\n",
      "Val Loss: 0.881006, Val Acc: 85.01%, Val-Class-Acc: {0: '79.35%', 1: '75.22%', 2: '85.42%', 3: '93.03%', 4: '75.00%', 5: '93.11%'}, LR: 0.000167\n",
      "Epoch 200/200, Train Loss: 0.022306, Train-Class-Acc: {0: '99.18%', 1: '99.18%', 2: '99.13%', 3: '99.69%', 4: '98.10%', 5: '99.55%'}\n",
      "Val Loss: 0.762179, Val Acc: 86.10%, Val-Class-Acc: {0: '77.17%', 1: '80.90%', 2: '90.97%', 3: '91.39%', 4: '85.00%', 5: '90.42%'}, LR: 0.000150\n",
      "\n",
      "üèÜ Best model saved as: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_best.pth (Val Accuracy: 88.06%)\n",
      "\n",
      "üìå Final model saved as: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_final.pth\n",
      "\n",
      "üéØ Top 5 Best Models:\n",
      "Epoch 23, Train Loss: 0.026478, Train-Acc: {0: '98.91%', 1: '98.95%', 2: '99.31%', 3: '99.59%', 4: '98.73%', 5: '99.70%'},\n",
      "Val Loss: 0.636669, Val Acc: 88.06%, Val-Acc: {0: '89.13%', 1: '80.60%', 2: '87.50%', 3: '92.62%', 4: '80.00%', 5: '92.81%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_23.pth\n",
      "Epoch 47, Train Loss: 0.012426, Train-Acc: {0: '100.00%', 1: '99.55%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%'},\n",
      "Val Loss: 0.685636, Val Acc: 87.82%, Val-Acc: {0: '79.89%', 1: '83.28%', 2: '90.28%', 3: '91.39%', 4: '85.00%', 5: '93.41%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_47.pth\n",
      "Epoch 5, Train Loss: 0.215030, Train-Acc: {0: '90.33%', 1: '89.60%', 2: '94.63%', 3: '96.52%', 4: '89.24%', 5: '95.37%'},\n",
      "Val Loss: 0.427990, Val Acc: 87.82%, Val-Acc: {0: '88.59%', 1: '78.21%', 2: '93.75%', 3: '94.26%', 4: '85.00%', 5: '90.12%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_5.pth\n",
      "Epoch 33, Train Loss: 0.017017, Train-Acc: {0: '99.59%', 1: '99.48%', 2: '99.65%', 3: '99.90%', 4: '100.00%', 5: '99.78%'},\n",
      "Val Loss: 0.665613, Val Acc: 87.74%, Val-Acc: {0: '78.80%', 1: '81.19%', 2: '94.44%', 3: '92.62%', 4: '82.50%', 5: '93.41%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_33.pth\n",
      "Epoch 32, Train Loss: 0.021410, Train-Acc: {0: '99.32%', 1: '99.33%', 2: '99.83%', 3: '99.80%', 4: '100.00%', 5: '99.85%'},\n",
      "Val Loss: 0.616755, Val Acc: 87.74%, Val-Acc: {0: '86.41%', 1: '80.00%', 2: '88.89%', 3: '93.44%', 4: '85.00%', 5: '91.92%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3/ResNet18_1D_epoch_32.pth\n",
      "\n",
      "üß† Model Summary:\n",
      "Total Parameters: 3,861,126\n",
      "Model Size (float32): 14.73 MB\n",
      "Total Training Time: 805.57 seconds\n",
      "---\n",
      "### Period 3\n",
      "+ ##### Total training time: 805.57 seconds\n",
      "+ ##### Model: ResNet18_1D\n",
      "+ ##### Training and saving in *'/mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_3'*\n",
      "+ ##### Best Epoch: 23\n",
      "#### __Val Accuracy: 88.06%__\n",
      "#### __Val-Class-Acc: {0: '89.13%', 1: '80.60%', 2: '87.50%', 3: '92.62%', 4: '80.00%', 5: '92.81%'}__\n",
      "#### __Total Parameters: 3,861,126__\n",
      "#### __Model Size (float32): 14.73 MB__\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# üìå Period 3: EWC Training (Protect Period 2)\n",
    "# ================================\n",
    "period = 3\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.join(BASE_DIR, \"stop_training.txt\")\n",
    "model_saving_folder = os.path.join(BASE_DIR, \"Trained_models\", \"EWC_CIL_v1\", f\"Period_{period}\")\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Load Period 3 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, f\"X_train_p{period}.npy\"))\n",
    "y_train = np.load(os.path.join(save_dir, f\"y_train_p{period}.npy\"))\n",
    "X_val   = np.load(os.path.join(save_dir, f\"X_test_p{period}.npy\"))\n",
    "y_val   = np.load(os.path.join(save_dir, f\"y_test_p{period}.npy\"))\n",
    "\n",
    "# ==== Device ====\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "# ==== Model Configuration ====\n",
    "input_channels = X_train.shape[2]\n",
    "output_size = len(np.unique(y_train))\n",
    "model = ResNet18_1D(input_channels=input_channels, output_size=output_size).to(device)\n",
    "\n",
    "# ==== Load Period 2 Best Model Weights ====\n",
    "prev_model_path = os.path.join(BASE_DIR, \"Trained_models\", \"EWC_CIL_v1\", \"Period_2\", \"ResNet18_1D_best.pth\")\n",
    "prev_checkpoint = torch.load(prev_model_path, map_location=device)\n",
    "state_dict = prev_checkpoint[\"model_state_dict\"]\n",
    "model_dict = model.state_dict()\n",
    "filtered_dict = {k: v for k, v in state_dict.items() if k in model_dict and model_dict[k].shape == v.shape}\n",
    "model.load_state_dict(filtered_dict, strict=False)\n",
    "for k in model_dict:\n",
    "    if k not in filtered_dict:\n",
    "        print(f\"üîç Not loaded: {k}, shape={model_dict[k].shape}\")\n",
    "print(\"‚úÖ Loaded Period 2 weights (except FC mismatch)\")\n",
    "\n",
    "# ==== Prepare EWC (from Period 2 training data) ====\n",
    "X_prev = np.load(os.path.join(save_dir, \"X_train_p2.npy\"))\n",
    "y_prev = np.load(os.path.join(save_dir, \"y_train_p2.npy\"))\n",
    "train_loader_prev = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_prev, dtype=torch.float32), torch.tensor(y_prev, dtype=torch.long)),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fisher_dict, params_dict = EWC.compute_fisher_and_params(model, train_loader_prev, criterion, device=device)\n",
    "ewc_state = EWC(fisher=fisher_dict, params=params_dict)\n",
    "print(\"üìà Fisher information computed from Period 2\")\n",
    "\n",
    "# ==== Optimizer / Scheduler ====\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "lambda_ewc = 1.0\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# ==== Training ====\n",
    "train_with_ewc_ecg(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name=\"ResNet18_1D\",\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    ewc=ewc_state,\n",
    "    lambda_ewc=lambda_ewc,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del X_train, y_train, X_val, y_val, X_prev, y_prev\n",
    "del prev_model_path, prev_checkpoint, state_dict, model_dict, filtered_dict\n",
    "del model, train_loader_prev, fisher_dict, params_dict, ewc_state\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bed76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Automatically selected GPU:\n",
      "    - CUDA Device ID : 2\n",
      "    - Memory Used    : 923 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "‚úÖ Loaded Period 2 weights (except FC mismatch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_321925/4113748664.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  prev_checkpoint = torch.load(prev_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Class Weights (normalized):\n",
      "  - Class 0: 0.1141\n",
      "  - Class 1: 0.0626\n",
      "  - Class 2: 0.1451\n",
      "  - Class 3: 0.0858\n",
      "  - Class 4: 0.5299\n",
      "  - Class 5: 0.0626\n",
      "üìà Fisher information computed from Period 2\n",
      "\n",
      "üöÄ 'train_with_ewc_ecg' started.\n",
      "‚úÖ Removed existing folder: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3\n",
      "\n",
      "‚úÖ Data Overview:\n",
      "X_train: torch.Size([5120, 5000, 12]), y_train: torch.Size([5120])\n",
      "X_val: torch.Size([1281, 5000, 12]), y_val: torch.Size([1281])\n",
      "Epoch 1/200, Train Loss: 0.789265, Train-Class-Acc: {0: '78.34%', 1: '60.88%', 2: '83.71%', 3: '85.14%', 4: '76.58%', 5: '82.66%'}\n",
      "Val Loss: 0.476409, Val Acc: 83.53%, Val-Class-Acc: {0: '95.11%', 1: '60.30%', 2: '84.03%', 3: '91.39%', 4: '87.50%', 5: '94.01%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.360411, Train-Class-Acc: {0: '88.01%', 1: '74.35%', 2: '92.55%', 3: '93.85%', 4: '93.67%', 5: '89.84%'}\n",
      "Val Loss: 0.454009, Val Acc: 86.49%, Val-Class-Acc: {0: '78.26%', 1: '83.88%', 2: '87.50%', 3: '92.21%', 4: '87.50%', 5: '88.92%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.354278, Train-Class-Acc: {0: '88.15%', 1: '74.57%', 2: '93.59%', 3: '93.55%', 4: '89.87%', 5: '91.70%'}\n",
      "Val Loss: 0.523021, Val Acc: 84.31%, Val-Class-Acc: {0: '77.72%', 1: '69.25%', 2: '93.75%', 3: '95.49%', 4: '87.50%', 5: '90.42%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.273215, Train-Class-Acc: {0: '89.78%', 1: '80.33%', 2: '95.49%', 3: '95.29%', 4: '93.67%', 5: '92.60%'}\n",
      "Val Loss: 0.663947, Val Acc: 85.09%, Val-Class-Acc: {0: '72.28%', 1: '82.39%', 2: '95.14%', 3: '90.16%', 4: '77.50%', 5: '87.72%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.264787, Train-Class-Acc: {0: '87.74%', 1: '81.38%', 2: '95.15%', 3: '94.98%', 4: '96.84%', 5: '92.38%'}\n",
      "Val Loss: 0.552682, Val Acc: 85.48%, Val-Class-Acc: {0: '76.09%', 1: '84.18%', 2: '81.94%', 3: '93.85%', 4: '85.00%', 5: '87.43%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.223609, Train-Class-Acc: {0: '91.96%', 1: '83.32%', 2: '95.84%', 3: '95.08%', 4: '97.47%', 5: '93.87%'}\n",
      "Val Loss: 0.607085, Val Acc: 81.34%, Val-Class-Acc: {0: '98.37%', 1: '65.67%', 2: '85.42%', 3: '89.75%', 4: '90.00%', 5: '78.74%'}, LR: 0.001000\n",
      "Epoch 7/200, Train Loss: 0.207737, Train-Class-Acc: {0: '93.19%', 1: '84.82%', 2: '96.71%', 3: '96.21%', 4: '97.47%', 5: '93.12%'}\n",
      "Val Loss: 0.539197, Val Acc: 85.79%, Val-Class-Acc: {0: '87.50%', 1: '68.36%', 2: '90.97%', 3: '93.85%', 4: '90.00%', 5: '93.71%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_1.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.199156, Train-Class-Acc: {0: '92.92%', 1: '85.34%', 2: '95.67%', 3: '96.31%', 4: '96.84%', 5: '93.87%'}\n",
      "Val Loss: 0.723074, Val Acc: 86.26%, Val-Class-Acc: {0: '88.59%', 1: '72.24%', 2: '84.72%', 3: '96.31%', 4: '72.50%', 5: '94.01%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_3.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_8.pth\n",
      "Epoch 9/200, Train Loss: 0.157481, Train-Class-Acc: {0: '93.60%', 1: '89.60%', 2: '97.23%', 3: '97.03%', 4: '96.84%', 5: '95.22%'}\n",
      "Val Loss: 0.561303, Val Acc: 86.73%, Val-Class-Acc: {0: '82.61%', 1: '78.51%', 2: '85.42%', 3: '94.26%', 4: '87.50%', 5: '92.22%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_4.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.111065, Train-Class-Acc: {0: '96.19%', 1: '91.55%', 2: '98.44%', 3: '98.26%', 4: '99.37%', 5: '96.26%'}\n",
      "Val Loss: 0.588177, Val Acc: 86.89%, Val-Class-Acc: {0: '81.52%', 1: '81.49%', 2: '89.58%', 3: '92.21%', 4: '82.50%', 5: '90.72%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_5.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_10.pth\n",
      "Epoch 11/200, Train Loss: 0.085421, Train-Class-Acc: {0: '96.87%', 1: '92.67%', 2: '98.96%', 3: '98.98%', 4: '99.37%', 5: '97.53%'}\n",
      "Val Loss: 0.620980, Val Acc: 84.15%, Val-Class-Acc: {0: '92.93%', 1: '64.78%', 2: '87.50%', 3: '91.39%', 4: '85.00%', 5: '91.92%'}, LR: 0.001000\n",
      "Epoch 12/200, Train Loss: 0.087411, Train-Class-Acc: {0: '97.00%', 1: '93.12%', 2: '98.09%', 3: '98.36%', 4: '98.73%', 5: '97.83%'}\n",
      "Val Loss: 0.593716, Val Acc: 86.49%, Val-Class-Acc: {0: '83.70%', 1: '77.91%', 2: '89.58%', 3: '94.67%', 4: '85.00%', 5: '89.52%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_7.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_12.pth\n",
      "Epoch 13/200, Train Loss: 0.113911, Train-Class-Acc: {0: '96.46%', 1: '92.45%', 2: '98.27%', 3: '96.82%', 4: '98.73%', 5: '96.11%'}\n",
      "Val Loss: 0.572768, Val Acc: 85.17%, Val-Class-Acc: {0: '83.70%', 1: '77.91%', 2: '90.28%', 3: '94.26%', 4: '85.00%', 5: '84.43%'}, LR: 0.001000\n",
      "Epoch 14/200, Train Loss: 0.086795, Train-Class-Acc: {0: '96.59%', 1: '93.79%', 2: '99.13%', 3: '99.08%', 4: '100.00%', 5: '97.61%'}\n",
      "Val Loss: 0.790128, Val Acc: 83.14%, Val-Class-Acc: {0: '93.48%', 1: '57.91%', 2: '95.14%', 3: '95.08%', 4: '82.50%', 5: '88.92%'}, LR: 0.000900\n",
      "Epoch 15/200, Train Loss: 0.133133, Train-Class-Acc: {0: '94.96%', 1: '91.32%', 2: '97.40%', 3: '97.85%', 4: '96.20%', 5: '95.96%'}\n",
      "Val Loss: 0.639845, Val Acc: 84.54%, Val-Class-Acc: {0: '76.63%', 1: '73.73%', 2: '90.97%', 3: '93.03%', 4: '77.50%', 5: '91.62%'}, LR: 0.000900\n",
      "Epoch 16/200, Train Loss: 0.103800, Train-Class-Acc: {0: '96.59%', 1: '92.82%', 2: '98.44%', 3: '97.03%', 4: '98.10%', 5: '97.31%'}\n",
      "Val Loss: 0.801797, Val Acc: 85.17%, Val-Class-Acc: {0: '93.48%', 1: '67.16%', 2: '93.06%', 3: '92.62%', 4: '82.50%', 5: '90.12%'}, LR: 0.000900\n",
      "Epoch 17/200, Train Loss: 0.130967, Train-Class-Acc: {0: '95.78%', 1: '92.37%', 2: '96.19%', 3: '97.44%', 4: '98.73%', 5: '96.04%'}\n",
      "Val Loss: 0.656441, Val Acc: 84.47%, Val-Class-Acc: {0: '86.96%', 1: '73.43%', 2: '88.89%', 3: '93.03%', 4: '82.50%', 5: '86.23%'}, LR: 0.000900\n",
      "Epoch 18/200, Train Loss: 0.069153, Train-Class-Acc: {0: '97.00%', 1: '95.29%', 2: '98.44%', 3: '99.28%', 4: '99.37%', 5: '98.28%'}\n",
      "Val Loss: 0.612197, Val Acc: 86.42%, Val-Class-Acc: {0: '89.13%', 1: '72.24%', 2: '92.36%', 3: '90.16%', 4: '85.00%', 5: '94.01%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_8.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_18.pth\n",
      "Epoch 19/200, Train Loss: 0.052222, Train-Class-Acc: {0: '98.09%', 1: '97.08%', 2: '98.61%', 3: '99.49%', 4: '100.00%', 5: '98.95%'}\n",
      "Val Loss: 0.725758, Val Acc: 85.87%, Val-Class-Acc: {0: '96.74%', 1: '67.46%', 2: '86.81%', 3: '93.44%', 4: '85.00%', 5: '92.51%'}, LR: 0.000900\n",
      "Epoch 20/200, Train Loss: 0.041820, Train-Class-Acc: {0: '98.09%', 1: '96.48%', 2: '99.31%', 3: '99.69%', 4: '100.00%', 5: '99.25%'}\n",
      "Val Loss: 0.665457, Val Acc: 85.71%, Val-Class-Acc: {0: '75.54%', 1: '83.28%', 2: '88.19%', 3: '93.44%', 4: '85.00%', 5: '87.13%'}, LR: 0.000900\n",
      "Epoch 21/200, Train Loss: 0.061431, Train-Class-Acc: {0: '97.55%', 1: '96.11%', 2: '99.13%', 3: '99.08%', 4: '100.00%', 5: '98.36%'}\n",
      "Val Loss: 0.640259, Val Acc: 85.79%, Val-Class-Acc: {0: '88.04%', 1: '68.36%', 2: '86.11%', 3: '93.85%', 4: '92.50%', 5: '95.21%'}, LR: 0.000900\n",
      "Epoch 22/200, Train Loss: 0.070090, Train-Class-Acc: {0: '96.19%', 1: '93.64%', 2: '99.13%', 3: '99.39%', 4: '99.37%', 5: '98.65%'}\n",
      "Val Loss: 0.718052, Val Acc: 86.42%, Val-Class-Acc: {0: '78.26%', 1: '85.67%', 2: '86.81%', 3: '90.98%', 4: '85.00%', 5: '88.32%'}, LR: 0.000900\n",
      "Epoch 23/200, Train Loss: 0.033831, Train-Class-Acc: {0: '98.77%', 1: '97.38%', 2: '99.83%', 3: '99.69%', 4: '100.00%', 5: '99.40%'}\n",
      "Val Loss: 0.801321, Val Acc: 87.35%, Val-Class-Acc: {0: '79.35%', 1: '86.27%', 2: '88.19%', 3: '88.52%', 4: '82.50%', 5: '92.22%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_18.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_23.pth\n",
      "Epoch 24/200, Train Loss: 0.025387, Train-Class-Acc: {0: '99.32%', 1: '98.73%', 2: '99.31%', 3: '99.80%', 4: '100.00%', 5: '99.03%'}\n",
      "Val Loss: 0.713929, Val Acc: 87.51%, Val-Class-Acc: {0: '88.04%', 1: '77.61%', 2: '92.36%', 3: '92.21%', 4: '82.50%', 5: '92.22%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_2.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_24.pth\n",
      "Epoch 25/200, Train Loss: 0.017845, Train-Class-Acc: {0: '99.73%', 1: '99.33%', 2: '99.83%', 3: '99.59%', 4: '100.00%', 5: '99.63%'}\n",
      "Val Loss: 0.809044, Val Acc: 87.43%, Val-Class-Acc: {0: '84.24%', 1: '79.40%', 2: '88.19%', 3: '93.03%', 4: '82.50%', 5: '93.41%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_12.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_25.pth\n",
      "Epoch 26/200, Train Loss: 0.009181, Train-Class-Acc: {0: '100.00%', 1: '99.85%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.85%'}\n",
      "Val Loss: 0.820304, Val Acc: 87.74%, Val-Class-Acc: {0: '87.50%', 1: '76.12%', 2: '88.19%', 3: '93.44%', 4: '82.50%', 5: '95.81%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_9.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_26.pth\n",
      "Epoch 27/200, Train Loss: 0.009219, Train-Class-Acc: {0: '100.00%', 1: '99.63%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.85%'}\n",
      "Val Loss: 0.825837, Val Acc: 87.51%, Val-Class-Acc: {0: '85.87%', 1: '79.10%', 2: '86.11%', 3: '93.85%', 4: '82.50%', 5: '93.41%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_10.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_27.pth\n",
      "Epoch 28/200, Train Loss: 0.008625, Train-Class-Acc: {0: '100.00%', 1: '99.85%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.796248, Val Acc: 87.20%, Val-Class-Acc: {0: '78.26%', 1: '80.30%', 2: '88.89%', 3: '95.08%', 4: '82.50%', 5: '93.11%'}, LR: 0.000810\n",
      "Epoch 29/200, Train Loss: 0.022533, Train-Class-Acc: {0: '99.73%', 1: '99.03%', 2: '99.13%', 3: '99.39%', 4: '100.00%', 5: '99.33%'}\n",
      "Val Loss: 0.798128, Val Acc: 85.79%, Val-Class-Acc: {0: '84.78%', 1: '74.63%', 2: '88.89%', 3: '93.03%', 4: '82.50%', 5: '91.32%'}, LR: 0.000810\n",
      "Epoch 30/200, Train Loss: 0.044747, Train-Class-Acc: {0: '98.91%', 1: '97.38%', 2: '98.96%', 3: '98.67%', 4: '100.00%', 5: '98.73%'}\n",
      "Val Loss: 0.818939, Val Acc: 85.71%, Val-Class-Acc: {0: '82.61%', 1: '75.52%', 2: '88.89%', 3: '95.49%', 4: '80.00%', 5: '89.82%'}, LR: 0.000810\n",
      "Epoch 31/200, Train Loss: 0.246281, Train-Class-Acc: {0: '93.05%', 1: '87.14%', 2: '94.80%', 3: '96.11%', 4: '94.30%', 5: '94.39%'}\n",
      "Val Loss: 0.663620, Val Acc: 84.86%, Val-Class-Acc: {0: '80.43%', 1: '73.13%', 2: '86.81%', 3: '90.98%', 4: '90.00%', 5: '93.11%'}, LR: 0.000810\n",
      "Epoch 32/200, Train Loss: 0.163474, Train-Class-Acc: {0: '93.87%', 1: '88.71%', 2: '97.40%', 3: '96.52%', 4: '97.47%', 5: '96.26%'}\n",
      "Val Loss: 0.717712, Val Acc: 83.76%, Val-Class-Acc: {0: '91.85%', 1: '64.18%', 2: '84.72%', 3: '91.39%', 4: '90.00%', 5: '92.22%'}, LR: 0.000810\n",
      "Epoch 33/200, Train Loss: 0.093968, Train-Class-Acc: {0: '97.41%', 1: '93.94%', 2: '98.27%', 3: '97.44%', 4: '98.73%', 5: '98.13%'}\n",
      "Val Loss: 0.733260, Val Acc: 83.29%, Val-Class-Acc: {0: '73.91%', 1: '80.90%', 2: '87.50%', 3: '94.67%', 4: '85.00%', 5: '80.54%'}, LR: 0.000810\n",
      "Epoch 34/200, Train Loss: 0.041241, Train-Class-Acc: {0: '98.77%', 1: '98.65%', 2: '98.96%', 3: '99.90%', 4: '100.00%', 5: '98.58%'}\n",
      "Val Loss: 0.831962, Val Acc: 85.71%, Val-Class-Acc: {0: '67.93%', 1: '82.39%', 2: '88.89%', 3: '90.16%', 4: '82.50%', 5: '94.61%'}, LR: 0.000810\n",
      "Epoch 35/200, Train Loss: 0.029147, Train-Class-Acc: {0: '99.18%', 1: '98.80%', 2: '99.31%', 3: '99.90%', 4: '100.00%', 5: '99.33%'}\n",
      "Val Loss: 0.780961, Val Acc: 86.34%, Val-Class-Acc: {0: '85.33%', 1: '74.63%', 2: '90.28%', 3: '90.16%', 4: '87.50%', 5: '94.01%'}, LR: 0.000810\n",
      "Epoch 36/200, Train Loss: 0.025963, Train-Class-Acc: {0: '99.18%', 1: '98.95%', 2: '99.48%', 3: '99.59%', 4: '100.00%', 5: '99.48%'}\n",
      "Val Loss: 0.736119, Val Acc: 86.10%, Val-Class-Acc: {0: '81.52%', 1: '80.90%', 2: '89.58%', 3: '92.21%', 4: '85.00%', 5: '88.02%'}, LR: 0.000729\n",
      "Epoch 37/200, Train Loss: 0.015060, Train-Class-Acc: {0: '100.00%', 1: '99.70%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.55%'}\n",
      "Val Loss: 0.850744, Val Acc: 87.51%, Val-Class-Acc: {0: '80.98%', 1: '84.18%', 2: '87.50%', 3: '92.21%', 4: '85.00%', 5: '91.32%'}, LR: 0.000729\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_23.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_37.pth\n",
      "Epoch 38/200, Train Loss: 0.010234, Train-Class-Acc: {0: '99.86%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.774113, Val Acc: 86.73%, Val-Class-Acc: {0: '82.07%', 1: '77.61%', 2: '87.50%', 3: '93.85%', 4: '85.00%', 5: '93.11%'}, LR: 0.000729\n",
      "Epoch 39/200, Train Loss: 0.008388, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.812801, Val Acc: 87.35%, Val-Class-Acc: {0: '83.70%', 1: '79.40%', 2: '87.50%', 3: '93.44%', 4: '82.50%', 5: '93.41%'}, LR: 0.000729\n",
      "Epoch 40/200, Train Loss: 0.007777, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.805267, Val Acc: 87.35%, Val-Class-Acc: {0: '85.87%', 1: '77.61%', 2: '87.50%', 3: '93.85%', 4: '85.00%', 5: '93.41%'}, LR: 0.000729\n",
      "Epoch 41/200, Train Loss: 0.007155, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.832366, Val Acc: 87.51%, Val-Class-Acc: {0: '85.33%', 1: '78.81%', 2: '87.50%', 3: '93.44%', 4: '82.50%', 5: '93.71%'}, LR: 0.000729\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_25.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_41.pth\n",
      "Epoch 42/200, Train Loss: 0.006954, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.825943, Val Acc: 87.43%, Val-Class-Acc: {0: '83.70%', 1: '79.70%', 2: '87.50%', 3: '93.44%', 4: '82.50%', 5: '93.41%'}, LR: 0.000729\n",
      "Epoch 43/200, Train Loss: 0.006644, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.817611, Val Acc: 87.51%, Val-Class-Acc: {0: '83.15%', 1: '80.60%', 2: '87.50%', 3: '93.44%', 4: '85.00%', 5: '92.81%'}, LR: 0.000729\n",
      "Epoch 44/200, Train Loss: 0.006376, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.820744, Val Acc: 87.43%, Val-Class-Acc: {0: '83.15%', 1: '79.70%', 2: '87.50%', 3: '93.44%', 4: '85.00%', 5: '93.41%'}, LR: 0.000729\n",
      "Epoch 45/200, Train Loss: 0.006092, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.814819, Val Acc: 87.12%, Val-Class-Acc: {0: '83.70%', 1: '79.70%', 2: '87.50%', 3: '93.03%', 4: '85.00%', 5: '92.22%'}, LR: 0.000729\n",
      "Epoch 46/200, Train Loss: 0.005968, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.876041, Val Acc: 87.67%, Val-Class-Acc: {0: '84.24%', 1: '79.10%', 2: '87.50%', 3: '93.03%', 4: '82.50%', 5: '94.91%'}, LR: 0.000729\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_24.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_46.pth\n",
      "Epoch 47/200, Train Loss: 0.005988, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.851011, Val Acc: 87.20%, Val-Class-Acc: {0: '82.61%', 1: '80.60%', 2: '87.50%', 3: '92.62%', 4: '85.00%', 5: '92.51%'}, LR: 0.000656\n",
      "Epoch 48/200, Train Loss: 0.005764, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.861020, Val Acc: 87.35%, Val-Class-Acc: {0: '83.70%', 1: '80.60%', 2: '87.50%', 3: '92.62%', 4: '85.00%', 5: '92.51%'}, LR: 0.000656\n",
      "Epoch 49/200, Train Loss: 0.005452, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.871865, Val Acc: 87.12%, Val-Class-Acc: {0: '84.24%', 1: '79.10%', 2: '87.50%', 3: '92.62%', 4: '85.00%', 5: '92.81%'}, LR: 0.000656\n",
      "Epoch 50/200, Train Loss: 0.005385, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.863389, Val Acc: 87.04%, Val-Class-Acc: {0: '83.15%', 1: '78.81%', 2: '87.50%', 3: '92.62%', 4: '82.50%', 5: '93.71%'}, LR: 0.000656\n",
      "Epoch 51/200, Train Loss: 0.005485, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.905453, Val Acc: 86.89%, Val-Class-Acc: {0: '83.15%', 1: '78.21%', 2: '85.42%', 3: '93.03%', 4: '85.00%', 5: '94.01%'}, LR: 0.000656\n",
      "Epoch 52/200, Train Loss: 0.005081, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.890162, Val Acc: 86.96%, Val-Class-Acc: {0: '82.07%', 1: '78.21%', 2: '86.81%', 3: '93.03%', 4: '85.00%', 5: '94.31%'}, LR: 0.000656\n",
      "Epoch 53/200, Train Loss: 0.005014, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.890544, Val Acc: 86.96%, Val-Class-Acc: {0: '84.24%', 1: '78.21%', 2: '86.11%', 3: '92.62%', 4: '85.00%', 5: '93.71%'}, LR: 0.000656\n",
      "Epoch 54/200, Train Loss: 0.004858, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.888416, Val Acc: 87.12%, Val-Class-Acc: {0: '82.61%', 1: '79.40%', 2: '86.11%', 3: '93.03%', 4: '85.00%', 5: '93.71%'}, LR: 0.000656\n",
      "Epoch 55/200, Train Loss: 0.004744, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.897132, Val Acc: 87.59%, Val-Class-Acc: {0: '84.24%', 1: '79.40%', 2: '86.11%', 3: '93.85%', 4: '85.00%', 5: '94.01%'}, LR: 0.000656\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_27.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_55.pth\n",
      "Epoch 56/200, Train Loss: 0.004574, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.912068, Val Acc: 87.90%, Val-Class-Acc: {0: '83.15%', 1: '80.90%', 2: '86.81%', 3: '93.85%', 4: '85.00%', 5: '94.01%'}, LR: 0.000656\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_37.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_56.pth\n",
      "Epoch 57/200, Train Loss: 0.004465, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.911242, Val Acc: 87.51%, Val-Class-Acc: {0: '84.24%', 1: '78.81%', 2: '86.11%', 3: '93.85%', 4: '85.00%', 5: '94.31%'}, LR: 0.000656\n",
      "Epoch 58/200, Train Loss: 0.004395, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.938931, Val Acc: 87.51%, Val-Class-Acc: {0: '83.15%', 1: '80.00%', 2: '86.11%', 3: '93.03%', 4: '85.00%', 5: '94.31%'}, LR: 0.000590\n",
      "Epoch 59/200, Train Loss: 0.004362, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.894290, Val Acc: 86.96%, Val-Class-Acc: {0: '84.24%', 1: '79.10%', 2: '86.11%', 3: '93.03%', 4: '85.00%', 5: '92.51%'}, LR: 0.000590\n",
      "Epoch 60/200, Train Loss: 0.004201, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.924350, Val Acc: 87.28%, Val-Class-Acc: {0: '83.70%', 1: '79.10%', 2: '86.11%', 3: '92.62%', 4: '85.00%', 5: '94.31%'}, LR: 0.000590\n",
      "Epoch 61/200, Train Loss: 0.004067, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.907020, Val Acc: 86.96%, Val-Class-Acc: {0: '83.70%', 1: '79.70%', 2: '86.11%', 3: '92.62%', 4: '85.00%', 5: '92.51%'}, LR: 0.000590\n",
      "Epoch 62/200, Train Loss: 0.004275, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.908627, Val Acc: 87.20%, Val-Class-Acc: {0: '85.87%', 1: '76.12%', 2: '87.50%', 3: '94.26%', 4: '85.00%', 5: '94.01%'}, LR: 0.000590\n",
      "Epoch 63/200, Train Loss: 0.003969, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.920627, Val Acc: 87.20%, Val-Class-Acc: {0: '84.24%', 1: '79.40%', 2: '86.11%', 3: '93.03%', 4: '85.00%', 5: '93.11%'}, LR: 0.000590\n",
      "Epoch 64/200, Train Loss: 0.003904, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.931297, Val Acc: 87.43%, Val-Class-Acc: {0: '85.33%', 1: '79.10%', 2: '87.50%', 3: '93.44%', 4: '85.00%', 5: '92.81%'}, LR: 0.000590\n",
      "Epoch 65/200, Train Loss: 0.003817, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.915692, Val Acc: 87.28%, Val-Class-Acc: {0: '84.78%', 1: '79.10%', 2: '87.50%', 3: '93.03%', 4: '85.00%', 5: '92.81%'}, LR: 0.000590\n",
      "Epoch 66/200, Train Loss: 0.043011, Train-Class-Acc: {0: '99.18%', 1: '98.20%', 2: '99.65%', 3: '99.28%', 4: '98.73%', 5: '98.73%'}\n",
      "Val Loss: 1.813426, Val Acc: 74.08%, Val-Class-Acc: {0: '82.61%', 1: '42.39%', 2: '91.67%', 3: '74.59%', 4: '70.00%', 5: '93.71%'}, LR: 0.000590\n",
      "Epoch 67/200, Train Loss: 0.555471, Train-Class-Acc: {0: '81.61%', 1: '71.73%', 2: '87.35%', 3: '89.04%', 4: '90.51%', 5: '87.29%'}\n",
      "Val Loss: 0.725695, Val Acc: 81.81%, Val-Class-Acc: {0: '85.33%', 1: '75.52%', 2: '87.50%', 3: '74.59%', 4: '80.00%', 5: '89.22%'}, LR: 0.000590\n",
      "Epoch 68/200, Train Loss: 0.220017, Train-Class-Acc: {0: '93.05%', 1: '86.39%', 2: '94.80%', 3: '94.06%', 4: '98.73%', 5: '94.25%'}\n",
      "Val Loss: 0.606325, Val Acc: 85.40%, Val-Class-Acc: {0: '90.22%', 1: '72.24%', 2: '86.11%', 3: '90.16%', 4: '85.00%', 5: '92.22%'}, LR: 0.000590\n",
      "Epoch 69/200, Train Loss: 0.067270, Train-Class-Acc: {0: '98.37%', 1: '95.66%', 2: '98.96%', 3: '98.57%', 4: '99.37%', 5: '97.98%'}\n",
      "Val Loss: 0.688899, Val Acc: 86.65%, Val-Class-Acc: {0: '78.80%', 1: '76.72%', 2: '88.19%', 3: '93.85%', 4: '82.50%', 5: '95.51%'}, LR: 0.000531\n",
      "Epoch 70/200, Train Loss: 0.029893, Train-Class-Acc: {0: '99.59%', 1: '98.80%', 2: '99.83%', 3: '99.59%', 4: '100.00%', 5: '99.25%'}\n",
      "Val Loss: 0.733556, Val Acc: 86.73%, Val-Class-Acc: {0: '84.78%', 1: '76.12%', 2: '86.11%', 3: '92.21%', 4: '82.50%', 5: '95.21%'}, LR: 0.000531\n",
      "Epoch 71/200, Train Loss: 0.019499, Train-Class-Acc: {0: '99.86%', 1: '99.48%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.85%'}\n",
      "Val Loss: 0.743658, Val Acc: 86.18%, Val-Class-Acc: {0: '84.78%', 1: '73.13%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '96.41%'}, LR: 0.000531\n",
      "Epoch 72/200, Train Loss: 0.015590, Train-Class-Acc: {0: '99.73%', 1: '99.70%', 2: '99.83%', 3: '99.90%', 4: '100.00%', 5: '99.85%'}\n",
      "Val Loss: 0.731508, Val Acc: 86.34%, Val-Class-Acc: {0: '84.24%', 1: '75.22%', 2: '87.50%', 3: '92.62%', 4: '85.00%', 5: '93.71%'}, LR: 0.000531\n",
      "Epoch 73/200, Train Loss: 0.011924, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.782984, Val Acc: 86.65%, Val-Class-Acc: {0: '80.43%', 1: '78.81%', 2: '87.50%', 3: '91.39%', 4: '82.50%', 5: '94.61%'}, LR: 0.000531\n",
      "Epoch 74/200, Train Loss: 0.011257, Train-Class-Acc: {0: '100.00%', 1: '99.78%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.85%'}\n",
      "Val Loss: 0.774134, Val Acc: 86.03%, Val-Class-Acc: {0: '76.63%', 1: '79.70%', 2: '88.19%', 3: '92.62%', 4: '82.50%', 5: '92.22%'}, LR: 0.000531\n",
      "Epoch 75/200, Train Loss: 0.010120, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '99.83%', 3: '99.90%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.820322, Val Acc: 86.03%, Val-Class-Acc: {0: '80.98%', 1: '77.31%', 2: '85.42%', 3: '91.39%', 4: '82.50%', 5: '94.31%'}, LR: 0.000531\n",
      "Epoch 76/200, Train Loss: 0.009074, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.840864, Val Acc: 86.42%, Val-Class-Acc: {0: '78.80%', 1: '80.60%', 2: '86.81%', 3: '90.57%', 4: '82.50%', 5: '93.71%'}, LR: 0.000531\n",
      "Epoch 77/200, Train Loss: 0.011337, Train-Class-Acc: {0: '99.73%', 1: '99.85%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.892381, Val Acc: 84.93%, Val-Class-Acc: {0: '92.93%', 1: '67.16%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '93.11%'}, LR: 0.000531\n",
      "Epoch 78/200, Train Loss: 0.019020, Train-Class-Acc: {0: '99.18%', 1: '98.50%', 2: '100.00%', 3: '99.80%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.854311, Val Acc: 86.73%, Val-Class-Acc: {0: '84.78%', 1: '77.01%', 2: '85.42%', 3: '91.80%', 4: '82.50%', 5: '94.91%'}, LR: 0.000531\n",
      "Epoch 79/200, Train Loss: 0.041231, Train-Class-Acc: {0: '97.28%', 1: '96.56%', 2: '99.48%', 3: '99.69%', 4: '100.00%', 5: '99.70%'}\n",
      "Val Loss: 0.865002, Val Acc: 85.09%, Val-Class-Acc: {0: '78.26%', 1: '75.52%', 2: '86.81%', 3: '92.21%', 4: '82.50%', 5: '92.81%'}, LR: 0.000531\n",
      "Epoch 80/200, Train Loss: 0.030089, Train-Class-Acc: {0: '99.05%', 1: '97.98%', 2: '99.48%', 3: '99.59%', 4: '100.00%', 5: '99.55%'}\n",
      "Val Loss: 0.783641, Val Acc: 87.35%, Val-Class-Acc: {0: '83.15%', 1: '80.00%', 2: '87.50%', 3: '91.39%', 4: '82.50%', 5: '94.61%'}, LR: 0.000478\n",
      "Epoch 81/200, Train Loss: 0.057107, Train-Class-Acc: {0: '98.64%', 1: '96.71%', 2: '98.61%', 3: '98.46%', 4: '98.73%', 5: '99.18%'}\n",
      "Val Loss: 0.842701, Val Acc: 85.95%, Val-Class-Acc: {0: '79.89%', 1: '76.42%', 2: '89.58%', 3: '95.49%', 4: '85.00%', 5: '90.42%'}, LR: 0.000478\n",
      "Epoch 82/200, Train Loss: 0.033861, Train-Class-Acc: {0: '98.37%', 1: '97.98%', 2: '99.31%', 3: '100.00%', 4: '100.00%', 5: '99.33%'}\n",
      "Val Loss: 0.979144, Val Acc: 85.95%, Val-Class-Acc: {0: '74.46%', 1: '80.30%', 2: '84.03%', 3: '93.85%', 4: '82.50%', 5: '93.41%'}, LR: 0.000478\n",
      "Epoch 83/200, Train Loss: 0.026685, Train-Class-Acc: {0: '99.46%', 1: '98.95%', 2: '99.13%', 3: '99.28%', 4: '100.00%', 5: '99.40%'}\n",
      "Val Loss: 0.902035, Val Acc: 86.34%, Val-Class-Acc: {0: '79.35%', 1: '81.19%', 2: '87.50%', 3: '88.52%', 4: '82.50%', 5: '93.71%'}, LR: 0.000478\n",
      "Epoch 84/200, Train Loss: 0.012633, Train-Class-Acc: {0: '99.86%', 1: '99.85%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.70%'}\n",
      "Val Loss: 0.934771, Val Acc: 86.73%, Val-Class-Acc: {0: '80.98%', 1: '80.90%', 2: '86.81%', 3: '90.16%', 4: '82.50%', 5: '93.71%'}, LR: 0.000478\n",
      "Epoch 85/200, Train Loss: 0.009144, Train-Class-Acc: {0: '100.00%', 1: '99.85%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.888486, Val Acc: 87.04%, Val-Class-Acc: {0: '80.43%', 1: '80.90%', 2: '88.19%', 3: '90.98%', 4: '82.50%', 5: '94.01%'}, LR: 0.000478\n",
      "Epoch 86/200, Train Loss: 0.008021, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.900009, Val Acc: 86.81%, Val-Class-Acc: {0: '82.07%', 1: '78.81%', 2: '87.50%', 3: '91.80%', 4: '82.50%', 5: '94.01%'}, LR: 0.000478\n",
      "Epoch 87/200, Train Loss: 0.007438, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.915740, Val Acc: 87.04%, Val-Class-Acc: {0: '82.07%', 1: '79.70%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '93.71%'}, LR: 0.000478\n",
      "Epoch 88/200, Train Loss: 0.007259, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.933784, Val Acc: 86.73%, Val-Class-Acc: {0: '80.43%', 1: '79.10%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '94.01%'}, LR: 0.000478\n",
      "Epoch 89/200, Train Loss: 0.007176, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.930627, Val Acc: 86.65%, Val-Class-Acc: {0: '79.35%', 1: '79.10%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '94.31%'}, LR: 0.000478\n",
      "Epoch 90/200, Train Loss: 0.008856, Train-Class-Acc: {0: '100.00%', 1: '99.85%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '99.85%'}\n",
      "Val Loss: 0.913645, Val Acc: 86.34%, Val-Class-Acc: {0: '80.43%', 1: '78.51%', 2: '88.19%', 3: '92.62%', 4: '82.50%', 5: '92.51%'}, LR: 0.000478\n",
      "Epoch 91/200, Train Loss: 0.010826, Train-Class-Acc: {0: '100.00%', 1: '99.78%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '99.55%'}\n",
      "Val Loss: 0.971275, Val Acc: 86.26%, Val-Class-Acc: {0: '76.09%', 1: '80.60%', 2: '87.50%', 3: '92.62%', 4: '82.50%', 5: '92.81%'}, LR: 0.000430\n",
      "Epoch 92/200, Train Loss: 0.007499, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.950992, Val Acc: 86.89%, Val-Class-Acc: {0: '80.98%', 1: '79.10%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '94.31%'}, LR: 0.000430\n",
      "Epoch 93/200, Train Loss: 0.006456, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.939178, Val Acc: 87.20%, Val-Class-Acc: {0: '83.15%', 1: '79.10%', 2: '87.50%', 3: '92.62%', 4: '82.50%', 5: '94.01%'}, LR: 0.000430\n",
      "Epoch 94/200, Train Loss: 0.006331, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.945655, Val Acc: 86.81%, Val-Class-Acc: {0: '83.15%', 1: '77.61%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '94.31%'}, LR: 0.000430\n",
      "Epoch 95/200, Train Loss: 0.006099, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.961595, Val Acc: 87.28%, Val-Class-Acc: {0: '82.61%', 1: '79.70%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '94.31%'}, LR: 0.000430\n",
      "Epoch 96/200, Train Loss: 0.005974, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.959159, Val Acc: 86.89%, Val-Class-Acc: {0: '82.61%', 1: '77.61%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '94.91%'}, LR: 0.000430\n",
      "Epoch 97/200, Train Loss: 0.005956, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.954470, Val Acc: 86.89%, Val-Class-Acc: {0: '80.98%', 1: '78.81%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '94.61%'}, LR: 0.000430\n",
      "Epoch 98/200, Train Loss: 0.005868, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.956455, Val Acc: 86.42%, Val-Class-Acc: {0: '79.35%', 1: '79.10%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '93.41%'}, LR: 0.000430\n",
      "Epoch 99/200, Train Loss: 0.005631, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.939293, Val Acc: 86.03%, Val-Class-Acc: {0: '80.98%', 1: '76.12%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '94.01%'}, LR: 0.000430\n",
      "Epoch 100/200, Train Loss: 0.005537, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.946271, Val Acc: 86.26%, Val-Class-Acc: {0: '82.07%', 1: '76.72%', 2: '86.81%', 3: '92.21%', 4: '82.50%', 5: '94.01%'}, LR: 0.000430\n",
      "Epoch 101/200, Train Loss: 0.005423, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.990869, Val Acc: 86.96%, Val-Class-Acc: {0: '80.43%', 1: '79.10%', 2: '86.81%', 3: '92.21%', 4: '82.50%', 5: '95.21%'}, LR: 0.000430\n",
      "Epoch 102/200, Train Loss: 0.005269, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.965169, Val Acc: 86.96%, Val-Class-Acc: {0: '81.52%', 1: '78.21%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '95.21%'}, LR: 0.000387\n",
      "Epoch 103/200, Train Loss: 0.005166, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.963772, Val Acc: 86.73%, Val-Class-Acc: {0: '81.52%', 1: '77.01%', 2: '88.19%', 3: '92.21%', 4: '82.50%', 5: '95.21%'}, LR: 0.000387\n",
      "Epoch 104/200, Train Loss: 0.005104, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.970527, Val Acc: 86.89%, Val-Class-Acc: {0: '80.98%', 1: '78.51%', 2: '87.50%', 3: '92.62%', 4: '82.50%', 5: '94.61%'}, LR: 0.000387\n",
      "Epoch 105/200, Train Loss: 0.005214, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.985715, Val Acc: 86.81%, Val-Class-Acc: {0: '82.61%', 1: '77.91%', 2: '86.81%', 3: '92.62%', 4: '82.50%', 5: '94.31%'}, LR: 0.000387\n",
      "Epoch 106/200, Train Loss: 0.004971, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.977791, Val Acc: 86.57%, Val-Class-Acc: {0: '83.15%', 1: '77.91%', 2: '87.50%', 3: '91.80%', 4: '82.50%', 5: '93.41%'}, LR: 0.000387\n",
      "Epoch 107/200, Train Loss: 0.005040, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.961133, Val Acc: 86.65%, Val-Class-Acc: {0: '82.61%', 1: '78.51%', 2: '88.19%', 3: '92.21%', 4: '82.50%', 5: '92.81%'}, LR: 0.000387\n",
      "Epoch 108/200, Train Loss: 0.004824, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.980963, Val Acc: 86.18%, Val-Class-Acc: {0: '83.15%', 1: '76.12%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '93.41%'}, LR: 0.000387\n",
      "Epoch 109/200, Train Loss: 0.004704, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.978003, Val Acc: 86.34%, Val-Class-Acc: {0: '80.98%', 1: '78.21%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '93.11%'}, LR: 0.000387\n",
      "Epoch 110/200, Train Loss: 0.004650, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.005889, Val Acc: 86.65%, Val-Class-Acc: {0: '83.70%', 1: '77.61%', 2: '86.11%', 3: '92.21%', 4: '82.50%', 5: '94.01%'}, LR: 0.000387\n",
      "Epoch 111/200, Train Loss: 0.004555, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.007176, Val Acc: 86.65%, Val-Class-Acc: {0: '81.52%', 1: '78.51%', 2: '86.11%', 3: '92.62%', 4: '82.50%', 5: '94.01%'}, LR: 0.000387\n",
      "Epoch 112/200, Train Loss: 0.004474, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.017699, Val Acc: 86.57%, Val-Class-Acc: {0: '80.98%', 1: '78.51%', 2: '86.11%', 3: '92.62%', 4: '82.50%', 5: '94.01%'}, LR: 0.000387\n",
      "Epoch 113/200, Train Loss: 0.004383, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.016025, Val Acc: 86.42%, Val-Class-Acc: {0: '82.07%', 1: '77.91%', 2: '86.11%', 3: '92.21%', 4: '82.50%', 5: '93.71%'}, LR: 0.000349\n",
      "Epoch 114/200, Train Loss: 0.004324, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.012630, Val Acc: 86.57%, Val-Class-Acc: {0: '82.61%', 1: '78.21%', 2: '87.50%', 3: '92.21%', 4: '82.50%', 5: '93.11%'}, LR: 0.000349\n",
      "Epoch 115/200, Train Loss: 0.016032, Train-Class-Acc: {0: '98.91%', 1: '99.18%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.014312, Val Acc: 85.09%, Val-Class-Acc: {0: '70.65%', 1: '81.19%', 2: '87.50%', 3: '87.70%', 4: '85.00%', 5: '94.01%'}, LR: 0.000349\n",
      "Epoch 116/200, Train Loss: 0.184863, Train-Class-Acc: {0: '92.23%', 1: '86.76%', 2: '96.36%', 3: '97.13%', 4: '96.20%', 5: '96.49%'}\n",
      "Val Loss: 0.697096, Val Acc: 84.23%, Val-Class-Acc: {0: '84.24%', 1: '73.43%', 2: '89.58%', 3: '92.21%', 4: '90.00%', 5: '86.23%'}, LR: 0.000349\n",
      "Epoch 117/200, Train Loss: 0.077225, Train-Class-Acc: {0: '96.59%', 1: '94.47%', 2: '98.61%', 3: '98.57%', 4: '100.00%', 5: '98.13%'}\n",
      "Val Loss: 0.769933, Val Acc: 86.10%, Val-Class-Acc: {0: '80.98%', 1: '74.93%', 2: '88.19%', 3: '90.98%', 4: '90.00%', 5: '95.21%'}, LR: 0.000349\n",
      "Epoch 118/200, Train Loss: 0.036406, Train-Class-Acc: {0: '99.46%', 1: '98.35%', 2: '99.31%', 3: '99.18%', 4: '100.00%', 5: '99.18%'}\n",
      "Val Loss: 0.830517, Val Acc: 85.17%, Val-Class-Acc: {0: '72.83%', 1: '76.72%', 2: '88.89%', 3: '94.67%', 4: '85.00%', 5: '91.92%'}, LR: 0.000349\n",
      "Epoch 119/200, Train Loss: 0.020526, Train-Class-Acc: {0: '99.32%', 1: '99.25%', 2: '99.65%', 3: '99.90%', 4: '100.00%', 5: '99.40%'}\n",
      "Val Loss: 0.930782, Val Acc: 86.57%, Val-Class-Acc: {0: '85.87%', 1: '80.00%', 2: '82.64%', 3: '88.93%', 4: '82.50%', 5: '94.01%'}, LR: 0.000349\n",
      "Epoch 120/200, Train Loss: 0.017032, Train-Class-Acc: {0: '99.73%', 1: '99.55%', 2: '99.83%', 3: '99.59%', 4: '100.00%', 5: '99.78%'}\n",
      "Val Loss: 0.949283, Val Acc: 86.73%, Val-Class-Acc: {0: '83.15%', 1: '76.12%', 2: '86.11%', 3: '93.03%', 4: '82.50%', 5: '95.51%'}, LR: 0.000349\n",
      "Epoch 121/200, Train Loss: 0.011770, Train-Class-Acc: {0: '100.00%', 1: '99.78%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '99.63%'}\n",
      "Val Loss: 0.943978, Val Acc: 86.18%, Val-Class-Acc: {0: '80.43%', 1: '77.91%', 2: '87.50%', 3: '93.03%', 4: '82.50%', 5: '92.51%'}, LR: 0.000349\n",
      "Epoch 122/200, Train Loss: 0.007237, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.966335, Val Acc: 86.18%, Val-Class-Acc: {0: '81.52%', 1: '77.91%', 2: '86.11%', 3: '91.39%', 4: '82.50%', 5: '93.71%'}, LR: 0.000349\n",
      "Epoch 123/200, Train Loss: 0.008733, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '99.85%'}\n",
      "Val Loss: 1.114824, Val Acc: 86.42%, Val-Class-Acc: {0: '85.87%', 1: '76.12%', 2: '81.25%', 3: '91.39%', 4: '82.50%', 5: '96.11%'}, LR: 0.000349\n",
      "Epoch 124/200, Train Loss: 0.013268, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '99.48%', 3: '99.90%', 4: '100.00%', 5: '99.85%'}\n",
      "Val Loss: 0.982047, Val Acc: 85.01%, Val-Class-Acc: {0: '77.72%', 1: '78.21%', 2: '89.58%', 3: '88.11%', 4: '82.50%', 5: '91.92%'}, LR: 0.000314\n",
      "Epoch 125/200, Train Loss: 0.007565, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.970115, Val Acc: 85.95%, Val-Class-Acc: {0: '81.52%', 1: '76.42%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '93.71%'}, LR: 0.000314\n",
      "Epoch 126/200, Train Loss: 0.006263, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.987104, Val Acc: 86.18%, Val-Class-Acc: {0: '83.15%', 1: '76.42%', 2: '86.81%', 3: '93.03%', 4: '82.50%', 5: '92.81%'}, LR: 0.000314\n",
      "Epoch 127/200, Train Loss: 0.005968, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.966317, Val Acc: 86.03%, Val-Class-Acc: {0: '81.52%', 1: '75.82%', 2: '85.42%', 3: '94.26%', 4: '82.50%', 5: '93.41%'}, LR: 0.000314\n",
      "Epoch 128/200, Train Loss: 0.005926, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.004297, Val Acc: 86.18%, Val-Class-Acc: {0: '79.89%', 1: '78.81%', 2: '85.42%', 3: '93.85%', 4: '82.50%', 5: '92.22%'}, LR: 0.000314\n",
      "Epoch 129/200, Train Loss: 0.005708, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.995561, Val Acc: 86.03%, Val-Class-Acc: {0: '82.07%', 1: '76.42%', 2: '86.11%', 3: '93.85%', 4: '82.50%', 5: '92.51%'}, LR: 0.000314\n",
      "Epoch 130/200, Train Loss: 0.005638, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.973244, Val Acc: 85.79%, Val-Class-Acc: {0: '81.52%', 1: '76.72%', 2: '87.50%', 3: '93.44%', 4: '82.50%', 5: '91.32%'}, LR: 0.000314\n",
      "Epoch 131/200, Train Loss: 0.006011, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.972868, Val Acc: 85.71%, Val-Class-Acc: {0: '80.98%', 1: '76.42%', 2: '86.11%', 3: '94.26%', 4: '82.50%', 5: '91.62%'}, LR: 0.000314\n",
      "Epoch 132/200, Train Loss: 0.011270, Train-Class-Acc: {0: '100.00%', 1: '99.78%', 2: '100.00%', 3: '99.69%', 4: '100.00%', 5: '99.55%'}\n",
      "Val Loss: 1.035680, Val Acc: 85.17%, Val-Class-Acc: {0: '79.35%', 1: '77.31%', 2: '86.11%', 3: '88.11%', 4: '82.50%', 5: '94.01%'}, LR: 0.000314\n",
      "Epoch 133/200, Train Loss: 0.012739, Train-Class-Acc: {0: '99.73%', 1: '99.55%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.63%'}\n",
      "Val Loss: 0.991214, Val Acc: 86.03%, Val-Class-Acc: {0: '86.41%', 1: '74.63%', 2: '86.81%', 3: '91.39%', 4: '82.50%', 5: '93.41%'}, LR: 0.000314\n",
      "Epoch 134/200, Train Loss: 0.013384, Train-Class-Acc: {0: '99.32%', 1: '99.63%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.70%'}\n",
      "Val Loss: 0.957736, Val Acc: 85.32%, Val-Class-Acc: {0: '82.07%', 1: '75.82%', 2: '87.50%', 3: '91.80%', 4: '82.50%', 5: '91.32%'}, LR: 0.000314\n",
      "Epoch 135/200, Train Loss: 0.008792, Train-Class-Acc: {0: '100.00%', 1: '99.85%', 2: '100.00%', 3: '99.69%', 4: '100.00%', 5: '99.85%'}\n",
      "Val Loss: 1.042351, Val Acc: 86.34%, Val-Class-Acc: {0: '84.78%', 1: '75.82%', 2: '86.81%', 3: '91.39%', 4: '82.50%', 5: '94.31%'}, LR: 0.000282\n",
      "Epoch 136/200, Train Loss: 0.009705, Train-Class-Acc: {0: '99.73%', 1: '99.63%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 1.126654, Val Acc: 85.95%, Val-Class-Acc: {0: '75.54%', 1: '81.49%', 2: '84.72%', 3: '92.21%', 4: '82.50%', 5: '92.51%'}, LR: 0.000282\n",
      "Epoch 137/200, Train Loss: 0.007827, Train-Class-Acc: {0: '99.86%', 1: '99.70%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.049054, Val Acc: 85.32%, Val-Class-Acc: {0: '78.80%', 1: '74.63%', 2: '89.58%', 3: '91.80%', 4: '82.50%', 5: '93.41%'}, LR: 0.000282\n",
      "Epoch 138/200, Train Loss: 0.006508, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.012324, Val Acc: 84.70%, Val-Class-Acc: {0: '83.15%', 1: '72.54%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '91.92%'}, LR: 0.000282\n",
      "Epoch 139/200, Train Loss: 0.005514, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.040624, Val Acc: 85.71%, Val-Class-Acc: {0: '80.98%', 1: '77.31%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '92.22%'}, LR: 0.000282\n",
      "Epoch 140/200, Train Loss: 0.005298, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.043801, Val Acc: 85.79%, Val-Class-Acc: {0: '82.07%', 1: '76.72%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '92.81%'}, LR: 0.000282\n",
      "Epoch 141/200, Train Loss: 0.005342, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.050606, Val Acc: 85.71%, Val-Class-Acc: {0: '82.07%', 1: '77.01%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '92.22%'}, LR: 0.000282\n",
      "Epoch 142/200, Train Loss: 0.005161, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.040577, Val Acc: 85.64%, Val-Class-Acc: {0: '82.07%', 1: '75.52%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '93.11%'}, LR: 0.000282\n",
      "Epoch 143/200, Train Loss: 0.005033, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.053036, Val Acc: 86.10%, Val-Class-Acc: {0: '81.52%', 1: '77.61%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '93.41%'}, LR: 0.000282\n",
      "Epoch 144/200, Train Loss: 0.004977, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.040718, Val Acc: 85.95%, Val-Class-Acc: {0: '82.07%', 1: '76.42%', 2: '86.11%', 3: '92.21%', 4: '82.50%', 5: '93.41%'}, LR: 0.000282\n",
      "Epoch 145/200, Train Loss: 0.004896, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.047190, Val Acc: 85.87%, Val-Class-Acc: {0: '81.52%', 1: '76.72%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '93.41%'}, LR: 0.000282\n",
      "Epoch 146/200, Train Loss: 0.004804, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.053955, Val Acc: 85.71%, Val-Class-Acc: {0: '81.52%', 1: '76.42%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '93.11%'}, LR: 0.000254\n",
      "Epoch 147/200, Train Loss: 0.004781, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.057891, Val Acc: 85.95%, Val-Class-Acc: {0: '81.52%', 1: '77.01%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '93.41%'}, LR: 0.000254\n",
      "Epoch 148/200, Train Loss: 0.004692, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.068806, Val Acc: 86.03%, Val-Class-Acc: {0: '80.43%', 1: '78.21%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '93.11%'}, LR: 0.000254\n",
      "Epoch 149/200, Train Loss: 0.004686, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.061465, Val Acc: 85.71%, Val-Class-Acc: {0: '83.15%', 1: '75.22%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '93.41%'}, LR: 0.000254\n",
      "Epoch 150/200, Train Loss: 0.004603, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.072895, Val Acc: 86.03%, Val-Class-Acc: {0: '80.98%', 1: '78.21%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '92.51%'}, LR: 0.000254\n",
      "Epoch 151/200, Train Loss: 0.004548, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.079039, Val Acc: 86.18%, Val-Class-Acc: {0: '81.52%', 1: '78.81%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '92.51%'}, LR: 0.000254\n",
      "Epoch 152/200, Train Loss: 0.004515, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.055383, Val Acc: 85.95%, Val-Class-Acc: {0: '84.24%', 1: '75.52%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '93.41%'}, LR: 0.000254\n",
      "Epoch 153/200, Train Loss: 0.004431, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.092831, Val Acc: 85.95%, Val-Class-Acc: {0: '81.52%', 1: '77.01%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '93.41%'}, LR: 0.000254\n",
      "Epoch 154/200, Train Loss: 0.004427, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.087624, Val Acc: 85.71%, Val-Class-Acc: {0: '80.98%', 1: '77.01%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '92.51%'}, LR: 0.000254\n",
      "Epoch 155/200, Train Loss: 0.004380, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.095741, Val Acc: 85.79%, Val-Class-Acc: {0: '82.61%', 1: '76.12%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '93.11%'}, LR: 0.000254\n",
      "Epoch 156/200, Train Loss: 0.004321, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.090313, Val Acc: 85.87%, Val-Class-Acc: {0: '80.98%', 1: '77.61%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '92.51%'}, LR: 0.000254\n",
      "Epoch 157/200, Train Loss: 0.004254, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.101878, Val Acc: 85.95%, Val-Class-Acc: {0: '80.98%', 1: '77.61%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '92.81%'}, LR: 0.000229\n",
      "Epoch 158/200, Train Loss: 0.004219, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.103873, Val Acc: 85.87%, Val-Class-Acc: {0: '82.07%', 1: '76.42%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '93.11%'}, LR: 0.000229\n",
      "Epoch 159/200, Train Loss: 0.004170, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.093658, Val Acc: 85.79%, Val-Class-Acc: {0: '81.52%', 1: '76.72%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '93.11%'}, LR: 0.000229\n",
      "Epoch 160/200, Train Loss: 0.004127, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.102184, Val Acc: 85.71%, Val-Class-Acc: {0: '81.52%', 1: '76.72%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '92.81%'}, LR: 0.000229\n",
      "Epoch 161/200, Train Loss: 0.004091, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.110845, Val Acc: 85.79%, Val-Class-Acc: {0: '80.98%', 1: '77.31%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '92.51%'}, LR: 0.000229\n",
      "Epoch 162/200, Train Loss: 0.004051, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.101032, Val Acc: 86.03%, Val-Class-Acc: {0: '80.98%', 1: '77.31%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '93.41%'}, LR: 0.000229\n",
      "Epoch 163/200, Train Loss: 0.004061, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.096162, Val Acc: 85.71%, Val-Class-Acc: {0: '83.15%', 1: '74.93%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '93.71%'}, LR: 0.000229\n",
      "Epoch 164/200, Train Loss: 0.003967, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.091016, Val Acc: 85.87%, Val-Class-Acc: {0: '82.07%', 1: '77.01%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '92.81%'}, LR: 0.000229\n",
      "Epoch 165/200, Train Loss: 0.003910, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.109050, Val Acc: 85.95%, Val-Class-Acc: {0: '81.52%', 1: '77.61%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '92.81%'}, LR: 0.000229\n",
      "Epoch 166/200, Train Loss: 0.003936, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.123793, Val Acc: 85.79%, Val-Class-Acc: {0: '81.52%', 1: '77.31%', 2: '86.11%', 3: '91.80%', 4: '82.50%', 5: '92.51%'}, LR: 0.000229\n",
      "Epoch 167/200, Train Loss: 0.004350, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.155792, Val Acc: 85.64%, Val-Class-Acc: {0: '78.26%', 1: '78.51%', 2: '86.11%', 3: '91.39%', 4: '82.50%', 5: '92.81%'}, LR: 0.000229\n",
      "Epoch 168/200, Train Loss: 0.005085, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.203276, Val Acc: 85.87%, Val-Class-Acc: {0: '77.17%', 1: '77.61%', 2: '85.42%', 3: '91.39%', 4: '82.50%', 5: '95.51%'}, LR: 0.000206\n",
      "Epoch 169/200, Train Loss: 0.075969, Train-Class-Acc: {0: '95.50%', 1: '95.14%', 2: '99.48%', 3: '99.49%', 4: '99.37%', 5: '98.73%'}\n",
      "Val Loss: 1.028400, Val Acc: 83.84%, Val-Class-Acc: {0: '78.80%', 1: '76.12%', 2: '77.08%', 3: '85.66%', 4: '87.50%', 5: '95.51%'}, LR: 0.000206\n",
      "Epoch 170/200, Train Loss: 0.086972, Train-Class-Acc: {0: '98.37%', 1: '96.34%', 2: '97.92%', 3: '97.34%', 4: '98.73%', 5: '98.65%'}\n",
      "Val Loss: 0.982703, Val Acc: 85.79%, Val-Class-Acc: {0: '82.61%', 1: '76.42%', 2: '83.33%', 3: '90.16%', 4: '82.50%', 5: '95.21%'}, LR: 0.000206\n",
      "Epoch 171/200, Train Loss: 0.016406, Train-Class-Acc: {0: '99.86%', 1: '99.55%', 2: '100.00%', 3: '99.69%', 4: '100.00%', 5: '99.70%'}\n",
      "Val Loss: 0.925670, Val Acc: 85.95%, Val-Class-Acc: {0: '82.07%', 1: '78.51%', 2: '86.11%', 3: '91.39%', 4: '85.00%', 5: '91.62%'}, LR: 0.000206\n",
      "Epoch 172/200, Train Loss: 0.007954, Train-Class-Acc: {0: '100.00%', 1: '99.85%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.928727, Val Acc: 86.10%, Val-Class-Acc: {0: '82.61%', 1: '78.81%', 2: '87.50%', 3: '91.80%', 4: '85.00%', 5: '90.72%'}, LR: 0.000206\n",
      "Epoch 173/200, Train Loss: 0.006427, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.929796, Val Acc: 86.34%, Val-Class-Acc: {0: '81.52%', 1: '78.21%', 2: '87.50%', 3: '91.80%', 4: '85.00%', 5: '92.81%'}, LR: 0.000206\n",
      "Epoch 174/200, Train Loss: 0.006405, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.927009, Val Acc: 86.26%, Val-Class-Acc: {0: '82.61%', 1: '76.72%', 2: '86.81%', 3: '91.80%', 4: '85.00%', 5: '93.71%'}, LR: 0.000206\n",
      "Epoch 175/200, Train Loss: 0.005576, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.972098, Val Acc: 85.95%, Val-Class-Acc: {0: '82.07%', 1: '77.91%', 2: '86.11%', 3: '90.16%', 4: '82.50%', 5: '93.41%'}, LR: 0.000206\n",
      "Epoch 176/200, Train Loss: 0.005497, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 0.921005, Val Acc: 86.34%, Val-Class-Acc: {0: '84.78%', 1: '74.93%', 2: '88.89%', 3: '92.21%', 4: '85.00%', 5: '93.41%'}, LR: 0.000206\n",
      "Epoch 177/200, Train Loss: 0.005926, Train-Class-Acc: {0: '100.00%', 1: '99.85%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 0.991963, Val Acc: 86.03%, Val-Class-Acc: {0: '82.61%', 1: '76.12%', 2: '88.19%', 3: '91.80%', 4: '82.50%', 5: '93.11%'}, LR: 0.000206\n",
      "Epoch 178/200, Train Loss: 0.004984, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.017968, Val Acc: 86.34%, Val-Class-Acc: {0: '80.98%', 1: '78.21%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '93.71%'}, LR: 0.000206\n",
      "Epoch 179/200, Train Loss: 0.004952, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.009431, Val Acc: 86.34%, Val-Class-Acc: {0: '84.24%', 1: '75.52%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '94.61%'}, LR: 0.000185\n",
      "Epoch 180/200, Train Loss: 0.004884, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.050006, Val Acc: 86.18%, Val-Class-Acc: {0: '82.07%', 1: '79.40%', 2: '86.11%', 3: '89.34%', 4: '82.50%', 5: '93.41%'}, LR: 0.000185\n",
      "Epoch 181/200, Train Loss: 0.005632, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.036967, Val Acc: 86.34%, Val-Class-Acc: {0: '80.98%', 1: '77.01%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '94.91%'}, LR: 0.000185\n",
      "Epoch 182/200, Train Loss: 0.004660, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.024068, Val Acc: 86.10%, Val-Class-Acc: {0: '82.07%', 1: '76.72%', 2: '86.81%', 3: '91.39%', 4: '82.50%', 5: '94.01%'}, LR: 0.000185\n",
      "Epoch 183/200, Train Loss: 0.004562, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.039149, Val Acc: 86.18%, Val-Class-Acc: {0: '80.43%', 1: '78.51%', 2: '86.81%', 3: '91.39%', 4: '82.50%', 5: '93.41%'}, LR: 0.000185\n",
      "Epoch 184/200, Train Loss: 0.004621, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.027254, Val Acc: 86.18%, Val-Class-Acc: {0: '83.70%', 1: '77.01%', 2: '86.81%', 3: '90.98%', 4: '82.50%', 5: '93.41%'}, LR: 0.000185\n",
      "Epoch 185/200, Train Loss: 0.004421, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.044117, Val Acc: 86.26%, Val-Class-Acc: {0: '83.70%', 1: '76.12%', 2: '86.81%', 3: '91.39%', 4: '82.50%', 5: '94.31%'}, LR: 0.000185\n",
      "Epoch 186/200, Train Loss: 0.004464, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.034890, Val Acc: 86.26%, Val-Class-Acc: {0: '83.15%', 1: '76.72%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '93.71%'}, LR: 0.000185\n",
      "Epoch 187/200, Train Loss: 0.004388, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.015444, Val Acc: 85.79%, Val-Class-Acc: {0: '82.07%', 1: '76.72%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '92.51%'}, LR: 0.000185\n",
      "Epoch 188/200, Train Loss: 0.004352, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.016383, Val Acc: 86.03%, Val-Class-Acc: {0: '83.15%', 1: '77.01%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '92.51%'}, LR: 0.000185\n",
      "Epoch 189/200, Train Loss: 0.004388, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.011528, Val Acc: 85.56%, Val-Class-Acc: {0: '81.52%', 1: '77.01%', 2: '86.81%', 3: '92.62%', 4: '82.50%', 5: '91.02%'}, LR: 0.000185\n",
      "Epoch 190/200, Train Loss: 0.004282, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.034220, Val Acc: 85.79%, Val-Class-Acc: {0: '82.07%', 1: '76.72%', 2: '86.81%', 3: '92.21%', 4: '82.50%', 5: '92.22%'}, LR: 0.000167\n",
      "Epoch 191/200, Train Loss: 0.004211, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.045985, Val Acc: 86.18%, Val-Class-Acc: {0: '83.15%', 1: '76.42%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '93.71%'}, LR: 0.000167\n",
      "Epoch 192/200, Train Loss: 0.004205, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.052465, Val Acc: 86.18%, Val-Class-Acc: {0: '82.07%', 1: '77.31%', 2: '86.81%', 3: '91.80%', 4: '82.50%', 5: '93.41%'}, LR: 0.000167\n",
      "Epoch 193/200, Train Loss: 0.004153, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.081480, Val Acc: 86.03%, Val-Class-Acc: {0: '80.43%', 1: '78.21%', 2: '86.81%', 3: '91.39%', 4: '82.50%', 5: '93.11%'}, LR: 0.000167\n",
      "Epoch 194/200, Train Loss: 0.004117, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.073343, Val Acc: 86.34%, Val-Class-Acc: {0: '83.15%', 1: '77.61%', 2: '86.81%', 3: '91.39%', 4: '82.50%', 5: '93.41%'}, LR: 0.000167\n",
      "Epoch 195/200, Train Loss: 0.004097, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.064182, Val Acc: 86.18%, Val-Class-Acc: {0: '82.61%', 1: '77.31%', 2: '86.81%', 3: '91.39%', 4: '82.50%', 5: '93.41%'}, LR: 0.000167\n",
      "Epoch 196/200, Train Loss: 0.004130, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.044417, Val Acc: 85.95%, Val-Class-Acc: {0: '82.07%', 1: '77.31%', 2: '88.19%', 3: '91.80%', 4: '82.50%', 5: '91.92%'}, LR: 0.000167\n",
      "Epoch 197/200, Train Loss: 0.005497, Train-Class-Acc: {0: '100.00%', 1: '99.85%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 1.057501, Val Acc: 85.71%, Val-Class-Acc: {0: '83.15%', 1: '74.93%', 2: '88.19%', 3: '89.75%', 4: '82.50%', 5: '94.31%'}, LR: 0.000167\n",
      "Epoch 198/200, Train Loss: 0.005051, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%'}\n",
      "Val Loss: 1.096481, Val Acc: 86.10%, Val-Class-Acc: {0: '82.61%', 1: '73.73%', 2: '88.19%', 3: '92.62%', 4: '82.50%', 5: '95.21%'}, LR: 0.000167\n",
      "Epoch 199/200, Train Loss: 0.004399, Train-Class-Acc: {0: '100.00%', 1: '99.93%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.088411, Val Acc: 86.18%, Val-Class-Acc: {0: '79.89%', 1: '75.52%', 2: '88.19%', 3: '93.03%', 4: '82.50%', 5: '94.91%'}, LR: 0.000167\n",
      "Epoch 200/200, Train Loss: 0.004104, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'}\n",
      "Val Loss: 1.099183, Val Acc: 85.79%, Val-Class-Acc: {0: '78.26%', 1: '76.72%', 2: '86.11%', 3: '93.03%', 4: '82.50%', 5: '94.01%'}, LR: 0.000167\n",
      "\n",
      "üèÜ Best model saved as: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_best.pth (Val Accuracy: 87.90%)\n",
      "\n",
      "üìå Final model saved as: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_final.pth\n",
      "\n",
      "üéØ Top 5 Best Models:\n",
      "Epoch 56, Train Loss: 0.004574, Train-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'},\n",
      "Val Loss: 0.912068, Val Acc: 87.90%, Val-Acc: {0: '83.15%', 1: '80.90%', 2: '86.81%', 3: '93.85%', 4: '85.00%', 5: '94.01%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_56.pth\n",
      "Epoch 26, Train Loss: 0.009181, Train-Acc: {0: '100.00%', 1: '99.85%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.85%'},\n",
      "Val Loss: 0.820304, Val Acc: 87.74%, Val-Acc: {0: '87.50%', 1: '76.12%', 2: '88.19%', 3: '93.44%', 4: '82.50%', 5: '95.81%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_26.pth\n",
      "Epoch 46, Train Loss: 0.005968, Train-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'},\n",
      "Val Loss: 0.876041, Val Acc: 87.67%, Val-Acc: {0: '84.24%', 1: '79.10%', 2: '87.50%', 3: '93.03%', 4: '82.50%', 5: '94.91%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_46.pth\n",
      "Epoch 55, Train Loss: 0.004744, Train-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'},\n",
      "Val Loss: 0.897132, Val Acc: 87.59%, Val-Acc: {0: '84.24%', 1: '79.40%', 2: '86.11%', 3: '93.85%', 4: '85.00%', 5: '94.01%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_55.pth\n",
      "Epoch 41, Train Loss: 0.007155, Train-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%'},\n",
      "Val Loss: 0.832366, Val Acc: 87.51%, Val-Acc: {0: '85.33%', 1: '78.81%', 2: '87.50%', 3: '93.44%', 4: '82.50%', 5: '93.71%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3/ResNet18_1D_epoch_41.pth\n",
      "\n",
      "üß† Model Summary:\n",
      "Total Parameters: 3,861,126\n",
      "Model Size (float32): 14.73 MB\n",
      "Total Training Time: 832.89 seconds\n",
      "---\n",
      "### Period 3\n",
      "+ ##### Total training time: 832.89 seconds\n",
      "+ ##### Model: ResNet18_1D\n",
      "+ ##### Training and saving in *'/mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_3'*\n",
      "+ ##### Best Epoch: 56\n",
      "#### __Val Accuracy: 87.90%__\n",
      "#### __Val-Class-Acc: {0: '83.15%', 1: '80.90%', 2: '86.81%', 3: '93.85%', 4: '85.00%', 5: '94.01%'}__\n",
      "#### __Total Parameters: 3,861,126__\n",
      "#### __Model Size (float32): 14.73 MB__\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# üìå Period 3: EWC Training (Protect Period 2)\n",
    "# weight = class_weights_tensor\n",
    "# ================================\n",
    "period = 3\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.join(BASE_DIR, \"stop_training.txt\")\n",
    "model_saving_folder = os.path.join(BASE_DIR, \"Trained_models\", \"EWC_CIL_v2\", f\"Period_{period}\")\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Load Period 3 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, f\"X_train_p{period}.npy\"))\n",
    "y_train = np.load(os.path.join(save_dir, f\"y_train_p{period}.npy\"))\n",
    "X_val   = np.load(os.path.join(save_dir, f\"X_test_p{period}.npy\"))\n",
    "y_val   = np.load(os.path.join(save_dir, f\"y_test_p{period}.npy\"))\n",
    "\n",
    "# ==== Device ====\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "# ==== Model Configuration ====\n",
    "input_channels = X_train.shape[2]\n",
    "output_size = len(np.unique(y_train))\n",
    "model = ResNet18_1D(input_channels=input_channels, output_size=output_size).to(device)\n",
    "\n",
    "# ==== Load Period 2 Best Model Weights ====\n",
    "prev_model_path = os.path.join(BASE_DIR, \"Trained_models\", \"EWC_CIL_v1\", \"Period_2\", \"ResNet18_1D_best.pth\")\n",
    "prev_checkpoint = torch.load(prev_model_path, map_location=device)\n",
    "state_dict = prev_checkpoint[\"model_state_dict\"]\n",
    "model_dict = model.state_dict()\n",
    "filtered_dict = {k: v for k, v in state_dict.items() if k in model_dict and model_dict[k].shape == v.shape}\n",
    "model.load_state_dict(filtered_dict, strict=False)\n",
    "for k in model_dict:\n",
    "    if k not in filtered_dict:\n",
    "        print(f\"üîç Not loaded: {k}, shape={model_dict[k].shape}\")\n",
    "print(\"‚úÖ Loaded Period 2 weights (except FC mismatch)\")\n",
    "\n",
    "# ==== Prepare EWC (from Period 2 training data) ====\n",
    "X_prev = np.load(os.path.join(save_dir, \"X_train_p2.npy\"))\n",
    "y_prev = np.load(os.path.join(save_dir, \"y_train_p2.npy\"))\n",
    "train_loader_prev = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_prev, dtype=torch.float32), torch.tensor(y_prev, dtype=torch.long)),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "class_weights_tensor = compute_class_weights(y_train, output_size)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor.to(device))\n",
    "fisher_dict, params_dict = EWC.compute_fisher_and_params(model, train_loader_prev, criterion, device=device)\n",
    "ewc_state = EWC(fisher=fisher_dict, params=params_dict)\n",
    "print(\"üìà Fisher information computed from Period 2\")\n",
    "\n",
    "# ==== Optimizer / Scheduler ====\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "lambda_ewc = 1.0\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# ==== Training ====\n",
    "train_with_ewc_ecg(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name=\"ResNet18_1D\",\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    ewc=ewc_state,\n",
    "    lambda_ewc=lambda_ewc,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del X_train, y_train, X_val, y_val, X_prev, y_prev\n",
    "del prev_model_path, prev_checkpoint, state_dict, model_dict, filtered_dict\n",
    "del model, train_loader_prev, fisher_dict, params_dict, ewc_state\n",
    "del class_weights_tensor\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df753cf",
   "metadata": {},
   "source": [
    "### Period 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d60731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Automatically selected GPU:\n",
      "    - CUDA Device ID : 2\n",
      "    - Memory Used    : 413 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "üìå Labels found: [np.int64(0), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9)]\n",
      "üìå Output size inferred as: 10\n",
      "‚úÖ Loaded Period 3 weights (except FC mismatch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_321925/273691142.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  prev_checkpoint = torch.load(prev_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Fisher information computed from Period 3\n",
      "\n",
      "üöÄ 'train_with_ewc_ecg' started.\n",
      "‚úÖ Removed existing folder: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4\n",
      "\n",
      "‚úÖ Data Overview:\n",
      "X_train: torch.Size([5493, 5000, 12]), y_train: torch.Size([5493])\n",
      "X_val: torch.Size([1374, 5000, 12]), y_val: torch.Size([1374])\n",
      "Epoch 1/200, Train Loss: 0.700510, Train-Class-Acc: {0: '87.74%', 2: '88.91%', 3: '92.62%', 4: '81.65%', 5: '92.82%', 6: '38.02%', 7: '62.67%', 8: '72.13%', 9: '27.70%'}\n",
      "Val Loss: 0.410923, Val Acc: 88.57%, Val-Class-Acc: {0: '88.04%', 2: '97.22%', 3: '98.36%', 4: '75.00%', 5: '96.42%', 6: '43.52%', 7: '89.60%', 8: '89.81%', 9: '59.46%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.387734, Train-Class-Acc: {0: '92.23%', 2: '95.15%', 3: '96.62%', 4: '92.41%', 5: '97.68%', 6: '59.91%', 7: '75.65%', 8: '83.60%', 9: '57.43%'}\n",
      "Val Loss: 0.455607, Val Acc: 87.48%, Val-Class-Acc: {0: '90.76%', 2: '92.36%', 3: '97.13%', 4: '77.50%', 5: '96.42%', 6: '44.44%', 7: '88.00%', 8: '84.71%', 9: '54.05%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.318811, Train-Class-Acc: {0: '93.46%', 2: '97.05%', 3: '97.64%', 4: '92.41%', 5: '97.61%', 6: '68.43%', 7: '76.65%', 8: '84.71%', 9: '70.95%'}\n",
      "Val Loss: 0.493742, Val Acc: 86.17%, Val-Class-Acc: {0: '67.39%', 2: '93.75%', 3: '97.54%', 4: '82.50%', 5: '97.61%', 6: '57.41%', 7: '88.80%', 8: '82.80%', 9: '64.86%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.287209, Train-Class-Acc: {0: '95.64%', 2: '95.49%', 3: '97.44%', 4: '93.04%', 5: '98.20%', 6: '71.66%', 7: '77.84%', 8: '86.78%', 9: '66.89%'}\n",
      "Val Loss: 0.505035, Val Acc: 87.12%, Val-Class-Acc: {0: '89.67%', 2: '90.28%', 3: '95.08%', 4: '92.50%', 5: '97.01%', 6: '50.93%', 7: '79.20%', 8: '84.71%', 9: '56.76%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.269117, Train-Class-Acc: {0: '94.55%', 2: '94.28%', 3: '97.03%', 4: '94.94%', 5: '98.28%', 6: '72.35%', 7: '78.84%', 8: '90.61%', 9: '75.68%'}\n",
      "Val Loss: 0.514688, Val Acc: 86.61%, Val-Class-Acc: {0: '84.78%', 2: '93.06%', 3: '98.77%', 4: '87.50%', 5: '94.93%', 6: '42.59%', 7: '78.40%', 8: '89.17%', 9: '59.46%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.183998, Train-Class-Acc: {0: '98.23%', 2: '98.09%', 3: '98.77%', 4: '91.77%', 5: '98.80%', 6: '82.95%', 7: '83.43%', 8: '90.92%', 9: '78.38%'}\n",
      "Val Loss: 0.567784, Val Acc: 86.10%, Val-Class-Acc: {0: '90.76%', 2: '93.06%', 3: '97.95%', 4: '85.00%', 5: '91.04%', 6: '42.59%', 7: '73.60%', 8: '91.72%', 9: '59.46%'}, LR: 0.001000\n",
      "Epoch 7/200, Train Loss: 0.172711, Train-Class-Acc: {0: '97.00%', 2: '98.61%', 3: '98.57%', 4: '96.20%', 5: '98.80%', 6: '82.72%', 7: '86.43%', 8: '92.68%', 9: '84.46%'}\n",
      "Val Loss: 0.599319, Val Acc: 86.90%, Val-Class-Acc: {0: '80.43%', 2: '93.06%', 3: '92.21%', 4: '82.50%', 5: '98.21%', 6: '48.15%', 7: '84.80%', 8: '89.81%', 9: '70.27%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_3.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.148475, Train-Class-Acc: {0: '96.32%', 2: '98.09%', 3: '98.26%', 4: '96.20%', 5: '99.10%', 6: '87.33%', 7: '88.82%', 8: '93.47%', 9: '83.78%'}\n",
      "Val Loss: 0.577898, Val Acc: 85.66%, Val-Class-Acc: {0: '76.63%', 2: '95.83%', 3: '96.72%', 4: '77.50%', 5: '94.93%', 6: '40.74%', 7: '85.60%', 8: '86.62%', 9: '70.27%'}, LR: 0.001000\n",
      "Epoch 9/200, Train Loss: 0.145524, Train-Class-Acc: {0: '97.00%', 2: '96.88%', 3: '98.67%', 4: '98.10%', 5: '98.88%', 6: '84.79%', 7: '90.62%', 8: '93.47%', 9: '88.51%'}\n",
      "Val Loss: 0.562706, Val Acc: 87.70%, Val-Class-Acc: {0: '92.39%', 2: '93.06%', 3: '97.13%', 4: '87.50%', 5: '94.93%', 6: '43.52%', 7: '85.60%', 8: '82.17%', 9: '75.68%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_5.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.133348, Train-Class-Acc: {0: '98.09%', 2: '97.57%', 3: '98.98%', 4: '93.67%', 5: '98.73%', 6: '86.64%', 7: '90.22%', 8: '95.38%', 9: '92.57%'}\n",
      "Val Loss: 0.638347, Val Acc: 86.17%, Val-Class-Acc: {0: '83.15%', 2: '90.97%', 3: '95.90%', 4: '75.00%', 5: '94.63%', 6: '54.63%', 7: '80.00%', 8: '87.90%', 9: '59.46%'}, LR: 0.001000\n",
      "Epoch 11/200, Train Loss: 0.157195, Train-Class-Acc: {0: '97.00%', 2: '97.05%', 3: '98.26%', 4: '94.94%', 5: '97.91%', 6: '88.25%', 7: '90.82%', 8: '94.59%', 9: '85.14%'}\n",
      "Val Loss: 0.748025, Val Acc: 84.35%, Val-Class-Acc: {0: '69.57%', 2: '86.81%', 3: '93.85%', 4: '87.50%', 5: '98.81%', 6: '41.67%', 7: '84.80%', 8: '89.17%', 9: '54.05%'}, LR: 0.001000\n",
      "Epoch 12/200, Train Loss: 0.114507, Train-Class-Acc: {0: '96.46%', 2: '98.79%', 3: '98.46%', 4: '96.84%', 5: '99.25%', 6: '90.09%', 7: '92.42%', 8: '95.38%', 9: '84.46%'}\n",
      "Val Loss: 0.646862, Val Acc: 86.83%, Val-Class-Acc: {0: '84.78%', 2: '90.28%', 3: '96.31%', 4: '82.50%', 5: '97.01%', 6: '53.70%', 7: '78.40%', 8: '87.26%', 9: '56.76%'}, LR: 0.001000\n",
      "Epoch 13/200, Train Loss: 0.053765, Train-Class-Acc: {0: '98.64%', 2: '98.96%', 3: '99.39%', 4: '99.37%', 5: '99.93%', 6: '96.77%', 7: '97.01%', 8: '97.77%', 9: '97.30%'}\n",
      "Val Loss: 0.662875, Val Acc: 86.75%, Val-Class-Acc: {0: '84.78%', 2: '90.97%', 3: '97.13%', 4: '82.50%', 5: '95.82%', 6: '42.59%', 7: '85.60%', 8: '88.54%', 9: '59.46%'}, LR: 0.000900\n",
      "Epoch 14/200, Train Loss: 0.036824, Train-Class-Acc: {0: '99.05%', 2: '99.48%', 3: '99.49%', 4: '100.00%', 5: '100.00%', 6: '98.39%', 7: '98.20%', 8: '99.36%', 9: '99.32%'}\n",
      "Val Loss: 0.695650, Val Acc: 87.48%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '96.72%', 4: '85.00%', 5: '97.31%', 6: '49.07%', 7: '81.60%', 8: '82.17%', 9: '75.68%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_7.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_14.pth\n",
      "Epoch 15/200, Train Loss: 0.037591, Train-Class-Acc: {0: '99.32%', 2: '98.61%', 3: '99.49%', 4: '99.37%', 5: '99.63%', 6: '98.85%', 7: '98.40%', 8: '98.57%', 9: '98.65%'}\n",
      "Val Loss: 0.627757, Val Acc: 86.90%, Val-Class-Acc: {0: '80.43%', 2: '90.97%', 3: '96.72%', 4: '82.50%', 5: '95.52%', 6: '56.48%', 7: '77.60%', 8: '89.17%', 9: '75.68%'}, LR: 0.000900\n",
      "Epoch 16/200, Train Loss: 0.046616, Train-Class-Acc: {0: '99.46%', 2: '99.13%', 3: '99.49%', 4: '99.37%', 5: '99.48%', 6: '96.77%', 7: '97.41%', 8: '98.25%', 9: '100.00%'}\n",
      "Val Loss: 0.700833, Val Acc: 86.90%, Val-Class-Acc: {0: '83.15%', 2: '91.67%', 3: '96.31%', 4: '82.50%', 5: '97.91%', 6: '43.52%', 7: '82.40%', 8: '86.62%', 9: '72.97%'}, LR: 0.000900\n",
      "Epoch 17/200, Train Loss: 0.114570, Train-Class-Acc: {0: '96.05%', 2: '98.44%', 3: '98.05%', 4: '98.10%', 5: '97.76%', 6: '91.71%', 7: '94.21%', 8: '94.75%', 9: '93.92%'}\n",
      "Val Loss: 0.998439, Val Acc: 79.33%, Val-Class-Acc: {0: '92.93%', 2: '86.11%', 3: '70.90%', 4: '82.50%', 5: '92.54%', 6: '50.93%', 7: '84.80%', 8: '68.15%', 9: '29.73%'}, LR: 0.000900\n",
      "Epoch 18/200, Train Loss: 0.129056, Train-Class-Acc: {0: '96.19%', 2: '98.09%', 3: '98.16%', 4: '98.10%', 5: '98.35%', 6: '89.86%', 7: '94.41%', 8: '95.06%', 9: '85.81%'}\n",
      "Val Loss: 0.781217, Val Acc: 83.77%, Val-Class-Acc: {0: '78.26%', 2: '81.94%', 3: '92.21%', 4: '82.50%', 5: '97.91%', 6: '31.48%', 7: '84.00%', 8: '90.45%', 9: '59.46%'}, LR: 0.000900\n",
      "Epoch 19/200, Train Loss: 0.097226, Train-Class-Acc: {0: '98.64%', 2: '97.40%', 3: '98.77%', 4: '98.73%', 5: '98.88%', 6: '93.32%', 7: '96.41%', 8: '97.61%', 9: '89.86%'}\n",
      "Val Loss: 0.655984, Val Acc: 85.59%, Val-Class-Acc: {0: '91.85%', 2: '91.67%', 3: '97.95%', 4: '82.50%', 5: '88.06%', 6: '53.70%', 7: '83.20%', 8: '81.53%', 9: '48.65%'}, LR: 0.000900\n",
      "Epoch 20/200, Train Loss: 0.063424, Train-Class-Acc: {0: '97.82%', 2: '98.96%', 3: '99.69%', 4: '98.73%', 5: '99.33%', 6: '95.85%', 7: '96.21%', 8: '97.93%', 9: '94.59%'}\n",
      "Val Loss: 0.774017, Val Acc: 86.75%, Val-Class-Acc: {0: '90.76%', 2: '91.67%', 3: '97.13%', 4: '82.50%', 5: '97.61%', 6: '39.81%', 7: '80.00%', 8: '83.44%', 9: '59.46%'}, LR: 0.000900\n",
      "Epoch 21/200, Train Loss: 0.052471, Train-Class-Acc: {0: '99.32%', 2: '98.61%', 3: '99.59%', 4: '98.10%', 5: '99.63%', 6: '94.93%', 7: '98.40%', 8: '98.25%', 9: '98.65%'}\n",
      "Val Loss: 0.735119, Val Acc: 85.81%, Val-Class-Acc: {0: '87.50%', 2: '91.67%', 3: '95.90%', 4: '60.00%', 5: '95.22%', 6: '40.74%', 7: '81.60%', 8: '90.45%', 9: '56.76%'}, LR: 0.000900\n",
      "Epoch 22/200, Train Loss: 0.040214, Train-Class-Acc: {0: '99.59%', 2: '99.48%', 3: '99.59%', 4: '96.20%', 5: '99.78%', 6: '96.77%', 7: '99.20%', 8: '99.36%', 9: '96.62%'}\n",
      "Val Loss: 0.700023, Val Acc: 86.68%, Val-Class-Acc: {0: '82.61%', 2: '87.50%', 3: '97.54%', 4: '85.00%', 5: '95.82%', 6: '51.85%', 7: '79.20%', 8: '87.90%', 9: '72.97%'}, LR: 0.000900\n",
      "Epoch 23/200, Train Loss: 0.036963, Train-Class-Acc: {0: '99.32%', 2: '99.65%', 3: '99.80%', 4: '98.73%', 5: '99.78%', 6: '98.16%', 7: '98.40%', 8: '99.52%', 9: '98.65%'}\n",
      "Val Loss: 0.706006, Val Acc: 86.68%, Val-Class-Acc: {0: '86.41%', 2: '88.89%', 3: '96.72%', 4: '82.50%', 5: '94.63%', 6: '54.63%', 7: '79.20%', 8: '86.62%', 9: '64.86%'}, LR: 0.000900\n",
      "Epoch 24/200, Train Loss: 0.025803, Train-Class-Acc: {0: '99.59%', 2: '99.48%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '98.62%', 7: '99.40%', 8: '99.36%', 9: '98.65%'}\n",
      "Val Loss: 0.671441, Val Acc: 87.05%, Val-Class-Acc: {0: '86.96%', 2: '93.75%', 3: '97.54%', 4: '77.50%', 5: '94.93%', 6: '51.85%', 7: '79.20%', 8: '84.71%', 9: '70.27%'}, LR: 0.000810\n",
      "Epoch 25/200, Train Loss: 0.014696, Train-Class-Acc: {0: '99.59%', 2: '99.83%', 3: '99.80%', 4: '100.00%', 5: '99.93%', 6: '99.54%', 7: '100.00%', 8: '99.84%', 9: '100.00%'}\n",
      "Val Loss: 0.636068, Val Acc: 87.77%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '97.54%', 4: '82.50%', 5: '96.12%', 6: '55.56%', 7: '78.40%', 8: '87.26%', 9: '64.86%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_4.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_25.pth\n",
      "Epoch 26/200, Train Loss: 0.012171, Train-Class-Acc: {0: '99.86%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '100.00%', 6: '99.77%', 7: '99.80%', 8: '99.84%', 9: '100.00%'}\n",
      "Val Loss: 0.654646, Val Acc: 87.55%, Val-Class-Acc: {0: '89.67%', 2: '93.75%', 3: '96.72%', 4: '80.00%', 5: '96.72%', 6: '51.85%', 7: '79.20%', 8: '82.80%', 9: '70.27%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_2.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_26.pth\n",
      "Epoch 27/200, Train Loss: 0.010305, Train-Class-Acc: {0: '100.00%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '99.80%', 8: '99.84%', 9: '100.00%'}\n",
      "Val Loss: 0.695779, Val Acc: 87.48%, Val-Class-Acc: {0: '85.33%', 2: '92.36%', 3: '97.13%', 4: '80.00%', 5: '96.72%', 6: '48.15%', 7: '80.00%', 8: '88.54%', 9: '75.68%'}, LR: 0.000810\n",
      "Epoch 28/200, Train Loss: 0.008133, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.672348, Val Acc: 87.63%, Val-Class-Acc: {0: '90.22%', 2: '91.67%', 3: '97.13%', 4: '82.50%', 5: '96.72%', 6: '47.22%', 7: '78.40%', 8: '85.99%', 9: '75.68%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_14.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_28.pth\n",
      "Epoch 29/200, Train Loss: 0.007276, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.666618, Val Acc: 87.85%, Val-Class-Acc: {0: '90.76%', 2: '90.97%', 3: '97.13%', 4: '80.00%', 5: '96.72%', 6: '50.00%', 7: '78.40%', 8: '87.26%', 9: '72.97%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_26.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_29.pth\n",
      "Epoch 30/200, Train Loss: 0.006519, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.661606, Val Acc: 87.77%, Val-Class-Acc: {0: '89.67%', 2: '91.67%', 3: '97.54%', 4: '82.50%', 5: '96.42%', 6: '49.07%', 7: '79.20%', 8: '87.26%', 9: '70.27%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_28.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_30.pth\n",
      "Epoch 31/200, Train Loss: 0.006182, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.655400, Val Acc: 87.99%, Val-Class-Acc: {0: '88.04%', 2: '91.67%', 3: '97.54%', 4: '82.50%', 5: '97.01%', 6: '48.15%', 7: '79.20%', 8: '89.17%', 9: '75.68%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_9.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_31.pth\n",
      "Epoch 32/200, Train Loss: 0.005946, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.671215, Val Acc: 87.99%, Val-Class-Acc: {0: '89.13%', 2: '91.67%', 3: '97.95%', 4: '82.50%', 5: '97.01%', 6: '48.15%', 7: '79.20%', 8: '87.90%', 9: '72.97%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_25.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_32.pth\n",
      "Epoch 33/200, Train Loss: 0.005524, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.666397, Val Acc: 87.85%, Val-Class-Acc: {0: '89.13%', 2: '91.67%', 3: '97.95%', 4: '82.50%', 5: '97.01%', 6: '47.22%', 7: '80.00%', 8: '86.62%', 9: '72.97%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_30.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_33.pth\n",
      "Epoch 34/200, Train Loss: 0.005140, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.666600, Val Acc: 87.99%, Val-Class-Acc: {0: '89.67%', 2: '91.67%', 3: '97.95%', 4: '82.50%', 5: '97.01%', 6: '48.15%', 7: '79.20%', 8: '87.26%', 9: '72.97%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_29.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_34.pth\n",
      "Epoch 35/200, Train Loss: 0.004982, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.661701, Val Acc: 87.77%, Val-Class-Acc: {0: '90.76%', 2: '91.67%', 3: '97.95%', 4: '82.50%', 5: '97.01%', 6: '47.22%', 7: '80.80%', 8: '84.08%', 9: '70.27%'}, LR: 0.000729\n",
      "Epoch 36/200, Train Loss: 0.004742, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.671295, Val Acc: 87.77%, Val-Class-Acc: {0: '89.67%', 2: '91.67%', 3: '97.95%', 4: '82.50%', 5: '97.01%', 6: '47.22%', 7: '78.40%', 8: '87.26%', 9: '70.27%'}, LR: 0.000729\n",
      "Epoch 37/200, Train Loss: 0.004586, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.656949, Val Acc: 87.99%, Val-Class-Acc: {0: '90.22%', 2: '92.36%', 3: '97.54%', 4: '82.50%', 5: '97.01%', 6: '46.30%', 7: '79.20%', 8: '87.90%', 9: '72.97%'}, LR: 0.000729\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_33.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_37.pth\n",
      "Epoch 38/200, Train Loss: 0.004401, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.665693, Val Acc: 88.06%, Val-Class-Acc: {0: '90.22%', 2: '92.36%', 3: '97.13%', 4: '82.50%', 5: '97.01%', 6: '47.22%', 7: '79.20%', 8: '88.54%', 9: '72.97%'}, LR: 0.000729\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_31.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_38.pth\n",
      "Epoch 39/200, Train Loss: 0.004510, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '99.80%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.729571, Val Acc: 87.55%, Val-Class-Acc: {0: '89.67%', 2: '92.36%', 3: '96.72%', 4: '82.50%', 5: '96.72%', 6: '41.67%', 7: '83.20%', 8: '86.62%', 9: '72.97%'}, LR: 0.000729\n",
      "Epoch 40/200, Train Loss: 0.268581, Train-Class-Acc: {0: '94.28%', 2: '95.32%', 3: '95.29%', 4: '90.51%', 5: '96.71%', 6: '82.95%', 7: '89.02%', 8: '91.24%', 9: '84.46%'}\n",
      "Val Loss: 0.931709, Val Acc: 76.93%, Val-Class-Acc: {0: '62.50%', 2: '81.25%', 3: '98.77%', 4: '77.50%', 5: '89.25%', 6: '47.22%', 7: '40.00%', 8: '89.17%', 9: '35.14%'}, LR: 0.000729\n",
      "Epoch 41/200, Train Loss: 0.236225, Train-Class-Acc: {0: '94.41%', 2: '94.80%', 3: '97.23%', 4: '93.04%', 5: '97.61%', 6: '81.11%', 7: '89.22%', 8: '91.24%', 9: '81.08%'}\n",
      "Val Loss: 0.684871, Val Acc: 84.28%, Val-Class-Acc: {0: '80.98%', 2: '88.19%', 3: '97.13%', 4: '75.00%', 5: '92.84%', 6: '49.07%', 7: '76.80%', 8: '83.44%', 9: '64.86%'}, LR: 0.000729\n",
      "Epoch 42/200, Train Loss: 0.094685, Train-Class-Acc: {0: '96.87%', 2: '98.61%', 3: '99.08%', 4: '98.10%', 5: '99.10%', 6: '92.86%', 7: '96.21%', 8: '97.13%', 9: '93.92%'}\n",
      "Val Loss: 0.792839, Val Acc: 84.64%, Val-Class-Acc: {0: '82.07%', 2: '88.19%', 3: '97.13%', 4: '77.50%', 5: '94.63%', 6: '32.41%', 7: '84.80%', 8: '86.62%', 9: '62.16%'}, LR: 0.000729\n",
      "Epoch 43/200, Train Loss: 0.050416, Train-Class-Acc: {0: '99.46%', 2: '99.65%', 3: '99.18%', 4: '96.84%', 5: '99.33%', 6: '96.31%', 7: '98.00%', 8: '99.04%', 9: '96.62%'}\n",
      "Val Loss: 0.769703, Val Acc: 86.46%, Val-Class-Acc: {0: '91.85%', 2: '89.58%', 3: '95.49%', 4: '87.50%', 5: '94.63%', 6: '52.78%', 7: '70.40%', 8: '86.62%', 9: '64.86%'}, LR: 0.000729\n",
      "Epoch 44/200, Train Loss: 0.032722, Train-Class-Acc: {0: '99.86%', 2: '99.65%', 3: '99.59%', 4: '99.37%', 5: '99.70%', 6: '98.85%', 7: '98.20%', 8: '99.36%', 9: '97.97%'}\n",
      "Val Loss: 0.742782, Val Acc: 86.17%, Val-Class-Acc: {0: '88.04%', 2: '91.67%', 3: '97.54%', 4: '80.00%', 5: '93.73%', 6: '40.74%', 7: '80.80%', 8: '86.62%', 9: '67.57%'}, LR: 0.000729\n",
      "Epoch 45/200, Train Loss: 0.018916, Train-Class-Acc: {0: '99.86%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.93%', 6: '98.85%', 7: '99.80%', 8: '99.52%', 9: '100.00%'}\n",
      "Val Loss: 0.776704, Val Acc: 86.39%, Val-Class-Acc: {0: '73.37%', 2: '88.89%', 3: '97.13%', 4: '82.50%', 5: '97.31%', 6: '56.48%', 7: '79.20%', 8: '90.45%', 9: '70.27%'}, LR: 0.000729\n",
      "Epoch 46/200, Train Loss: 0.017936, Train-Class-Acc: {0: '99.46%', 2: '100.00%', 3: '100.00%', 4: '99.37%', 5: '99.93%', 6: '99.54%', 7: '99.60%', 8: '99.36%', 9: '98.65%'}\n",
      "Val Loss: 0.716112, Val Acc: 86.54%, Val-Class-Acc: {0: '82.61%', 2: '93.75%', 3: '96.72%', 4: '82.50%', 5: '94.93%', 6: '48.15%', 7: '80.80%', 8: '88.54%', 9: '62.16%'}, LR: 0.000656\n",
      "Epoch 47/200, Train Loss: 0.012445, Train-Class-Acc: {0: '99.86%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '99.80%', 8: '99.84%', 9: '100.00%'}\n",
      "Val Loss: 0.707264, Val Acc: 86.32%, Val-Class-Acc: {0: '83.70%', 2: '92.36%', 3: '96.72%', 4: '80.00%', 5: '95.52%', 6: '45.37%', 7: '76.80%', 8: '88.54%', 9: '72.97%'}, LR: 0.000656\n",
      "Epoch 48/200, Train Loss: 0.011714, Train-Class-Acc: {0: '99.86%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '99.77%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.683592, Val Acc: 87.34%, Val-Class-Acc: {0: '84.78%', 2: '93.06%', 3: '95.90%', 4: '82.50%', 5: '96.72%', 6: '48.15%', 7: '79.20%', 8: '90.45%', 9: '70.27%'}, LR: 0.000656\n",
      "Epoch 49/200, Train Loss: 0.012670, Train-Class-Acc: {0: '99.73%', 2: '99.83%', 3: '99.90%', 4: '100.00%', 5: '99.93%', 6: '99.77%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.766017, Val Acc: 85.81%, Val-Class-Acc: {0: '76.63%', 2: '93.06%', 3: '96.72%', 4: '82.50%', 5: '95.82%', 6: '39.81%', 7: '81.60%', 8: '90.45%', 9: '72.97%'}, LR: 0.000656\n",
      "Epoch 50/200, Train Loss: 0.008971, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.717083, Val Acc: 86.90%, Val-Class-Acc: {0: '82.61%', 2: '92.36%', 3: '95.90%', 4: '85.00%', 5: '97.01%', 6: '46.30%', 7: '80.00%', 8: '89.17%', 9: '70.27%'}, LR: 0.000656\n",
      "Epoch 51/200, Train Loss: 0.008429, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.692055, Val Acc: 87.34%, Val-Class-Acc: {0: '85.87%', 2: '92.36%', 3: '97.54%', 4: '85.00%', 5: '95.82%', 6: '48.15%', 7: '80.00%', 8: '87.90%', 9: '70.27%'}, LR: 0.000656\n",
      "Epoch 52/200, Train Loss: 0.007260, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.704828, Val Acc: 87.63%, Val-Class-Acc: {0: '86.96%', 2: '92.36%', 3: '97.13%', 4: '85.00%', 5: '97.31%', 6: '45.37%', 7: '80.00%', 8: '88.54%', 9: '70.27%'}, LR: 0.000656\n",
      "Epoch 53/200, Train Loss: 0.006763, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.708400, Val Acc: 87.48%, Val-Class-Acc: {0: '86.41%', 2: '92.36%', 3: '97.13%', 4: '85.00%', 5: '97.31%', 6: '46.30%', 7: '78.40%', 8: '88.54%', 9: '70.27%'}, LR: 0.000656\n",
      "Epoch 54/200, Train Loss: 0.006458, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.715641, Val Acc: 86.90%, Val-Class-Acc: {0: '82.07%', 2: '92.36%', 3: '97.13%', 4: '85.00%', 5: '97.01%', 6: '44.44%', 7: '80.00%', 8: '89.17%', 9: '70.27%'}, LR: 0.000656\n",
      "Epoch 55/200, Train Loss: 0.006083, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.706930, Val Acc: 87.12%, Val-Class-Acc: {0: '83.70%', 2: '91.67%', 3: '97.13%', 4: '82.50%', 5: '97.61%', 6: '46.30%', 7: '78.40%', 8: '89.17%', 9: '70.27%'}, LR: 0.000656\n",
      "Epoch 56/200, Train Loss: 0.005830, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.698072, Val Acc: 87.26%, Val-Class-Acc: {0: '85.33%', 2: '90.97%', 3: '96.72%', 4: '85.00%', 5: '97.31%', 6: '47.22%', 7: '79.20%', 8: '88.54%', 9: '70.27%'}, LR: 0.000656\n",
      "Epoch 57/200, Train Loss: 0.005645, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.700331, Val Acc: 87.19%, Val-Class-Acc: {0: '85.33%', 2: '90.97%', 3: '97.13%', 4: '85.00%', 5: '97.01%', 6: '45.37%', 7: '80.80%', 8: '87.90%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 58/200, Train Loss: 0.005444, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.702891, Val Acc: 87.12%, Val-Class-Acc: {0: '84.24%', 2: '91.67%', 3: '97.13%', 4: '85.00%', 5: '97.31%', 6: '46.30%', 7: '78.40%', 8: '88.54%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 59/200, Train Loss: 0.005234, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.702774, Val Acc: 87.26%, Val-Class-Acc: {0: '84.78%', 2: '92.36%', 3: '96.72%', 4: '85.00%', 5: '97.31%', 6: '45.37%', 7: '80.00%', 8: '88.54%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 60/200, Train Loss: 0.005141, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.710203, Val Acc: 87.34%, Val-Class-Acc: {0: '82.07%', 2: '92.36%', 3: '96.31%', 4: '82.50%', 5: '97.31%', 6: '48.15%', 7: '82.40%', 8: '89.17%', 9: '72.97%'}, LR: 0.000590\n",
      "Epoch 61/200, Train Loss: 0.004943, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.692167, Val Acc: 87.48%, Val-Class-Acc: {0: '85.33%', 2: '92.36%', 3: '97.13%', 4: '82.50%', 5: '97.31%', 6: '47.22%', 7: '81.60%', 8: '87.26%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 62/200, Train Loss: 0.004773, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.695696, Val Acc: 87.48%, Val-Class-Acc: {0: '85.87%', 2: '92.36%', 3: '97.13%', 4: '82.50%', 5: '97.01%', 6: '47.22%', 7: '81.60%', 8: '87.26%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 63/200, Train Loss: 0.004617, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.708768, Val Acc: 87.34%, Val-Class-Acc: {0: '86.41%', 2: '91.67%', 3: '97.13%', 4: '82.50%', 5: '97.31%', 6: '44.44%', 7: '80.00%', 8: '88.54%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 64/200, Train Loss: 0.004512, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.711887, Val Acc: 86.83%, Val-Class-Acc: {0: '83.15%', 2: '92.36%', 3: '97.13%', 4: '82.50%', 5: '97.31%', 6: '45.37%', 7: '77.60%', 8: '88.54%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 65/200, Train Loss: 0.004443, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.708572, Val Acc: 87.19%, Val-Class-Acc: {0: '84.78%', 2: '92.36%', 3: '97.13%', 4: '82.50%', 5: '97.31%', 6: '46.30%', 7: '78.40%', 8: '88.54%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 66/200, Train Loss: 0.004268, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.698609, Val Acc: 87.34%, Val-Class-Acc: {0: '84.24%', 2: '92.36%', 3: '96.72%', 4: '82.50%', 5: '97.31%', 6: '49.07%', 7: '80.00%', 8: '87.90%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 67/200, Train Loss: 0.004084, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.701942, Val Acc: 87.34%, Val-Class-Acc: {0: '84.78%', 2: '91.67%', 3: '97.13%', 4: '82.50%', 5: '97.31%', 6: '44.44%', 7: '80.80%', 8: '89.81%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 68/200, Train Loss: 0.004043, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.703055, Val Acc: 87.41%, Val-Class-Acc: {0: '85.33%', 2: '91.67%', 3: '97.54%', 4: '85.00%', 5: '97.01%', 6: '46.30%', 7: '80.80%', 8: '87.90%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 69/200, Train Loss: 0.003958, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.699290, Val Acc: 87.48%, Val-Class-Acc: {0: '86.41%', 2: '91.67%', 3: '97.13%', 4: '82.50%', 5: '97.01%', 6: '45.37%', 7: '82.40%', 8: '87.90%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 70/200, Train Loss: 0.003815, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.712600, Val Acc: 87.55%, Val-Class-Acc: {0: '85.33%', 2: '91.67%', 3: '97.54%', 4: '82.50%', 5: '97.61%', 6: '44.44%', 7: '81.60%', 8: '89.17%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 71/200, Train Loss: 0.003687, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.708469, Val Acc: 87.55%, Val-Class-Acc: {0: '87.50%', 2: '91.67%', 3: '97.13%', 4: '82.50%', 5: '97.31%', 6: '44.44%', 7: '80.00%', 8: '89.17%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 72/200, Train Loss: 0.003612, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.710139, Val Acc: 87.77%, Val-Class-Acc: {0: '88.04%', 2: '91.67%', 3: '97.95%', 4: '82.50%', 5: '97.01%', 6: '45.37%', 7: '81.60%', 8: '87.90%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 73/200, Train Loss: 0.003556, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.714810, Val Acc: 87.70%, Val-Class-Acc: {0: '89.13%', 2: '91.67%', 3: '97.54%', 4: '85.00%', 5: '97.31%', 6: '43.52%', 7: '80.00%', 8: '87.90%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 74/200, Train Loss: 0.003425, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.725011, Val Acc: 87.55%, Val-Class-Acc: {0: '87.50%', 2: '91.67%', 3: '97.13%', 4: '85.00%', 5: '97.31%', 6: '43.52%', 7: '80.80%', 8: '88.54%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 75/200, Train Loss: 0.003364, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.720560, Val Acc: 87.48%, Val-Class-Acc: {0: '87.50%', 2: '91.67%', 3: '97.54%', 4: '82.50%', 5: '97.01%', 6: '41.67%', 7: '82.40%', 8: '88.54%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 76/200, Train Loss: 0.003260, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.726501, Val Acc: 87.05%, Val-Class-Acc: {0: '85.87%', 2: '91.67%', 3: '97.13%', 4: '82.50%', 5: '96.72%', 6: '42.59%', 7: '80.80%', 8: '88.54%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 77/200, Train Loss: 0.003166, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.721784, Val Acc: 87.12%, Val-Class-Acc: {0: '86.41%', 2: '91.67%', 3: '97.54%', 4: '82.50%', 5: '96.72%', 6: '42.59%', 7: '80.00%', 8: '88.54%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 78/200, Train Loss: 0.003103, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.720205, Val Acc: 87.05%, Val-Class-Acc: {0: '87.50%', 2: '91.67%', 3: '97.95%', 4: '82.50%', 5: '96.42%', 6: '41.67%', 7: '80.80%', 8: '87.26%', 9: '67.57%'}, LR: 0.000531\n",
      "Epoch 79/200, Train Loss: 0.003033, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.763327, Val Acc: 86.46%, Val-Class-Acc: {0: '84.24%', 2: '90.97%', 3: '97.95%', 4: '82.50%', 5: '97.31%', 6: '36.11%', 7: '80.80%', 8: '87.90%', 9: '70.27%'}, LR: 0.000478\n",
      "Epoch 80/200, Train Loss: 0.003030, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.714489, Val Acc: 87.05%, Val-Class-Acc: {0: '84.78%', 2: '91.67%', 3: '97.54%', 4: '80.00%', 5: '97.01%', 6: '43.52%', 7: '81.60%', 8: '87.90%', 9: '70.27%'}, LR: 0.000478\n",
      "Epoch 81/200, Train Loss: 0.002902, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.715354, Val Acc: 87.05%, Val-Class-Acc: {0: '88.04%', 2: '91.67%', 3: '97.13%', 4: '80.00%', 5: '97.01%', 6: '41.67%', 7: '80.00%', 8: '87.26%', 9: '70.27%'}, LR: 0.000478\n",
      "Epoch 82/200, Train Loss: 0.002800, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.730699, Val Acc: 87.34%, Val-Class-Acc: {0: '86.96%', 2: '91.67%', 3: '97.54%', 4: '80.00%', 5: '97.31%', 6: '44.44%', 7: '80.00%', 8: '88.54%', 9: '67.57%'}, LR: 0.000478\n",
      "Epoch 83/200, Train Loss: 0.002739, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.730356, Val Acc: 87.05%, Val-Class-Acc: {0: '87.50%', 2: '91.67%', 3: '96.72%', 4: '85.00%', 5: '97.31%', 6: '39.81%', 7: '80.80%', 8: '87.26%', 9: '70.27%'}, LR: 0.000478\n",
      "Epoch 84/200, Train Loss: 0.002662, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.735475, Val Acc: 86.83%, Val-Class-Acc: {0: '85.87%', 2: '91.67%', 3: '97.54%', 4: '80.00%', 5: '97.31%', 6: '37.96%', 7: '80.80%', 8: '88.54%', 9: '70.27%'}, LR: 0.000478\n",
      "Epoch 85/200, Train Loss: 0.002601, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.725907, Val Acc: 86.75%, Val-Class-Acc: {0: '86.41%', 2: '91.67%', 3: '96.72%', 4: '80.00%', 5: '97.01%', 6: '38.89%', 7: '81.60%', 8: '87.90%', 9: '70.27%'}, LR: 0.000478\n",
      "Epoch 86/200, Train Loss: 0.002603, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.738751, Val Acc: 86.17%, Val-Class-Acc: {0: '85.87%', 2: '91.67%', 3: '96.72%', 4: '80.00%', 5: '94.93%', 6: '37.96%', 7: '84.00%', 8: '86.62%', 9: '70.27%'}, LR: 0.000478\n",
      "Epoch 87/200, Train Loss: 0.434160, Train-Class-Acc: {0: '87.60%', 2: '92.20%', 3: '94.26%', 4: '89.24%', 5: '95.59%', 6: '74.42%', 7: '81.64%', 8: '83.60%', 9: '73.65%'}\n",
      "Val Loss: 0.665911, Val Acc: 82.39%, Val-Class-Acc: {0: '88.04%', 2: '76.39%', 3: '93.85%', 4: '80.00%', 5: '90.75%', 6: '50.93%', 7: '80.80%', 8: '82.17%', 9: '27.03%'}, LR: 0.000478\n",
      "Epoch 88/200, Train Loss: 0.188168, Train-Class-Acc: {0: '95.64%', 2: '96.19%', 3: '97.44%', 4: '95.57%', 5: '97.53%', 6: '84.10%', 7: '89.62%', 8: '92.83%', 9: '85.14%'}\n",
      "Val Loss: 0.608464, Val Acc: 85.74%, Val-Class-Acc: {0: '91.85%', 2: '92.36%', 3: '96.31%', 4: '85.00%', 5: '94.33%', 6: '51.85%', 7: '83.20%', 8: '71.97%', 9: '48.65%'}, LR: 0.000478\n",
      "Epoch 89/200, Train Loss: 0.046557, Train-Class-Acc: {0: '99.18%', 2: '99.31%', 3: '99.69%', 4: '99.37%', 5: '99.48%', 6: '97.47%', 7: '98.60%', 8: '98.89%', 9: '96.62%'}\n",
      "Val Loss: 0.619547, Val Acc: 86.68%, Val-Class-Acc: {0: '85.87%', 2: '91.67%', 3: '97.13%', 4: '80.00%', 5: '95.22%', 6: '57.41%', 7: '78.40%', 8: '83.44%', 9: '59.46%'}, LR: 0.000478\n",
      "Epoch 90/200, Train Loss: 0.019081, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.69%', 4: '100.00%', 5: '99.93%', 6: '99.54%', 7: '99.80%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.641720, Val Acc: 85.95%, Val-Class-Acc: {0: '84.24%', 2: '90.97%', 3: '96.31%', 4: '82.50%', 5: '96.12%', 6: '49.07%', 7: '77.60%', 8: '80.89%', 9: '75.68%'}, LR: 0.000430\n",
      "Epoch 91/200, Train Loss: 0.011830, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '99.77%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.639536, Val Acc: 87.41%, Val-Class-Acc: {0: '84.78%', 2: '92.36%', 3: '96.31%', 4: '82.50%', 5: '96.72%', 6: '48.15%', 7: '82.40%', 8: '86.62%', 9: '78.38%'}, LR: 0.000430\n",
      "Epoch 92/200, Train Loss: 0.009781, Train-Class-Acc: {0: '99.86%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.658119, Val Acc: 87.05%, Val-Class-Acc: {0: '88.59%', 2: '90.28%', 3: '95.90%', 4: '82.50%', 5: '96.42%', 6: '47.22%', 7: '81.60%', 8: '84.08%', 9: '75.68%'}, LR: 0.000430\n",
      "Epoch 93/200, Train Loss: 0.008464, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.670631, Val Acc: 87.34%, Val-Class-Acc: {0: '86.96%', 2: '90.28%', 3: '96.31%', 4: '85.00%', 5: '96.42%', 6: '46.30%', 7: '82.40%', 8: '87.26%', 9: '75.68%'}, LR: 0.000430\n",
      "Epoch 94/200, Train Loss: 0.009086, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '99.54%', 7: '99.80%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.688455, Val Acc: 86.68%, Val-Class-Acc: {0: '86.41%', 2: '88.19%', 3: '96.31%', 4: '82.50%', 5: '96.72%', 6: '51.85%', 7: '80.00%', 8: '84.71%', 9: '64.86%'}, LR: 0.000430\n",
      "Epoch 95/200, Train Loss: 0.007296, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.684764, Val Acc: 86.83%, Val-Class-Acc: {0: '84.24%', 2: '89.58%', 3: '95.90%', 4: '82.50%', 5: '97.01%', 6: '47.22%', 7: '81.60%', 8: '87.26%', 9: '72.97%'}, LR: 0.000430\n",
      "Epoch 96/200, Train Loss: 0.006691, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.673039, Val Acc: 87.05%, Val-Class-Acc: {0: '86.96%', 2: '89.58%', 3: '96.31%', 4: '82.50%', 5: '96.42%', 6: '48.15%', 7: '81.60%', 8: '85.99%', 9: '72.97%'}, LR: 0.000430\n",
      "Epoch 97/200, Train Loss: 0.006277, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.698568, Val Acc: 86.83%, Val-Class-Acc: {0: '86.41%', 2: '90.28%', 3: '96.31%', 4: '82.50%', 5: '96.72%', 6: '46.30%', 7: '78.40%', 8: '87.26%', 9: '72.97%'}, LR: 0.000430\n",
      "Epoch 98/200, Train Loss: 0.005903, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.690299, Val Acc: 86.75%, Val-Class-Acc: {0: '84.24%', 2: '90.28%', 3: '96.31%', 4: '82.50%', 5: '97.01%', 6: '46.30%', 7: '80.00%', 8: '86.62%', 9: '75.68%'}, LR: 0.000430\n",
      "Epoch 99/200, Train Loss: 0.005843, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.697471, Val Acc: 86.46%, Val-Class-Acc: {0: '83.70%', 2: '90.28%', 3: '95.90%', 4: '82.50%', 5: '96.72%', 6: '45.37%', 7: '80.00%', 8: '87.26%', 9: '72.97%'}, LR: 0.000430\n",
      "Epoch 100/200, Train Loss: 0.005474, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.688403, Val Acc: 86.61%, Val-Class-Acc: {0: '86.41%', 2: '90.28%', 3: '96.31%', 4: '85.00%', 5: '95.52%', 6: '46.30%', 7: '79.20%', 8: '87.26%', 9: '70.27%'}, LR: 0.000430\n",
      "Epoch 101/200, Train Loss: 0.005210, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.701509, Val Acc: 86.54%, Val-Class-Acc: {0: '86.96%', 2: '90.28%', 3: '96.31%', 4: '82.50%', 5: '96.12%', 6: '47.22%', 7: '79.20%', 8: '84.71%', 9: '70.27%'}, LR: 0.000387\n",
      "Epoch 102/200, Train Loss: 0.005141, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.702619, Val Acc: 86.83%, Val-Class-Acc: {0: '84.24%', 2: '90.28%', 3: '96.31%', 4: '85.00%', 5: '96.42%', 6: '47.22%', 7: '80.80%', 8: '86.62%', 9: '75.68%'}, LR: 0.000387\n",
      "Epoch 103/200, Train Loss: 0.004938, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.693290, Val Acc: 86.90%, Val-Class-Acc: {0: '84.78%', 2: '89.58%', 3: '96.31%', 4: '82.50%', 5: '96.72%', 6: '47.22%', 7: '81.60%', 8: '85.99%', 9: '78.38%'}, LR: 0.000387\n",
      "Epoch 104/200, Train Loss: 0.004800, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.703100, Val Acc: 86.68%, Val-Class-Acc: {0: '85.87%', 2: '89.58%', 3: '96.72%', 4: '82.50%', 5: '95.82%', 6: '46.30%', 7: '81.60%', 8: '85.35%', 9: '75.68%'}, LR: 0.000387\n",
      "Epoch 105/200, Train Loss: 0.004736, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.715075, Val Acc: 86.54%, Val-Class-Acc: {0: '83.15%', 2: '90.97%', 3: '96.72%', 4: '85.00%', 5: '96.12%', 6: '44.44%', 7: '80.80%', 8: '86.62%', 9: '75.68%'}, LR: 0.000387\n",
      "Epoch 106/200, Train Loss: 0.004602, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.709550, Val Acc: 86.97%, Val-Class-Acc: {0: '85.87%', 2: '90.97%', 3: '96.72%', 4: '82.50%', 5: '96.42%', 6: '46.30%', 7: '81.60%', 8: '85.99%', 9: '72.97%'}, LR: 0.000387\n",
      "Epoch 107/200, Train Loss: 0.004473, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.711470, Val Acc: 86.61%, Val-Class-Acc: {0: '84.78%', 2: '90.28%', 3: '96.72%', 4: '82.50%', 5: '96.42%', 6: '45.37%', 7: '80.80%', 8: '85.99%', 9: '72.97%'}, LR: 0.000387\n",
      "Epoch 108/200, Train Loss: 0.004375, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.699038, Val Acc: 86.90%, Val-Class-Acc: {0: '84.78%', 2: '90.28%', 3: '96.72%', 4: '82.50%', 5: '97.01%', 6: '46.30%', 7: '81.60%', 8: '85.99%', 9: '72.97%'}, LR: 0.000387\n",
      "Epoch 109/200, Train Loss: 0.004263, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.719951, Val Acc: 86.54%, Val-Class-Acc: {0: '83.70%', 2: '90.28%', 3: '96.72%', 4: '82.50%', 5: '97.01%', 6: '45.37%', 7: '79.20%', 8: '86.62%', 9: '72.97%'}, LR: 0.000387\n",
      "Epoch 110/200, Train Loss: 0.004153, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.715633, Val Acc: 86.90%, Val-Class-Acc: {0: '85.87%', 2: '90.28%', 3: '96.72%', 4: '82.50%', 5: '97.01%', 6: '45.37%', 7: '80.00%', 8: '86.62%', 9: '72.97%'}, LR: 0.000387\n",
      "Epoch 111/200, Train Loss: 0.004103, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.711213, Val Acc: 86.46%, Val-Class-Acc: {0: '86.96%', 2: '90.97%', 3: '96.72%', 4: '82.50%', 5: '96.12%', 6: '45.37%', 7: '79.20%', 8: '83.44%', 9: '72.97%'}, LR: 0.000387\n",
      "Epoch 112/200, Train Loss: 0.004016, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.726300, Val Acc: 86.61%, Val-Class-Acc: {0: '86.41%', 2: '90.28%', 3: '96.31%', 4: '82.50%', 5: '96.42%', 6: '44.44%', 7: '80.80%', 8: '85.35%', 9: '72.97%'}, LR: 0.000349\n",
      "Epoch 113/200, Train Loss: 0.003900, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.732388, Val Acc: 86.68%, Val-Class-Acc: {0: '85.33%', 2: '90.97%', 3: '96.72%', 4: '82.50%', 5: '96.72%', 6: '42.59%', 7: '80.80%', 8: '86.62%', 9: '72.97%'}, LR: 0.000349\n",
      "Epoch 114/200, Train Loss: 0.003850, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.725796, Val Acc: 86.75%, Val-Class-Acc: {0: '87.50%', 2: '89.58%', 3: '96.72%', 4: '82.50%', 5: '96.42%', 6: '44.44%', 7: '80.00%', 8: '85.99%', 9: '72.97%'}, LR: 0.000349\n",
      "Epoch 115/200, Train Loss: 0.003760, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.728566, Val Acc: 86.46%, Val-Class-Acc: {0: '86.41%', 2: '90.28%', 3: '96.72%', 4: '85.00%', 5: '95.82%', 6: '44.44%', 7: '79.20%', 8: '85.35%', 9: '72.97%'}, LR: 0.000349\n",
      "Epoch 116/200, Train Loss: 0.003684, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.739933, Val Acc: 86.75%, Val-Class-Acc: {0: '83.70%', 2: '90.97%', 3: '96.31%', 4: '87.50%', 5: '96.72%', 6: '44.44%', 7: '79.20%', 8: '88.54%', 9: '72.97%'}, LR: 0.000349\n",
      "Epoch 117/200, Train Loss: 0.003628, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.754399, Val Acc: 86.75%, Val-Class-Acc: {0: '85.87%', 2: '90.97%', 3: '96.31%', 4: '87.50%', 5: '96.72%', 6: '42.59%', 7: '79.20%', 8: '86.62%', 9: '75.68%'}, LR: 0.000349\n",
      "Epoch 118/200, Train Loss: 0.003561, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.760176, Val Acc: 86.75%, Val-Class-Acc: {0: '84.24%', 2: '90.28%', 3: '96.31%', 4: '85.00%', 5: '96.72%', 6: '42.59%', 7: '81.60%', 8: '88.54%', 9: '72.97%'}, LR: 0.000349\n",
      "Epoch 119/200, Train Loss: 0.003511, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.744873, Val Acc: 87.19%, Val-Class-Acc: {0: '86.96%', 2: '90.97%', 3: '96.31%', 4: '92.50%', 5: '97.31%', 6: '42.59%', 7: '80.00%', 8: '87.26%', 9: '70.27%'}, LR: 0.000349\n",
      "Epoch 120/200, Train Loss: 0.003552, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.770123, Val Acc: 86.17%, Val-Class-Acc: {0: '84.24%', 2: '90.97%', 3: '96.72%', 4: '87.50%', 5: '96.72%', 6: '36.11%', 7: '79.20%', 8: '87.26%', 9: '75.68%'}, LR: 0.000349\n",
      "Epoch 121/200, Train Loss: 0.003493, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.757226, Val Acc: 86.32%, Val-Class-Acc: {0: '84.78%', 2: '90.97%', 3: '96.31%', 4: '82.50%', 5: '97.01%', 6: '40.74%', 7: '79.20%', 8: '85.99%', 9: '75.68%'}, LR: 0.000349\n",
      "Epoch 122/200, Train Loss: 0.003324, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.754346, Val Acc: 86.46%, Val-Class-Acc: {0: '85.33%', 2: '90.97%', 3: '96.31%', 4: '82.50%', 5: '96.72%', 6: '42.59%', 7: '79.20%', 8: '86.62%', 9: '72.97%'}, LR: 0.000349\n",
      "Epoch 123/200, Train Loss: 0.003248, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.763584, Val Acc: 86.54%, Val-Class-Acc: {0: '85.33%', 2: '90.97%', 3: '95.90%', 4: '87.50%', 5: '96.42%', 6: '41.67%', 7: '79.20%', 8: '87.26%', 9: '75.68%'}, LR: 0.000314\n",
      "Epoch 124/200, Train Loss: 0.003188, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.760481, Val Acc: 86.54%, Val-Class-Acc: {0: '84.78%', 2: '90.97%', 3: '95.90%', 4: '82.50%', 5: '96.72%', 6: '42.59%', 7: '80.80%', 8: '85.99%', 9: '78.38%'}, LR: 0.000314\n",
      "Epoch 125/200, Train Loss: 0.003156, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.768099, Val Acc: 86.54%, Val-Class-Acc: {0: '85.33%', 2: '90.97%', 3: '96.31%', 4: '85.00%', 5: '96.72%', 6: '43.52%', 7: '79.20%', 8: '85.99%', 9: '72.97%'}, LR: 0.000314\n",
      "Epoch 126/200, Train Loss: 0.003091, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.785386, Val Acc: 86.54%, Val-Class-Acc: {0: '85.33%', 2: '90.97%', 3: '95.49%', 4: '85.00%', 5: '96.42%', 6: '41.67%', 7: '80.00%', 8: '87.90%', 9: '75.68%'}, LR: 0.000314\n",
      "Epoch 127/200, Train Loss: 0.003020, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.769308, Val Acc: 86.61%, Val-Class-Acc: {0: '85.33%', 2: '90.97%', 3: '96.72%', 4: '85.00%', 5: '96.12%', 6: '41.67%', 7: '79.20%', 8: '87.90%', 9: '75.68%'}, LR: 0.000314\n",
      "Epoch 128/200, Train Loss: 0.002984, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.767716, Val Acc: 86.68%, Val-Class-Acc: {0: '85.33%', 2: '90.97%', 3: '96.31%', 4: '82.50%', 5: '96.72%', 6: '43.52%', 7: '79.20%', 8: '87.26%', 9: '75.68%'}, LR: 0.000314\n",
      "Epoch 129/200, Train Loss: 0.002933, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.781382, Val Acc: 86.46%, Val-Class-Acc: {0: '85.87%', 2: '90.97%', 3: '96.72%', 4: '82.50%', 5: '96.42%', 6: '39.81%', 7: '80.80%', 8: '85.99%', 9: '75.68%'}, LR: 0.000314\n",
      "Epoch 130/200, Train Loss: 0.002896, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.772940, Val Acc: 86.90%, Val-Class-Acc: {0: '84.24%', 2: '90.97%', 3: '96.31%', 4: '82.50%', 5: '96.42%', 6: '42.59%', 7: '84.00%', 8: '87.26%', 9: '78.38%'}, LR: 0.000314\n",
      "Epoch 131/200, Train Loss: 0.002808, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.773396, Val Acc: 86.83%, Val-Class-Acc: {0: '85.87%', 2: '90.97%', 3: '96.72%', 4: '85.00%', 5: '96.72%', 6: '42.59%', 7: '79.20%', 8: '87.26%', 9: '75.68%'}, LR: 0.000314\n",
      "Epoch 132/200, Train Loss: 0.002761, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.790619, Val Acc: 86.61%, Val-Class-Acc: {0: '85.87%', 2: '90.97%', 3: '96.72%', 4: '87.50%', 5: '96.42%', 6: '38.89%', 7: '79.20%', 8: '87.90%', 9: '75.68%'}, LR: 0.000314\n",
      "Epoch 133/200, Train Loss: 0.002716, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.779100, Val Acc: 86.75%, Val-Class-Acc: {0: '85.87%', 2: '90.97%', 3: '96.72%', 4: '85.00%', 5: '96.42%', 6: '42.59%', 7: '79.20%', 8: '87.26%', 9: '75.68%'}, LR: 0.000314\n",
      "Epoch 134/200, Train Loss: 0.002670, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.789882, Val Acc: 86.68%, Val-Class-Acc: {0: '85.33%', 2: '90.97%', 3: '96.72%', 4: '85.00%', 5: '96.42%', 6: '41.67%', 7: '80.00%', 8: '87.90%', 9: '72.97%'}, LR: 0.000282\n",
      "Epoch 135/200, Train Loss: 0.002622, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.794465, Val Acc: 86.75%, Val-Class-Acc: {0: '87.50%', 2: '90.97%', 3: '96.72%', 4: '85.00%', 5: '96.42%', 6: '40.74%', 7: '80.80%', 8: '85.99%', 9: '72.97%'}, LR: 0.000282\n",
      "Epoch 136/200, Train Loss: 0.002610, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.771032, Val Acc: 86.61%, Val-Class-Acc: {0: '85.33%', 2: '90.97%', 3: '96.31%', 4: '80.00%', 5: '97.01%', 6: '42.59%', 7: '79.20%', 8: '87.26%', 9: '75.68%'}, LR: 0.000282\n",
      "Epoch 137/200, Train Loss: 0.002547, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.795363, Val Acc: 86.61%, Val-Class-Acc: {0: '85.33%', 2: '90.97%', 3: '95.90%', 4: '80.00%', 5: '96.42%', 6: '41.67%', 7: '83.20%', 8: '85.99%', 9: '78.38%'}, LR: 0.000282\n",
      "Epoch 138/200, Train Loss: 0.002504, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.808541, Val Acc: 86.68%, Val-Class-Acc: {0: '85.87%', 2: '90.97%', 3: '96.31%', 4: '80.00%', 5: '96.42%', 6: '40.74%', 7: '81.60%', 8: '87.26%', 9: '78.38%'}, LR: 0.000282\n",
      "Epoch 139/200, Train Loss: 0.002469, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.784801, Val Acc: 86.75%, Val-Class-Acc: {0: '88.04%', 2: '90.97%', 3: '96.31%', 4: '82.50%', 5: '95.82%', 6: '41.67%', 7: '80.80%', 8: '86.62%', 9: '75.68%'}, LR: 0.000282\n",
      "Epoch 140/200, Train Loss: 0.002422, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.816353, Val Acc: 86.24%, Val-Class-Acc: {0: '84.24%', 2: '90.97%', 3: '95.90%', 4: '82.50%', 5: '96.12%', 6: '38.89%', 7: '80.00%', 8: '88.54%', 9: '78.38%'}, LR: 0.000282\n",
      "Epoch 141/200, Train Loss: 0.002643, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.783145, Val Acc: 86.61%, Val-Class-Acc: {0: '88.59%', 2: '90.28%', 3: '96.72%', 4: '80.00%', 5: '94.93%', 6: '41.67%', 7: '80.80%', 8: '88.54%', 9: '70.27%'}, LR: 0.000282\n",
      "Epoch 142/200, Train Loss: 0.028282, Train-Class-Acc: {0: '99.59%', 2: '99.48%', 3: '99.80%', 4: '100.00%', 5: '99.70%', 6: '98.16%', 7: '98.60%', 8: '98.41%', 9: '98.65%'}\n",
      "Val Loss: 1.172315, Val Acc: 78.38%, Val-Class-Acc: {0: '76.63%', 2: '86.81%', 3: '91.80%', 4: '70.00%', 5: '81.49%', 6: '26.85%', 7: '81.60%', 8: '78.98%', 9: '83.78%'}, LR: 0.000282\n",
      "Epoch 143/200, Train Loss: 0.226435, Train-Class-Acc: {0: '94.01%', 2: '95.15%', 3: '97.95%', 4: '94.94%', 5: '97.83%', 6: '81.80%', 7: '86.43%', 8: '92.68%', 9: '84.46%'}\n",
      "Val Loss: 0.698545, Val Acc: 84.93%, Val-Class-Acc: {0: '87.50%', 2: '92.36%', 3: '96.31%', 4: '75.00%', 5: '92.24%', 6: '38.89%', 7: '81.60%', 8: '82.80%', 9: '67.57%'}, LR: 0.000282\n",
      "Epoch 144/200, Train Loss: 0.033547, Train-Class-Acc: {0: '99.86%', 2: '99.83%', 3: '99.49%', 4: '98.73%', 5: '99.63%', 6: '98.62%', 7: '99.20%', 8: '99.36%', 9: '97.30%'}\n",
      "Val Loss: 0.697090, Val Acc: 85.44%, Val-Class-Acc: {0: '84.78%', 2: '89.58%', 3: '97.13%', 4: '80.00%', 5: '93.73%', 6: '44.44%', 7: '80.00%', 8: '85.35%', 9: '64.86%'}, LR: 0.000282\n",
      "Epoch 145/200, Train Loss: 0.014961, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.59%', 4: '100.00%', 5: '99.93%', 6: '99.31%', 7: '99.80%', 8: '99.68%', 9: '100.00%'}\n",
      "Val Loss: 0.729923, Val Acc: 85.52%, Val-Class-Acc: {0: '84.78%', 2: '88.19%', 3: '94.26%', 4: '80.00%', 5: '96.12%', 6: '41.67%', 7: '80.00%', 8: '88.54%', 9: '64.86%'}, LR: 0.000254\n",
      "Epoch 146/200, Train Loss: 0.010844, Train-Class-Acc: {0: '99.86%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '100.00%', 6: '99.77%', 7: '99.80%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.727849, Val Acc: 86.10%, Val-Class-Acc: {0: '86.96%', 2: '88.19%', 3: '97.13%', 4: '80.00%', 5: '96.42%', 6: '43.52%', 7: '78.40%', 8: '85.99%', 9: '64.86%'}, LR: 0.000254\n",
      "Epoch 147/200, Train Loss: 0.006726, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.742312, Val Acc: 85.59%, Val-Class-Acc: {0: '85.33%', 2: '87.50%', 3: '96.72%', 4: '80.00%', 5: '95.22%', 6: '42.59%', 7: '79.20%', 8: '87.26%', 9: '64.86%'}, LR: 0.000254\n",
      "Epoch 148/200, Train Loss: 0.005608, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.736001, Val Acc: 85.59%, Val-Class-Acc: {0: '86.96%', 2: '87.50%', 3: '96.72%', 4: '80.00%', 5: '95.52%', 6: '38.89%', 7: '80.00%', 8: '85.99%', 9: '67.57%'}, LR: 0.000254\n",
      "Epoch 149/200, Train Loss: 0.005050, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.741514, Val Acc: 85.81%, Val-Class-Acc: {0: '85.87%', 2: '88.89%', 3: '96.72%', 4: '80.00%', 5: '95.52%', 6: '40.74%', 7: '80.00%', 8: '86.62%', 9: '67.57%'}, LR: 0.000254\n",
      "Epoch 150/200, Train Loss: 0.005530, Train-Class-Acc: {0: '100.00%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.750186, Val Acc: 86.39%, Val-Class-Acc: {0: '86.96%', 2: '91.67%', 3: '96.31%', 4: '82.50%', 5: '95.82%', 6: '45.37%', 7: '78.40%', 8: '85.35%', 9: '67.57%'}, LR: 0.000254\n",
      "Epoch 151/200, Train Loss: 0.008776, Train-Class-Acc: {0: '99.86%', 2: '99.65%', 3: '100.00%', 4: '100.00%', 5: '99.78%', 6: '100.00%', 7: '99.80%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.760878, Val Acc: 85.44%, Val-Class-Acc: {0: '86.96%', 2: '88.89%', 3: '95.90%', 4: '80.00%', 5: '96.12%', 6: '41.67%', 7: '78.40%', 8: '84.71%', 9: '59.46%'}, LR: 0.000254\n",
      "Epoch 152/200, Train Loss: 0.008582, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '99.80%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.729586, Val Acc: 85.52%, Val-Class-Acc: {0: '85.33%', 2: '86.81%', 3: '96.72%', 4: '80.00%', 5: '94.63%', 6: '46.30%', 7: '80.00%', 8: '86.62%', 9: '59.46%'}, LR: 0.000254\n",
      "Epoch 153/200, Train Loss: 0.005784, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.761611, Val Acc: 85.23%, Val-Class-Acc: {0: '84.78%', 2: '87.50%', 3: '96.31%', 4: '80.00%', 5: '95.82%', 6: '44.44%', 7: '77.60%', 8: '84.71%', 9: '62.16%'}, LR: 0.000254\n",
      "Epoch 154/200, Train Loss: 0.004505, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.777852, Val Acc: 85.37%, Val-Class-Acc: {0: '86.41%', 2: '86.81%', 3: '96.31%', 4: '80.00%', 5: '95.52%', 6: '41.67%', 7: '80.00%', 8: '85.35%', 9: '62.16%'}, LR: 0.000254\n",
      "Epoch 155/200, Train Loss: 0.011247, Train-Class-Acc: {0: '99.86%', 2: '99.48%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '99.77%', 7: '99.40%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.791557, Val Acc: 84.86%, Val-Class-Acc: {0: '81.52%', 2: '87.50%', 3: '95.90%', 4: '80.00%', 5: '94.03%', 6: '44.44%', 7: '83.20%', 8: '85.35%', 9: '62.16%'}, LR: 0.000254\n",
      "Epoch 156/200, Train Loss: 0.006789, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.785049, Val Acc: 85.95%, Val-Class-Acc: {0: '83.70%', 2: '89.58%', 3: '96.72%', 4: '80.00%', 5: '95.52%', 6: '45.37%', 7: '80.80%', 8: '85.99%', 9: '67.57%'}, LR: 0.000229\n",
      "Epoch 157/200, Train Loss: 0.004407, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.778799, Val Acc: 85.44%, Val-Class-Acc: {0: '82.61%', 2: '90.28%', 3: '96.72%', 4: '80.00%', 5: '94.93%', 6: '44.44%', 7: '79.20%', 8: '85.35%', 9: '67.57%'}, LR: 0.000229\n",
      "Epoch 158/200, Train Loss: 0.004126, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.775386, Val Acc: 85.81%, Val-Class-Acc: {0: '83.70%', 2: '90.28%', 3: '96.72%', 4: '80.00%', 5: '95.82%', 6: '44.44%', 7: '80.00%', 8: '85.35%', 9: '64.86%'}, LR: 0.000229\n",
      "Epoch 159/200, Train Loss: 0.004030, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.768543, Val Acc: 85.95%, Val-Class-Acc: {0: '84.24%', 2: '89.58%', 3: '96.72%', 4: '80.00%', 5: '95.22%', 6: '48.15%', 7: '80.80%', 8: '84.08%', 9: '67.57%'}, LR: 0.000229\n",
      "Epoch 160/200, Train Loss: 0.003879, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.801636, Val Acc: 85.59%, Val-Class-Acc: {0: '83.15%', 2: '91.67%', 3: '95.90%', 4: '80.00%', 5: '95.22%', 6: '39.81%', 7: '82.40%', 8: '85.99%', 9: '67.57%'}, LR: 0.000229\n",
      "Epoch 161/200, Train Loss: 0.003756, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.793645, Val Acc: 85.52%, Val-Class-Acc: {0: '85.87%', 2: '87.50%', 3: '96.72%', 4: '80.00%', 5: '95.22%', 6: '41.67%', 7: '81.60%', 8: '84.08%', 9: '67.57%'}, LR: 0.000229\n",
      "Epoch 162/200, Train Loss: 0.003632, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.787458, Val Acc: 85.74%, Val-Class-Acc: {0: '83.70%', 2: '89.58%', 3: '96.72%', 4: '82.50%', 5: '94.93%', 6: '45.37%', 7: '80.80%', 8: '84.71%', 9: '67.57%'}, LR: 0.000229\n",
      "Epoch 163/200, Train Loss: 0.003555, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.793781, Val Acc: 85.74%, Val-Class-Acc: {0: '84.24%', 2: '88.89%', 3: '96.72%', 4: '80.00%', 5: '95.22%', 6: '46.30%', 7: '80.00%', 8: '85.35%', 9: '64.86%'}, LR: 0.000229\n",
      "Epoch 164/200, Train Loss: 0.003520, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.799351, Val Acc: 85.30%, Val-Class-Acc: {0: '83.70%', 2: '88.19%', 3: '96.72%', 4: '80.00%', 5: '94.93%', 6: '42.59%', 7: '80.00%', 8: '85.35%', 9: '67.57%'}, LR: 0.000229\n",
      "Epoch 165/200, Train Loss: 0.003438, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.803746, Val Acc: 85.59%, Val-Class-Acc: {0: '83.70%', 2: '87.50%', 3: '96.72%', 4: '80.00%', 5: '96.42%', 6: '39.81%', 7: '80.80%', 8: '86.62%', 9: '67.57%'}, LR: 0.000229\n",
      "Epoch 166/200, Train Loss: 0.003411, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.805748, Val Acc: 85.66%, Val-Class-Acc: {0: '84.24%', 2: '87.50%', 3: '96.72%', 4: '82.50%', 5: '95.82%', 6: '39.81%', 7: '81.60%', 8: '86.62%', 9: '67.57%'}, LR: 0.000229\n",
      "Epoch 167/200, Train Loss: 0.003331, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.797911, Val Acc: 85.37%, Val-Class-Acc: {0: '83.15%', 2: '88.19%', 3: '95.90%', 4: '80.00%', 5: '96.12%', 6: '39.81%', 7: '81.60%', 8: '85.99%', 9: '67.57%'}, LR: 0.000206\n",
      "Epoch 168/200, Train Loss: 0.003258, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.803161, Val Acc: 85.44%, Val-Class-Acc: {0: '83.70%', 2: '88.19%', 3: '96.31%', 4: '80.00%', 5: '95.82%', 6: '39.81%', 7: '82.40%', 8: '85.35%', 9: '67.57%'}, LR: 0.000206\n",
      "Epoch 169/200, Train Loss: 0.003220, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.810972, Val Acc: 85.15%, Val-Class-Acc: {0: '83.70%', 2: '88.19%', 3: '96.31%', 4: '80.00%', 5: '95.82%', 6: '39.81%', 7: '79.20%', 8: '85.35%', 9: '67.57%'}, LR: 0.000206\n",
      "Epoch 170/200, Train Loss: 0.003247, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.802137, Val Acc: 85.59%, Val-Class-Acc: {0: '84.24%', 2: '88.89%', 3: '96.72%', 4: '80.00%', 5: '95.52%', 6: '41.67%', 7: '81.60%', 8: '85.35%', 9: '64.86%'}, LR: 0.000206\n",
      "Epoch 171/200, Train Loss: 0.003162, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.816308, Val Acc: 85.66%, Val-Class-Acc: {0: '86.41%', 2: '88.89%', 3: '96.31%', 4: '80.00%', 5: '95.22%', 6: '39.81%', 7: '82.40%', 8: '84.71%', 9: '67.57%'}, LR: 0.000206\n",
      "Epoch 172/200, Train Loss: 0.003085, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.812533, Val Acc: 85.44%, Val-Class-Acc: {0: '84.24%', 2: '89.58%', 3: '95.90%', 4: '82.50%', 5: '94.93%', 6: '39.81%', 7: '80.80%', 8: '85.99%', 9: '70.27%'}, LR: 0.000206\n",
      "Epoch 173/200, Train Loss: 0.003122, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.806356, Val Acc: 85.74%, Val-Class-Acc: {0: '84.24%', 2: '90.28%', 3: '95.90%', 4: '82.50%', 5: '95.22%', 6: '40.74%', 7: '82.40%', 8: '85.99%', 9: '67.57%'}, LR: 0.000206\n",
      "Epoch 174/200, Train Loss: 0.003061, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.819562, Val Acc: 85.74%, Val-Class-Acc: {0: '85.87%', 2: '88.19%', 3: '96.31%', 4: '80.00%', 5: '95.52%', 6: '38.89%', 7: '82.40%', 8: '85.99%', 9: '70.27%'}, LR: 0.000206\n",
      "Epoch 175/200, Train Loss: 0.003019, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.827435, Val Acc: 85.59%, Val-Class-Acc: {0: '83.70%', 2: '88.19%', 3: '96.31%', 4: '80.00%', 5: '96.12%', 6: '38.89%', 7: '81.60%', 8: '87.26%', 9: '67.57%'}, LR: 0.000206\n",
      "Epoch 176/200, Train Loss: 0.002997, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.822824, Val Acc: 85.52%, Val-Class-Acc: {0: '84.24%', 2: '90.97%', 3: '95.90%', 4: '80.00%', 5: '95.52%', 6: '38.89%', 7: '80.00%', 8: '86.62%', 9: '67.57%'}, LR: 0.000206\n",
      "Epoch 177/200, Train Loss: 0.002936, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.826042, Val Acc: 85.44%, Val-Class-Acc: {0: '83.70%', 2: '89.58%', 3: '96.31%', 4: '82.50%', 5: '95.82%', 6: '37.04%', 7: '80.80%', 8: '86.62%', 9: '67.57%'}, LR: 0.000206\n",
      "Epoch 178/200, Train Loss: 0.002904, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.823031, Val Acc: 85.74%, Val-Class-Acc: {0: '86.96%', 2: '89.58%', 3: '96.72%', 4: '80.00%', 5: '94.93%', 6: '40.74%', 7: '80.00%', 8: '84.71%', 9: '70.27%'}, LR: 0.000185\n",
      "Epoch 179/200, Train Loss: 0.002884, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.841309, Val Acc: 85.74%, Val-Class-Acc: {0: '84.78%', 2: '88.19%', 3: '96.31%', 4: '80.00%', 5: '96.12%', 6: '37.96%', 7: '81.60%', 8: '87.90%', 9: '67.57%'}, LR: 0.000185\n",
      "Epoch 180/200, Train Loss: 0.002845, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.823202, Val Acc: 85.37%, Val-Class-Acc: {0: '84.78%', 2: '87.50%', 3: '96.72%', 4: '82.50%', 5: '95.22%', 6: '38.89%', 7: '81.60%', 8: '85.35%', 9: '67.57%'}, LR: 0.000185\n",
      "Epoch 181/200, Train Loss: 0.002861, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.838700, Val Acc: 85.59%, Val-Class-Acc: {0: '84.24%', 2: '89.58%', 3: '95.08%', 4: '80.00%', 5: '96.42%', 6: '37.96%', 7: '82.40%', 8: '86.62%', 9: '67.57%'}, LR: 0.000185\n",
      "Epoch 182/200, Train Loss: 0.002816, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.831356, Val Acc: 85.37%, Val-Class-Acc: {0: '84.24%', 2: '89.58%', 3: '95.49%', 4: '80.00%', 5: '95.82%', 6: '36.11%', 7: '82.40%', 8: '86.62%', 9: '67.57%'}, LR: 0.000185\n",
      "Epoch 183/200, Train Loss: 0.002785, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.831076, Val Acc: 85.37%, Val-Class-Acc: {0: '84.24%', 2: '88.89%', 3: '96.31%', 4: '80.00%', 5: '95.52%', 6: '37.04%', 7: '81.60%', 8: '85.99%', 9: '70.27%'}, LR: 0.000185\n",
      "Epoch 184/200, Train Loss: 0.002749, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.838818, Val Acc: 85.74%, Val-Class-Acc: {0: '84.24%', 2: '88.89%', 3: '95.90%', 4: '80.00%', 5: '96.42%', 6: '38.89%', 7: '81.60%', 8: '87.26%', 9: '67.57%'}, LR: 0.000185\n",
      "Epoch 185/200, Train Loss: 0.006375, Train-Class-Acc: {0: '99.86%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '99.32%'}\n",
      "Val Loss: 0.959939, Val Acc: 83.92%, Val-Class-Acc: {0: '91.30%', 2: '90.28%', 3: '95.49%', 4: '80.00%', 5: '88.36%', 6: '37.04%', 7: '80.80%', 8: '82.17%', 9: '64.86%'}, LR: 0.000185\n",
      "Epoch 186/200, Train Loss: 0.039775, Train-Class-Acc: {0: '99.46%', 2: '99.31%', 3: '99.90%', 4: '100.00%', 5: '99.10%', 6: '96.08%', 7: '99.20%', 8: '98.57%', 9: '97.97%'}\n",
      "Val Loss: 0.966135, Val Acc: 83.19%, Val-Class-Acc: {0: '70.11%', 2: '90.28%', 3: '95.08%', 4: '77.50%', 5: '91.94%', 6: '50.00%', 7: '74.40%', 8: '90.45%', 9: '64.86%'}, LR: 0.000185\n",
      "Epoch 187/200, Train Loss: 0.039566, Train-Class-Acc: {0: '99.18%', 2: '99.83%', 3: '99.69%', 4: '98.73%', 5: '99.33%', 6: '96.54%', 7: '98.00%', 8: '98.09%', 9: '95.95%'}\n",
      "Val Loss: 0.810677, Val Acc: 84.86%, Val-Class-Acc: {0: '77.72%', 2: '84.72%', 3: '95.90%', 4: '85.00%', 5: '94.33%', 6: '47.22%', 7: '82.40%', 8: '87.26%', 9: '70.27%'}, LR: 0.000185\n",
      "Epoch 188/200, Train Loss: 0.015331, Train-Class-Acc: {0: '99.86%', 2: '99.65%', 3: '99.80%', 4: '99.37%', 5: '100.00%', 6: '99.08%', 7: '99.60%', 8: '99.68%', 9: '100.00%'}\n",
      "Val Loss: 0.749407, Val Acc: 85.59%, Val-Class-Acc: {0: '82.07%', 2: '92.36%', 3: '91.80%', 4: '82.50%', 5: '94.93%', 6: '47.22%', 7: '81.60%', 8: '87.90%', 9: '70.27%'}, LR: 0.000185\n",
      "Epoch 189/200, Train Loss: 0.011316, Train-Class-Acc: {0: '99.86%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.85%', 6: '99.08%', 7: '100.00%', 8: '99.68%', 9: '100.00%'}\n",
      "Val Loss: 0.814098, Val Acc: 85.01%, Val-Class-Acc: {0: '79.89%', 2: '90.28%', 3: '97.13%', 4: '82.50%', 5: '94.93%', 6: '42.59%', 7: '75.20%', 8: '87.90%', 9: '67.57%'}, LR: 0.000167\n",
      "Epoch 190/200, Train Loss: 0.006582, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '99.77%', 7: '99.60%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.777002, Val Acc: 85.52%, Val-Class-Acc: {0: '83.15%', 2: '90.97%', 3: '95.08%', 4: '82.50%', 5: '94.93%', 6: '46.30%', 7: '78.40%', 8: '86.62%', 9: '64.86%'}, LR: 0.000167\n",
      "Epoch 191/200, Train Loss: 0.004851, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.779712, Val Acc: 85.44%, Val-Class-Acc: {0: '83.70%', 2: '89.58%', 3: '96.31%', 4: '80.00%', 5: '95.22%', 6: '39.81%', 7: '81.60%', 8: '85.99%', 9: '67.57%'}, LR: 0.000167\n",
      "Epoch 192/200, Train Loss: 0.004571, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '99.77%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.783404, Val Acc: 85.74%, Val-Class-Acc: {0: '83.15%', 2: '91.67%', 3: '96.31%', 4: '82.50%', 5: '95.22%', 6: '45.37%', 7: '80.00%', 8: '84.71%', 9: '64.86%'}, LR: 0.000167\n",
      "Epoch 193/200, Train Loss: 0.003914, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.793716, Val Acc: 85.52%, Val-Class-Acc: {0: '84.78%', 2: '89.58%', 3: '95.90%', 4: '82.50%', 5: '95.22%', 6: '42.59%', 7: '80.00%', 8: '84.71%', 9: '67.57%'}, LR: 0.000167\n",
      "Epoch 194/200, Train Loss: 0.004377, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '99.77%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.824588, Val Acc: 85.52%, Val-Class-Acc: {0: '84.24%', 2: '90.97%', 3: '95.90%', 4: '80.00%', 5: '94.93%', 6: '38.89%', 7: '84.00%', 8: '84.08%', 9: '70.27%'}, LR: 0.000167\n",
      "Epoch 195/200, Train Loss: 0.003739, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.805558, Val Acc: 86.17%, Val-Class-Acc: {0: '89.13%', 2: '91.67%', 3: '96.31%', 4: '80.00%', 5: '95.22%', 6: '39.81%', 7: '81.60%', 8: '84.71%', 9: '64.86%'}, LR: 0.000167\n",
      "Epoch 196/200, Train Loss: 0.003564, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.797120, Val Acc: 85.88%, Val-Class-Acc: {0: '84.24%', 2: '90.97%', 3: '96.31%', 4: '82.50%', 5: '95.22%', 6: '44.44%', 7: '81.60%', 8: '84.71%', 9: '64.86%'}, LR: 0.000167\n",
      "Epoch 197/200, Train Loss: 0.003516, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.795365, Val Acc: 85.81%, Val-Class-Acc: {0: '83.70%', 2: '90.97%', 3: '96.72%', 4: '82.50%', 5: '95.22%', 6: '44.44%', 7: '79.20%', 8: '85.35%', 9: '67.57%'}, LR: 0.000167\n",
      "Epoch 198/200, Train Loss: 0.003551, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.799196, Val Acc: 85.66%, Val-Class-Acc: {0: '83.70%', 2: '88.89%', 3: '96.72%', 4: '82.50%', 5: '94.93%', 6: '42.59%', 7: '83.20%', 8: '84.71%', 9: '67.57%'}, LR: 0.000167\n",
      "Epoch 199/200, Train Loss: 0.003415, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.806190, Val Acc: 85.81%, Val-Class-Acc: {0: '84.78%', 2: '90.28%', 3: '96.72%', 4: '82.50%', 5: '95.22%', 6: '38.89%', 7: '83.20%', 8: '85.35%', 9: '67.57%'}, LR: 0.000167\n",
      "Epoch 200/200, Train Loss: 0.003261, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.795523, Val Acc: 86.03%, Val-Class-Acc: {0: '84.24%', 2: '90.28%', 3: '96.72%', 4: '82.50%', 5: '95.22%', 6: '45.37%', 7: '81.60%', 8: '85.35%', 9: '64.86%'}, LR: 0.000150\n",
      "\n",
      "üèÜ Best model saved as: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_best.pth (Val Accuracy: 88.57%)\n",
      "\n",
      "üìå Final model saved as: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_final.pth\n",
      "\n",
      "üéØ Top 5 Best Models:\n",
      "Epoch 1, Train Loss: 0.700510, Train-Acc: {0: '87.74%', 2: '88.91%', 3: '92.62%', 4: '81.65%', 5: '92.82%', 6: '38.02%', 7: '62.67%', 8: '72.13%', 9: '27.70%'},\n",
      "Val Loss: 0.410923, Val Acc: 88.57%, Val-Acc: {0: '88.04%', 2: '97.22%', 3: '98.36%', 4: '75.00%', 5: '96.42%', 6: '43.52%', 7: '89.60%', 8: '89.81%', 9: '59.46%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_1.pth\n",
      "Epoch 38, Train Loss: 0.004401, Train-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'},\n",
      "Val Loss: 0.665693, Val Acc: 88.06%, Val-Acc: {0: '90.22%', 2: '92.36%', 3: '97.13%', 4: '82.50%', 5: '97.01%', 6: '47.22%', 7: '79.20%', 8: '88.54%', 9: '72.97%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_38.pth\n",
      "Epoch 37, Train Loss: 0.004586, Train-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'},\n",
      "Val Loss: 0.656949, Val Acc: 87.99%, Val-Acc: {0: '90.22%', 2: '92.36%', 3: '97.54%', 4: '82.50%', 5: '97.01%', 6: '46.30%', 7: '79.20%', 8: '87.90%', 9: '72.97%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_37.pth\n",
      "Epoch 34, Train Loss: 0.005140, Train-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'},\n",
      "Val Loss: 0.666600, Val Acc: 87.99%, Val-Acc: {0: '89.67%', 2: '91.67%', 3: '97.95%', 4: '82.50%', 5: '97.01%', 6: '48.15%', 7: '79.20%', 8: '87.26%', 9: '72.97%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_34.pth\n",
      "Epoch 32, Train Loss: 0.005946, Train-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'},\n",
      "Val Loss: 0.671215, Val Acc: 87.99%, Val-Acc: {0: '89.13%', 2: '91.67%', 3: '97.95%', 4: '82.50%', 5: '97.01%', 6: '48.15%', 7: '79.20%', 8: '87.90%', 9: '72.97%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4/ResNet18_1D_epoch_32.pth\n",
      "\n",
      "üß† Model Summary:\n",
      "Total Parameters: 3,865,226\n",
      "Model Size (float32): 14.74 MB\n",
      "Total Training Time: 736.80 seconds\n",
      "---\n",
      "### Period 4\n",
      "+ ##### Total training time: 736.80 seconds\n",
      "+ ##### Model: ResNet18_1D\n",
      "+ ##### Training and saving in *'/mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v1/Period_4'*\n",
      "+ ##### Best Epoch: 1\n",
      "#### __Val Accuracy: 88.57%__\n",
      "#### __Val-Class-Acc: {0: '88.04%', 2: '97.22%', 3: '98.36%', 4: '75.00%', 5: '96.42%', 6: '43.52%', 7: '89.60%', 8: '89.81%', 9: '59.46%'}__\n",
      "#### __Total Parameters: 3,865,226__\n",
      "#### __Model Size (float32): 14.74 MB__\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# üìå Period 4: EWC Training (Protect Period 3)\n",
    "# ================================\n",
    "period = 4\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.join(BASE_DIR, \"stop_training.txt\")\n",
    "model_saving_folder = os.path.join(BASE_DIR, \"Trained_models\", \"EWC_CIL_v1\", f\"Period_{period}\")\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Load Period 4 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, f\"X_train_p{period}.npy\"))\n",
    "y_train = np.load(os.path.join(save_dir, f\"y_train_p{period}.npy\"))\n",
    "X_val   = np.load(os.path.join(save_dir, f\"X_test_p{period}.npy\"))\n",
    "y_val   = np.load(os.path.join(save_dir, f\"y_test_p{period}.npy\"))\n",
    "\n",
    "# ==== Device ====\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "# ==== Model Configuration ====\n",
    "input_channels = X_train.shape[2]\n",
    "output_size = int(np.max(y_train)) + 1  # avoid indexing problems due to missing class 1\n",
    "model = ResNet18_1D(input_channels=input_channels, output_size=output_size).to(device)\n",
    "print(\"üìå Labels found:\", sorted(np.unique(y_train)))\n",
    "print(\"üìå Output size inferred as:\", output_size)\n",
    "\n",
    "# ==== Load Period 3 Best Model Weights ====\n",
    "prev_model_path = os.path.join(BASE_DIR, \"Trained_models\", \"EWC_CIL_v1\", \"Period_3\", \"ResNet18_1D_best.pth\")\n",
    "prev_checkpoint = torch.load(prev_model_path, map_location=device)\n",
    "state_dict = prev_checkpoint[\"model_state_dict\"]\n",
    "model_dict = model.state_dict()\n",
    "filtered_dict = {k: v for k, v in state_dict.items() if k in model_dict and model_dict[k].shape == v.shape}\n",
    "model.load_state_dict(filtered_dict, strict=False)\n",
    "for k in model_dict:\n",
    "    if k not in filtered_dict:\n",
    "        print(f\"üîç Not loaded: {k}, shape={model_dict[k].shape}\")\n",
    "print(\"‚úÖ Loaded Period 3 weights (except FC mismatch)\")\n",
    "\n",
    "# ==== Prepare EWC (from Period 3 training data) ====\n",
    "X_prev = np.load(os.path.join(save_dir, \"X_train_p3.npy\"))\n",
    "y_prev = np.load(os.path.join(save_dir, \"y_train_p3.npy\"))\n",
    "train_loader_prev = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_prev, dtype=torch.float32), torch.tensor(y_prev, dtype=torch.long)),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fisher_dict, params_dict = EWC.compute_fisher_and_params(model, train_loader_prev, criterion, device=device)\n",
    "ewc_state = EWC(fisher=fisher_dict, params=params_dict)\n",
    "print(\"üìà Fisher information computed from Period 3\")\n",
    "\n",
    "# ==== Optimizer / Scheduler ====\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "lambda_ewc = 1.0\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# ==== Training ====\n",
    "train_with_ewc_ecg(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name=\"ResNet18_1D\",\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    ewc=ewc_state,\n",
    "    lambda_ewc=lambda_ewc,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del X_train, y_train, X_val, y_val, X_prev, y_prev\n",
    "del prev_model_path, prev_checkpoint, state_dict, model_dict, filtered_dict\n",
    "del model, train_loader_prev, fisher_dict, params_dict, ewc_state\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd234357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Automatically selected GPU:\n",
      "    - CUDA Device ID : 2\n",
      "    - Memory Used    : 1780 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "üìå Labels found: [np.int64(0), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9)]\n",
      "üìå Output size inferred as: 10\n",
      "‚úÖ Loaded Period 3 weights (except FC mismatch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_321925/1256595526.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  prev_checkpoint = torch.load(prev_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Class Weights (normalized):\n",
      "  - Class 0: 0.0571\n",
      "  - Class 1: 0.0000 (excluded)\n",
      "  - Class 2: 0.0727\n",
      "  - Class 3: 0.0430\n",
      "  - Class 4: 0.2654\n",
      "  - Class 5: 0.0314\n",
      "  - Class 6: 0.0966\n",
      "  - Class 7: 0.0837\n",
      "  - Class 8: 0.0668\n",
      "  - Class 9: 0.2833\n",
      "üìà Fisher information computed from Period 3\n",
      "\n",
      "üöÄ 'train_with_ewc_ecg' started.\n",
      "‚úÖ Removed existing folder: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4\n",
      "\n",
      "‚úÖ Data Overview:\n",
      "X_train: torch.Size([5493, 5000, 12]), y_train: torch.Size([5493])\n",
      "X_val: torch.Size([1374, 5000, 12]), y_val: torch.Size([1374])\n",
      "Epoch 1/200, Train Loss: 0.931900, Train-Class-Acc: {0: '80.65%', 2: '87.52%', 3: '88.11%', 4: '88.61%', 5: '86.69%', 6: '41.01%', 7: '57.09%', 8: '61.46%', 9: '58.11%'}\n",
      "Val Loss: 0.560247, Val Acc: 85.30%, Val-Class-Acc: {0: '88.59%', 2: '93.75%', 3: '85.25%', 4: '92.50%', 5: '91.34%', 6: '63.89%', 7: '84.00%', 8: '77.07%', 9: '75.68%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.576124, Train-Class-Acc: {0: '86.78%', 2: '94.63%', 3: '95.39%', 4: '93.04%', 5: '93.42%', 6: '61.75%', 7: '70.26%', 8: '73.73%', 9: '77.70%'}\n",
      "Val Loss: 0.624563, Val Acc: 84.28%, Val-Class-Acc: {0: '91.30%', 2: '94.44%', 3: '97.13%', 4: '97.50%', 5: '80.00%', 6: '54.63%', 7: '79.20%', 8: '80.89%', 9: '67.57%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.419412, Train-Class-Acc: {0: '91.42%', 2: '95.84%', 3: '94.88%', 4: '96.84%', 5: '93.87%', 6: '70.51%', 7: '76.05%', 8: '82.48%', 9: '83.78%'}\n",
      "Val Loss: 0.654673, Val Acc: 81.08%, Val-Class-Acc: {0: '83.70%', 2: '81.94%', 3: '89.75%', 4: '92.50%', 5: '83.58%', 6: '40.74%', 7: '84.80%', 8: '78.34%', 9: '89.19%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.349087, Train-Class-Acc: {0: '91.14%', 2: '96.53%', 3: '95.70%', 4: '96.84%', 5: '94.24%', 6: '78.57%', 7: '76.65%', 8: '85.67%', 9: '90.54%'}\n",
      "Val Loss: 0.633347, Val Acc: 86.83%, Val-Class-Acc: {0: '80.98%', 2: '91.67%', 3: '96.72%', 4: '92.50%', 5: '95.52%', 6: '55.56%', 7: '83.20%', 8: '78.98%', 9: '83.78%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.278301, Train-Class-Acc: {0: '95.50%', 2: '96.19%', 3: '96.21%', 4: '98.73%', 5: '96.11%', 6: '78.34%', 7: '80.24%', 8: '86.78%', 9: '95.27%'}\n",
      "Val Loss: 0.684141, Val Acc: 86.46%, Val-Class-Acc: {0: '83.15%', 2: '88.89%', 3: '97.54%', 4: '92.50%', 5: '95.52%', 6: '32.41%', 7: '88.00%', 8: '87.90%', 9: '78.38%'}, LR: 0.001000\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.236879, Train-Class-Acc: {0: '93.60%', 2: '97.05%', 3: '97.54%', 4: '99.37%', 5: '96.19%', 6: '81.34%', 7: '83.23%', 8: '87.58%', 9: '94.59%'}\n",
      "Val Loss: 0.960382, Val Acc: 81.22%, Val-Class-Acc: {0: '57.61%', 2: '93.06%', 3: '98.36%', 4: '90.00%', 5: '89.55%', 6: '40.74%', 7: '87.20%', 8: '78.98%', 9: '62.16%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_3.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_6.pth\n",
      "Epoch 7/200, Train Loss: 0.336493, Train-Class-Acc: {0: '89.78%', 2: '92.20%', 3: '94.47%', 4: '96.20%', 5: '94.84%', 6: '82.72%', 7: '80.64%', 8: '86.46%', 9: '89.19%'}\n",
      "Val Loss: 0.755062, Val Acc: 85.95%, Val-Class-Acc: {0: '83.15%', 2: '84.72%', 3: '97.54%', 4: '85.00%', 5: '96.12%', 6: '59.26%', 7: '80.80%', 8: '80.25%', 9: '56.76%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_6.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.224156, Train-Class-Acc: {0: '93.46%', 2: '96.01%', 3: '96.62%', 4: '96.84%', 5: '95.59%', 6: '84.56%', 7: '86.43%', 8: '90.92%', 9: '96.62%'}\n",
      "Val Loss: 0.907198, Val Acc: 83.70%, Val-Class-Acc: {0: '76.09%', 2: '75.69%', 3: '91.80%', 4: '82.50%', 5: '97.91%', 6: '52.78%', 7: '84.80%', 8: '80.89%', 9: '70.27%'}, LR: 0.001000\n",
      "Epoch 9/200, Train Loss: 0.177350, Train-Class-Acc: {0: '95.50%', 2: '97.05%', 3: '97.03%', 4: '100.00%', 5: '97.31%', 6: '88.02%', 7: '86.83%', 8: '94.75%', 9: '97.30%'}\n",
      "Val Loss: 0.755027, Val Acc: 85.52%, Val-Class-Acc: {0: '85.33%', 2: '91.67%', 3: '97.54%', 4: '90.00%', 5: '90.45%', 6: '60.19%', 7: '80.00%', 8: '75.80%', 9: '67.57%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_2.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.136188, Train-Class-Acc: {0: '96.05%', 2: '98.79%', 3: '97.64%', 4: '99.37%', 5: '97.08%', 6: '93.32%', 7: '92.61%', 8: '93.15%', 9: '95.27%'}\n",
      "Val Loss: 0.875095, Val Acc: 86.03%, Val-Class-Acc: {0: '89.13%', 2: '82.64%', 3: '96.31%', 4: '85.00%', 5: '94.63%', 6: '52.78%', 7: '82.40%', 8: '84.71%', 9: '54.05%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_1.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_10.pth\n",
      "Epoch 11/200, Train Loss: 0.117281, Train-Class-Acc: {0: '96.73%', 2: '98.09%', 3: '98.26%', 4: '99.37%', 5: '96.63%', 6: '94.93%', 7: '93.21%', 8: '95.54%', 9: '99.32%'}\n",
      "Val Loss: 0.882138, Val Acc: 87.05%, Val-Class-Acc: {0: '94.02%', 2: '92.36%', 3: '95.49%', 4: '82.50%', 5: '93.13%', 6: '50.93%', 7: '88.00%', 8: '78.34%', 9: '64.86%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_9.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_11.pth\n",
      "Epoch 12/200, Train Loss: 0.082289, Train-Class-Acc: {0: '97.14%', 2: '97.75%', 3: '98.77%', 4: '100.00%', 5: '98.50%', 6: '96.77%', 7: '95.81%', 8: '96.82%', 9: '99.32%'}\n",
      "Val Loss: 0.880817, Val Acc: 87.48%, Val-Class-Acc: {0: '88.59%', 2: '91.67%', 3: '93.44%', 4: '87.50%', 5: '96.12%', 6: '58.33%', 7: '79.20%', 8: '88.54%', 9: '56.76%'}, LR: 0.001000\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_7.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_12.pth\n",
      "Epoch 13/200, Train Loss: 0.053553, Train-Class-Acc: {0: '98.64%', 2: '99.31%', 3: '99.08%', 4: '100.00%', 5: '99.48%', 6: '96.54%', 7: '97.01%', 8: '98.09%', 9: '98.65%'}\n",
      "Val Loss: 0.961956, Val Acc: 86.10%, Val-Class-Acc: {0: '90.76%', 2: '84.72%', 3: '94.67%', 4: '87.50%', 5: '92.54%', 6: '45.37%', 7: '84.80%', 8: '86.62%', 9: '72.97%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_10.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_13.pth\n",
      "Epoch 14/200, Train Loss: 0.067131, Train-Class-Acc: {0: '98.23%', 2: '99.31%', 3: '98.57%', 4: '99.37%', 5: '98.88%', 6: '96.54%', 7: '95.81%', 8: '97.77%', 9: '100.00%'}\n",
      "Val Loss: 1.172105, Val Acc: 85.44%, Val-Class-Acc: {0: '87.50%', 2: '88.89%', 3: '96.72%', 4: '85.00%', 5: '95.82%', 6: '33.33%', 7: '84.80%', 8: '81.53%', 9: '64.86%'}, LR: 0.000900\n",
      "Epoch 15/200, Train Loss: 0.157604, Train-Class-Acc: {0: '95.23%', 2: '97.23%', 3: '96.31%', 4: '96.20%', 5: '97.61%', 6: '92.86%', 7: '93.41%', 8: '92.52%', 9: '97.30%'}\n",
      "Val Loss: 0.987028, Val Acc: 83.19%, Val-Class-Acc: {0: '77.72%', 2: '96.53%', 3: '96.31%', 4: '90.00%', 5: '90.15%', 6: '30.56%', 7: '80.80%', 8: '78.98%', 9: '81.08%'}, LR: 0.000900\n",
      "Epoch 16/200, Train Loss: 0.153096, Train-Class-Acc: {0: '95.23%', 2: '98.09%', 3: '96.62%', 4: '99.37%', 5: '96.93%', 6: '90.32%', 7: '90.82%', 8: '92.68%', 9: '97.30%'}\n",
      "Val Loss: 1.022541, Val Acc: 84.72%, Val-Class-Acc: {0: '74.46%', 2: '95.14%', 3: '91.80%', 4: '90.00%', 5: '95.52%', 6: '41.67%', 7: '80.80%', 8: '88.54%', 9: '67.57%'}, LR: 0.000900\n",
      "Epoch 17/200, Train Loss: 0.069396, Train-Class-Acc: {0: '98.09%', 2: '98.96%', 3: '98.46%', 4: '100.00%', 5: '98.80%', 6: '95.62%', 7: '96.61%', 8: '97.61%', 9: '97.97%'}\n",
      "Val Loss: 0.847720, Val Acc: 85.52%, Val-Class-Acc: {0: '82.07%', 2: '94.44%', 3: '92.62%', 4: '90.00%', 5: '91.94%', 6: '50.93%', 7: '80.80%', 8: '86.62%', 9: '70.27%'}, LR: 0.000900\n",
      "Epoch 18/200, Train Loss: 0.056494, Train-Class-Acc: {0: '96.87%', 2: '99.83%', 3: '99.59%', 4: '100.00%', 5: '98.88%', 6: '97.47%', 7: '98.00%', 8: '96.34%', 9: '98.65%'}\n",
      "Val Loss: 0.944698, Val Acc: 85.74%, Val-Class-Acc: {0: '82.07%', 2: '89.58%', 3: '97.13%', 4: '87.50%', 5: '91.64%', 6: '52.78%', 7: '82.40%', 8: '85.35%', 9: '67.57%'}, LR: 0.000900\n",
      "Epoch 19/200, Train Loss: 0.053211, Train-Class-Acc: {0: '97.55%', 2: '99.83%', 3: '99.69%', 4: '100.00%', 5: '99.48%', 6: '98.39%', 7: '98.40%', 8: '98.89%', 9: '97.97%'}\n",
      "Val Loss: 0.929943, Val Acc: 85.15%, Val-Class-Acc: {0: '72.83%', 2: '91.67%', 3: '96.31%', 4: '87.50%', 5: '95.52%', 6: '55.56%', 7: '78.40%', 8: '80.89%', 9: '78.38%'}, LR: 0.000900\n",
      "Epoch 20/200, Train Loss: 0.041529, Train-Class-Acc: {0: '98.23%', 2: '100.00%', 3: '99.59%', 4: '100.00%', 5: '99.18%', 6: '97.93%', 7: '98.80%', 8: '98.25%', 9: '99.32%'}\n",
      "Val Loss: 1.051128, Val Acc: 86.90%, Val-Class-Acc: {0: '89.13%', 2: '91.67%', 3: '96.72%', 4: '90.00%', 5: '96.42%', 6: '42.59%', 7: '83.20%', 8: '84.08%', 9: '56.76%'}, LR: 0.000900\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_13.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_20.pth\n",
      "Epoch 21/200, Train Loss: 0.047337, Train-Class-Acc: {0: '98.50%', 2: '98.79%', 3: '99.59%', 4: '100.00%', 5: '99.70%', 6: '98.62%', 7: '99.20%', 8: '97.61%', 9: '99.32%'}\n",
      "Val Loss: 1.014395, Val Acc: 85.95%, Val-Class-Acc: {0: '81.52%', 2: '93.75%', 3: '93.44%', 4: '90.00%', 5: '96.42%', 6: '44.44%', 7: '80.00%', 8: '85.99%', 9: '70.27%'}, LR: 0.000900\n",
      "Epoch 22/200, Train Loss: 0.111254, Train-Class-Acc: {0: '93.05%', 2: '98.27%', 3: '98.87%', 4: '100.00%', 5: '98.80%', 6: '94.70%', 7: '96.61%', 8: '95.86%', 9: '96.62%'}\n",
      "Val Loss: 1.007502, Val Acc: 85.88%, Val-Class-Acc: {0: '84.78%', 2: '90.28%', 3: '94.67%', 4: '87.50%', 5: '92.24%', 6: '46.30%', 7: '84.80%', 8: '86.62%', 9: '72.97%'}, LR: 0.000900\n",
      "Epoch 23/200, Train Loss: 0.171768, Train-Class-Acc: {0: '94.14%', 2: '97.23%', 3: '96.72%', 4: '98.73%', 5: '94.76%', 6: '93.78%', 7: '92.61%', 8: '94.43%', 9: '94.59%'}\n",
      "Val Loss: 1.246050, Val Acc: 79.48%, Val-Class-Acc: {0: '70.65%', 2: '91.67%', 3: '95.49%', 4: '80.00%', 5: '90.45%', 6: '43.52%', 7: '72.80%', 8: '59.24%', 9: '83.78%'}, LR: 0.000900\n",
      "Epoch 24/200, Train Loss: 0.186842, Train-Class-Acc: {0: '93.73%', 2: '96.71%', 3: '96.62%', 4: '97.47%', 5: '95.66%', 6: '90.32%', 7: '91.02%', 8: '94.11%', 9: '94.59%'}\n",
      "Val Loss: 1.039990, Val Acc: 83.33%, Val-Class-Acc: {0: '82.61%', 2: '95.14%', 3: '87.70%', 4: '95.00%', 5: '91.94%', 6: '45.37%', 7: '82.40%', 8: '75.16%', 9: '70.27%'}, LR: 0.000810\n",
      "Epoch 25/200, Train Loss: 0.101860, Train-Class-Acc: {0: '98.09%', 2: '98.61%', 3: '96.11%', 4: '99.37%', 5: '97.08%', 6: '96.08%', 7: '96.01%', 8: '97.29%', 9: '98.65%'}\n",
      "Val Loss: 0.883436, Val Acc: 86.32%, Val-Class-Acc: {0: '88.59%', 2: '89.58%', 3: '91.80%', 4: '92.50%', 5: '93.73%', 6: '48.15%', 7: '83.20%', 8: '87.26%', 9: '70.27%'}, LR: 0.000810\n",
      "Epoch 26/200, Train Loss: 0.034160, Train-Class-Acc: {0: '99.73%', 2: '99.83%', 3: '99.80%', 4: '100.00%', 5: '99.48%', 6: '98.62%', 7: '99.40%', 8: '99.68%', 9: '100.00%'}\n",
      "Val Loss: 0.912545, Val Acc: 86.10%, Val-Class-Acc: {0: '85.87%', 2: '89.58%', 3: '93.85%', 4: '90.00%', 5: '93.73%', 6: '60.19%', 7: '80.80%', 8: '80.25%', 9: '67.57%'}, LR: 0.000810\n",
      "Epoch 27/200, Train Loss: 0.041273, Train-Class-Acc: {0: '98.09%', 2: '99.83%', 3: '99.69%', 4: '100.00%', 5: '99.63%', 6: '98.85%', 7: '99.40%', 8: '98.25%', 9: '98.65%'}\n",
      "Val Loss: 0.998102, Val Acc: 86.24%, Val-Class-Acc: {0: '82.61%', 2: '90.28%', 3: '95.49%', 4: '90.00%', 5: '94.93%', 6: '48.15%', 7: '78.40%', 8: '89.17%', 9: '70.27%'}, LR: 0.000810\n",
      "Epoch 28/200, Train Loss: 0.022936, Train-Class-Acc: {0: '99.32%', 2: '99.83%', 3: '99.80%', 4: '100.00%', 5: '100.00%', 6: '99.77%', 7: '99.60%', 8: '99.20%', 9: '100.00%'}\n",
      "Val Loss: 0.951671, Val Acc: 87.19%, Val-Class-Acc: {0: '83.15%', 2: '95.14%', 3: '97.13%', 4: '87.50%', 5: '94.93%', 6: '49.07%', 7: '80.80%', 8: '86.62%', 9: '75.68%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_5.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_28.pth\n",
      "Epoch 29/200, Train Loss: 0.020556, Train-Class-Acc: {0: '99.59%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.85%', 6: '99.54%', 7: '99.20%', 8: '99.20%', 9: '100.00%'}\n",
      "Val Loss: 1.058575, Val Acc: 86.24%, Val-Class-Acc: {0: '88.59%', 2: '95.14%', 3: '94.67%', 4: '85.00%', 5: '93.73%', 6: '42.59%', 7: '82.40%', 8: '85.35%', 9: '62.16%'}, LR: 0.000810\n",
      "Epoch 30/200, Train Loss: 0.018398, Train-Class-Acc: {0: '99.73%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.78%', 6: '99.54%', 7: '99.60%', 8: '99.52%', 9: '100.00%'}\n",
      "Val Loss: 1.010003, Val Acc: 86.97%, Val-Class-Acc: {0: '87.50%', 2: '92.36%', 3: '96.31%', 4: '92.50%', 5: '95.52%', 6: '38.89%', 7: '83.20%', 8: '87.90%', 9: '67.57%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_4.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_30.pth\n",
      "Epoch 31/200, Train Loss: 0.012637, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '99.84%', 9: '100.00%'}\n",
      "Val Loss: 1.026687, Val Acc: 87.48%, Val-Class-Acc: {0: '87.50%', 2: '93.75%', 3: '95.49%', 4: '90.00%', 5: '96.42%', 6: '46.30%', 7: '83.20%', 8: '85.35%', 9: '70.27%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_20.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_31.pth\n",
      "Epoch 32/200, Train Loss: 0.011612, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.019543, Val Acc: 87.19%, Val-Class-Acc: {0: '87.50%', 2: '92.36%', 3: '95.08%', 4: '90.00%', 5: '95.82%', 6: '45.37%', 7: '84.00%', 8: '85.99%', 9: '70.27%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_30.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_32.pth\n",
      "Epoch 33/200, Train Loss: 0.010574, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.995674, Val Acc: 87.19%, Val-Class-Acc: {0: '88.04%', 2: '92.36%', 3: '95.49%', 4: '90.00%', 5: '96.12%', 6: '43.52%', 7: '84.80%', 8: '84.71%', 9: '70.27%'}, LR: 0.000810\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_11.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_33.pth\n",
      "Epoch 34/200, Train Loss: 0.009794, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.004566, Val Acc: 87.05%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '95.49%', 4: '90.00%', 5: '96.12%', 6: '41.67%', 7: '84.80%', 8: '85.35%', 9: '70.27%'}, LR: 0.000810\n",
      "Epoch 35/200, Train Loss: 0.009579, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.999391, Val Acc: 87.41%, Val-Class-Acc: {0: '88.59%', 2: '93.75%', 3: '95.49%', 4: '90.00%', 5: '96.12%', 6: '42.59%', 7: '84.80%', 8: '85.35%', 9: '70.27%'}, LR: 0.000729\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_28.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_35.pth\n",
      "Epoch 36/200, Train Loss: 0.009298, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.030558, Val Acc: 87.63%, Val-Class-Acc: {0: '88.04%', 2: '93.75%', 3: '95.08%', 4: '90.00%', 5: '96.72%', 6: '41.67%', 7: '85.60%', 8: '86.62%', 9: '72.97%'}, LR: 0.000729\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_32.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_36.pth\n",
      "Epoch 37/200, Train Loss: 0.008955, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.010634, Val Acc: 87.48%, Val-Class-Acc: {0: '88.04%', 2: '94.44%', 3: '95.90%', 4: '90.00%', 5: '95.52%', 6: '41.67%', 7: '84.80%', 8: '86.62%', 9: '72.97%'}, LR: 0.000729\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_33.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_37.pth\n",
      "Epoch 38/200, Train Loss: 0.010647, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.78%', 6: '99.77%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.008331, Val Acc: 86.97%, Val-Class-Acc: {0: '84.78%', 2: '92.36%', 3: '95.08%', 4: '90.00%', 5: '95.82%', 6: '49.07%', 7: '81.60%', 8: '85.99%', 9: '72.97%'}, LR: 0.000729\n",
      "Epoch 39/200, Train Loss: 0.009496, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.010060, Val Acc: 87.26%, Val-Class-Acc: {0: '89.67%', 2: '95.14%', 3: '95.90%', 4: '90.00%', 5: '94.63%', 6: '41.67%', 7: '84.00%', 8: '85.35%', 9: '70.27%'}, LR: 0.000729\n",
      "Epoch 40/200, Train Loss: 0.009871, Train-Class-Acc: {0: '100.00%', 2: '99.83%', 3: '99.90%', 4: '100.00%', 5: '99.85%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.062132, Val Acc: 87.34%, Val-Class-Acc: {0: '88.59%', 2: '92.36%', 3: '95.90%', 4: '92.50%', 5: '96.12%', 6: '37.96%', 7: '84.00%', 8: '87.90%', 9: '72.97%'}, LR: 0.000729\n",
      "Epoch 41/200, Train Loss: 0.008941, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.85%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.023656, Val Acc: 87.26%, Val-Class-Acc: {0: '88.59%', 2: '93.75%', 3: '94.67%', 4: '90.00%', 5: '96.72%', 6: '38.89%', 7: '83.20%', 8: '87.26%', 9: '72.97%'}, LR: 0.000729\n",
      "Epoch 42/200, Train Loss: 0.015262, Train-Class-Acc: {0: '99.46%', 2: '99.65%', 3: '99.59%', 4: '100.00%', 5: '99.78%', 6: '100.00%', 7: '99.40%', 8: '99.84%', 9: '100.00%'}\n",
      "Val Loss: 1.013150, Val Acc: 84.72%, Val-Class-Acc: {0: '82.07%', 2: '97.22%', 3: '95.08%', 4: '87.50%', 5: '88.66%', 6: '44.44%', 7: '86.40%', 8: '84.08%', 9: '56.76%'}, LR: 0.000729\n",
      "Epoch 43/200, Train Loss: 0.168545, Train-Class-Acc: {0: '96.19%', 2: '98.27%', 3: '97.85%', 4: '95.57%', 5: '97.01%', 6: '93.78%', 7: '92.61%', 8: '94.43%', 9: '97.30%'}\n",
      "Val Loss: 1.326718, Val Acc: 79.26%, Val-Class-Acc: {0: '69.02%', 2: '90.97%', 3: '77.05%', 4: '92.50%', 5: '93.43%', 6: '28.70%', 7: '87.20%', 8: '77.07%', 9: '86.49%'}, LR: 0.000729\n",
      "Epoch 44/200, Train Loss: 0.413952, Train-Class-Acc: {0: '87.33%', 2: '94.63%', 3: '94.26%', 4: '94.94%', 5: '91.85%', 6: '79.95%', 7: '83.43%', 8: '88.85%', 9: '86.49%'}\n",
      "Val Loss: 0.889821, Val Acc: 81.95%, Val-Class-Acc: {0: '86.41%', 2: '90.28%', 3: '93.03%', 4: '95.00%', 5: '81.79%', 6: '54.63%', 7: '78.40%', 8: '75.80%', 9: '59.46%'}, LR: 0.000729\n",
      "Epoch 45/200, Train Loss: 0.140421, Train-Class-Acc: {0: '96.59%', 2: '97.40%', 3: '97.64%', 4: '98.10%', 5: '96.19%', 6: '94.47%', 7: '92.81%', 8: '94.75%', 9: '95.95%'}\n",
      "Val Loss: 0.924691, Val Acc: 85.66%, Val-Class-Acc: {0: '88.59%', 2: '94.44%', 3: '95.49%', 4: '85.00%', 5: '86.87%', 6: '62.04%', 7: '80.00%', 8: '81.53%', 9: '67.57%'}, LR: 0.000729\n",
      "Epoch 46/200, Train Loss: 0.058067, Train-Class-Acc: {0: '98.37%', 2: '99.48%', 3: '99.28%', 4: '99.37%', 5: '99.18%', 6: '98.16%', 7: '97.01%', 8: '98.57%', 9: '98.65%'}\n",
      "Val Loss: 1.000528, Val Acc: 83.84%, Val-Class-Acc: {0: '91.30%', 2: '86.81%', 3: '89.75%', 4: '92.50%', 5: '91.94%', 6: '42.59%', 7: '84.00%', 8: '78.34%', 9: '56.76%'}, LR: 0.000656\n",
      "Epoch 47/200, Train Loss: 0.047172, Train-Class-Acc: {0: '99.32%', 2: '98.79%', 3: '98.16%', 4: '100.00%', 5: '99.48%', 6: '98.39%', 7: '99.00%', 8: '97.93%', 9: '100.00%'}\n",
      "Val Loss: 0.957155, Val Acc: 86.10%, Val-Class-Acc: {0: '88.04%', 2: '93.75%', 3: '93.03%', 4: '82.50%', 5: '90.75%', 6: '45.37%', 7: '83.20%', 8: '91.08%', 9: '70.27%'}, LR: 0.000656\n",
      "Epoch 48/200, Train Loss: 0.021451, Train-Class-Acc: {0: '99.73%', 2: '100.00%', 3: '99.80%', 4: '100.00%', 5: '99.78%', 6: '99.54%', 7: '99.80%', 8: '99.84%', 9: '100.00%'}\n",
      "Val Loss: 1.050977, Val Acc: 86.10%, Val-Class-Acc: {0: '83.15%', 2: '91.67%', 3: '93.44%', 4: '90.00%', 5: '94.33%', 6: '46.30%', 7: '81.60%', 8: '89.17%', 9: '70.27%'}, LR: 0.000656\n",
      "Epoch 49/200, Train Loss: 0.016544, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.80%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.055831, Val Acc: 86.54%, Val-Class-Acc: {0: '89.13%', 2: '91.67%', 3: '97.13%', 4: '90.00%', 5: '93.73%', 6: '40.74%', 7: '80.80%', 8: '85.35%', 9: '72.97%'}, LR: 0.000656\n",
      "Epoch 50/200, Train Loss: 0.014890, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '100.00%', 6: '99.77%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.987594, Val Acc: 86.61%, Val-Class-Acc: {0: '83.70%', 2: '91.67%', 3: '93.44%', 4: '90.00%', 5: '94.03%', 6: '52.78%', 7: '81.60%', 8: '88.54%', 9: '72.97%'}, LR: 0.000656\n",
      "Epoch 51/200, Train Loss: 0.016114, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '99.54%', 7: '99.80%', 8: '99.68%', 9: '100.00%'}\n",
      "Val Loss: 1.019625, Val Acc: 86.75%, Val-Class-Acc: {0: '85.87%', 2: '91.67%', 3: '95.08%', 4: '90.00%', 5: '94.63%', 6: '44.44%', 7: '83.20%', 8: '87.90%', 9: '72.97%'}, LR: 0.000656\n",
      "Epoch 52/200, Train Loss: 0.014205, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '99.84%', 9: '100.00%'}\n",
      "Val Loss: 1.055265, Val Acc: 86.75%, Val-Class-Acc: {0: '88.04%', 2: '92.36%', 3: '96.72%', 4: '87.50%', 5: '94.63%', 6: '41.67%', 7: '81.60%', 8: '85.99%', 9: '72.97%'}, LR: 0.000656\n",
      "Epoch 53/200, Train Loss: 0.013103, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.004348, Val Acc: 86.97%, Val-Class-Acc: {0: '86.96%', 2: '93.75%', 3: '96.72%', 4: '90.00%', 5: '94.93%', 6: '47.22%', 7: '80.80%', 8: '84.71%', 9: '67.57%'}, LR: 0.000656\n",
      "Epoch 54/200, Train Loss: 0.011819, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.027025, Val Acc: 86.90%, Val-Class-Acc: {0: '87.50%', 2: '91.67%', 3: '97.13%', 4: '90.00%', 5: '94.63%', 6: '44.44%', 7: '82.40%', 8: '85.35%', 9: '70.27%'}, LR: 0.000656\n",
      "Epoch 55/200, Train Loss: 0.011048, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.006691, Val Acc: 86.68%, Val-Class-Acc: {0: '86.41%', 2: '91.67%', 3: '96.31%', 4: '90.00%', 5: '94.63%', 6: '44.44%', 7: '83.20%', 8: '85.99%', 9: '67.57%'}, LR: 0.000656\n",
      "Epoch 56/200, Train Loss: 0.010754, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.052958, Val Acc: 86.32%, Val-Class-Acc: {0: '86.96%', 2: '92.36%', 3: '96.31%', 4: '90.00%', 5: '94.63%', 6: '40.74%', 7: '81.60%', 8: '84.71%', 9: '70.27%'}, LR: 0.000656\n",
      "Epoch 57/200, Train Loss: 0.010556, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.042509, Val Acc: 86.75%, Val-Class-Acc: {0: '86.96%', 2: '92.36%', 3: '96.72%', 4: '90.00%', 5: '94.93%', 6: '43.52%', 7: '83.20%', 8: '84.08%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 58/200, Train Loss: 0.010065, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.057733, Val Acc: 86.46%, Val-Class-Acc: {0: '86.96%', 2: '91.67%', 3: '95.49%', 4: '90.00%', 5: '94.93%', 6: '43.52%', 7: '83.20%', 8: '84.71%', 9: '67.57%'}, LR: 0.000590\n",
      "Epoch 59/200, Train Loss: 0.009637, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.032393, Val Acc: 86.32%, Val-Class-Acc: {0: '85.87%', 2: '92.36%', 3: '95.49%', 4: '90.00%', 5: '94.33%', 6: '44.44%', 7: '84.00%', 8: '84.08%', 9: '67.57%'}, LR: 0.000590\n",
      "Epoch 60/200, Train Loss: 0.009341, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.032604, Val Acc: 86.24%, Val-Class-Acc: {0: '85.33%', 2: '93.06%', 3: '96.31%', 4: '90.00%', 5: '94.03%', 6: '42.59%', 7: '81.60%', 8: '85.99%', 9: '67.57%'}, LR: 0.000590\n",
      "Epoch 61/200, Train Loss: 0.009062, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.036951, Val Acc: 86.32%, Val-Class-Acc: {0: '87.50%', 2: '92.36%', 3: '96.31%', 4: '90.00%', 5: '94.33%', 6: '41.67%', 7: '81.60%', 8: '84.71%', 9: '67.57%'}, LR: 0.000590\n",
      "Epoch 62/200, Train Loss: 0.008850, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.018305, Val Acc: 86.39%, Val-Class-Acc: {0: '87.50%', 2: '91.67%', 3: '96.31%', 4: '90.00%', 5: '94.33%', 6: '42.59%', 7: '82.40%', 8: '84.71%', 9: '67.57%'}, LR: 0.000590\n",
      "Epoch 63/200, Train Loss: 0.008909, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.023770, Val Acc: 86.61%, Val-Class-Acc: {0: '88.04%', 2: '93.75%', 3: '96.72%', 4: '90.00%', 5: '94.03%', 6: '42.59%', 7: '81.60%', 8: '84.71%', 9: '67.57%'}, LR: 0.000590\n",
      "Epoch 64/200, Train Loss: 0.008457, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.024135, Val Acc: 86.39%, Val-Class-Acc: {0: '84.24%', 2: '93.06%', 3: '96.72%', 4: '90.00%', 5: '94.33%', 6: '42.59%', 7: '81.60%', 8: '86.62%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 65/200, Train Loss: 0.008596, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.014249, Val Acc: 86.75%, Val-Class-Acc: {0: '86.41%', 2: '92.36%', 3: '96.31%', 4: '90.00%', 5: '95.22%', 6: '45.37%', 7: '80.80%', 8: '85.35%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 66/200, Train Loss: 0.008191, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.021527, Val Acc: 86.97%, Val-Class-Acc: {0: '89.13%', 2: '93.06%', 3: '95.90%', 4: '90.00%', 5: '94.63%', 6: '44.44%', 7: '83.20%', 8: '84.71%', 9: '67.57%'}, LR: 0.000590\n",
      "Epoch 67/200, Train Loss: 0.007861, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.003811, Val Acc: 87.12%, Val-Class-Acc: {0: '87.50%', 2: '93.06%', 3: '96.72%', 4: '90.00%', 5: '95.22%', 6: '45.37%', 7: '81.60%', 8: '85.35%', 9: '70.27%'}, LR: 0.000590\n",
      "Epoch 68/200, Train Loss: 0.007598, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.006114, Val Acc: 86.75%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '95.90%', 4: '90.00%', 5: '95.22%', 6: '44.44%', 7: '80.80%', 8: '85.35%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 69/200, Train Loss: 0.007426, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.998831, Val Acc: 86.90%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '96.31%', 4: '90.00%', 5: '94.63%', 6: '44.44%', 7: '83.20%', 8: '85.35%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 70/200, Train Loss: 0.007237, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.014478, Val Acc: 86.83%, Val-Class-Acc: {0: '88.04%', 2: '93.06%', 3: '96.31%', 4: '90.00%', 5: '95.22%', 6: '44.44%', 7: '80.80%', 8: '84.71%', 9: '67.57%'}, LR: 0.000531\n",
      "Epoch 71/200, Train Loss: 0.007084, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.016000, Val Acc: 86.97%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '96.31%', 4: '90.00%', 5: '95.22%', 6: '44.44%', 7: '83.20%', 8: '85.35%', 9: '67.57%'}, LR: 0.000531\n",
      "Epoch 72/200, Train Loss: 0.006906, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.994344, Val Acc: 86.90%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '96.31%', 4: '90.00%', 5: '95.22%', 6: '46.30%', 7: '80.80%', 8: '85.35%', 9: '67.57%'}, LR: 0.000531\n",
      "Epoch 73/200, Train Loss: 0.006751, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.999091, Val Acc: 87.19%, Val-Class-Acc: {0: '88.59%', 2: '93.75%', 3: '96.31%', 4: '90.00%', 5: '94.93%', 6: '45.37%', 7: '82.40%', 8: '85.35%', 9: '67.57%'}, LR: 0.000531\n",
      "Epoch 74/200, Train Loss: 0.006620, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.012361, Val Acc: 86.90%, Val-Class-Acc: {0: '86.41%', 2: '91.67%', 3: '96.31%', 4: '90.00%', 5: '95.52%', 6: '47.22%', 7: '80.00%', 8: '85.99%', 9: '70.27%'}, LR: 0.000531\n",
      "Epoch 75/200, Train Loss: 0.006497, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.012278, Val Acc: 86.46%, Val-Class-Acc: {0: '86.41%', 2: '93.06%', 3: '96.72%', 4: '90.00%', 5: '94.93%', 6: '44.44%', 7: '78.40%', 8: '85.35%', 9: '67.57%'}, LR: 0.000531\n",
      "Epoch 76/200, Train Loss: 0.006331, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.007836, Val Acc: 86.97%, Val-Class-Acc: {0: '89.13%', 2: '93.75%', 3: '96.72%', 4: '90.00%', 5: '94.93%', 6: '43.52%', 7: '80.80%', 8: '84.71%', 9: '67.57%'}, LR: 0.000531\n",
      "Epoch 77/200, Train Loss: 0.006186, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.008258, Val Acc: 86.97%, Val-Class-Acc: {0: '87.50%', 2: '93.75%', 3: '97.13%', 4: '90.00%', 5: '94.63%', 6: '44.44%', 7: '80.00%', 8: '86.62%', 9: '67.57%'}, LR: 0.000531\n",
      "Epoch 78/200, Train Loss: 0.005975, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.008285, Val Acc: 86.97%, Val-Class-Acc: {0: '88.04%', 2: '93.75%', 3: '96.72%', 4: '90.00%', 5: '94.93%', 6: '44.44%', 7: '79.20%', 8: '86.62%', 9: '67.57%'}, LR: 0.000531\n",
      "Epoch 79/200, Train Loss: 0.005923, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 0.973084, Val Acc: 86.90%, Val-Class-Acc: {0: '88.04%', 2: '93.75%', 3: '96.31%', 4: '90.00%', 5: '94.03%', 6: '45.37%', 7: '82.40%', 8: '85.35%', 9: '67.57%'}, LR: 0.000478\n",
      "Epoch 80/200, Train Loss: 0.006279, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.046894, Val Acc: 87.05%, Val-Class-Acc: {0: '88.59%', 2: '93.75%', 3: '96.31%', 4: '90.00%', 5: '95.82%', 6: '42.59%', 7: '80.80%', 8: '85.35%', 9: '67.57%'}, LR: 0.000478\n",
      "Epoch 81/200, Train Loss: 0.008726, Train-Class-Acc: {0: '100.00%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '99.78%', 6: '99.77%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.023900, Val Acc: 84.79%, Val-Class-Acc: {0: '80.98%', 2: '87.50%', 3: '95.90%', 4: '90.00%', 5: '90.75%', 6: '49.07%', 7: '78.40%', 8: '87.26%', 9: '75.68%'}, LR: 0.000478\n",
      "Epoch 82/200, Train Loss: 0.282860, Train-Class-Acc: {0: '89.65%', 2: '95.49%', 3: '95.39%', 4: '98.10%', 5: '93.64%', 6: '86.64%', 7: '89.22%', 8: '91.56%', 9: '93.92%'}\n",
      "Val Loss: 1.115515, Val Acc: 81.22%, Val-Class-Acc: {0: '76.63%', 2: '90.97%', 3: '93.85%', 4: '90.00%', 5: '95.52%', 6: '62.96%', 7: '71.20%', 8: '50.32%', 9: '62.16%'}, LR: 0.000478\n",
      "Epoch 83/200, Train Loss: 0.219077, Train-Class-Acc: {0: '93.19%', 2: '96.01%', 3: '95.29%', 4: '97.47%', 5: '96.04%', 6: '91.94%', 7: '90.82%', 8: '92.36%', 9: '94.59%'}\n",
      "Val Loss: 1.140372, Val Acc: 84.64%, Val-Class-Acc: {0: '75.54%', 2: '90.28%', 3: '91.80%', 4: '87.50%', 5: '96.12%', 6: '38.89%', 7: '84.80%', 8: '91.08%', 9: '59.46%'}, LR: 0.000478\n",
      "Epoch 84/200, Train Loss: 0.087525, Train-Class-Acc: {0: '96.59%', 2: '98.61%', 3: '98.77%', 4: '100.00%', 5: '98.43%', 6: '95.39%', 7: '97.41%', 8: '96.18%', 9: '98.65%'}\n",
      "Val Loss: 1.105671, Val Acc: 85.15%, Val-Class-Acc: {0: '77.72%', 2: '88.19%', 3: '95.90%', 4: '90.00%', 5: '93.13%', 6: '49.07%', 7: '75.20%', 8: '94.27%', 9: '62.16%'}, LR: 0.000478\n",
      "Epoch 85/200, Train Loss: 0.035426, Train-Class-Acc: {0: '99.05%', 2: '99.48%', 3: '99.59%', 4: '100.00%', 5: '99.33%', 6: '98.85%', 7: '99.40%', 8: '99.20%', 9: '99.32%'}\n",
      "Val Loss: 1.088727, Val Acc: 86.46%, Val-Class-Acc: {0: '85.87%', 2: '92.36%', 3: '95.08%', 4: '87.50%', 5: '94.93%', 6: '43.52%', 7: '84.00%', 8: '87.90%', 9: '59.46%'}, LR: 0.000478\n",
      "Epoch 86/200, Train Loss: 0.019907, Train-Class-Acc: {0: '99.59%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.63%', 6: '99.31%', 7: '99.60%', 8: '99.68%', 9: '100.00%'}\n",
      "Val Loss: 1.065756, Val Acc: 86.46%, Val-Class-Acc: {0: '83.15%', 2: '90.28%', 3: '95.90%', 4: '90.00%', 5: '94.93%', 6: '46.30%', 7: '81.60%', 8: '89.81%', 9: '64.86%'}, LR: 0.000478\n",
      "Epoch 87/200, Train Loss: 0.015123, Train-Class-Acc: {0: '99.86%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '99.85%', 6: '100.00%', 7: '99.80%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.048067, Val Acc: 86.24%, Val-Class-Acc: {0: '85.33%', 2: '92.36%', 3: '95.90%', 4: '82.50%', 5: '95.22%', 6: '44.44%', 7: '80.00%', 8: '86.62%', 9: '67.57%'}, LR: 0.000478\n",
      "Epoch 88/200, Train Loss: 0.011705, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.051703, Val Acc: 87.12%, Val-Class-Acc: {0: '86.41%', 2: '92.36%', 3: '95.49%', 4: '85.00%', 5: '95.22%', 6: '45.37%', 7: '83.20%', 8: '89.17%', 9: '70.27%'}, LR: 0.000478\n",
      "Epoch 89/200, Train Loss: 0.010749, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.006089, Val Acc: 87.05%, Val-Class-Acc: {0: '85.33%', 2: '92.36%', 3: '95.90%', 4: '87.50%', 5: '94.93%', 6: '49.07%', 7: '80.80%', 8: '88.54%', 9: '70.27%'}, LR: 0.000478\n",
      "Epoch 90/200, Train Loss: 0.011613, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.78%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.050103, Val Acc: 86.61%, Val-Class-Acc: {0: '85.33%', 2: '92.36%', 3: '95.90%', 4: '82.50%', 5: '95.22%', 6: '45.37%', 7: '81.60%', 8: '87.90%', 9: '67.57%'}, LR: 0.000430\n",
      "Epoch 91/200, Train Loss: 0.010273, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.044651, Val Acc: 86.97%, Val-Class-Acc: {0: '87.50%', 2: '93.75%', 3: '95.90%', 4: '87.50%', 5: '95.52%', 6: '45.37%', 7: '80.00%', 8: '86.62%', 9: '67.57%'}, LR: 0.000430\n",
      "Epoch 92/200, Train Loss: 0.009597, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.090192, Val Acc: 87.26%, Val-Class-Acc: {0: '88.04%', 2: '93.06%', 3: '95.90%', 4: '87.50%', 5: '95.52%', 6: '42.59%', 7: '82.40%', 8: '88.54%', 9: '70.27%'}, LR: 0.000430\n",
      "Epoch 93/200, Train Loss: 0.009325, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.052699, Val Acc: 87.19%, Val-Class-Acc: {0: '87.50%', 2: '92.36%', 3: '95.90%', 4: '87.50%', 5: '95.82%', 6: '44.44%', 7: '82.40%', 8: '87.90%', 9: '67.57%'}, LR: 0.000430\n",
      "Epoch 94/200, Train Loss: 0.009355, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.024265, Val Acc: 86.75%, Val-Class-Acc: {0: '84.24%', 2: '93.75%', 3: '95.90%', 4: '87.50%', 5: '94.63%', 6: '44.44%', 7: '81.60%', 8: '89.17%', 9: '70.27%'}, LR: 0.000430\n",
      "Epoch 95/200, Train Loss: 0.008948, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.053642, Val Acc: 87.05%, Val-Class-Acc: {0: '88.04%', 2: '93.06%', 3: '95.90%', 4: '87.50%', 5: '95.22%', 6: '44.44%', 7: '81.60%', 8: '87.26%', 9: '67.57%'}, LR: 0.000430\n",
      "Epoch 96/200, Train Loss: 0.008634, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.054486, Val Acc: 86.97%, Val-Class-Acc: {0: '87.50%', 2: '92.36%', 3: '95.90%', 4: '90.00%', 5: '95.52%', 6: '41.67%', 7: '82.40%', 8: '87.90%', 9: '67.57%'}, LR: 0.000430\n",
      "Epoch 97/200, Train Loss: 0.008382, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.067632, Val Acc: 86.90%, Val-Class-Acc: {0: '85.33%', 2: '93.75%', 3: '95.90%', 4: '90.00%', 5: '95.22%', 6: '41.67%', 7: '82.40%', 8: '89.17%', 9: '67.57%'}, LR: 0.000430\n",
      "Epoch 98/200, Train Loss: 0.008207, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.080262, Val Acc: 87.12%, Val-Class-Acc: {0: '86.41%', 2: '93.06%', 3: '95.90%', 4: '90.00%', 5: '95.82%', 6: '41.67%', 7: '81.60%', 8: '89.81%', 9: '67.57%'}, LR: 0.000430\n",
      "Epoch 99/200, Train Loss: 0.008168, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.040200, Val Acc: 87.55%, Val-Class-Acc: {0: '88.04%', 2: '93.75%', 3: '95.90%', 4: '90.00%', 5: '95.82%', 6: '44.44%', 7: '81.60%', 8: '89.17%', 9: '67.57%'}, LR: 0.000430\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_35.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_99.pth\n",
      "Epoch 100/200, Train Loss: 0.009753, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.69%', 4: '100.00%', 5: '100.00%', 6: '99.77%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.005990, Val Acc: 87.63%, Val-Class-Acc: {0: '88.04%', 2: '92.36%', 3: '96.72%', 4: '87.50%', 5: '95.52%', 6: '50.00%', 7: '80.00%', 8: '88.54%', 9: '67.57%'}, LR: 0.000430\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_12.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_100.pth\n",
      "Epoch 101/200, Train Loss: 0.008044, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.009315, Val Acc: 87.34%, Val-Class-Acc: {0: '88.04%', 2: '92.36%', 3: '95.90%', 4: '87.50%', 5: '95.52%', 6: '48.15%', 7: '81.60%', 8: '87.26%', 9: '67.57%'}, LR: 0.000387\n",
      "Epoch 102/200, Train Loss: 0.007728, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.033284, Val Acc: 87.41%, Val-Class-Acc: {0: '87.50%', 2: '91.67%', 3: '96.31%', 4: '90.00%', 5: '95.52%', 6: '47.22%', 7: '82.40%', 8: '87.90%', 9: '67.57%'}, LR: 0.000387\n",
      "Epoch 103/200, Train Loss: 0.007828, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.038710, Val Acc: 87.05%, Val-Class-Acc: {0: '86.41%', 2: '91.67%', 3: '96.31%', 4: '90.00%', 5: '95.52%', 6: '47.22%', 7: '82.40%', 8: '85.99%', 9: '67.57%'}, LR: 0.000387\n",
      "Epoch 104/200, Train Loss: 0.007417, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.049400, Val Acc: 87.19%, Val-Class-Acc: {0: '89.13%', 2: '90.97%', 3: '96.31%', 4: '90.00%', 5: '95.52%', 6: '46.30%', 7: '82.40%', 8: '85.35%', 9: '67.57%'}, LR: 0.000387\n",
      "Epoch 105/200, Train Loss: 0.007265, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.064583, Val Acc: 87.19%, Val-Class-Acc: {0: '88.04%', 2: '93.75%', 3: '95.90%', 4: '90.00%', 5: '95.52%', 6: '40.74%', 7: '82.40%', 8: '88.54%', 9: '67.57%'}, LR: 0.000387\n",
      "Epoch 106/200, Train Loss: 0.007086, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.042899, Val Acc: 87.19%, Val-Class-Acc: {0: '86.96%', 2: '93.75%', 3: '95.90%', 4: '90.00%', 5: '95.52%', 6: '43.52%', 7: '82.40%', 8: '87.90%', 9: '67.57%'}, LR: 0.000387\n",
      "Epoch 107/200, Train Loss: 0.006981, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.075750, Val Acc: 87.34%, Val-Class-Acc: {0: '88.04%', 2: '91.67%', 3: '96.31%', 4: '90.00%', 5: '96.12%', 6: '42.59%', 7: '83.20%', 8: '87.90%', 9: '67.57%'}, LR: 0.000387\n",
      "Epoch 108/200, Train Loss: 0.006793, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.048873, Val Acc: 87.12%, Val-Class-Acc: {0: '87.50%', 2: '91.67%', 3: '96.31%', 4: '90.00%', 5: '95.52%', 6: '43.52%', 7: '82.40%', 8: '87.90%', 9: '67.57%'}, LR: 0.000387\n",
      "Epoch 109/200, Train Loss: 0.006853, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.077990, Val Acc: 87.48%, Val-Class-Acc: {0: '88.59%', 2: '92.36%', 3: '95.90%', 4: '90.00%', 5: '94.93%', 6: '48.15%', 7: '82.40%', 8: '87.90%', 9: '67.57%'}, LR: 0.000387\n",
      "Epoch 110/200, Train Loss: 0.006625, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.084609, Val Acc: 87.34%, Val-Class-Acc: {0: '86.41%', 2: '91.67%', 3: '96.31%', 4: '90.00%', 5: '95.52%', 6: '45.37%', 7: '82.40%', 8: '89.81%', 9: '67.57%'}, LR: 0.000387\n",
      "Epoch 111/200, Train Loss: 0.006419, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.070785, Val Acc: 87.55%, Val-Class-Acc: {0: '88.59%', 2: '92.36%', 3: '96.31%', 4: '90.00%', 5: '95.52%', 6: '45.37%', 7: '82.40%', 8: '88.54%', 9: '67.57%'}, LR: 0.000387\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_31.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_111.pth\n",
      "Epoch 112/200, Train Loss: 0.006324, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.067579, Val Acc: 87.41%, Val-Class-Acc: {0: '87.50%', 2: '92.36%', 3: '96.31%', 4: '90.00%', 5: '95.52%', 6: '46.30%', 7: '81.60%', 8: '88.54%', 9: '67.57%'}, LR: 0.000349\n",
      "Epoch 113/200, Train Loss: 0.006274, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.088178, Val Acc: 87.70%, Val-Class-Acc: {0: '88.59%', 2: '93.06%', 3: '96.31%', 4: '90.00%', 5: '96.42%', 6: '45.37%', 7: '81.60%', 8: '87.90%', 9: '67.57%'}, LR: 0.000349\n",
      "üóë Removed: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_37.pth\n",
      "‚úÖ Saved model: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_113.pth\n",
      "Epoch 114/200, Train Loss: 0.006216, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.094257, Val Acc: 86.83%, Val-Class-Acc: {0: '88.04%', 2: '92.36%', 3: '96.31%', 4: '85.00%', 5: '95.52%', 6: '43.52%', 7: '86.40%', 8: '81.53%', 9: '70.27%'}, LR: 0.000349\n",
      "Epoch 115/200, Train Loss: 0.006401, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.087915, Val Acc: 86.75%, Val-Class-Acc: {0: '87.50%', 2: '91.67%', 3: '95.90%', 4: '90.00%', 5: '95.52%', 6: '42.59%', 7: '80.80%', 8: '87.26%', 9: '67.57%'}, LR: 0.000349\n",
      "Epoch 116/200, Train Loss: 0.009611, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '99.60%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.144261, Val Acc: 86.61%, Val-Class-Acc: {0: '87.50%', 2: '87.50%', 3: '95.49%', 4: '90.00%', 5: '94.93%', 6: '49.07%', 7: '79.20%', 8: '89.17%', 9: '64.86%'}, LR: 0.000349\n",
      "Epoch 117/200, Train Loss: 0.126834, Train-Class-Acc: {0: '95.50%', 2: '98.44%', 3: '98.77%', 4: '97.47%', 5: '98.50%', 6: '93.55%', 7: '95.21%', 8: '92.52%', 9: '98.65%'}\n",
      "Val Loss: 0.973078, Val Acc: 83.99%, Val-Class-Acc: {0: '75.00%', 2: '88.89%', 3: '94.67%', 4: '90.00%', 5: '89.25%', 6: '52.78%', 7: '84.80%', 8: '84.71%', 9: '70.27%'}, LR: 0.000349\n",
      "Epoch 118/200, Train Loss: 0.095568, Train-Class-Acc: {0: '96.73%', 2: '98.61%', 3: '98.98%', 4: '99.37%', 5: '98.58%', 6: '95.85%', 7: '94.41%', 8: '96.66%', 9: '96.62%'}\n",
      "Val Loss: 1.180723, Val Acc: 83.55%, Val-Class-Acc: {0: '77.17%', 2: '88.19%', 3: '90.57%', 4: '92.50%', 5: '95.22%', 6: '46.30%', 7: '83.20%', 8: '76.43%', 9: '75.68%'}, LR: 0.000349\n",
      "Epoch 119/200, Train Loss: 0.035813, Train-Class-Acc: {0: '99.05%', 2: '99.65%', 3: '98.77%', 4: '99.37%', 5: '99.33%', 6: '98.85%', 7: '99.00%', 8: '99.68%', 9: '99.32%'}\n",
      "Val Loss: 1.231357, Val Acc: 84.93%, Val-Class-Acc: {0: '84.78%', 2: '90.97%', 3: '90.98%', 4: '92.50%', 5: '94.63%', 6: '44.44%', 7: '83.20%', 8: '85.99%', 9: '45.95%'}, LR: 0.000349\n",
      "Epoch 120/200, Train Loss: 0.065717, Train-Class-Acc: {0: '99.59%', 2: '98.61%', 3: '98.87%', 4: '95.57%', 5: '99.55%', 6: '99.77%', 7: '98.60%', 8: '99.20%', 9: '97.97%'}\n",
      "Val Loss: 1.260624, Val Acc: 84.13%, Val-Class-Acc: {0: '86.41%', 2: '96.53%', 3: '90.98%', 4: '90.00%', 5: '94.33%', 6: '32.41%', 7: '80.80%', 8: '78.98%', 9: '64.86%'}, LR: 0.000349\n",
      "Epoch 121/200, Train Loss: 0.028229, Train-Class-Acc: {0: '99.59%', 2: '99.48%', 3: '99.18%', 4: '99.37%', 5: '99.63%', 6: '99.54%', 7: '99.20%', 8: '99.36%', 9: '100.00%'}\n",
      "Val Loss: 1.235587, Val Acc: 83.92%, Val-Class-Acc: {0: '80.98%', 2: '93.06%', 3: '96.72%', 4: '80.00%', 5: '91.94%', 6: '39.81%', 7: '77.60%', 8: '80.89%', 9: '72.97%'}, LR: 0.000349\n",
      "Epoch 122/200, Train Loss: 0.016424, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.80%', 4: '100.00%', 5: '99.85%', 6: '99.77%', 7: '100.00%', 8: '99.84%', 9: '100.00%'}\n",
      "Val Loss: 1.227210, Val Acc: 85.81%, Val-Class-Acc: {0: '88.04%', 2: '88.89%', 3: '96.31%', 4: '77.50%', 5: '94.03%', 6: '43.52%', 7: '82.40%', 8: '85.99%', 9: '62.16%'}, LR: 0.000349\n",
      "Epoch 123/200, Train Loss: 0.011642, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.209666, Val Acc: 86.24%, Val-Class-Acc: {0: '86.41%', 2: '93.75%', 3: '95.90%', 4: '87.50%', 5: '94.03%', 6: '44.44%', 7: '79.20%', 8: '85.99%', 9: '67.57%'}, LR: 0.000314\n",
      "Epoch 124/200, Train Loss: 0.009703, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.219894, Val Acc: 86.39%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '96.31%', 4: '82.50%', 5: '94.03%', 6: '45.37%', 7: '81.60%', 8: '85.99%', 9: '64.86%'}, LR: 0.000314\n",
      "Epoch 125/200, Train Loss: 0.009394, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.233740, Val Acc: 86.24%, Val-Class-Acc: {0: '87.50%', 2: '90.97%', 3: '95.90%', 4: '82.50%', 5: '94.03%', 6: '42.59%', 7: '82.40%', 8: '87.90%', 9: '64.86%'}, LR: 0.000314\n",
      "Epoch 126/200, Train Loss: 0.008963, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.198502, Val Acc: 86.32%, Val-Class-Acc: {0: '88.59%', 2: '91.67%', 3: '96.72%', 4: '87.50%', 5: '93.43%', 6: '46.30%', 7: '78.40%', 8: '85.35%', 9: '67.57%'}, LR: 0.000314\n",
      "Epoch 127/200, Train Loss: 0.008717, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.131702, Val Acc: 86.61%, Val-Class-Acc: {0: '89.13%', 2: '92.36%', 3: '95.90%', 4: '85.00%', 5: '93.43%', 6: '49.07%', 7: '80.80%', 8: '84.71%', 9: '67.57%'}, LR: 0.000314\n",
      "Epoch 128/200, Train Loss: 0.009468, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '99.90%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '99.80%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.169810, Val Acc: 86.46%, Val-Class-Acc: {0: '87.50%', 2: '92.36%', 3: '96.31%', 4: '85.00%', 5: '93.73%', 6: '44.44%', 7: '80.80%', 8: '86.62%', 9: '70.27%'}, LR: 0.000314\n",
      "Epoch 129/200, Train Loss: 0.008286, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.154924, Val Acc: 86.68%, Val-Class-Acc: {0: '85.87%', 2: '92.36%', 3: '96.72%', 4: '85.00%', 5: '94.63%', 6: '48.15%', 7: '80.80%', 8: '85.35%', 9: '70.27%'}, LR: 0.000314\n",
      "Epoch 130/200, Train Loss: 0.007913, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.150015, Val Acc: 86.24%, Val-Class-Acc: {0: '87.50%', 2: '92.36%', 3: '94.26%', 4: '85.00%', 5: '94.03%', 6: '45.37%', 7: '81.60%', 8: '85.99%', 9: '70.27%'}, LR: 0.000314\n",
      "Epoch 131/200, Train Loss: 0.007780, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.175879, Val Acc: 85.59%, Val-Class-Acc: {0: '85.87%', 2: '91.67%', 3: '94.26%', 4: '85.00%', 5: '93.73%', 6: '39.81%', 7: '81.60%', 8: '87.26%', 9: '70.27%'}, LR: 0.000314\n",
      "Epoch 132/200, Train Loss: 0.007613, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.173940, Val Acc: 86.46%, Val-Class-Acc: {0: '86.41%', 2: '93.75%', 3: '95.90%', 4: '87.50%', 5: '93.73%', 6: '45.37%', 7: '80.00%', 8: '86.62%', 9: '70.27%'}, LR: 0.000314\n",
      "Epoch 133/200, Train Loss: 0.007459, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.150898, Val Acc: 86.32%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '95.08%', 4: '87.50%', 5: '94.03%', 6: '44.44%', 7: '81.60%', 8: '84.71%', 9: '72.97%'}, LR: 0.000314\n",
      "Epoch 134/200, Train Loss: 0.007387, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.162340, Val Acc: 86.32%, Val-Class-Acc: {0: '88.59%', 2: '92.36%', 3: '95.08%', 4: '87.50%', 5: '93.73%', 6: '43.52%', 7: '80.00%', 8: '86.62%', 9: '70.27%'}, LR: 0.000282\n",
      "Epoch 135/200, Train Loss: 0.007256, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.159391, Val Acc: 86.83%, Val-Class-Acc: {0: '88.04%', 2: '92.36%', 3: '96.31%', 4: '87.50%', 5: '94.63%', 6: '48.15%', 7: '80.00%', 8: '84.71%', 9: '70.27%'}, LR: 0.000282\n",
      "Epoch 136/200, Train Loss: 0.007188, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.144454, Val Acc: 86.39%, Val-Class-Acc: {0: '88.04%', 2: '91.67%', 3: '95.90%', 4: '87.50%', 5: '93.73%', 6: '45.37%', 7: '81.60%', 8: '84.71%', 9: '70.27%'}, LR: 0.000282\n",
      "Epoch 137/200, Train Loss: 0.007055, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.161819, Val Acc: 86.32%, Val-Class-Acc: {0: '88.04%', 2: '92.36%', 3: '95.90%', 4: '87.50%', 5: '94.33%', 6: '41.67%', 7: '80.80%', 8: '85.35%', 9: '70.27%'}, LR: 0.000282\n",
      "Epoch 138/200, Train Loss: 0.007016, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.160883, Val Acc: 86.46%, Val-Class-Acc: {0: '88.59%', 2: '93.75%', 3: '95.08%', 4: '87.50%', 5: '94.33%', 6: '40.74%', 7: '81.60%', 8: '85.99%', 9: '70.27%'}, LR: 0.000282\n",
      "Epoch 139/200, Train Loss: 0.006923, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.181500, Val Acc: 86.17%, Val-Class-Acc: {0: '88.04%', 2: '93.75%', 3: '95.08%', 4: '87.50%', 5: '93.13%', 6: '40.74%', 7: '80.80%', 8: '87.26%', 9: '70.27%'}, LR: 0.000282\n",
      "Epoch 140/200, Train Loss: 0.006837, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.133015, Val Acc: 86.32%, Val-Class-Acc: {0: '88.04%', 2: '92.36%', 3: '95.08%', 4: '87.50%', 5: '94.33%', 6: '43.52%', 7: '79.20%', 8: '86.62%', 9: '70.27%'}, LR: 0.000282\n",
      "Epoch 141/200, Train Loss: 0.006659, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.167449, Val Acc: 86.39%, Val-Class-Acc: {0: '88.59%', 2: '92.36%', 3: '94.26%', 4: '87.50%', 5: '94.63%', 6: '41.67%', 7: '81.60%', 8: '86.62%', 9: '70.27%'}, LR: 0.000282\n",
      "Epoch 142/200, Train Loss: 0.006597, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.199060, Val Acc: 86.17%, Val-Class-Acc: {0: '87.50%', 2: '92.36%', 3: '94.26%', 4: '87.50%', 5: '94.63%', 6: '39.81%', 7: '81.60%', 8: '87.26%', 9: '70.27%'}, LR: 0.000282\n",
      "Epoch 143/200, Train Loss: 0.006452, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.172552, Val Acc: 86.39%, Val-Class-Acc: {0: '88.04%', 2: '90.97%', 3: '95.90%', 4: '87.50%', 5: '94.63%', 6: '41.67%', 7: '80.80%', 8: '86.62%', 9: '70.27%'}, LR: 0.000282\n",
      "Epoch 144/200, Train Loss: 0.006334, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.183956, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 2: '93.06%', 3: '95.90%', 4: '87.50%', 5: '94.93%', 6: '40.74%', 7: '80.80%', 8: '86.62%', 9: '70.27%'}, LR: 0.000282\n",
      "Epoch 145/200, Train Loss: 0.006409, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.159631, Val Acc: 86.17%, Val-Class-Acc: {0: '88.04%', 2: '90.97%', 3: '94.26%', 4: '87.50%', 5: '94.63%', 6: '43.52%', 7: '80.00%', 8: '86.62%', 9: '70.27%'}, LR: 0.000254\n",
      "Epoch 146/200, Train Loss: 0.006281, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.171381, Val Acc: 86.32%, Val-Class-Acc: {0: '88.59%', 2: '92.36%', 3: '95.08%', 4: '87.50%', 5: '94.63%', 6: '40.74%', 7: '80.80%', 8: '86.62%', 9: '67.57%'}, LR: 0.000254\n",
      "Epoch 147/200, Train Loss: 0.006344, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.140953, Val Acc: 86.10%, Val-Class-Acc: {0: '87.50%', 2: '90.97%', 3: '95.08%', 4: '87.50%', 5: '94.63%', 6: '41.67%', 7: '80.00%', 8: '86.62%', 9: '70.27%'}, LR: 0.000254\n",
      "Epoch 148/200, Train Loss: 0.006094, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.172147, Val Acc: 86.24%, Val-Class-Acc: {0: '88.04%', 2: '90.97%', 3: '95.49%', 4: '87.50%', 5: '95.22%', 6: '41.67%', 7: '80.00%', 8: '85.99%', 9: '67.57%'}, LR: 0.000254\n",
      "Epoch 149/200, Train Loss: 0.006022, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.138155, Val Acc: 86.10%, Val-Class-Acc: {0: '88.59%', 2: '91.67%', 3: '95.90%', 4: '87.50%', 5: '92.84%', 6: '42.59%', 7: '80.80%', 8: '85.99%', 9: '70.27%'}, LR: 0.000254\n",
      "Epoch 150/200, Train Loss: 0.005874, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.149105, Val Acc: 86.10%, Val-Class-Acc: {0: '88.59%', 2: '92.36%', 3: '95.49%', 4: '87.50%', 5: '94.03%', 6: '38.89%', 7: '79.20%', 8: '87.26%', 9: '70.27%'}, LR: 0.000254\n",
      "Epoch 151/200, Train Loss: 0.005797, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.172439, Val Acc: 86.17%, Val-Class-Acc: {0: '88.59%', 2: '90.97%', 3: '96.31%', 4: '87.50%', 5: '94.33%', 6: '40.74%', 7: '80.00%', 8: '85.99%', 9: '67.57%'}, LR: 0.000254\n",
      "Epoch 152/200, Train Loss: 0.005774, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.145982, Val Acc: 86.32%, Val-Class-Acc: {0: '88.59%', 2: '92.36%', 3: '95.90%', 4: '87.50%', 5: '94.63%', 6: '42.59%', 7: '79.20%', 8: '85.35%', 9: '67.57%'}, LR: 0.000254\n",
      "Epoch 153/200, Train Loss: 0.005661, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.167664, Val Acc: 86.32%, Val-Class-Acc: {0: '88.59%', 2: '90.28%', 3: '96.31%', 4: '87.50%', 5: '94.63%', 6: '42.59%', 7: '80.00%', 8: '85.99%', 9: '67.57%'}, LR: 0.000254\n",
      "Epoch 154/200, Train Loss: 0.005599, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.156508, Val Acc: 86.03%, Val-Class-Acc: {0: '85.87%', 2: '92.36%', 3: '95.49%', 4: '87.50%', 5: '94.33%', 6: '40.74%', 7: '79.20%', 8: '88.54%', 9: '67.57%'}, LR: 0.000254\n",
      "Epoch 155/200, Train Loss: 0.005466, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.156081, Val Acc: 86.39%, Val-Class-Acc: {0: '88.04%', 2: '93.06%', 3: '95.90%', 4: '87.50%', 5: '94.93%', 6: '40.74%', 7: '79.20%', 8: '86.62%', 9: '67.57%'}, LR: 0.000254\n",
      "Epoch 156/200, Train Loss: 0.005408, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.156044, Val Acc: 86.24%, Val-Class-Acc: {0: '88.04%', 2: '93.06%', 3: '95.90%', 4: '87.50%', 5: '94.63%', 6: '40.74%', 7: '79.20%', 8: '85.99%', 9: '67.57%'}, LR: 0.000229\n",
      "Epoch 157/200, Train Loss: 0.005504, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.142569, Val Acc: 85.88%, Val-Class-Acc: {0: '86.41%', 2: '93.06%', 3: '95.49%', 4: '87.50%', 5: '92.84%', 6: '41.67%', 7: '78.40%', 8: '86.62%', 9: '78.38%'}, LR: 0.000229\n",
      "Epoch 158/200, Train Loss: 0.005554, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.179534, Val Acc: 86.68%, Val-Class-Acc: {0: '89.13%', 2: '90.97%', 3: '95.90%', 4: '87.50%', 5: '95.82%', 6: '41.67%', 7: '80.80%', 8: '85.35%', 9: '70.27%'}, LR: 0.000229\n",
      "Epoch 159/200, Train Loss: 0.005294, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.176070, Val Acc: 86.46%, Val-Class-Acc: {0: '88.59%', 2: '91.67%', 3: '95.90%', 4: '87.50%', 5: '94.63%', 6: '41.67%', 7: '80.80%', 8: '85.99%', 9: '70.27%'}, LR: 0.000229\n",
      "Epoch 160/200, Train Loss: 0.005183, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.154020, Val Acc: 86.24%, Val-Class-Acc: {0: '88.04%', 2: '91.67%', 3: '95.90%', 4: '87.50%', 5: '93.73%', 6: '40.74%', 7: '82.40%', 8: '85.99%', 9: '70.27%'}, LR: 0.000229\n",
      "Epoch 161/200, Train Loss: 0.005095, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.165773, Val Acc: 86.03%, Val-Class-Acc: {0: '88.59%', 2: '89.58%', 3: '95.90%', 4: '87.50%', 5: '93.43%', 6: '41.67%', 7: '80.80%', 8: '86.62%', 9: '70.27%'}, LR: 0.000229\n",
      "Epoch 162/200, Train Loss: 0.004997, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.150883, Val Acc: 86.10%, Val-Class-Acc: {0: '88.04%', 2: '90.97%', 3: '95.90%', 4: '87.50%', 5: '93.43%', 6: '42.59%', 7: '80.00%', 8: '86.62%', 9: '70.27%'}, LR: 0.000229\n",
      "Epoch 163/200, Train Loss: 0.004930, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.162836, Val Acc: 86.68%, Val-Class-Acc: {0: '89.13%', 2: '92.36%', 3: '95.90%', 4: '87.50%', 5: '94.93%', 6: '43.52%', 7: '80.00%', 8: '85.35%', 9: '70.27%'}, LR: 0.000229\n",
      "Epoch 164/200, Train Loss: 0.004879, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.163477, Val Acc: 86.75%, Val-Class-Acc: {0: '89.13%', 2: '92.36%', 3: '95.90%', 4: '87.50%', 5: '94.33%', 6: '40.74%', 7: '84.00%', 8: '85.99%', 9: '70.27%'}, LR: 0.000229\n",
      "Epoch 165/200, Train Loss: 0.004783, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.158539, Val Acc: 86.10%, Val-Class-Acc: {0: '86.96%', 2: '92.36%', 3: '95.90%', 4: '87.50%', 5: '94.33%', 6: '39.81%', 7: '80.00%', 8: '86.62%', 9: '70.27%'}, LR: 0.000229\n",
      "Epoch 166/200, Train Loss: 0.004746, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.154125, Val Acc: 86.75%, Val-Class-Acc: {0: '88.59%', 2: '92.36%', 3: '95.90%', 4: '87.50%', 5: '94.63%', 6: '43.52%', 7: '81.60%', 8: '85.99%', 9: '70.27%'}, LR: 0.000229\n",
      "Epoch 167/200, Train Loss: 0.004668, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.119997, Val Acc: 86.68%, Val-Class-Acc: {0: '87.50%', 2: '92.36%', 3: '95.90%', 4: '87.50%', 5: '94.33%', 6: '42.59%', 7: '81.60%', 8: '87.26%', 9: '72.97%'}, LR: 0.000206\n",
      "Epoch 168/200, Train Loss: 0.004592, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.157239, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 2: '92.36%', 3: '95.90%', 4: '87.50%', 5: '94.33%', 6: '41.67%', 7: '82.40%', 8: '86.62%', 9: '70.27%'}, LR: 0.000206\n",
      "Epoch 169/200, Train Loss: 0.004963, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.226181, Val Acc: 86.03%, Val-Class-Acc: {0: '84.24%', 2: '91.67%', 3: '96.72%', 4: '87.50%', 5: '94.33%', 6: '38.89%', 7: '81.60%', 8: '88.54%', 9: '67.57%'}, LR: 0.000206\n",
      "Epoch 170/200, Train Loss: 0.067789, Train-Class-Acc: {0: '97.55%', 2: '98.96%', 3: '98.77%', 4: '99.37%', 5: '99.40%', 6: '96.31%', 7: '97.21%', 8: '97.45%', 9: '98.65%'}\n",
      "Val Loss: 1.416251, Val Acc: 84.72%, Val-Class-Acc: {0: '87.50%', 2: '88.89%', 3: '97.13%', 4: '85.00%', 5: '93.43%', 6: '37.96%', 7: '77.60%', 8: '82.17%', 9: '64.86%'}, LR: 0.000206\n",
      "Epoch 171/200, Train Loss: 0.035658, Train-Class-Acc: {0: '98.50%', 2: '99.48%', 3: '99.28%', 4: '100.00%', 5: '99.55%', 6: '97.47%', 7: '99.20%', 8: '98.41%', 9: '100.00%'}\n",
      "Val Loss: 1.226712, Val Acc: 85.44%, Val-Class-Acc: {0: '83.70%', 2: '92.36%', 3: '97.13%', 4: '85.00%', 5: '94.63%', 6: '43.52%', 7: '79.20%', 8: '82.17%', 9: '64.86%'}, LR: 0.000206\n",
      "Epoch 172/200, Train Loss: 0.009649, Train-Class-Acc: {0: '100.00%', 2: '99.83%', 3: '100.00%', 4: '100.00%', 5: '99.85%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.180038, Val Acc: 86.17%, Val-Class-Acc: {0: '83.15%', 2: '91.67%', 3: '95.90%', 4: '87.50%', 5: '94.63%', 6: '44.44%', 7: '81.60%', 8: '87.26%', 9: '70.27%'}, LR: 0.000206\n",
      "Epoch 173/200, Train Loss: 0.007482, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.148274, Val Acc: 86.10%, Val-Class-Acc: {0: '83.70%', 2: '89.58%', 3: '95.08%', 4: '87.50%', 5: '94.63%', 6: '46.30%', 7: '83.20%', 8: '87.26%', 9: '67.57%'}, LR: 0.000206\n",
      "Epoch 174/200, Train Loss: 0.007128, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.93%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.141042, Val Acc: 86.39%, Val-Class-Acc: {0: '85.33%', 2: '92.36%', 3: '95.08%', 4: '87.50%', 5: '94.33%', 6: '46.30%', 7: '82.40%', 8: '85.99%', 9: '70.27%'}, LR: 0.000206\n",
      "Epoch 175/200, Train Loss: 0.006265, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.135827, Val Acc: 86.54%, Val-Class-Acc: {0: '85.33%', 2: '92.36%', 3: '95.08%', 4: '87.50%', 5: '94.93%', 6: '45.37%', 7: '83.20%', 8: '85.99%', 9: '70.27%'}, LR: 0.000206\n",
      "Epoch 176/200, Train Loss: 0.007207, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '99.85%', 6: '100.00%', 7: '99.80%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.151117, Val Acc: 86.54%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '95.08%', 4: '85.00%', 5: '94.63%', 6: '46.30%', 7: '83.20%', 8: '84.71%', 9: '67.57%'}, LR: 0.000206\n",
      "Epoch 177/200, Train Loss: 0.005859, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.170572, Val Acc: 86.46%, Val-Class-Acc: {0: '84.78%', 2: '93.06%', 3: '95.08%', 4: '87.50%', 5: '94.93%', 6: '43.52%', 7: '81.60%', 8: '86.62%', 9: '75.68%'}, LR: 0.000206\n",
      "Epoch 178/200, Train Loss: 0.005773, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.211050, Val Acc: 86.24%, Val-Class-Acc: {0: '86.41%', 2: '92.36%', 3: '95.08%', 4: '82.50%', 5: '95.22%', 6: '43.52%', 7: '81.60%', 8: '85.99%', 9: '67.57%'}, LR: 0.000185\n",
      "Epoch 179/200, Train Loss: 0.005745, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.195014, Val Acc: 86.46%, Val-Class-Acc: {0: '86.41%', 2: '93.06%', 3: '95.08%', 4: '85.00%', 5: '94.93%', 6: '44.44%', 7: '82.40%', 8: '85.35%', 9: '70.27%'}, LR: 0.000185\n",
      "Epoch 180/200, Train Loss: 0.005668, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.199065, Val Acc: 86.39%, Val-Class-Acc: {0: '87.50%', 2: '92.36%', 3: '95.08%', 4: '85.00%', 5: '94.93%', 6: '43.52%', 7: '81.60%', 8: '85.99%', 9: '67.57%'}, LR: 0.000185\n",
      "Epoch 181/200, Train Loss: 0.005591, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.187385, Val Acc: 86.39%, Val-Class-Acc: {0: '86.41%', 2: '91.67%', 3: '95.08%', 4: '85.00%', 5: '94.93%', 6: '44.44%', 7: '81.60%', 8: '86.62%', 9: '70.27%'}, LR: 0.000185\n",
      "Epoch 182/200, Train Loss: 0.005331, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.187129, Val Acc: 86.10%, Val-Class-Acc: {0: '84.24%', 2: '92.36%', 3: '95.08%', 4: '85.00%', 5: '94.63%', 6: '43.52%', 7: '81.60%', 8: '86.62%', 9: '72.97%'}, LR: 0.000185\n",
      "Epoch 183/200, Train Loss: 0.005378, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.184804, Val Acc: 86.17%, Val-Class-Acc: {0: '84.78%', 2: '92.36%', 3: '96.31%', 4: '85.00%', 5: '94.03%', 6: '43.52%', 7: '81.60%', 8: '86.62%', 9: '70.27%'}, LR: 0.000185\n",
      "Epoch 184/200, Train Loss: 0.005264, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.186431, Val Acc: 86.39%, Val-Class-Acc: {0: '86.41%', 2: '92.36%', 3: '95.08%', 4: '85.00%', 5: '94.63%', 6: '43.52%', 7: '81.60%', 8: '86.62%', 9: '72.97%'}, LR: 0.000185\n",
      "Epoch 185/200, Train Loss: 0.005137, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.185160, Val Acc: 86.46%, Val-Class-Acc: {0: '86.41%', 2: '92.36%', 3: '95.08%', 4: '87.50%', 5: '94.63%', 6: '44.44%', 7: '80.80%', 8: '86.62%', 9: '72.97%'}, LR: 0.000185\n",
      "Epoch 186/200, Train Loss: 0.005242, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.184116, Val Acc: 86.17%, Val-Class-Acc: {0: '85.33%', 2: '91.67%', 3: '95.49%', 4: '87.50%', 5: '94.33%', 6: '42.59%', 7: '80.00%', 8: '87.26%', 9: '75.68%'}, LR: 0.000185\n",
      "Epoch 187/200, Train Loss: 0.005185, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.167519, Val Acc: 86.17%, Val-Class-Acc: {0: '83.70%', 2: '93.06%', 3: '95.49%', 4: '87.50%', 5: '94.33%', 6: '42.59%', 7: '80.80%', 8: '87.26%', 9: '75.68%'}, LR: 0.000185\n",
      "Epoch 188/200, Train Loss: 0.005042, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.194388, Val Acc: 86.54%, Val-Class-Acc: {0: '86.41%', 2: '93.06%', 3: '95.90%', 4: '87.50%', 5: '94.33%', 6: '42.59%', 7: '80.80%', 8: '87.26%', 9: '72.97%'}, LR: 0.000185\n",
      "Epoch 189/200, Train Loss: 0.004988, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.197358, Val Acc: 86.54%, Val-Class-Acc: {0: '85.87%', 2: '92.36%', 3: '95.49%', 4: '87.50%', 5: '94.93%', 6: '41.67%', 7: '81.60%', 8: '87.26%', 9: '75.68%'}, LR: 0.000167\n",
      "Epoch 190/200, Train Loss: 0.005041, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.191489, Val Acc: 86.90%, Val-Class-Acc: {0: '88.04%', 2: '93.06%', 3: '96.31%', 4: '87.50%', 5: '94.93%', 6: '44.44%', 7: '80.80%', 8: '85.99%', 9: '70.27%'}, LR: 0.000167\n",
      "Epoch 191/200, Train Loss: 0.004878, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.187121, Val Acc: 86.68%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '96.31%', 4: '87.50%', 5: '94.33%', 6: '42.59%', 7: '81.60%', 8: '87.26%', 9: '70.27%'}, LR: 0.000167\n",
      "Epoch 192/200, Train Loss: 0.004858, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.223426, Val Acc: 86.54%, Val-Class-Acc: {0: '88.04%', 2: '93.06%', 3: '96.31%', 4: '87.50%', 5: '94.33%', 6: '41.67%', 7: '80.80%', 8: '86.62%', 9: '67.57%'}, LR: 0.000167\n",
      "Epoch 193/200, Train Loss: 0.004796, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.191820, Val Acc: 86.39%, Val-Class-Acc: {0: '85.87%', 2: '92.36%', 3: '96.31%', 4: '87.50%', 5: '94.33%', 6: '43.52%', 7: '80.80%', 8: '87.26%', 9: '67.57%'}, LR: 0.000167\n",
      "Epoch 194/200, Train Loss: 0.004773, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.208265, Val Acc: 86.39%, Val-Class-Acc: {0: '86.41%', 2: '92.36%', 3: '96.31%', 4: '87.50%', 5: '94.33%', 6: '41.67%', 7: '80.80%', 8: '87.26%', 9: '70.27%'}, LR: 0.000167\n",
      "Epoch 195/200, Train Loss: 0.004701, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.193177, Val Acc: 86.39%, Val-Class-Acc: {0: '84.78%', 2: '93.06%', 3: '95.90%', 4: '87.50%', 5: '94.33%', 6: '41.67%', 7: '81.60%', 8: '87.26%', 9: '75.68%'}, LR: 0.000167\n",
      "Epoch 196/200, Train Loss: 0.004681, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.210942, Val Acc: 86.54%, Val-Class-Acc: {0: '85.87%', 2: '92.36%', 3: '95.90%', 4: '87.50%', 5: '94.63%', 6: '42.59%', 7: '81.60%', 8: '87.26%', 9: '72.97%'}, LR: 0.000167\n",
      "Epoch 197/200, Train Loss: 0.004704, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.132189, Val Acc: 86.24%, Val-Class-Acc: {0: '84.78%', 2: '93.06%', 3: '96.31%', 4: '87.50%', 5: '93.13%', 6: '43.52%', 7: '80.80%', 8: '87.26%', 9: '75.68%'}, LR: 0.000167\n",
      "Epoch 198/200, Train Loss: 0.004709, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.178685, Val Acc: 86.83%, Val-Class-Acc: {0: '85.33%', 2: '93.06%', 3: '96.31%', 4: '87.50%', 5: '94.93%', 6: '42.59%', 7: '82.40%', 8: '87.26%', 9: '75.68%'}, LR: 0.000167\n",
      "Epoch 199/200, Train Loss: 0.004586, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.176058, Val Acc: 86.83%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '96.31%', 4: '87.50%', 5: '94.93%', 6: '42.59%', 7: '80.80%', 8: '86.62%', 9: '75.68%'}, LR: 0.000167\n",
      "Epoch 200/200, Train Loss: 0.004519, Train-Class-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'}\n",
      "Val Loss: 1.187738, Val Acc: 87.05%, Val-Class-Acc: {0: '86.96%', 2: '93.06%', 3: '96.31%', 4: '87.50%', 5: '94.93%', 6: '44.44%', 7: '80.80%', 8: '87.26%', 9: '75.68%'}, LR: 0.000150\n",
      "\n",
      "üèÜ Best model saved as: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_best.pth (Val Accuracy: 87.70%)\n",
      "\n",
      "üìå Final model saved as: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_final.pth\n",
      "\n",
      "üéØ Top 5 Best Models:\n",
      "Epoch 113, Train Loss: 0.006274, Train-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'},\n",
      "Val Loss: 1.088178, Val Acc: 87.70%, Val-Acc: {0: '88.59%', 2: '93.06%', 3: '96.31%', 4: '90.00%', 5: '96.42%', 6: '45.37%', 7: '81.60%', 8: '87.90%', 9: '67.57%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_113.pth\n",
      "Epoch 100, Train Loss: 0.009753, Train-Acc: {0: '100.00%', 2: '100.00%', 3: '99.69%', 4: '100.00%', 5: '100.00%', 6: '99.77%', 7: '100.00%', 8: '100.00%', 9: '100.00%'},\n",
      "Val Loss: 1.005990, Val Acc: 87.63%, Val-Acc: {0: '88.04%', 2: '92.36%', 3: '96.72%', 4: '87.50%', 5: '95.52%', 6: '50.00%', 7: '80.00%', 8: '88.54%', 9: '67.57%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_100.pth\n",
      "Epoch 36, Train Loss: 0.009298, Train-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'},\n",
      "Val Loss: 1.030558, Val Acc: 87.63%, Val-Acc: {0: '88.04%', 2: '93.75%', 3: '95.08%', 4: '90.00%', 5: '96.72%', 6: '41.67%', 7: '85.60%', 8: '86.62%', 9: '72.97%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_36.pth\n",
      "Epoch 111, Train Loss: 0.006419, Train-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'},\n",
      "Val Loss: 1.070785, Val Acc: 87.55%, Val-Acc: {0: '88.59%', 2: '92.36%', 3: '96.31%', 4: '90.00%', 5: '95.52%', 6: '45.37%', 7: '82.40%', 8: '88.54%', 9: '67.57%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_111.pth\n",
      "Epoch 99, Train Loss: 0.008168, Train-Acc: {0: '100.00%', 2: '100.00%', 3: '100.00%', 4: '100.00%', 5: '100.00%', 6: '100.00%', 7: '100.00%', 8: '100.00%', 9: '100.00%'},\n",
      "Val Loss: 1.040200, Val Acc: 87.55%, Val-Acc: {0: '88.04%', 2: '93.75%', 3: '95.90%', 4: '90.00%', 5: '95.82%', 6: '44.44%', 7: '81.60%', 8: '89.17%', 9: '67.57%'}, Model Path: /mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4/ResNet18_1D_epoch_99.pth\n",
      "\n",
      "üß† Model Summary:\n",
      "Total Parameters: 3,865,226\n",
      "Model Size (float32): 14.74 MB\n",
      "Total Training Time: 738.86 seconds\n",
      "---\n",
      "### Period 4\n",
      "+ ##### Total training time: 738.86 seconds\n",
      "+ ##### Model: ResNet18_1D\n",
      "+ ##### Training and saving in *'/mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL/Trained_models/EWC_CIL_v2/Period_4'*\n",
      "+ ##### Best Epoch: 113\n",
      "#### __Val Accuracy: 87.70%__\n",
      "#### __Val-Class-Acc: {0: '88.59%', 2: '93.06%', 3: '96.31%', 4: '90.00%', 5: '96.42%', 6: '45.37%', 7: '81.60%', 8: '87.90%', 9: '67.57%'}__\n",
      "#### __Total Parameters: 3,865,226__\n",
      "#### __Model Size (float32): 14.74 MB__\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# üìå Period 4: EWC Training (Protect Period 3)\n",
    "# weight = class_weights_tensor\n",
    "# ================================\n",
    "period = 4\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.join(BASE_DIR, \"stop_training.txt\")\n",
    "model_saving_folder = os.path.join(BASE_DIR, \"Trained_models\", \"EWC_CIL_v2\", f\"Period_{period}\")\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Load Period 4 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, f\"X_train_p{period}.npy\"))\n",
    "y_train = np.load(os.path.join(save_dir, f\"y_train_p{period}.npy\"))\n",
    "X_val   = np.load(os.path.join(save_dir, f\"X_test_p{period}.npy\"))\n",
    "y_val   = np.load(os.path.join(save_dir, f\"y_test_p{period}.npy\"))\n",
    "\n",
    "# ==== Device ====\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "# ==== Model Configuration ====\n",
    "input_channels = X_train.shape[2]\n",
    "output_size = int(np.max(y_train)) + 1  # avoid indexing problems due to missing class 1\n",
    "model = ResNet18_1D(input_channels=input_channels, output_size=output_size).to(device)\n",
    "print(\"üìå Labels found:\", sorted(np.unique(y_train)))\n",
    "print(\"üìå Output size inferred as:\", output_size)\n",
    "\n",
    "# ==== Load Period 3 Best Model Weights ====\n",
    "prev_model_path = os.path.join(BASE_DIR, \"Trained_models\", \"EWC_CIL_v2\", \"Period_3\", \"ResNet18_1D_best.pth\")\n",
    "prev_checkpoint = torch.load(prev_model_path, map_location=device)\n",
    "state_dict = prev_checkpoint[\"model_state_dict\"]\n",
    "model_dict = model.state_dict()\n",
    "filtered_dict = {k: v for k, v in state_dict.items() if k in model_dict and model_dict[k].shape == v.shape}\n",
    "model.load_state_dict(filtered_dict, strict=False)\n",
    "for k in model_dict:\n",
    "    if k not in filtered_dict:\n",
    "        print(f\"üîç Not loaded: {k}, shape={model_dict[k].shape}\")\n",
    "print(\"‚úÖ Loaded Period 3 weights (except FC mismatch)\")\n",
    "\n",
    "# ==== Prepare EWC (from Period 3 training data) ====\n",
    "X_prev = np.load(os.path.join(save_dir, \"X_train_p3.npy\"))\n",
    "y_prev = np.load(os.path.join(save_dir, \"y_train_p3.npy\"))\n",
    "train_loader_prev = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_prev, dtype=torch.float32), torch.tensor(y_prev, dtype=torch.long)),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "exclude_labels = [1]  # ÂÅáË®≠ y_train Ê≤íÊúâ class 1Ôºå‰ΩÜ output_size ÈÇÑÊòØÂåÖÂê´ÂÆÉ\n",
    "class_weights_tensor = compute_class_weights(y_train, output_size, exclude_classes=exclude_labels)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor.to(device))\n",
    "fisher_dict, params_dict = EWC.compute_fisher_and_params(model, train_loader_prev, criterion, device=device)\n",
    "ewc_state = EWC(fisher=fisher_dict, params=params_dict)\n",
    "print(\"üìà Fisher information computed from Period 3\")\n",
    "\n",
    "# ==== Optimizer / Scheduler ====\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "lambda_ewc = 1.0\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# ==== Training ====\n",
    "train_with_ewc_ecg(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name=\"ResNet18_1D\",\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    ewc=ewc_state,\n",
    "    lambda_ewc=lambda_ewc,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del X_train, y_train, X_val, y_val, X_prev, y_prev\n",
    "del prev_model_path, prev_checkpoint, state_dict, model_dict, filtered_dict\n",
    "del model, train_loader_prev, fisher_dict, params_dict, ewc_state\n",
    "del class_weights_tensor\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d51b6",
   "metadata": {},
   "source": [
    "##  Compute FWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66e5d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fwt_ecg(previous_model, init_model, X_val, y_val, known_classes, batch_size=64):\n",
    "    \"\"\"\n",
    "    FWT computation for ECG-style inputs with 1D CNN (e.g., ResNet18_1D).\n",
    "    X_val: shape [B, T, C]  (e.g., [N, 5000, 12])\n",
    "    y_val: shape [B]        (e.g., [N])\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    previous_model.to(device).eval()\n",
    "    init_model.to(device).eval()\n",
    "\n",
    "    # Âè™ÈÅ∏Âèñ known classes\n",
    "    mask = np.isin(y_val, known_classes)\n",
    "    X_known = X_val[mask]\n",
    "    y_known = y_val[mask]\n",
    "\n",
    "    if len(y_known) == 0:\n",
    "        print(f\"‚ö†Ô∏è No validation samples for known classes {known_classes}.\")\n",
    "        return None, None, None\n",
    "\n",
    "    print(f\"üìã Total samples for known classes {known_classes}: {len(y_known)}\")\n",
    "\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(X_known, dtype=torch.float32),\n",
    "        torch.tensor(y_known, dtype=torch.long)\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    correct_prev, correct_init, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            out_prev = previous_model(xb)  # [B, C]\n",
    "            out_init = init_model(xb)\n",
    "\n",
    "            preds_prev = torch.argmax(out_prev, dim=-1)\n",
    "            preds_init = torch.argmax(out_init, dim=-1)\n",
    "\n",
    "            correct_prev += (preds_prev == yb).sum().item()\n",
    "            correct_init += (preds_init == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "\n",
    "    acc_prev = 100 * correct_prev / total\n",
    "    acc_init = 100 * correct_init / total\n",
    "    fwt_value = acc_prev - acc_init\n",
    "\n",
    "    print(f\"\\n### üîç FWT Debug Info:\")\n",
    "    print(f\"- Total evaluated samples: {total}\")\n",
    "    print(f\"- Accuracy by previous model: {acc_prev:.2f}%\")\n",
    "    print(f\"- Accuracy by init model:     {acc_init:.2f}%\")\n",
    "    print(f\"- FWT = Acc_prev - Acc_init = {fwt_value:.2f}%\")\n",
    "\n",
    "    return fwt_value, acc_prev, acc_init\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ed330",
   "metadata": {},
   "source": [
    "### Period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f893da6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Automatically selected GPU:\n",
      "    - CUDA Device ID : 0\n",
      "    - Memory Used    : 7699 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4147895/2896414891.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(prev_model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Total samples for known classes [0, 1]: 428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4147895/1383618855.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(X_known, dtype=torch.float32),\n",
      "/tmp/ipykernel_4147895/1383618855.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y_known, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### üîç FWT Debug Info:\n",
      "- Total evaluated samples: 428\n",
      "- Accuracy by previous model: 89.25%\n",
      "- Accuracy by init model:     45.09%\n",
      "- FWT = Acc_prev - Acc_init = 44.16%\n"
     ]
    }
   ],
   "source": [
    "X_val   = np.load(os.path.join(save_dir, f\"X_test_p{2}.npy\"))\n",
    "y_val   = np.load(os.path.join(save_dir, f\"y_test_p{2}.npy\"))\n",
    "known_classes = [0,1]\n",
    "\n",
    "device = auto_select_cuda_device()\n",
    "input_channels = X_val.shape[2]\n",
    "output_size_prev = 2\n",
    "\n",
    "# === Previous Model ===\n",
    "prev_model_path = os.path.join(BASE_DIR, \"ResNet18_Selection\", \"ResNet18_big_inplane_v1\", \"ResNet18_big_inplane_1D_best.pth\")\n",
    "previous_model = ResNet18_1D(input_channels=input_channels, output_size=output_size_prev).to(device)\n",
    "checkpoint = torch.load(prev_model_path, map_location=device)\n",
    "previous_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# === Init Model ===\n",
    "init_model = ResNet18_1D(input_channels=input_channels, output_size=output_size_prev).to(device)\n",
    "\n",
    "# === Tensor Conversion ===\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# === FWT Calculation ===\n",
    "fwt, acc_prev, acc_init = compute_fwt_ecg(previous_model, init_model, X_val_tensor, y_val_tensor, known_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214fd919",
   "metadata": {},
   "source": [
    "### Period 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd72e22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Automatically selected GPU:\n",
      "    - CUDA Device ID : 0\n",
      "    - Memory Used    : 7775 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4147895/3352287397.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(prev_model_path, map_location=device)\n",
      "/tmp/ipykernel_4147895/1383618855.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(X_known, dtype=torch.float32),\n",
      "/tmp/ipykernel_4147895/1383618855.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y_known, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Total samples for known classes [0, 1, 2, 3]: 907\n",
      "\n",
      "### üîç FWT Debug Info:\n",
      "- Total evaluated samples: 907\n",
      "- Accuracy by previous model: 89.20%\n",
      "- Accuracy by init model:     22.27%\n",
      "- FWT = Acc_prev - Acc_init = 66.92%\n"
     ]
    }
   ],
   "source": [
    "X_val   = np.load(os.path.join(save_dir, f\"X_test_p{3}.npy\"))\n",
    "y_val   = np.load(os.path.join(save_dir, f\"y_test_p{3}.npy\"))\n",
    "known_classes = [0,1,2,3]\n",
    "\n",
    "device = auto_select_cuda_device()\n",
    "input_channels = X_val.shape[2]\n",
    "output_size_prev = 4\n",
    "\n",
    "# === Previous Model ===\n",
    "prev_model_path = os.path.join(BASE_DIR, \"Trained_models\", \"EWC_CIL_v1\", \"Period_2\", \"ResNet18_1D_best.pth\")\n",
    "previous_model = ResNet18_1D(input_channels=input_channels, output_size=output_size_prev).to(device)\n",
    "checkpoint = torch.load(prev_model_path, map_location=device)\n",
    "previous_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# === Init Model ===\n",
    "init_model = ResNet18_1D(input_channels=input_channels, output_size=output_size_prev).to(device)\n",
    "\n",
    "# === Tensor Conversion ===\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# === FWT Calculation ===\n",
    "fwt, acc_prev, acc_init = compute_fwt_ecg(previous_model, init_model, X_val_tensor, y_val_tensor, known_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab2ceef",
   "metadata": {},
   "source": [
    "### Period 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccb1cb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Automatically selected GPU:\n",
      "    - CUDA Device ID : 0\n",
      "    - Memory Used    : 7775 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "üìã Total samples for known classes [0, 1, 2, 3, 4, 5]: 947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4147895/1314541160.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(prev_model_path, map_location=device)\n",
      "/tmp/ipykernel_4147895/1383618855.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(X_known, dtype=torch.float32),\n",
      "/tmp/ipykernel_4147895/1383618855.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y_known, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### üîç FWT Debug Info:\n",
      "- Total evaluated samples: 947\n",
      "- Accuracy by previous model: 96.73%\n",
      "- Accuracy by init model:     23.55%\n",
      "- FWT = Acc_prev - Acc_init = 73.18%\n"
     ]
    }
   ],
   "source": [
    "X_val   = np.load(os.path.join(save_dir, f\"X_test_p{4}.npy\"))\n",
    "y_val   = np.load(os.path.join(save_dir, f\"y_test_p{4}.npy\"))\n",
    "known_classes = [0,1,2,3,4,5]\n",
    "\n",
    "device = auto_select_cuda_device()\n",
    "input_channels = X_val.shape[2]\n",
    "output_size_prev = 6\n",
    "\n",
    "# === Previous Model ===\n",
    "prev_model_path = os.path.join(BASE_DIR, \"Trained_models\", \"EWC_CIL_v1\", \"Period_3\", \"ResNet18_1D_best.pth\")\n",
    "previous_model = ResNet18_1D(input_channels=input_channels, output_size=output_size_prev).to(device)\n",
    "checkpoint = torch.load(prev_model_path, map_location=device)\n",
    "previous_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# === Init Model ===\n",
    "init_model = ResNet18_1D(input_channels=input_channels, output_size=output_size_prev).to(device)\n",
    "\n",
    "# === Tensor Conversion ===\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# === FWT Calculation ===\n",
    "fwt, acc_prev, acc_init = compute_fwt_ecg(previous_model, init_model, X_val_tensor, y_val_tensor, known_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f96626",
   "metadata": {},
   "source": [
    "## üìä Summary: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4e71f",
   "metadata": {},
   "source": [
    "### ‚úîÔ∏è CPSC - EWC: Validation Summary\n",
    "\n",
    "| Period | Training Time (s) | Validation Accuracy | Class-wise Accuracy                                                                 |\n",
    "|--------|-------------------|---------------------|--------------------------------------------------------------------------------------|\n",
    "| 1      | 134.66            | **88.86%**          | {0: 91.85%, 1: 85.87%}                                                              |\n",
    "| 2      | 439.15            | **88.73%**          | {0: 92.39%, 1: 81.56%, 2: 84.72%, 3: 95.49%}                                        |\n",
    "| 3      | 805.57            | **88.06%**          | {0: 89.13%, 1: 80.60%, 2: 87.50%, 3: 92.62%, 4: 80.00%, 5: 92.81%}                  |\n",
    "| 4      | 736.80            | **88.57%**          | {0: 88.04%, 2: 97.22%, 3: 98.36%, 4: 75.00%, 5: 96.42%, 6: 43.52%, 7: 89.60%, 8: 89.81%, 9: 59.46%} |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c55aa",
   "metadata": {},
   "source": [
    "### üß† Continual Learning Metrics\n",
    "\n",
    "| Period | AA_old (%) | AA_new (%) | BWT (%) | FWT (%) | FWT Classes        | Prev. Model Acc | Init Model Acc |\n",
    "|--------|------------|------------|---------|---------|---------------------|------------------|-----------------|\n",
    "| 2      | 86.98%     | 90.11%     | -1.88%  | 44.16%  | [0, 1]              | 89.25%           | 45.09%          |\n",
    "| 3      | 87.46%     | 86.41%     | -1.08%  | 66.92%  | [0, 1, 2, 3]        | 89.20%           | 22.27%          |\n",
    "| 4      | 91.01%     | 70.60%     | +2.60%  | 73.18%  | [0, 1, 2, 3, 4, 5]  | 96.73%           | 23.55%          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb435fb",
   "metadata": {},
   "source": [
    "### üì¶ Model Size per Period\n",
    "\n",
    "| Period | Output Size | Total Params | Œî Params vs Prev | Œî % vs Prev | Model Size (float32) |\n",
    "|--------|-------------|--------------|------------------|-------------|-----------------------|\n",
    "| 1      | 2           | 3,857,026    | ‚Äî                | ‚Äî           | 14.71 MB              |\n",
    "| 2      | 4           | 3,859,076    | +2,050           | +0.05%      | 14.72 MB              |\n",
    "| 3      | 6           | 3,861,126    | +2,050           | +0.05%      | 14.73 MB              |\n",
    "| 4      | 10          | 3,865,226    | +4,100           | +0.11%      | 14.74 MB              |\n",
    "\n",
    "**üìà Model Growth Rate (MGR) = (3,865,226 - 3,857,026) / (3,857,026 √ó 3) ‚âà +0.07%**\n",
    "\n",
    "**üìà Max trainable ratio = 100%**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
