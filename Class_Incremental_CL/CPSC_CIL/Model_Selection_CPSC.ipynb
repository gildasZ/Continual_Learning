{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07af288c",
   "metadata": {},
   "source": [
    "## __Check first before starting__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f00b1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /mnt/mydisk/Continual_Learning_JL/Continual_Learning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "Working_directory = os.path.normpath(\"/mnt/mydisk/Continual_Learning_JL/Continual_Learning/\")\n",
    "os.chdir(Working_directory)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97bdf56",
   "metadata": {},
   "source": [
    "## __All imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83b85d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating system and file management\n",
    "import os\n",
    "import shutil\n",
    "import contextlib\n",
    "import traceback\n",
    "import gc\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import subprocess\n",
    "import time\n",
    "import re, pickle\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "from glob import glob\n",
    "from math import ceil\n",
    "\n",
    "# Jupyter notebook widgets and display\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_interactions import zoom_factory, panhandler\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from ta import trend, momentum, volatility, volume\n",
    "\n",
    "# Mathematical and scientific computing\n",
    "import math\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# Type hinting\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "# Deep learning with PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a496fe70",
   "metadata": {},
   "source": [
    "## __📁 Path Settings and Constants__\n",
    "This cell defines essential paths and constants for the CPSC2018 ECG dataset processing:\n",
    "- `BASE_DIR`: Root directory of the project.\n",
    "- `save_dir`: Path to the preprocessed `.npy` files (one for each continual learning period).\n",
    "- `ECG_PATH`: Directory containing original `.mat` and `.hea` files.\n",
    "- `MAX_LEN`: Length of each ECG sample, fixed to 5000 time steps (i.e., 10 seconds at 500Hz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7748e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/mnt/mydisk/Continual_Learning_JL/Continual_Learning/Class_Incremental_CL/CPSC_CIL\"\n",
    "save_dir = os.path.join(BASE_DIR, \"processed\")\n",
    "ECG_PATH = os.path.join(BASE_DIR, \"datas\")\n",
    "MAX_LEN = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba7249f",
   "metadata": {},
   "source": [
    "## __🏷️ Label Mapping and Period Configuration__\n",
    "\n",
    "This section defines:\n",
    "- `snomed_map`: Mapping from SNOMED CT codes to readable class names for 9 major ECG conditions.\n",
    "- `period_label_map`: Incremental learning task structure across four periods.  \n",
    "  Class `1` is reserved for \"OTHER\" abnormalities until Period 4 when all 9 classes are explicitly categorized.\n",
    "- `print_class_distribution()`: Helper function to show class-wise data distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "103ca271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNOMED CT to readable names\n",
    "snomed_map = {\n",
    "    \"426783006\": \"NSR\",    # 正常竇性心律\n",
    "    \"270492004\": \"I-AVB\",  # 一度房室傳導阻滯\n",
    "    \"164889003\": \"AF\",     # 心房纖維顫動\n",
    "    \"164909002\": \"LBBB\",   # 左束支傳導阻滯\n",
    "    \"59118001\":  \"RBBB\",   # 右束支傳導阻滯\n",
    "    \"284470004\": \"PAC\",    # 心房早期搏動\n",
    "    \"164884008\": \"PVC\",    # 室性早期搏動\n",
    "    \"429622005\": \"STD\",    # ST 段壓低\n",
    "    \"164931005\": \"STE\"     # ST 段抬高\n",
    "}\n",
    "\n",
    "# Period class mapping (固定 class 1 是「其他異常」直到 P4 移除)\n",
    "period_label_map = {\n",
    "    1: {\"NSR\": 0, \"OTHER\": 1},\n",
    "    2: {\"NSR\": 0, \"I-AVB\": 2, \"AF\": 3, \"OTHER\": 1},\n",
    "    3: {\"NSR\": 0, \"I-AVB\": 2, \"AF\": 3, \"LBBB\": 4, \"RBBB\": 5, \"OTHER\": 1},\n",
    "    4: {\"NSR\": 0, \"I-AVB\": 2, \"AF\": 3, \"LBBB\": 4, \"RBBB\": 5, \"PAC\": 6, \"PVC\": 7, \"STD\": 8, \"STE\": 9}\n",
    "}\n",
    "\n",
    "def print_class_distribution(y, label_map):\n",
    "    y = np.array(y).flatten()\n",
    "    total = len(y)\n",
    "    all_labels = sorted(label_map.values())\n",
    "    print(\"\\n📊 Class Distribution\")\n",
    "    for lbl in all_labels:\n",
    "        count = np.sum(y == lbl)\n",
    "        label = [k for k, v in label_map.items() if v == lbl]\n",
    "        name = label[0] if label else str(lbl)\n",
    "        print(f\"  ├─ Label {lbl:<2} ({name:<10}) → {count:>5} samples ({(count/total)*100:5.2f}%)\")\n",
    "\n",
    "def ensure_folder(folder_path: str) -> None:\n",
    "    \"\"\"Ensure the given folder exists, create it if not.\"\"\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f95af3",
   "metadata": {},
   "source": [
    "## 📦 EX. Load Example (Period 4) Data and View Format\n",
    "\n",
    "This example demonstrates how to load preprocessed `.npy` data for **Period 4**, and inspect the dataset shapes and label distribution.  \n",
    "Use this format as a reference when loading data in other methods (e.g., EWC, PNN, DynEx-CLoRA).\n",
    "\n",
    "Each ECG sample:\n",
    "- Has shape `(5000, 12)` → represents 10 seconds (at 500Hz) across 12-lead channels.\n",
    "- Corresponding label is an integer ID (e.g., 0–9) defined by `period_label_map[4]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a401dc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded\n",
      "X_train shape: (5493, 5000, 12)\n",
      "y_train shape: (5493,)\n",
      "X_test shape: (1374, 5000, 12)\n",
      "y_test shape: (1374,)\n",
      "\n",
      "📊 Class Distribution\n",
      "  ├─ Label 0  (NSR       ) →   734 samples (13.36%)\n",
      "  ├─ Label 2  (I-AVB     ) →   577 samples (10.50%)\n",
      "  ├─ Label 3  (AF        ) →   976 samples (17.77%)\n",
      "  ├─ Label 4  (LBBB      ) →   158 samples ( 2.88%)\n",
      "  ├─ Label 5  (RBBB      ) →  1337 samples (24.34%)\n",
      "  ├─ Label 6  (PAC       ) →   434 samples ( 7.90%)\n",
      "  ├─ Label 7  (PVC       ) →   501 samples ( 9.12%)\n",
      "  ├─ Label 8  (STD       ) →   628 samples (11.43%)\n",
      "  ├─ Label 9  (STE       ) →   148 samples ( 2.69%)\n",
      "\n",
      "📊 Class Distribution\n",
      "  ├─ Label 0  (NSR       ) →   184 samples (13.39%)\n",
      "  ├─ Label 2  (I-AVB     ) →   144 samples (10.48%)\n",
      "  ├─ Label 3  (AF        ) →   244 samples (17.76%)\n",
      "  ├─ Label 4  (LBBB      ) →    40 samples ( 2.91%)\n",
      "  ├─ Label 5  (RBBB      ) →   335 samples (24.38%)\n",
      "  ├─ Label 6  (PAC       ) →   108 samples ( 7.86%)\n",
      "  ├─ Label 7  (PVC       ) →   125 samples ( 9.10%)\n",
      "  ├─ Label 8  (STD       ) →   157 samples (11.43%)\n",
      "  ├─ Label 9  (STE       ) →    37 samples ( 2.69%)\n"
     ]
    }
   ],
   "source": [
    "# 範例:載入 period 4\n",
    "save_dir = os.path.join(BASE_DIR, \"processed\")\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p4.npy\"))\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p4.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p4.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p4.npy\"))\n",
    "\n",
    "print(\"✅ Loaded\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print_class_distribution(y_train, period_label_map[4])\n",
    "print_class_distribution(y_test, period_label_map[4])\n",
    "\n",
    "del X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d4b54b",
   "metadata": {},
   "source": [
    "## __Check GPU, CUDA, Pytorch__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d50a987a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  5 13:04:45 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.86.15              Driver Version: 570.86.15      CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off |   00000000:2A:00.0 Off |                  Off |\n",
      "| 51%   77C    P2            294W /  300W |   11188MiB /  49140MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000               Off |   00000000:3D:00.0 Off |                  Off |\n",
      "| 30%   35C    P5             20W /  300W |      18MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000               Off |   00000000:AB:00.0 Off |                  Off |\n",
      "| 30%   33C    P5             35W /  300W |      18MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2843      G   /usr/lib/xorg/Xorg                        4MiB |\n",
      "|    0   N/A  N/A         1462999      C   python                                 8456MiB |\n",
      "|    1   N/A  N/A            2843      G   /usr/lib/xorg/Xorg                        4MiB |\n",
      "|    2   N/A  N/A            2843      G   /usr/lib/xorg/Xorg                        4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f78325",
   "metadata": {},
   "source": [
    "### CUDA Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00875f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "             GPU Configuration Check              \n",
      "==================================================\n",
      "PyTorch Version          : 2.5.1\n",
      "GPU Available            : Yes\n",
      "--------------------------------------------------\n",
      "                   GPU Details                    \n",
      "--------------------------------------------------\n",
      "Device Name              : NVIDIA RTX A6000\n",
      "Number of GPUs           : 3\n",
      "Current Device Index     : 0\n",
      "Compute Capability       : 8.6\n",
      "Total CUDA Cores         : 10752\n",
      "Total Memory (GB)        : 47.41\n",
      "Allocated Memory (GB)    : 0.00\n",
      "Reserved Memory (GB)     : 0.00\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def check_gpu_config():\n",
    "    \"\"\"\n",
    "    Check GPU availability and display detailed configuration information.\n",
    "    \"\"\"\n",
    "    # Check if GPU is available\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    \n",
    "    # Print header\n",
    "    print(\"=\" * 50)\n",
    "    print(\"GPU Configuration Check\".center(50))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic GPU availability\n",
    "    print(f\"{'PyTorch Version':<25}: {torch.__version__}\")\n",
    "    print(f\"{'GPU Available':<25}: {'Yes' if gpu_available else 'No'}\")\n",
    "    \n",
    "    # If GPU is available, print detailed info\n",
    "    if gpu_available:\n",
    "        print(\"-\" * 50)\n",
    "        print(\"GPU Details\".center(50))\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Device info\n",
    "        print(f\"{'Device Name':<25}: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"{'Number of GPUs':<25}: {torch.cuda.device_count()}\")\n",
    "        print(f\"{'Current Device Index':<25}: {torch.cuda.current_device()}\")\n",
    "        \n",
    "        # Compute capability and CUDA cores\n",
    "        props = torch.cuda.get_device_properties(0)\n",
    "        print(f\"{'Compute Capability':<25}: {props.major}.{props.minor}\")\n",
    "        print(f\"{'Total CUDA Cores':<25}: {props.multi_processor_count * 128}\")  # Approx. 128 cores per SM\n",
    "        \n",
    "        # Memory info\n",
    "        total_memory = props.total_memory / (1024 ** 3)  # Convert to GB\n",
    "        memory_allocated = torch.cuda.memory_allocated(0) / (1024 ** 3)\n",
    "        memory_reserved = torch.cuda.memory_reserved(0) / (1024 ** 3)\n",
    "        print(f\"{'Total Memory (GB)':<25}: {total_memory:.2f}\")\n",
    "        print(f\"{'Allocated Memory (GB)':<25}: {memory_allocated:.2f}\")\n",
    "        print(f\"{'Reserved Memory (GB)':<25}: {memory_reserved:.2f}\")\n",
    "    else:\n",
    "        print(\"-\" * 50)\n",
    "        print(\"No GPU detected. Running on CPU.\".center(50))\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_gpu_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a868ff5",
   "metadata": {},
   "source": [
    "### PyTorch Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d153a6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "              PyTorch Configuration               \n",
      "==================================================\n",
      "PyTorch Version          : 2.5.1\n",
      "CUDA Compiled Version    : 12.1\n",
      "CUDA Available           : Yes\n",
      "Number of GPUs           : 3\n",
      "GPU Name                 : NVIDIA RTX A6000\n",
      "--------------------------------------------------\n",
      "Random Seed              : 42 (Seeding successful!)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def print_torch_config():\n",
    "    \"\"\"Print PyTorch and CUDA configuration in a formatted manner.\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"PyTorch Configuration\".center(50))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic PyTorch and CUDA info\n",
    "    print(f\"{'PyTorch Version':<25}: {torch.__version__}\")\n",
    "    print(f\"{'CUDA Compiled Version':<25}: {torch.version.cuda}\")\n",
    "    print(f\"{'CUDA Available':<25}: {'Yes' if torch.cuda.is_available() else 'No'}\")\n",
    "    print(f\"{'Number of GPUs':<25}: {torch.cuda.device_count()}\")\n",
    "\n",
    "    # GPU details if available\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"{'GPU Name':<25}: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Seed setting\n",
    "    torch.manual_seed(42)\n",
    "    print(f\"{'Random Seed':<25}: 42 (Seeding successful!)\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print_torch_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbab549",
   "metadata": {},
   "source": [
    "## __⚙️ GPU Selection — Auto-select the least loaded GPU__\n",
    "This code automatically scans available GPUs and selects the one with the lowest current memory usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4ffdd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Automatically selected GPU:\n",
      "    - CUDA Device ID : 1\n",
      "    - Memory Used    : 18 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "def auto_select_cuda_device(verbose=True):\n",
    "    \"\"\"\n",
    "    Automatically selects the CUDA GPU with the least memory usage.\n",
    "    Falls back to CPU if no GPU is available.\n",
    "    \"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"🚫 No CUDA GPU available. Using CPU.\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    try:\n",
    "        # Run nvidia-smi to get memory usage of each GPU\n",
    "        smi_output = subprocess.check_output(\n",
    "            ['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'],\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        memory_used = [int(x) for x in smi_output.strip().split('\\n')]\n",
    "        best_gpu = int(np.argmin(memory_used))\n",
    "\n",
    "        if verbose:\n",
    "            print(\"🎯 Automatically selected GPU:\")\n",
    "            print(f\"    - CUDA Device ID : {best_gpu}\")\n",
    "            print(f\"    - Memory Used    : {memory_used[best_gpu]} MiB\")\n",
    "            print(f\"    - Device Name    : {torch.cuda.get_device_name(best_gpu)}\")\n",
    "        return torch.device(f\"cuda:{best_gpu}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to auto-detect GPU. Falling back to cuda:0. ({e})\")\n",
    "        return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Execute and assign\n",
    "device = auto_select_cuda_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfae7c5a",
   "metadata": {},
   "source": [
    "## __Model Selection__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838dcf0",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "714093c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, dropout: float = 0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):  # x: (B, 5000, 12)\n",
    "        B = x.size(0)\n",
    "        x = x.view(B, -1)  # → (B, 60000)\n",
    "        x = self.drop1(self.relu1(self.bn1(self.fc1(x))))\n",
    "        x = self.drop2(self.relu2(self.bn2(self.fc2(x))))\n",
    "        return self.out(x)  # → (B, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344f6c2",
   "metadata": {},
   "source": [
    "### ResNet 18 - 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6aa85ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_1D(nn.Module):\n",
    "    def __init__(self, input_channels: int, output_size: int):\n",
    "        super(ResNet18_1D, self).__init__()\n",
    "        base_model = resnet18(pretrained=False)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = base_model.layer1\n",
    "        self.layer2 = base_model.layer2\n",
    "        self.layer3 = base_model.layer3\n",
    "        self.layer4 = base_model.layer4\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Linear(512, output_size)\n",
    "\n",
    "        self._convert_layers_to_1d()\n",
    "        # self._init_weights()\n",
    "\n",
    "    def _convert_layers_to_1d(self):\n",
    "        for name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "            layer = getattr(self, name)\n",
    "            for block in layer:\n",
    "                block.conv1 = nn.Conv1d(block.conv1.in_channels, block.conv1.out_channels,\n",
    "                                        kernel_size=3, stride=block.conv1.stride[0],\n",
    "                                        padding=1, bias=False)\n",
    "                block.bn1 = nn.BatchNorm1d(block.bn1.num_features)\n",
    "                block.conv2 = nn.Conv1d(block.conv2.in_channels, block.conv2.out_channels,\n",
    "                                        kernel_size=3, stride=1, padding=1, bias=False)\n",
    "                block.bn2 = nn.BatchNorm1d(block.bn2.num_features)\n",
    "                if block.downsample is not None:\n",
    "                    conv = nn.Conv1d(block.downsample[0].in_channels,\n",
    "                                     block.downsample[0].out_channels,\n",
    "                                     kernel_size=1, stride=block.downsample[0].stride[0], bias=False)\n",
    "                    bn = nn.BatchNorm1d(block.downsample[1].num_features)\n",
    "                    block.downsample = nn.Sequential(conv, bn)\n",
    "\n",
    "    # def _init_weights(self):\n",
    "    #     for m in self.modules():\n",
    "    #         if isinstance(m, nn.Conv1d):\n",
    "    #             nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "    #         elif isinstance(m, nn.BatchNorm1d):\n",
    "    #             nn.init.constant_(m.weight, 1)\n",
    "    #             nn.init.constant_(m.bias, 0)\n",
    "    #         elif isinstance(m, nn.Linear):\n",
    "    #             nn.init.xavier_uniform_(m.weight)\n",
    "    #             nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):  # x: (B, T, D)\n",
    "        x = x.permute(0, 2, 1)  # → (B, D, T)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.global_pool(x).squeeze(-1)  # → (B, 512)\n",
    "        x = self.classifier(x)               # → (B, num_classes)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c889e08",
   "metadata": {},
   "source": [
    "### ResNet 18 - 1D_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "981c36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_1D_v2(nn.Module):\n",
    "    def __init__(self, input_channels: int, output_size: int, dropout_rate=0.2):\n",
    "        super(ResNet18_1D_v2, self).__init__()\n",
    "        base_model = resnet18(pretrained=False)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=15, stride=2, padding=7, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = base_model.layer1\n",
    "        self.layer2 = base_model.layer2\n",
    "        self.layer3 = base_model.layer3\n",
    "        self.layer4 = base_model.layer4\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        # 分類器 - 加入dropout和一個額外的層\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(256, output_size)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate/2)  # 較小的dropout率\n",
    "\n",
    "        # self.classifier = nn.Linear(512, output_size)\n",
    "\n",
    "        self._convert_layers_to_1d()\n",
    "\n",
    "    def _convert_layers_to_1d(self):\n",
    "        for name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "            layer = getattr(self, name)\n",
    "            for block in layer:\n",
    "                block.conv1 = nn.Conv1d(block.conv1.in_channels, block.conv1.out_channels,\n",
    "                                        kernel_size=3, stride=block.conv1.stride[0],\n",
    "                                        padding=1, bias=False)\n",
    "                block.bn1 = nn.BatchNorm1d(block.bn1.num_features)\n",
    "                block.conv2 = nn.Conv1d(block.conv2.in_channels, block.conv2.out_channels,\n",
    "                                        kernel_size=3, stride=1, padding=1, bias=False)\n",
    "                block.bn2 = nn.BatchNorm1d(block.bn2.num_features)\n",
    "                if block.downsample is not None:\n",
    "                    conv = nn.Conv1d(block.downsample[0].in_channels,\n",
    "                                     block.downsample[0].out_channels,\n",
    "                                     kernel_size=1, stride=block.downsample[0].stride[0], bias=False)\n",
    "                    bn = nn.BatchNorm1d(block.downsample[1].num_features)\n",
    "                    block.downsample = nn.Sequential(conv, bn)\n",
    "\n",
    "    def forward(self, x):  # x: (B, T, D)\n",
    "        x = x.permute(0, 2, 1)  # → (B, D, T)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.global_pool(x).squeeze(-1)  # → (B, 512)\n",
    "        # x = self.classifier(x)               # → (B, num_classes)\n",
    "        \n",
    "        x = self.dropout1(F.relu(self.fc1(x)))\n",
    "        x = self.dropout2(self.fc2(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c9798",
   "metadata": {},
   "source": [
    "### ResNet 18 - 1D improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e238252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_1D_Improved(nn.Module):\n",
    "    def __init__(self, input_channels: int, output_size: int, dropout_rate=0.2):\n",
    "        super(ResNet18_1D_Improved, self).__init__()\n",
    "        base_model = resnet18(pretrained=False)\n",
    "        \n",
    "        # 初始卷積層調整 - 較小的kernel size和stride，更適合ECG信號的特點\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=15, stride=2, padding=7, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # 基本的ResNet層\n",
    "        self.layer1 = base_model.layer1\n",
    "        self.layer2 = base_model.layer2\n",
    "        self.layer3 = base_model.layer3\n",
    "        self.layer4 = base_model.layer4\n",
    "        \n",
    "        # 加入注意力機制\n",
    "        self.attention = SEBlock1D(512)\n",
    "        \n",
    "        # 全局池化\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # 分類器 - 加入dropout和一個額外的層\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(256, output_size)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate/2)  # 較小的dropout率\n",
    "        \n",
    "        self._convert_layers_to_1d()\n",
    "        \n",
    "    def _convert_layers_to_1d(self):\n",
    "        for name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
    "            layer = getattr(self, name)\n",
    "            for block in layer:\n",
    "                # 調整卷積核大小，對於ECG信號，較大的卷積核可能更好\n",
    "                block.conv1 = nn.Conv1d(block.conv1.in_channels, block.conv1.out_channels,\n",
    "                                       kernel_size=7, stride=block.conv1.stride[0],\n",
    "                                       padding=3, bias=False)\n",
    "                block.bn1 = nn.BatchNorm1d(block.bn1.num_features)\n",
    "                block.conv2 = nn.Conv1d(block.conv2.in_channels, block.conv2.out_channels,\n",
    "                                       kernel_size=5, stride=1, padding=2, bias=False)\n",
    "                block.bn2 = nn.BatchNorm1d(block.bn2.num_features)\n",
    "                if block.downsample is not None:\n",
    "                    conv = nn.Conv1d(block.downsample[0].in_channels,\n",
    "                                    block.downsample[0].out_channels,\n",
    "                                    kernel_size=1, stride=block.downsample[0].stride[0], bias=False)\n",
    "                    bn = nn.BatchNorm1d(block.downsample[1].num_features)\n",
    "                    block.downsample = nn.Sequential(conv, bn)\n",
    "    \n",
    "    def forward(self, x):  # x: (B, T, D)\n",
    "        x = x.permute(0, 2, 1)  # → (B, D, T)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # 應用注意力機制\n",
    "        x = self.attention(x)\n",
    "        \n",
    "        x = self.global_pool(x).squeeze(-1)  # → (B, 512)\n",
    "        \n",
    "        # 使用兩層分類器\n",
    "        x = self.dropout1(F.relu(self.fc1(x)))\n",
    "        x = self.dropout2(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Squeeze-and-Excitation Block for 1D - 注意力機制\n",
    "class SEBlock1D(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock1D, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f778d9b",
   "metadata": {},
   "source": [
    "### Bi-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "902360d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, input_size=12, hidden_size=64, num_classes=2, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "\n",
    "    def forward(self, x):  # x: (B, 5000, 12)\n",
    "        B = x.size(0)\n",
    "        h0 = torch.zeros(self.num_layers * 2, B, self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)   # (B, T, 2*H)\n",
    "        out = self.drop(out)\n",
    "        out = out.mean(dim=1)      # → (B, 2*H)\n",
    "        out = self.fc(out)         # → (B, num_classes)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdac9350",
   "metadata": {},
   "source": [
    "### Bi-GRU with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7ab0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRUWithAttention(nn.Module):\n",
    "    def __init__(self, input_size: int = 12, hidden_size: int = 64, output_size: int = 2,\n",
    "                 num_layers: int = 2, dropout: float = 0.0):\n",
    "        super(BiGRUWithAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.attention_fc = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)  # → (B, T, 2*H)\n",
    "\n",
    "        attn = torch.tanh(self.attention_fc(out))  # → (B, T, 2*H)\n",
    "        out = attn * out                            # Element-wise attention\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = out.mean(dim=1)  # Mean pooling → (B, 2*H)\n",
    "        out = self.fc(out)     # → (B, output_size)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebc8c6",
   "metadata": {},
   "source": [
    "## __Training and validation function__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616acb4",
   "metadata": {},
   "source": [
    "### Extra Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3ce00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classwise_accuracy(student_logits_flat, y_batch, class_correct, class_total):\n",
    "    \"\"\"\n",
    "    Computes per-class accuracy by accumulating correct and total samples for each class using vectorized operations.\n",
    "    \n",
    "    Args:\n",
    "        student_logits_flat (torch.Tensor): Model predictions (logits) in shape [batch_size * seq_len, output_size]\n",
    "        y_batch (torch.Tensor): True labels in shape [batch_size * seq_len]\n",
    "        class_correct (dict): Dictionary to store correct predictions per class\n",
    "        class_total (dict): Dictionary to store total samples per class\n",
    "    \"\"\"\n",
    "    # Ensure inputs are on the same device\n",
    "    if student_logits_flat.device != y_batch.device:\n",
    "        raise ValueError(\"student_logits_flat and y_batch must be on the same device\")\n",
    "\n",
    "    # Convert logits to predicted class indices\n",
    "    predictions = torch.argmax(student_logits_flat, dim=-1)  # Shape: [batch_size * seq_len]\n",
    "\n",
    "    # Compute correct predictions mask\n",
    "    correct_mask = (predictions == y_batch)  # Shape: [batch_size * seq_len], boolean\n",
    "\n",
    "    # Get unique labels in this batch\n",
    "    unique_labels = torch.unique(y_batch)\n",
    "\n",
    "    # Update class_total and class_correct using vectorized operations\n",
    "    for label in unique_labels:\n",
    "        label = label.item()  # Convert tensor to scalar\n",
    "        if label not in class_total:\n",
    "            class_total[label] = 0\n",
    "            class_correct[label] = 0\n",
    "        \n",
    "        # Count total samples for this label\n",
    "        label_mask = (y_batch == label)\n",
    "        class_total[label] += label_mask.sum().item()\n",
    "        \n",
    "        # Count correct predictions for this label\n",
    "        class_correct[label] += (label_mask & correct_mask).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724647c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_parameter_info(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    param_size_bytes = total_params * 4\n",
    "    param_size_MB = param_size_bytes / (1024**2)\n",
    "    return total_params, param_size_MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca5631be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從第一個附件保留的數據增強函數\n",
    "def augment_ecg(signal, sigma=0.05, shift_max=20):\n",
    "    \"\"\"\n",
    "    對ECG信號進行數據增強\n",
    "    \n",
    "    Args:\n",
    "        signal: 形狀為 (B, T, C) 的ECG信號\n",
    "        sigma: 噪聲標準差\n",
    "        shift_max: 最大時間偏移量\n",
    "    \n",
    "    Returns:\n",
    "        增強後的信號\n",
    "    \"\"\"\n",
    "    # 添加噪聲\n",
    "    noise = np.random.normal(0, sigma, signal.shape)\n",
    "    signal_noisy = signal + noise\n",
    "    \n",
    "    # 隨機時間偏移\n",
    "    shift = np.random.randint(-shift_max, shift_max)\n",
    "    if shift > 0:\n",
    "        signal_shifted = np.pad(signal_noisy[:, :-shift, :], ((0, 0), (shift, 0), (0, 0)), mode='edge')\n",
    "    elif shift < 0:\n",
    "        signal_shifted = np.pad(signal_noisy[:, -shift:, :], ((0, 0), (0, -shift), (0, 0)), mode='edge')\n",
    "    else:\n",
    "        signal_shifted = signal_noisy\n",
    "        \n",
    "    # 縮放幅度 (±10%)\n",
    "    scale = np.random.uniform(0.9, 1.1)\n",
    "    signal_scaled = signal_shifted * scale\n",
    "    \n",
    "    return signal_scaled\n",
    "\n",
    "# 從第一個附件保留的ECG數據集類\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, X, y, augment=False, device=None):\n",
    "        \"\"\"\n",
    "        ECG數據集類，支持數據增強\n",
    "        \n",
    "        Args:\n",
    "            X: 輸入數據，形狀為 (N, T, C)\n",
    "            y: 標籤\n",
    "            augment: 是否使用數據增強\n",
    "            device: 設備(CPU/GPU)\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.augment = augment\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx].copy()  # 創建副本以避免修改原始數據\n",
    "        \n",
    "        if self.augment and np.random.rand() > 0.5:  # 50% 的概率進行增強\n",
    "            x = augment_ecg(x[np.newaxis, ...])[0]  # 增加和移除 batch 維度\n",
    "            \n",
    "        x_tensor = torch.FloatTensor(x)\n",
    "        y_tensor = torch.LongTensor([self.y[idx]])[0]\n",
    "        \n",
    "        if self.device:\n",
    "            x_tensor = x_tensor.to(self.device)\n",
    "            y_tensor = y_tensor.to(self.device)\n",
    "            \n",
    "        return x_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe5f03",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0852b101",
   "metadata": {},
   "source": [
    "#### No use_class_weights version (For unbalanced Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7836ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_general_classifier(model, output_size, criterion, optimizer,\n",
    "                                   X_train, y_train, X_val, y_val, scheduler=None,\n",
    "                                   num_epochs=10, batch_size=64, model_saving_folder=None,\n",
    "                                   model_name=None, stop_signal_file=None, device=None):\n",
    "\n",
    "    print(\"\\n🚀 'train_model_general_classifier' started.\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # === Folder Setup ===\n",
    "    if model_saving_folder:\n",
    "        if os.path.exists(model_saving_folder):\n",
    "            shutil.rmtree(model_saving_folder)\n",
    "            print(f\"✅ Removed existing folder: {model_saving_folder}\")\n",
    "        os.makedirs(model_saving_folder, exist_ok=True)\n",
    "\n",
    "    model_name = model_name or 'model'\n",
    "    model_saving_folder = model_saving_folder or './saved_models'\n",
    "    device = device\n",
    "\n",
    "    # === Tensor Conversion ===\n",
    "    # X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    # y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    # X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    # y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "    # train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    # val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    # === 創建數據集和數據加載器 ===\n",
    "    train_dataset = ECGDataset(X_train, y_train, augment=True, device=device)\n",
    "    val_dataset   = ECGDataset(X_val, y_val, augment=False, device=device)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(\"\\n✅ Data Overview:\")\n",
    "    print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "\n",
    "    best_results = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        class_correct, class_total = {}, {}\n",
    "\n",
    "        if stop_signal_file and os.path.exists(stop_signal_file):\n",
    "            print(\"\\n🛑 Stop signal detected. Exiting training loop.\")\n",
    "            break\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)  # (B, C)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * X_batch.size(0)\n",
    "            compute_classwise_accuracy(outputs, y_batch, class_correct, class_total)\n",
    "\n",
    "        train_loss = epoch_loss / len(train_loader.dataset)\n",
    "        train_acc = {int(c): f\"{(class_correct[c] / class_total[c]) * 100:.2f}%\" if class_total[c] > 0 else \"0.00%\"\n",
    "                     for c in sorted(class_total.keys())}\n",
    "\n",
    "        # === Validation ===\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        val_class_correct, val_class_total = {}, {}\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                outputs = model(X_batch)\n",
    "                val_loss += criterion(outputs, y_batch).item() * X_batch.size(0)\n",
    "                predictions = torch.argmax(outputs, dim=-1)\n",
    "                val_correct += (predictions == y_batch).sum().item()\n",
    "                val_total += y_batch.size(0)\n",
    "                compute_classwise_accuracy(outputs, y_batch, val_class_correct, val_class_total)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_acc_cls = {int(c): f\"{(val_class_correct[c] / val_class_total[c]) * 100:.2f}%\" if val_class_total[c] > 0 else \"0.00%\"\n",
    "                       for c in sorted(val_class_total.keys())}\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}, Train-Class-Acc: {train_acc}\")\n",
    "        print(f\"Val Loss: {val_loss:.6f}, Val Acc: {val_acc * 100:.2f}%, Val-Class-Acc: {val_acc_cls}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        model_path = os.path.join(model_saving_folder, f\"{model_name}_epoch_{epoch+1}.pth\")\n",
    "        current = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_acc,\n",
    "            'train_classwise_accuracy': train_acc,\n",
    "            'val_classwise_accuracy': val_acc_cls,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'learning_rate': optimizer.param_groups[0]['lr'],\n",
    "            'model_path': model_path\n",
    "        }\n",
    "\n",
    "        if len(best_results) < 5 or val_acc > best_results[-1]['val_accuracy']:\n",
    "            if len(best_results) == 5:\n",
    "                to_remove = best_results.pop()\n",
    "                if os.path.exists(to_remove['model_path']):\n",
    "                    os.remove(to_remove['model_path'])\n",
    "                    print(f\"🗑 Removed: {to_remove['model_path']}\")\n",
    "            best_results.append(current)\n",
    "            best_results.sort(key=lambda x: (x['val_accuracy'], x['epoch']), reverse=True)\n",
    "            torch.save(current, model_path)\n",
    "            print(f\"✅ Saved model: {model_path}\")\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    total_params, param_size_MB = get_model_parameter_info(model)\n",
    "\n",
    "    if best_results:\n",
    "        best = best_results[0]\n",
    "        best_model_path = os.path.join(model_saving_folder, f\"{model_name}_best.pth\")\n",
    "        torch.save(best, best_model_path)\n",
    "        print(f\"\\n🏆 Best model saved as: {best_model_path} (Val Accuracy: {best['val_accuracy'] * 100:.2f}%)\")\n",
    "\n",
    "    final_model_path = os.path.join(model_saving_folder, f\"{model_name}_final.pth\")\n",
    "    torch.save(current, final_model_path)\n",
    "    print(f\"\\n📌 Final model saved as: {final_model_path}\")\n",
    "\n",
    "    print(\"\\n🎯 Top 5 Best Models:\")\n",
    "    for res in best_results:\n",
    "        print(f\"Epoch {res['epoch']}, Train Loss: {res['train_loss']:.6f}, Train-Acc: {res['train_classwise_accuracy']},\\n\"\n",
    "              f\"Val Loss: {res['val_loss']:.6f}, Val Acc: {res['val_accuracy']*100:.2f}%, Val-Class-Acc: {res['val_classwise_accuracy']},\"\n",
    "              f\" Model Path: {res['model_path']}\")\n",
    "\n",
    "    print(f\"\\n🧠 Model Summary:\")\n",
    "    print(f\"Total Parameters: {total_params:,}\")\n",
    "    print(f\"Model Size (float32): {param_size_MB:.2f} MB\")\n",
    "    print(f\"Total Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "    # 🔥 Cleanup\n",
    "    del X_train, y_train, X_val, y_val, train_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return {\n",
    "        'training_time_sec': training_time,\n",
    "        'total_params': total_params,\n",
    "        'model_size_MB': param_size_MB,\n",
    "        'best_val_accuracy': best_results[0]['val_accuracy'] if best_results else None,\n",
    "        'val_classwise_accuracy': best_results[0]['val_classwise_accuracy'] if best_results else None,\n",
    "        'best_model_path': best_model_path if best_results else None,\n",
    "        'final_model_path': final_model_path\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43acccaa",
   "metadata": {},
   "source": [
    "#### use_class_weights version (For unbalanced Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "89009504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_general_classifier_use_class_weights(model, output_size, criterion, optimizer,\n",
    "                                   X_train, y_train, X_val, y_val, scheduler=None,\n",
    "                                   num_epochs=10, batch_size=64, model_saving_folder=None,\n",
    "                                   model_name=None, stop_signal_file=None, device=None,\n",
    "                                   use_class_weights=False):\n",
    "    \n",
    "    print(\"\\n🚀 'train_model_general_classifier' started.\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # === Folder Setup ===\n",
    "    if model_saving_folder:\n",
    "        if os.path.exists(model_saving_folder):\n",
    "            shutil.rmtree(model_saving_folder)\n",
    "            print(f\"✅ Removed existing folder: {model_saving_folder}\")\n",
    "        os.makedirs(model_saving_folder, exist_ok=True)\n",
    "\n",
    "    model_name = model_name or 'model'\n",
    "    model_saving_folder = model_saving_folder or './saved_models'\n",
    "    device = device\n",
    "\n",
    "    # === Tensor Conversion ===\n",
    "    # X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    # y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    # X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    # y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "    # train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    # val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    # === 創建數據集和數據加載器 ===\n",
    "    train_dataset = ECGDataset(X_train, y_train, augment=True, device=device)\n",
    "    val_dataset   = ECGDataset(X_val, y_val, augment=False, device=device)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(\"\\n✅ Data Overview:\")\n",
    "    print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "\n",
    "    # === Optional: 使用類別權重 ===\n",
    "    if use_class_weights:\n",
    "        from sklearn.utils.class_weight import compute_class_weight\n",
    "        class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "        class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        print(f\"✅ 使用類別權重: {class_weights.cpu().numpy()}\")\n",
    "    else:\n",
    "        print(\"✅ 使用標準交叉熵損失函數(無類別權重)\")\n",
    "\n",
    "    best_results = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        class_correct, class_total = {}, {}\n",
    "\n",
    "        if stop_signal_file and os.path.exists(stop_signal_file):\n",
    "            print(\"\\n🛑 Stop signal detected. Exiting training loop.\")\n",
    "            break\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)  # (B, C)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * X_batch.size(0)\n",
    "            compute_classwise_accuracy(outputs, y_batch, class_correct, class_total)\n",
    "\n",
    "        train_loss = epoch_loss / len(train_loader.dataset)\n",
    "        train_acc = {int(c): f\"{(class_correct[c] / class_total[c]) * 100:.2f}%\" if class_total[c] > 0 else \"0.00%\"\n",
    "                     for c in sorted(class_total.keys())}\n",
    "\n",
    "        # === Validation ===\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        val_class_correct, val_class_total = {}, {}\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                outputs = model(X_batch)\n",
    "                val_loss += criterion(outputs, y_batch).item() * X_batch.size(0)\n",
    "                predictions = torch.argmax(outputs, dim=-1)\n",
    "                val_correct += (predictions == y_batch).sum().item()\n",
    "                val_total += y_batch.size(0)\n",
    "                compute_classwise_accuracy(outputs, y_batch, val_class_correct, val_class_total)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_acc_cls = {int(c): f\"{(val_class_correct[c] / val_class_total[c]) * 100:.2f}%\" if val_class_total[c] > 0 else \"0.00%\"\n",
    "                       for c in sorted(val_class_total.keys())}\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}, Train-Class-Acc: {train_acc}\")\n",
    "        print(f\"Val Loss: {val_loss:.6f}, Val Acc: {val_acc * 100:.2f}%, Val-Class-Acc: {val_acc_cls}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        model_path = os.path.join(model_saving_folder, f\"{model_name}_epoch_{epoch+1}.pth\")\n",
    "        current = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_acc,\n",
    "            'train_classwise_accuracy': train_acc,\n",
    "            'val_classwise_accuracy': val_acc_cls,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'learning_rate': optimizer.param_groups[0]['lr'],\n",
    "            'model_path': model_path\n",
    "        }\n",
    "\n",
    "        if len(best_results) < 5 or val_acc > best_results[-1]['val_accuracy']:\n",
    "            if len(best_results) == 5:\n",
    "                to_remove = best_results.pop()\n",
    "                if os.path.exists(to_remove['model_path']):\n",
    "                    os.remove(to_remove['model_path'])\n",
    "                    print(f\"🗑 Removed: {to_remove['model_path']}\")\n",
    "            best_results.append(current)\n",
    "            best_results.sort(key=lambda x: (x['val_accuracy'], x['epoch']), reverse=True)\n",
    "            torch.save(current, model_path)\n",
    "            print(f\"✅ Saved model: {model_path}\")\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    total_params, param_size_MB = get_model_parameter_info(model)\n",
    "\n",
    "    if best_results:\n",
    "        best = best_results[0]\n",
    "        best_model_path = os.path.join(model_saving_folder, f\"{model_name}_best.pth\")\n",
    "        torch.save(best, best_model_path)\n",
    "        print(f\"\\n🏆 Best model saved as: {best_model_path} (Val Accuracy: {best['val_accuracy'] * 100:.2f}%)\")\n",
    "\n",
    "    final_model_path = os.path.join(model_saving_folder, f\"{model_name}_final.pth\")\n",
    "    torch.save(current, final_model_path)\n",
    "    print(f\"\\n📌 Final model saved as: {final_model_path}\")\n",
    "\n",
    "    print(\"\\n🎯 Top 5 Best Models:\")\n",
    "    for res in best_results:\n",
    "        print(f\"Epoch {res['epoch']}, Train Loss: {res['train_loss']:.6f}, Train-Acc: {res['train_classwise_accuracy']},\\n\"\n",
    "              f\"Val Loss: {res['val_loss']:.6f}, Val Acc: {res['val_accuracy']*100:.2f}%, Val-Class-Acc: {res['val_classwise_accuracy']},\"\n",
    "              f\" Model Path: {res['model_path']}\")\n",
    "\n",
    "    print(f\"\\n🧠 Model Summary:\")\n",
    "    print(f\"Total Parameters: {total_params:,}\")\n",
    "    print(f\"Model Size (float32): {param_size_MB:.2f} MB\")\n",
    "    print(f\"Total Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "    # 🔥 Cleanup\n",
    "    del X_train, y_train, X_val, y_val, train_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return {\n",
    "        'training_time_sec': training_time,\n",
    "        'total_params': total_params,\n",
    "        'model_size_MB': param_size_MB,\n",
    "        'best_val_accuracy': best_results[0]['val_accuracy'] if best_results else None,\n",
    "        'val_classwise_accuracy': best_results[0]['val_classwise_accuracy'] if best_results else None,\n",
    "        'best_model_path': best_model_path if best_results else None,\n",
    "        'final_model_path': final_model_path\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1085b2",
   "metadata": {},
   "source": [
    "## __Test Model__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71972f72",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1777cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Automatically selected GPU:\n",
      "    - CUDA Device ID : 1\n",
      "    - Memory Used    : 595 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "✅ input shape: (1468, 5000, 12)\n",
      "✅ unique y_train: [0 1]\n",
      "✅ unique y_test : [0 1]\n",
      "\n",
      "🚀 'train_model_general_classifier' started.\n",
      "✅ Removed existing folder: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP\n",
      "\n",
      "✅ Data Overview:\n",
      "X_train: torch.Size([1468, 5000, 12]), y_train: torch.Size([1468])\n",
      "X_val: torch.Size([368, 5000, 12]), y_val: torch.Size([368])\n",
      "Epoch 1/200, Train Loss: 1.326211, Train-Class-Acc: {0: '57.36%', 1: '58.17%'}\n",
      "Val Loss: 1.390308, Val Acc: 54.35%, Val-Class-Acc: {0: '86.96%', 1: '21.74%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.332756, Train-Class-Acc: {0: '85.83%', 1: '87.19%'}\n",
      "Val Loss: 1.040174, Val Acc: 62.23%, Val-Class-Acc: {0: '38.59%', 1: '85.87%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.077726, Train-Class-Acc: {0: '97.41%', 1: '98.23%'}\n",
      "Val Loss: 0.813031, Val Acc: 63.04%, Val-Class-Acc: {0: '66.30%', 1: '59.78%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.018557, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.861587, Val Acc: 64.40%, Val-Class-Acc: {0: '61.96%', 1: '66.85%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.006918, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.945417, Val Acc: 62.23%, Val-Class-Acc: {0: '58.70%', 1: '65.76%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.005881, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.003988, Val Acc: 62.23%, Val-Class-Acc: {0: '50.00%', 1: '74.46%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_1.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_6.pth\n",
      "Epoch 7/200, Train Loss: 0.003388, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.025516, Val Acc: 62.50%, Val-Class-Acc: {0: '53.80%', 1: '71.20%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_2.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.002806, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.050058, Val Acc: 62.23%, Val-Class-Acc: {0: '54.35%', 1: '70.11%'}, LR: 0.001000\n",
      "Epoch 9/200, Train Loss: 0.001920, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.075949, Val Acc: 62.50%, Val-Class-Acc: {0: '53.80%', 1: '71.20%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_5.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.001342, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.096961, Val Acc: 61.96%, Val-Class-Acc: {0: '53.80%', 1: '70.11%'}, LR: 0.001000\n",
      "Epoch 11/200, Train Loss: 0.001215, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.118557, Val Acc: 61.96%, Val-Class-Acc: {0: '53.80%', 1: '70.11%'}, LR: 0.001000\n",
      "Epoch 12/200, Train Loss: 0.001363, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.123183, Val Acc: 61.96%, Val-Class-Acc: {0: '53.80%', 1: '70.11%'}, LR: 0.001000\n",
      "Epoch 13/200, Train Loss: 0.000828, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.150504, Val Acc: 62.23%, Val-Class-Acc: {0: '54.35%', 1: '70.11%'}, LR: 0.001000\n",
      "Epoch 14/200, Train Loss: 0.001213, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.177703, Val Acc: 61.96%, Val-Class-Acc: {0: '52.72%', 1: '71.20%'}, LR: 0.001000\n",
      "Epoch 15/200, Train Loss: 0.000722, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.197543, Val Acc: 62.77%, Val-Class-Acc: {0: '52.17%', 1: '73.37%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_6.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_15.pth\n",
      "Epoch 16/200, Train Loss: 0.000706, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.206513, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000900\n",
      "Epoch 17/200, Train Loss: 0.000584, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.210327, Val Acc: 62.23%, Val-Class-Acc: {0: '53.80%', 1: '70.65%'}, LR: 0.000900\n",
      "Epoch 18/200, Train Loss: 0.000681, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.241901, Val Acc: 61.68%, Val-Class-Acc: {0: '51.63%', 1: '71.74%'}, LR: 0.000900\n",
      "Epoch 19/200, Train Loss: 0.000491, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.248148, Val Acc: 61.96%, Val-Class-Acc: {0: '52.72%', 1: '71.20%'}, LR: 0.000900\n",
      "Epoch 20/200, Train Loss: 0.000670, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.242275, Val Acc: 61.96%, Val-Class-Acc: {0: '54.35%', 1: '69.57%'}, LR: 0.000900\n",
      "Epoch 21/200, Train Loss: 0.000775, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.269029, Val Acc: 61.96%, Val-Class-Acc: {0: '53.26%', 1: '70.65%'}, LR: 0.000900\n",
      "Epoch 22/200, Train Loss: 0.000445, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.258932, Val Acc: 62.50%, Val-Class-Acc: {0: '54.89%', 1: '70.11%'}, LR: 0.000900\n",
      "Epoch 23/200, Train Loss: 0.000475, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.272149, Val Acc: 62.77%, Val-Class-Acc: {0: '55.43%', 1: '70.11%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_7.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_23.pth\n",
      "Epoch 24/200, Train Loss: 0.000296, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.299866, Val Acc: 62.23%, Val-Class-Acc: {0: '52.72%', 1: '71.74%'}, LR: 0.000900\n",
      "Epoch 25/200, Train Loss: 0.000333, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.321825, Val Acc: 61.96%, Val-Class-Acc: {0: '52.17%', 1: '71.74%'}, LR: 0.000900\n",
      "Epoch 26/200, Train Loss: 0.000391, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.325662, Val Acc: 61.68%, Val-Class-Acc: {0: '52.72%', 1: '70.65%'}, LR: 0.000810\n",
      "Epoch 27/200, Train Loss: 0.000229, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.345019, Val Acc: 62.50%, Val-Class-Acc: {0: '52.72%', 1: '72.28%'}, LR: 0.000810\n",
      "Epoch 28/200, Train Loss: 0.000348, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.358449, Val Acc: 63.04%, Val-Class-Acc: {0: '52.17%', 1: '73.91%'}, LR: 0.000810\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_9.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_28.pth\n",
      "Epoch 29/200, Train Loss: 0.000287, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.337752, Val Acc: 62.23%, Val-Class-Acc: {0: '54.35%', 1: '70.11%'}, LR: 0.000810\n",
      "Epoch 30/200, Train Loss: 0.000174, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.351941, Val Acc: 62.23%, Val-Class-Acc: {0: '52.72%', 1: '71.74%'}, LR: 0.000810\n",
      "Epoch 31/200, Train Loss: 0.000159, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.357195, Val Acc: 62.50%, Val-Class-Acc: {0: '53.80%', 1: '71.20%'}, LR: 0.000810\n",
      "Epoch 32/200, Train Loss: 0.000341, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.371737, Val Acc: 62.23%, Val-Class-Acc: {0: '53.80%', 1: '70.65%'}, LR: 0.000810\n",
      "Epoch 33/200, Train Loss: 0.000306, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.359072, Val Acc: 62.23%, Val-Class-Acc: {0: '54.89%', 1: '69.57%'}, LR: 0.000810\n",
      "Epoch 34/200, Train Loss: 0.000207, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.375491, Val Acc: 61.68%, Val-Class-Acc: {0: '54.89%', 1: '68.48%'}, LR: 0.000810\n",
      "Epoch 35/200, Train Loss: 0.000141, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.360666, Val Acc: 62.23%, Val-Class-Acc: {0: '55.43%', 1: '69.02%'}, LR: 0.000810\n",
      "Epoch 36/200, Train Loss: 0.000196, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.393692, Val Acc: 62.50%, Val-Class-Acc: {0: '54.35%', 1: '70.65%'}, LR: 0.000810\n",
      "Epoch 37/200, Train Loss: 0.000172, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.399042, Val Acc: 61.96%, Val-Class-Acc: {0: '53.80%', 1: '70.11%'}, LR: 0.000729\n",
      "Epoch 38/200, Train Loss: 0.000167, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.414969, Val Acc: 62.50%, Val-Class-Acc: {0: '54.35%', 1: '70.65%'}, LR: 0.000729\n",
      "Epoch 39/200, Train Loss: 0.000228, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.391342, Val Acc: 62.50%, Val-Class-Acc: {0: '55.43%', 1: '69.57%'}, LR: 0.000729\n",
      "Epoch 40/200, Train Loss: 0.000249, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.402870, Val Acc: 62.23%, Val-Class-Acc: {0: '53.80%', 1: '70.65%'}, LR: 0.000729\n",
      "Epoch 41/200, Train Loss: 0.000144, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.414038, Val Acc: 61.96%, Val-Class-Acc: {0: '53.26%', 1: '70.65%'}, LR: 0.000729\n",
      "Epoch 42/200, Train Loss: 0.000202, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.460401, Val Acc: 61.68%, Val-Class-Acc: {0: '50.54%', 1: '72.83%'}, LR: 0.000729\n",
      "Epoch 43/200, Train Loss: 0.000143, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.445611, Val Acc: 62.50%, Val-Class-Acc: {0: '51.63%', 1: '73.37%'}, LR: 0.000729\n",
      "Epoch 44/200, Train Loss: 0.000119, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.433064, Val Acc: 61.96%, Val-Class-Acc: {0: '52.72%', 1: '71.20%'}, LR: 0.000729\n",
      "Epoch 45/200, Train Loss: 0.000165, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.435305, Val Acc: 62.23%, Val-Class-Acc: {0: '52.72%', 1: '71.74%'}, LR: 0.000729\n",
      "Epoch 46/200, Train Loss: 0.000101, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.450838, Val Acc: 61.41%, Val-Class-Acc: {0: '51.63%', 1: '71.20%'}, LR: 0.000729\n",
      "Epoch 47/200, Train Loss: 0.000085, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.445278, Val Acc: 61.68%, Val-Class-Acc: {0: '54.35%', 1: '69.02%'}, LR: 0.000729\n",
      "Epoch 48/200, Train Loss: 0.000123, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.442417, Val Acc: 61.68%, Val-Class-Acc: {0: '53.26%', 1: '70.11%'}, LR: 0.000656\n",
      "Epoch 49/200, Train Loss: 0.000093, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.468898, Val Acc: 61.41%, Val-Class-Acc: {0: '52.72%', 1: '70.11%'}, LR: 0.000656\n",
      "Epoch 50/200, Train Loss: 0.000121, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.472166, Val Acc: 62.23%, Val-Class-Acc: {0: '53.26%', 1: '71.20%'}, LR: 0.000656\n",
      "Epoch 51/200, Train Loss: 0.000103, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.472184, Val Acc: 61.96%, Val-Class-Acc: {0: '53.26%', 1: '70.65%'}, LR: 0.000656\n",
      "Epoch 52/200, Train Loss: 0.000084, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.486622, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000656\n",
      "Epoch 53/200, Train Loss: 0.000113, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.487169, Val Acc: 62.23%, Val-Class-Acc: {0: '52.17%', 1: '72.28%'}, LR: 0.000656\n",
      "Epoch 54/200, Train Loss: 0.000176, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.520353, Val Acc: 61.68%, Val-Class-Acc: {0: '49.46%', 1: '73.91%'}, LR: 0.000656\n",
      "Epoch 55/200, Train Loss: 0.000071, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.468645, Val Acc: 61.96%, Val-Class-Acc: {0: '53.80%', 1: '70.11%'}, LR: 0.000656\n",
      "Epoch 56/200, Train Loss: 0.000087, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.468241, Val Acc: 60.87%, Val-Class-Acc: {0: '54.35%', 1: '67.39%'}, LR: 0.000656\n",
      "Epoch 57/200, Train Loss: 0.000066, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.494812, Val Acc: 61.41%, Val-Class-Acc: {0: '52.72%', 1: '70.11%'}, LR: 0.000656\n",
      "Epoch 58/200, Train Loss: 0.000072, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.510376, Val Acc: 61.96%, Val-Class-Acc: {0: '52.17%', 1: '71.74%'}, LR: 0.000656\n",
      "Epoch 59/200, Train Loss: 0.000122, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.511624, Val Acc: 62.23%, Val-Class-Acc: {0: '52.17%', 1: '72.28%'}, LR: 0.000590\n",
      "Epoch 60/200, Train Loss: 0.000054, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.505479, Val Acc: 61.68%, Val-Class-Acc: {0: '52.72%', 1: '70.65%'}, LR: 0.000590\n",
      "Epoch 61/200, Train Loss: 0.000055, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.501941, Val Acc: 61.68%, Val-Class-Acc: {0: '53.26%', 1: '70.11%'}, LR: 0.000590\n",
      "Epoch 62/200, Train Loss: 0.000078, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.511371, Val Acc: 62.50%, Val-Class-Acc: {0: '53.26%', 1: '71.74%'}, LR: 0.000590\n",
      "Epoch 63/200, Train Loss: 0.000064, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.526730, Val Acc: 61.41%, Val-Class-Acc: {0: '50.54%', 1: '72.28%'}, LR: 0.000590\n",
      "Epoch 64/200, Train Loss: 0.000074, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.534139, Val Acc: 62.50%, Val-Class-Acc: {0: '52.17%', 1: '72.83%'}, LR: 0.000590\n",
      "Epoch 65/200, Train Loss: 0.000058, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.511822, Val Acc: 61.41%, Val-Class-Acc: {0: '53.80%', 1: '69.02%'}, LR: 0.000590\n",
      "Epoch 66/200, Train Loss: 0.000080, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.544304, Val Acc: 61.68%, Val-Class-Acc: {0: '51.63%', 1: '71.74%'}, LR: 0.000590\n",
      "Epoch 67/200, Train Loss: 0.000062, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.558912, Val Acc: 61.96%, Val-Class-Acc: {0: '51.63%', 1: '72.28%'}, LR: 0.000590\n",
      "Epoch 68/200, Train Loss: 0.000063, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.539401, Val Acc: 61.68%, Val-Class-Acc: {0: '53.26%', 1: '70.11%'}, LR: 0.000590\n",
      "Epoch 69/200, Train Loss: 0.000059, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.520809, Val Acc: 61.41%, Val-Class-Acc: {0: '53.26%', 1: '69.57%'}, LR: 0.000590\n",
      "Epoch 70/200, Train Loss: 0.000052, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.558925, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000531\n",
      "Epoch 71/200, Train Loss: 0.000080, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.530948, Val Acc: 61.14%, Val-Class-Acc: {0: '53.80%', 1: '68.48%'}, LR: 0.000531\n",
      "Epoch 72/200, Train Loss: 0.000044, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.534515, Val Acc: 60.87%, Val-Class-Acc: {0: '53.80%', 1: '67.93%'}, LR: 0.000531\n",
      "Epoch 73/200, Train Loss: 0.000049, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.556890, Val Acc: 62.50%, Val-Class-Acc: {0: '52.72%', 1: '72.28%'}, LR: 0.000531\n",
      "Epoch 74/200, Train Loss: 0.000039, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.549601, Val Acc: 62.23%, Val-Class-Acc: {0: '53.26%', 1: '71.20%'}, LR: 0.000531\n",
      "Epoch 75/200, Train Loss: 0.000078, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.569875, Val Acc: 61.96%, Val-Class-Acc: {0: '51.63%', 1: '72.28%'}, LR: 0.000531\n",
      "Epoch 76/200, Train Loss: 0.000105, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.588741, Val Acc: 61.96%, Val-Class-Acc: {0: '51.09%', 1: '72.83%'}, LR: 0.000531\n",
      "Epoch 77/200, Train Loss: 0.000062, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.566929, Val Acc: 61.41%, Val-Class-Acc: {0: '52.72%', 1: '70.11%'}, LR: 0.000531\n",
      "Epoch 78/200, Train Loss: 0.000057, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.563508, Val Acc: 61.68%, Val-Class-Acc: {0: '53.26%', 1: '70.11%'}, LR: 0.000531\n",
      "Epoch 79/200, Train Loss: 0.000065, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.558198, Val Acc: 60.87%, Val-Class-Acc: {0: '53.80%', 1: '67.93%'}, LR: 0.000531\n",
      "Epoch 80/200, Train Loss: 0.000068, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.568857, Val Acc: 61.14%, Val-Class-Acc: {0: '53.80%', 1: '68.48%'}, LR: 0.000531\n",
      "Epoch 81/200, Train Loss: 0.000060, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.597267, Val Acc: 61.41%, Val-Class-Acc: {0: '51.09%', 1: '71.74%'}, LR: 0.000478\n",
      "Epoch 82/200, Train Loss: 0.000043, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.601886, Val Acc: 61.14%, Val-Class-Acc: {0: '51.09%', 1: '71.20%'}, LR: 0.000478\n",
      "Epoch 83/200, Train Loss: 0.000038, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.592660, Val Acc: 61.96%, Val-Class-Acc: {0: '52.17%', 1: '71.74%'}, LR: 0.000478\n",
      "Epoch 84/200, Train Loss: 0.000040, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.582988, Val Acc: 62.23%, Val-Class-Acc: {0: '52.72%', 1: '71.74%'}, LR: 0.000478\n",
      "Epoch 85/200, Train Loss: 0.000032, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.593523, Val Acc: 61.68%, Val-Class-Acc: {0: '52.72%', 1: '70.65%'}, LR: 0.000478\n",
      "Epoch 86/200, Train Loss: 0.000044, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.594482, Val Acc: 61.96%, Val-Class-Acc: {0: '52.72%', 1: '71.20%'}, LR: 0.000478\n",
      "Epoch 87/200, Train Loss: 0.000047, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.592084, Val Acc: 61.96%, Val-Class-Acc: {0: '53.26%', 1: '70.65%'}, LR: 0.000478\n",
      "Epoch 88/200, Train Loss: 0.000043, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.596292, Val Acc: 61.68%, Val-Class-Acc: {0: '52.72%', 1: '70.65%'}, LR: 0.000478\n",
      "Epoch 89/200, Train Loss: 0.000038, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.579964, Val Acc: 61.41%, Val-Class-Acc: {0: '53.80%', 1: '69.02%'}, LR: 0.000478\n",
      "Epoch 90/200, Train Loss: 0.000039, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.614954, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000478\n",
      "Epoch 91/200, Train Loss: 0.000027, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.605530, Val Acc: 61.41%, Val-Class-Acc: {0: '50.54%', 1: '72.28%'}, LR: 0.000478\n",
      "Epoch 92/200, Train Loss: 0.000051, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.613622, Val Acc: 61.96%, Val-Class-Acc: {0: '52.72%', 1: '71.20%'}, LR: 0.000430\n",
      "Epoch 93/200, Train Loss: 0.000033, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.606308, Val Acc: 61.41%, Val-Class-Acc: {0: '53.26%', 1: '69.57%'}, LR: 0.000430\n",
      "Epoch 94/200, Train Loss: 0.000034, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.610474, Val Acc: 61.68%, Val-Class-Acc: {0: '53.26%', 1: '70.11%'}, LR: 0.000430\n",
      "Epoch 95/200, Train Loss: 0.000044, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.621031, Val Acc: 61.68%, Val-Class-Acc: {0: '52.72%', 1: '70.65%'}, LR: 0.000430\n",
      "Epoch 96/200, Train Loss: 0.000046, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.608651, Val Acc: 61.96%, Val-Class-Acc: {0: '53.26%', 1: '70.65%'}, LR: 0.000430\n",
      "Epoch 97/200, Train Loss: 0.000037, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.635461, Val Acc: 61.14%, Val-Class-Acc: {0: '51.63%', 1: '70.65%'}, LR: 0.000430\n",
      "Epoch 98/200, Train Loss: 0.000035, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.609104, Val Acc: 61.41%, Val-Class-Acc: {0: '52.17%', 1: '70.65%'}, LR: 0.000430\n",
      "Epoch 99/200, Train Loss: 0.000034, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.599028, Val Acc: 60.87%, Val-Class-Acc: {0: '53.80%', 1: '67.93%'}, LR: 0.000430\n",
      "Epoch 100/200, Train Loss: 0.000031, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.630514, Val Acc: 61.96%, Val-Class-Acc: {0: '52.72%', 1: '71.20%'}, LR: 0.000430\n",
      "Epoch 101/200, Train Loss: 0.000028, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.613836, Val Acc: 61.41%, Val-Class-Acc: {0: '52.72%', 1: '70.11%'}, LR: 0.000430\n",
      "Epoch 102/200, Train Loss: 0.000041, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.627828, Val Acc: 61.96%, Val-Class-Acc: {0: '52.17%', 1: '71.74%'}, LR: 0.000430\n",
      "Epoch 103/200, Train Loss: 0.000043, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.607914, Val Acc: 60.87%, Val-Class-Acc: {0: '53.80%', 1: '67.93%'}, LR: 0.000387\n",
      "Epoch 104/200, Train Loss: 0.000038, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.649027, Val Acc: 61.41%, Val-Class-Acc: {0: '51.63%', 1: '71.20%'}, LR: 0.000387\n",
      "Epoch 105/200, Train Loss: 0.000064, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.619808, Val Acc: 60.87%, Val-Class-Acc: {0: '53.26%', 1: '68.48%'}, LR: 0.000387\n",
      "Epoch 106/200, Train Loss: 0.000029, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.667281, Val Acc: 62.23%, Val-Class-Acc: {0: '52.17%', 1: '72.28%'}, LR: 0.000387\n",
      "Epoch 107/200, Train Loss: 0.000024, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.664733, Val Acc: 62.23%, Val-Class-Acc: {0: '52.17%', 1: '72.28%'}, LR: 0.000387\n",
      "Epoch 108/200, Train Loss: 0.000023, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.639363, Val Acc: 61.96%, Val-Class-Acc: {0: '52.72%', 1: '71.20%'}, LR: 0.000387\n",
      "Epoch 109/200, Train Loss: 0.000024, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.639848, Val Acc: 61.14%, Val-Class-Acc: {0: '53.26%', 1: '69.02%'}, LR: 0.000387\n",
      "Epoch 110/200, Train Loss: 0.000029, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.633749, Val Acc: 61.14%, Val-Class-Acc: {0: '53.80%', 1: '68.48%'}, LR: 0.000387\n",
      "Epoch 111/200, Train Loss: 0.000031, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.656503, Val Acc: 61.41%, Val-Class-Acc: {0: '53.80%', 1: '69.02%'}, LR: 0.000387\n",
      "Epoch 112/200, Train Loss: 0.000026, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.668585, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000387\n",
      "Epoch 113/200, Train Loss: 0.000059, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.649936, Val Acc: 60.87%, Val-Class-Acc: {0: '53.26%', 1: '68.48%'}, LR: 0.000387\n",
      "Epoch 114/200, Train Loss: 0.000042, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.690715, Val Acc: 61.68%, Val-Class-Acc: {0: '50.54%', 1: '72.83%'}, LR: 0.000349\n",
      "Epoch 115/200, Train Loss: 0.000029, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.648076, Val Acc: 61.41%, Val-Class-Acc: {0: '54.35%', 1: '68.48%'}, LR: 0.000349\n",
      "Epoch 116/200, Train Loss: 0.000022, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.661922, Val Acc: 61.68%, Val-Class-Acc: {0: '52.72%', 1: '70.65%'}, LR: 0.000349\n",
      "Epoch 117/200, Train Loss: 0.000020, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.664432, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000349\n",
      "Epoch 118/200, Train Loss: 0.000050, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.650482, Val Acc: 62.23%, Val-Class-Acc: {0: '53.26%', 1: '71.20%'}, LR: 0.000349\n",
      "Epoch 119/200, Train Loss: 0.000037, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.652006, Val Acc: 61.68%, Val-Class-Acc: {0: '52.72%', 1: '70.65%'}, LR: 0.000349\n",
      "Epoch 120/200, Train Loss: 0.000036, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.651245, Val Acc: 60.87%, Val-Class-Acc: {0: '53.80%', 1: '67.93%'}, LR: 0.000349\n",
      "Epoch 121/200, Train Loss: 0.000026, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.698966, Val Acc: 61.41%, Val-Class-Acc: {0: '51.63%', 1: '71.20%'}, LR: 0.000349\n",
      "Epoch 122/200, Train Loss: 0.000061, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.682078, Val Acc: 62.23%, Val-Class-Acc: {0: '52.17%', 1: '72.28%'}, LR: 0.000349\n",
      "Epoch 123/200, Train Loss: 0.000023, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.685864, Val Acc: 62.23%, Val-Class-Acc: {0: '52.72%', 1: '71.74%'}, LR: 0.000349\n",
      "Epoch 124/200, Train Loss: 0.000047, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.680455, Val Acc: 61.41%, Val-Class-Acc: {0: '53.26%', 1: '69.57%'}, LR: 0.000349\n",
      "Epoch 125/200, Train Loss: 0.000047, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.701383, Val Acc: 62.50%, Val-Class-Acc: {0: '52.17%', 1: '72.83%'}, LR: 0.000314\n",
      "Epoch 126/200, Train Loss: 0.000041, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.663502, Val Acc: 61.41%, Val-Class-Acc: {0: '53.26%', 1: '69.57%'}, LR: 0.000314\n",
      "Epoch 127/200, Train Loss: 0.000024, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.698059, Val Acc: 62.23%, Val-Class-Acc: {0: '53.26%', 1: '71.20%'}, LR: 0.000314\n",
      "Epoch 128/200, Train Loss: 0.000019, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.692158, Val Acc: 62.23%, Val-Class-Acc: {0: '52.17%', 1: '72.28%'}, LR: 0.000314\n",
      "Epoch 129/200, Train Loss: 0.000022, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.686116, Val Acc: 61.41%, Val-Class-Acc: {0: '53.26%', 1: '69.57%'}, LR: 0.000314\n",
      "Epoch 130/200, Train Loss: 0.000017, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.688722, Val Acc: 61.96%, Val-Class-Acc: {0: '52.72%', 1: '71.20%'}, LR: 0.000314\n",
      "Epoch 131/200, Train Loss: 0.000022, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.695717, Val Acc: 62.23%, Val-Class-Acc: {0: '52.72%', 1: '71.74%'}, LR: 0.000314\n",
      "Epoch 132/200, Train Loss: 0.000021, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.680510, Val Acc: 61.96%, Val-Class-Acc: {0: '53.26%', 1: '70.65%'}, LR: 0.000314\n",
      "Epoch 133/200, Train Loss: 0.000029, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.701811, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000314\n",
      "Epoch 134/200, Train Loss: 0.000013, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.695728, Val Acc: 61.68%, Val-Class-Acc: {0: '52.72%', 1: '70.65%'}, LR: 0.000314\n",
      "Epoch 135/200, Train Loss: 0.000018, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.686908, Val Acc: 62.50%, Val-Class-Acc: {0: '52.17%', 1: '72.83%'}, LR: 0.000314\n",
      "Epoch 136/200, Train Loss: 0.000020, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.682841, Val Acc: 61.14%, Val-Class-Acc: {0: '52.72%', 1: '69.57%'}, LR: 0.000282\n",
      "Epoch 137/200, Train Loss: 0.000024, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.697938, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000282\n",
      "Epoch 138/200, Train Loss: 0.000047, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.703888, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000282\n",
      "Epoch 139/200, Train Loss: 0.000032, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.687633, Val Acc: 61.41%, Val-Class-Acc: {0: '53.80%', 1: '69.02%'}, LR: 0.000282\n",
      "Epoch 140/200, Train Loss: 0.000020, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.695486, Val Acc: 61.68%, Val-Class-Acc: {0: '54.35%', 1: '69.02%'}, LR: 0.000282\n",
      "Epoch 141/200, Train Loss: 0.000024, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.703961, Val Acc: 61.14%, Val-Class-Acc: {0: '53.80%', 1: '68.48%'}, LR: 0.000282\n",
      "Epoch 142/200, Train Loss: 0.000020, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.705199, Val Acc: 61.68%, Val-Class-Acc: {0: '53.80%', 1: '69.57%'}, LR: 0.000282\n",
      "Epoch 143/200, Train Loss: 0.000020, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.696473, Val Acc: 61.14%, Val-Class-Acc: {0: '53.26%', 1: '69.02%'}, LR: 0.000282\n",
      "Epoch 144/200, Train Loss: 0.000019, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.689210, Val Acc: 61.41%, Val-Class-Acc: {0: '53.80%', 1: '69.02%'}, LR: 0.000282\n",
      "Epoch 145/200, Train Loss: 0.000021, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.703032, Val Acc: 61.41%, Val-Class-Acc: {0: '53.80%', 1: '69.02%'}, LR: 0.000282\n",
      "Epoch 146/200, Train Loss: 0.000018, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.708974, Val Acc: 61.96%, Val-Class-Acc: {0: '52.72%', 1: '71.20%'}, LR: 0.000282\n",
      "Epoch 147/200, Train Loss: 0.000018, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.716958, Val Acc: 62.23%, Val-Class-Acc: {0: '52.17%', 1: '72.28%'}, LR: 0.000254\n",
      "Epoch 148/200, Train Loss: 0.000019, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.704164, Val Acc: 61.14%, Val-Class-Acc: {0: '53.26%', 1: '69.02%'}, LR: 0.000254\n",
      "Epoch 149/200, Train Loss: 0.000026, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.704200, Val Acc: 61.14%, Val-Class-Acc: {0: '52.17%', 1: '70.11%'}, LR: 0.000254\n",
      "Epoch 150/200, Train Loss: 0.000026, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.725993, Val Acc: 62.23%, Val-Class-Acc: {0: '52.17%', 1: '72.28%'}, LR: 0.000254\n",
      "Epoch 151/200, Train Loss: 0.000019, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.721652, Val Acc: 60.87%, Val-Class-Acc: {0: '52.72%', 1: '69.02%'}, LR: 0.000254\n",
      "Epoch 152/200, Train Loss: 0.000020, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.722057, Val Acc: 61.14%, Val-Class-Acc: {0: '52.17%', 1: '70.11%'}, LR: 0.000254\n",
      "Epoch 153/200, Train Loss: 0.000028, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.726255, Val Acc: 61.96%, Val-Class-Acc: {0: '52.17%', 1: '71.74%'}, LR: 0.000254\n",
      "Epoch 154/200, Train Loss: 0.000013, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.716267, Val Acc: 61.68%, Val-Class-Acc: {0: '53.80%', 1: '69.57%'}, LR: 0.000254\n",
      "Epoch 155/200, Train Loss: 0.000029, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.720804, Val Acc: 61.14%, Val-Class-Acc: {0: '53.26%', 1: '69.02%'}, LR: 0.000254\n",
      "Epoch 156/200, Train Loss: 0.000014, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.723423, Val Acc: 61.14%, Val-Class-Acc: {0: '53.26%', 1: '69.02%'}, LR: 0.000254\n",
      "Epoch 157/200, Train Loss: 0.000022, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.747020, Val Acc: 61.14%, Val-Class-Acc: {0: '52.17%', 1: '70.11%'}, LR: 0.000254\n",
      "Epoch 158/200, Train Loss: 0.000019, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.762366, Val Acc: 61.96%, Val-Class-Acc: {0: '51.63%', 1: '72.28%'}, LR: 0.000229\n",
      "Epoch 159/200, Train Loss: 0.000018, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.769041, Val Acc: 61.14%, Val-Class-Acc: {0: '48.91%', 1: '73.37%'}, LR: 0.000229\n",
      "Epoch 160/200, Train Loss: 0.000014, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.735614, Val Acc: 61.96%, Val-Class-Acc: {0: '52.17%', 1: '71.74%'}, LR: 0.000229\n",
      "Epoch 161/200, Train Loss: 0.000017, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.730273, Val Acc: 62.23%, Val-Class-Acc: {0: '53.80%', 1: '70.65%'}, LR: 0.000229\n",
      "Epoch 162/200, Train Loss: 0.000024, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.738253, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000229\n",
      "Epoch 163/200, Train Loss: 0.000019, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.750296, Val Acc: 61.41%, Val-Class-Acc: {0: '52.17%', 1: '70.65%'}, LR: 0.000229\n",
      "Epoch 164/200, Train Loss: 0.000021, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.733542, Val Acc: 61.14%, Val-Class-Acc: {0: '53.26%', 1: '69.02%'}, LR: 0.000229\n",
      "Epoch 165/200, Train Loss: 0.000010, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.731816, Val Acc: 61.41%, Val-Class-Acc: {0: '53.80%', 1: '69.02%'}, LR: 0.000229\n",
      "Epoch 166/200, Train Loss: 0.000014, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.732934, Val Acc: 60.87%, Val-Class-Acc: {0: '53.26%', 1: '68.48%'}, LR: 0.000229\n",
      "Epoch 167/200, Train Loss: 0.000010, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.730271, Val Acc: 61.14%, Val-Class-Acc: {0: '53.26%', 1: '69.02%'}, LR: 0.000229\n",
      "Epoch 168/200, Train Loss: 0.000016, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.716603, Val Acc: 61.14%, Val-Class-Acc: {0: '54.35%', 1: '67.93%'}, LR: 0.000229\n",
      "Epoch 169/200, Train Loss: 0.000018, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.731440, Val Acc: 61.14%, Val-Class-Acc: {0: '52.72%', 1: '69.57%'}, LR: 0.000206\n",
      "Epoch 170/200, Train Loss: 0.000020, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.750258, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000206\n",
      "Epoch 171/200, Train Loss: 0.000024, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.738453, Val Acc: 61.14%, Val-Class-Acc: {0: '53.80%', 1: '68.48%'}, LR: 0.000206\n",
      "Epoch 172/200, Train Loss: 0.000015, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.749901, Val Acc: 60.87%, Val-Class-Acc: {0: '52.72%', 1: '69.02%'}, LR: 0.000206\n",
      "Epoch 173/200, Train Loss: 0.000011, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.745852, Val Acc: 61.41%, Val-Class-Acc: {0: '52.72%', 1: '70.11%'}, LR: 0.000206\n",
      "Epoch 174/200, Train Loss: 0.000015, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.745387, Val Acc: 61.41%, Val-Class-Acc: {0: '53.26%', 1: '69.57%'}, LR: 0.000206\n",
      "Epoch 175/200, Train Loss: 0.000015, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.753787, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000206\n",
      "Epoch 176/200, Train Loss: 0.000014, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.759103, Val Acc: 62.23%, Val-Class-Acc: {0: '52.17%', 1: '72.28%'}, LR: 0.000206\n",
      "Epoch 177/200, Train Loss: 0.000019, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.774452, Val Acc: 61.41%, Val-Class-Acc: {0: '52.17%', 1: '70.65%'}, LR: 0.000206\n",
      "Epoch 178/200, Train Loss: 0.000020, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.781236, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000206\n",
      "Epoch 179/200, Train Loss: 0.000017, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.788176, Val Acc: 62.23%, Val-Class-Acc: {0: '52.17%', 1: '72.28%'}, LR: 0.000206\n",
      "Epoch 180/200, Train Loss: 0.000019, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.763532, Val Acc: 61.41%, Val-Class-Acc: {0: '52.17%', 1: '70.65%'}, LR: 0.000185\n",
      "Epoch 181/200, Train Loss: 0.000017, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.776930, Val Acc: 61.68%, Val-Class-Acc: {0: '52.17%', 1: '71.20%'}, LR: 0.000185\n",
      "Epoch 182/200, Train Loss: 0.000014, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.763977, Val Acc: 61.14%, Val-Class-Acc: {0: '52.72%', 1: '69.57%'}, LR: 0.000185\n",
      "Epoch 183/200, Train Loss: 0.000020, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.746912, Val Acc: 60.87%, Val-Class-Acc: {0: '53.26%', 1: '68.48%'}, LR: 0.000185\n",
      "Epoch 184/200, Train Loss: 0.000014, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.757593, Val Acc: 61.41%, Val-Class-Acc: {0: '53.80%', 1: '69.02%'}, LR: 0.000185\n",
      "Epoch 185/200, Train Loss: 0.000026, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.796449, Val Acc: 61.68%, Val-Class-Acc: {0: '50.54%', 1: '72.83%'}, LR: 0.000185\n",
      "Epoch 186/200, Train Loss: 0.000010, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.758191, Val Acc: 61.41%, Val-Class-Acc: {0: '52.17%', 1: '70.65%'}, LR: 0.000185\n",
      "Epoch 187/200, Train Loss: 0.000018, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.802995, Val Acc: 61.41%, Val-Class-Acc: {0: '51.63%', 1: '71.20%'}, LR: 0.000185\n",
      "Epoch 188/200, Train Loss: 0.000023, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.823222, Val Acc: 61.68%, Val-Class-Acc: {0: '51.63%', 1: '71.74%'}, LR: 0.000185\n",
      "Epoch 189/200, Train Loss: 0.000018, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.752381, Val Acc: 61.14%, Val-Class-Acc: {0: '53.26%', 1: '69.02%'}, LR: 0.000185\n",
      "Epoch 190/200, Train Loss: 0.000010, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.776372, Val Acc: 61.96%, Val-Class-Acc: {0: '53.26%', 1: '70.65%'}, LR: 0.000185\n",
      "Epoch 191/200, Train Loss: 0.000016, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.782309, Val Acc: 61.41%, Val-Class-Acc: {0: '52.72%', 1: '70.11%'}, LR: 0.000167\n",
      "Epoch 192/200, Train Loss: 0.000017, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.764492, Val Acc: 61.14%, Val-Class-Acc: {0: '52.72%', 1: '69.57%'}, LR: 0.000167\n",
      "Epoch 193/200, Train Loss: 0.000013, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.790363, Val Acc: 61.14%, Val-Class-Acc: {0: '52.72%', 1: '69.57%'}, LR: 0.000167\n",
      "Epoch 194/200, Train Loss: 0.000009, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.806751, Val Acc: 62.23%, Val-Class-Acc: {0: '51.63%', 1: '72.83%'}, LR: 0.000167\n",
      "Epoch 195/200, Train Loss: 0.000012, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.799565, Val Acc: 61.96%, Val-Class-Acc: {0: '52.17%', 1: '71.74%'}, LR: 0.000167\n",
      "Epoch 196/200, Train Loss: 0.000011, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.779137, Val Acc: 60.87%, Val-Class-Acc: {0: '52.17%', 1: '69.57%'}, LR: 0.000167\n",
      "Epoch 197/200, Train Loss: 0.000015, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.764798, Val Acc: 61.68%, Val-Class-Acc: {0: '53.26%', 1: '70.11%'}, LR: 0.000167\n",
      "Epoch 198/200, Train Loss: 0.000010, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.760415, Val Acc: 60.87%, Val-Class-Acc: {0: '53.80%', 1: '67.93%'}, LR: 0.000167\n",
      "Epoch 199/200, Train Loss: 0.000017, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.765861, Val Acc: 60.60%, Val-Class-Acc: {0: '53.80%', 1: '67.39%'}, LR: 0.000167\n",
      "Epoch 200/200, Train Loss: 0.000019, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.765199, Val Acc: 61.14%, Val-Class-Acc: {0: '53.80%', 1: '68.48%'}, LR: 0.000167\n",
      "\n",
      "🏆 Best model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_best.pth (Val Accuracy: 64.40%)\n",
      "\n",
      "📌 Final model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_final.pth\n",
      "\n",
      "🎯 Top 5 Best Models:\n",
      "Epoch 4, Train Loss: 0.018557, Train-Acc: {0: '100.00%', 1: '100.00%'},\n",
      "Val Loss: 0.861587, Val Acc: 64.40%, Val-Class-Acc: {0: '61.96%', 1: '66.85%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_4.pth\n",
      "Epoch 28, Train Loss: 0.000348, Train-Acc: {0: '100.00%', 1: '100.00%'},\n",
      "Val Loss: 1.358449, Val Acc: 63.04%, Val-Class-Acc: {0: '52.17%', 1: '73.91%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_28.pth\n",
      "Epoch 3, Train Loss: 0.077726, Train-Acc: {0: '97.41%', 1: '98.23%'},\n",
      "Val Loss: 0.813031, Val Acc: 63.04%, Val-Class-Acc: {0: '66.30%', 1: '59.78%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_3.pth\n",
      "Epoch 23, Train Loss: 0.000475, Train-Acc: {0: '100.00%', 1: '100.00%'},\n",
      "Val Loss: 1.272149, Val Acc: 62.77%, Val-Class-Acc: {0: '55.43%', 1: '70.11%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_23.pth\n",
      "Epoch 15, Train Loss: 0.000722, Train-Acc: {0: '100.00%', 1: '100.00%'},\n",
      "Val Loss: 1.197543, Val Acc: 62.77%, Val-Class-Acc: {0: '52.17%', 1: '73.37%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/MLP/MLP_epoch_15.pth\n",
      "\n",
      "🧠 Model Summary:\n",
      "Total Parameters: 62,496,770\n",
      "Model Size (float32): 238.41 MB\n",
      "Total Training Time: 53.49 seconds\n"
     ]
    }
   ],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# ==== Model Hyperparameters ====\n",
    "input_size = X_train.shape[1] * X_train.shape[2]  # 5000 × 12 = 60000\n",
    "hidden_size = 1024\n",
    "output_size = len(np.unique(y_train))  # Period 1 通常為 2 類（NSR 與 OTHER）\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "dropout = 0.0\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "print(\"✅ input shape:\", X_train.shape)\n",
    "print(\"✅ unique y_train:\", np.unique(y_train))\n",
    "print(\"✅ unique y_test :\", np.unique(y_test))\n",
    "assert np.max(y_train) < output_size\n",
    "assert np.max(y_test) < output_size\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/MLP\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Model ====\n",
    "model = MLP(\n",
    "    input_dim=input_size,\n",
    "    hidden_dim=hidden_size,\n",
    "    output_dim=output_size,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "# ==== Optimizer and Training ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "result_summary = train_model_general_classifier(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name='MLP',\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del model, X_train, y_train, X_test, y_test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed8c049",
   "metadata": {},
   "source": [
    "### ResNet 18 - 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597e8f2",
   "metadata": {},
   "source": [
    "#### No Init Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90039f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Automatically selected GPU:\n",
      "    - CUDA Device ID : 1\n",
      "    - Memory Used    : 1379 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "✅ input shape: (1468, 5000, 12)\n",
      "✅ unique y_train: [0 1]\n",
      "✅ unique y_test : [0 1]\n",
      "\n",
      "🚀 'train_model_general_classifier' started.\n",
      "✅ Removed existing folder: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Data Overview:\n",
      "X_train: torch.Size([1468, 5000, 12]), y_train: torch.Size([1468])\n",
      "X_val: torch.Size([368, 5000, 12]), y_val: torch.Size([368])\n",
      "Epoch 1/200, Train Loss: 0.484366, Train-Class-Acc: {0: '78.61%', 1: '75.20%'}\n",
      "Val Loss: 0.520067, Val Acc: 75.82%, Val-Class-Acc: {0: '95.11%', 1: '56.52%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.388365, Train-Class-Acc: {0: '84.60%', 1: '78.20%'}\n",
      "Val Loss: 0.402622, Val Acc: 83.42%, Val-Class-Acc: {0: '75.54%', 1: '91.30%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.358777, Train-Class-Acc: {0: '86.38%', 1: '79.84%'}\n",
      "Val Loss: 0.371163, Val Acc: 84.51%, Val-Class-Acc: {0: '88.59%', 1: '80.43%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.348711, Train-Class-Acc: {0: '88.83%', 1: '81.20%'}\n",
      "Val Loss: 0.403566, Val Acc: 82.61%, Val-Class-Acc: {0: '80.98%', 1: '84.24%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.329307, Train-Class-Acc: {0: '89.92%', 1: '79.16%'}\n",
      "Val Loss: 0.457996, Val Acc: 77.99%, Val-Class-Acc: {0: '81.52%', 1: '74.46%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.308524, Train-Class-Acc: {0: '88.69%', 1: '82.83%'}\n",
      "Val Loss: 0.342745, Val Acc: 86.14%, Val-Class-Acc: {0: '86.41%', 1: '85.87%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_1.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_6.pth\n",
      "Epoch 7/200, Train Loss: 0.311840, Train-Class-Acc: {0: '88.96%', 1: '82.83%'}\n",
      "Val Loss: 0.351491, Val Acc: 85.33%, Val-Class-Acc: {0: '95.65%', 1: '75.00%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_5.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.278598, Train-Class-Acc: {0: '90.87%', 1: '84.33%'}\n",
      "Val Loss: 0.412721, Val Acc: 82.07%, Val-Class-Acc: {0: '72.83%', 1: '91.30%'}, LR: 0.001000\n",
      "Epoch 9/200, Train Loss: 0.282265, Train-Class-Acc: {0: '89.92%', 1: '85.29%'}\n",
      "Val Loss: 0.391554, Val Acc: 86.68%, Val-Class-Acc: {0: '95.11%', 1: '78.26%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_4.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.297356, Train-Class-Acc: {0: '87.47%', 1: '84.60%'}\n",
      "Val Loss: 0.500523, Val Acc: 80.71%, Val-Class-Acc: {0: '66.30%', 1: '95.11%'}, LR: 0.001000\n",
      "Epoch 11/200, Train Loss: 0.260676, Train-Class-Acc: {0: '91.42%', 1: '88.28%'}\n",
      "Val Loss: 0.386485, Val Acc: 83.97%, Val-Class-Acc: {0: '88.59%', 1: '79.35%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_2.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_11.pth\n",
      "Epoch 12/200, Train Loss: 0.245733, Train-Class-Acc: {0: '91.69%', 1: '87.47%'}\n",
      "Val Loss: 0.334056, Val Acc: 86.14%, Val-Class-Acc: {0: '89.13%', 1: '83.15%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_11.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_12.pth\n",
      "Epoch 13/200, Train Loss: 0.245493, Train-Class-Acc: {0: '92.23%', 1: '86.10%'}\n",
      "Val Loss: 0.397917, Val Acc: 83.70%, Val-Class-Acc: {0: '72.28%', 1: '95.11%'}, LR: 0.001000\n",
      "Epoch 14/200, Train Loss: 0.242167, Train-Class-Acc: {0: '91.96%', 1: '88.96%'}\n",
      "Val Loss: 0.386497, Val Acc: 86.96%, Val-Class-Acc: {0: '90.76%', 1: '83.15%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_3.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_14.pth\n",
      "Epoch 15/200, Train Loss: 0.211830, Train-Class-Acc: {0: '93.87%', 1: '89.37%'}\n",
      "Val Loss: 0.367632, Val Acc: 88.04%, Val-Class-Acc: {0: '90.76%', 1: '85.33%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_7.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_15.pth\n",
      "Epoch 16/200, Train Loss: 0.210111, Train-Class-Acc: {0: '92.92%', 1: '89.10%'}\n",
      "Val Loss: 0.347673, Val Acc: 88.86%, Val-Class-Acc: {0: '89.13%', 1: '88.59%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_6.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_16.pth\n",
      "Epoch 17/200, Train Loss: 0.203446, Train-Class-Acc: {0: '93.60%', 1: '89.65%'}\n",
      "Val Loss: 0.451215, Val Acc: 80.43%, Val-Class-Acc: {0: '72.28%', 1: '88.59%'}, LR: 0.001000\n",
      "Epoch 18/200, Train Loss: 0.187087, Train-Class-Acc: {0: '94.82%', 1: '91.01%'}\n",
      "Val Loss: 0.388979, Val Acc: 85.33%, Val-Class-Acc: {0: '86.96%', 1: '83.70%'}, LR: 0.001000\n",
      "Epoch 19/200, Train Loss: 0.187709, Train-Class-Acc: {0: '93.19%', 1: '92.10%'}\n",
      "Val Loss: 0.399310, Val Acc: 85.87%, Val-Class-Acc: {0: '91.85%', 1: '79.89%'}, LR: 0.001000\n",
      "Epoch 20/200, Train Loss: 0.147908, Train-Class-Acc: {0: '95.23%', 1: '92.51%'}\n",
      "Val Loss: 0.410946, Val Acc: 87.50%, Val-Class-Acc: {0: '93.48%', 1: '81.52%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_12.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_20.pth\n",
      "Epoch 21/200, Train Loss: 0.157799, Train-Class-Acc: {0: '94.96%', 1: '92.23%'}\n",
      "Val Loss: 0.425978, Val Acc: 87.23%, Val-Class-Acc: {0: '86.96%', 1: '87.50%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_9.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_21.pth\n",
      "Epoch 22/200, Train Loss: 0.137978, Train-Class-Acc: {0: '95.10%', 1: '93.73%'}\n",
      "Val Loss: 0.605324, Val Acc: 81.25%, Val-Class-Acc: {0: '96.20%', 1: '66.30%'}, LR: 0.001000\n",
      "Epoch 23/200, Train Loss: 0.164701, Train-Class-Acc: {0: '94.55%', 1: '91.28%'}\n",
      "Val Loss: 0.595512, Val Acc: 83.70%, Val-Class-Acc: {0: '77.17%', 1: '90.22%'}, LR: 0.001000\n",
      "Epoch 24/200, Train Loss: 0.120683, Train-Class-Acc: {0: '96.05%', 1: '94.14%'}\n",
      "Val Loss: 0.668442, Val Acc: 79.35%, Val-Class-Acc: {0: '63.59%', 1: '95.11%'}, LR: 0.000900\n",
      "Epoch 25/200, Train Loss: 0.121877, Train-Class-Acc: {0: '95.23%', 1: '95.10%'}\n",
      "Val Loss: 0.469834, Val Acc: 86.14%, Val-Class-Acc: {0: '91.30%', 1: '80.98%'}, LR: 0.000900\n",
      "Epoch 26/200, Train Loss: 0.136212, Train-Class-Acc: {0: '95.64%', 1: '93.05%'}\n",
      "Val Loss: 0.549180, Val Acc: 83.15%, Val-Class-Acc: {0: '89.67%', 1: '76.63%'}, LR: 0.000900\n",
      "Epoch 27/200, Train Loss: 0.104780, Train-Class-Acc: {0: '95.91%', 1: '95.37%'}\n",
      "Val Loss: 0.597619, Val Acc: 84.24%, Val-Class-Acc: {0: '86.41%', 1: '82.07%'}, LR: 0.000900\n",
      "Epoch 28/200, Train Loss: 0.115720, Train-Class-Acc: {0: '96.05%', 1: '94.82%'}\n",
      "Val Loss: 0.518910, Val Acc: 87.50%, Val-Class-Acc: {0: '88.04%', 1: '86.96%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_14.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_28.pth\n",
      "Epoch 29/200, Train Loss: 0.125886, Train-Class-Acc: {0: '96.73%', 1: '94.01%'}\n",
      "Val Loss: 0.749177, Val Acc: 83.97%, Val-Class-Acc: {0: '96.20%', 1: '71.74%'}, LR: 0.000900\n",
      "Epoch 30/200, Train Loss: 0.147695, Train-Class-Acc: {0: '95.64%', 1: '93.05%'}\n",
      "Val Loss: 0.486947, Val Acc: 88.04%, Val-Class-Acc: {0: '90.22%', 1: '85.87%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_21.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_30.pth\n",
      "Epoch 31/200, Train Loss: 0.113761, Train-Class-Acc: {0: '96.46%', 1: '95.50%'}\n",
      "Val Loss: 0.643369, Val Acc: 83.15%, Val-Class-Acc: {0: '94.02%', 1: '72.28%'}, LR: 0.000900\n",
      "Epoch 32/200, Train Loss: 0.061393, Train-Class-Acc: {0: '98.37%', 1: '97.00%'}\n",
      "Val Loss: 0.574783, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000900\n",
      "Epoch 33/200, Train Loss: 0.065358, Train-Class-Acc: {0: '97.82%', 1: '97.55%'}\n",
      "Val Loss: 0.697903, Val Acc: 83.97%, Val-Class-Acc: {0: '88.04%', 1: '79.89%'}, LR: 0.000900\n",
      "Epoch 34/200, Train Loss: 0.094859, Train-Class-Acc: {0: '97.00%', 1: '95.64%'}\n",
      "Val Loss: 0.721028, Val Acc: 85.87%, Val-Class-Acc: {0: '89.13%', 1: '82.61%'}, LR: 0.000900\n",
      "Epoch 35/200, Train Loss: 0.079773, Train-Class-Acc: {0: '97.14%', 1: '97.68%'}\n",
      "Val Loss: 0.661482, Val Acc: 82.61%, Val-Class-Acc: {0: '86.96%', 1: '78.26%'}, LR: 0.000810\n",
      "Epoch 36/200, Train Loss: 0.096468, Train-Class-Acc: {0: '97.55%', 1: '95.23%'}\n",
      "Val Loss: 0.642684, Val Acc: 84.24%, Val-Class-Acc: {0: '82.07%', 1: '86.41%'}, LR: 0.000810\n",
      "Epoch 37/200, Train Loss: 0.066655, Train-Class-Acc: {0: '97.28%', 1: '97.55%'}\n",
      "Val Loss: 0.645538, Val Acc: 85.87%, Val-Class-Acc: {0: '89.67%', 1: '82.07%'}, LR: 0.000810\n",
      "Epoch 38/200, Train Loss: 0.041159, Train-Class-Acc: {0: '99.05%', 1: '98.23%'}\n",
      "Val Loss: 0.673898, Val Acc: 84.78%, Val-Class-Acc: {0: '89.67%', 1: '79.89%'}, LR: 0.000810\n",
      "Epoch 39/200, Train Loss: 0.043987, Train-Class-Acc: {0: '97.96%', 1: '98.77%'}\n",
      "Val Loss: 0.805633, Val Acc: 85.05%, Val-Class-Acc: {0: '92.39%', 1: '77.72%'}, LR: 0.000810\n",
      "Epoch 40/200, Train Loss: 0.027633, Train-Class-Acc: {0: '99.59%', 1: '99.18%'}\n",
      "Val Loss: 0.711833, Val Acc: 82.07%, Val-Class-Acc: {0: '79.35%', 1: '84.78%'}, LR: 0.000810\n",
      "Epoch 41/200, Train Loss: 0.023914, Train-Class-Acc: {0: '99.32%', 1: '99.18%'}\n",
      "Val Loss: 0.723248, Val Acc: 84.51%, Val-Class-Acc: {0: '82.07%', 1: '86.96%'}, LR: 0.000810\n",
      "Epoch 42/200, Train Loss: 0.032447, Train-Class-Acc: {0: '98.77%', 1: '99.05%'}\n",
      "Val Loss: 0.830406, Val Acc: 84.78%, Val-Class-Acc: {0: '88.04%', 1: '81.52%'}, LR: 0.000810\n",
      "Epoch 43/200, Train Loss: 0.011583, Train-Class-Acc: {0: '99.86%', 1: '99.86%'}\n",
      "Val Loss: 0.787054, Val Acc: 83.15%, Val-Class-Acc: {0: '84.78%', 1: '81.52%'}, LR: 0.000810\n",
      "Epoch 44/200, Train Loss: 0.011609, Train-Class-Acc: {0: '99.46%', 1: '99.73%'}\n",
      "Val Loss: 0.942164, Val Acc: 83.70%, Val-Class-Acc: {0: '90.76%', 1: '76.63%'}, LR: 0.000810\n",
      "Epoch 45/200, Train Loss: 0.021002, Train-Class-Acc: {0: '99.46%', 1: '98.77%'}\n",
      "Val Loss: 0.887219, Val Acc: 85.60%, Val-Class-Acc: {0: '86.41%', 1: '84.78%'}, LR: 0.000810\n",
      "Epoch 46/200, Train Loss: 0.022221, Train-Class-Acc: {0: '99.18%', 1: '98.77%'}\n",
      "Val Loss: 0.799593, Val Acc: 84.78%, Val-Class-Acc: {0: '86.96%', 1: '82.61%'}, LR: 0.000729\n",
      "Epoch 47/200, Train Loss: 0.023786, Train-Class-Acc: {0: '99.32%', 1: '99.46%'}\n",
      "Val Loss: 0.949816, Val Acc: 85.33%, Val-Class-Acc: {0: '91.85%', 1: '78.80%'}, LR: 0.000729\n",
      "Epoch 48/200, Train Loss: 0.066293, Train-Class-Acc: {0: '98.09%', 1: '97.28%'}\n",
      "Val Loss: 0.834645, Val Acc: 85.33%, Val-Class-Acc: {0: '79.35%', 1: '91.30%'}, LR: 0.000729\n",
      "Epoch 49/200, Train Loss: 0.063158, Train-Class-Acc: {0: '97.41%', 1: '97.82%'}\n",
      "Val Loss: 1.003962, Val Acc: 84.51%, Val-Class-Acc: {0: '91.30%', 1: '77.72%'}, LR: 0.000729\n",
      "Epoch 50/200, Train Loss: 0.056715, Train-Class-Acc: {0: '98.37%', 1: '97.96%'}\n",
      "Val Loss: 1.012802, Val Acc: 82.07%, Val-Class-Acc: {0: '93.48%', 1: '70.65%'}, LR: 0.000729\n",
      "Epoch 51/200, Train Loss: 0.046857, Train-Class-Acc: {0: '98.64%', 1: '98.09%'}\n",
      "Val Loss: 0.806226, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000729\n",
      "Epoch 52/200, Train Loss: 0.027691, Train-Class-Acc: {0: '98.64%', 1: '99.73%'}\n",
      "Val Loss: 0.869774, Val Acc: 84.78%, Val-Class-Acc: {0: '91.30%', 1: '78.26%'}, LR: 0.000729\n",
      "Epoch 53/200, Train Loss: 0.015611, Train-Class-Acc: {0: '99.59%', 1: '99.32%'}\n",
      "Val Loss: 0.852398, Val Acc: 83.70%, Val-Class-Acc: {0: '83.15%', 1: '84.24%'}, LR: 0.000729\n",
      "Epoch 54/200, Train Loss: 0.016485, Train-Class-Acc: {0: '99.18%', 1: '99.46%'}\n",
      "Val Loss: 0.915659, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000729\n",
      "Epoch 55/200, Train Loss: 0.025181, Train-Class-Acc: {0: '99.18%', 1: '98.50%'}\n",
      "Val Loss: 0.882325, Val Acc: 84.78%, Val-Class-Acc: {0: '92.93%', 1: '76.63%'}, LR: 0.000729\n",
      "Epoch 56/200, Train Loss: 0.034934, Train-Class-Acc: {0: '98.91%', 1: '98.77%'}\n",
      "Val Loss: 0.785374, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000729\n",
      "Epoch 57/200, Train Loss: 0.018815, Train-Class-Acc: {0: '99.32%', 1: '99.32%'}\n",
      "Val Loss: 0.899002, Val Acc: 85.33%, Val-Class-Acc: {0: '89.13%', 1: '81.52%'}, LR: 0.000656\n",
      "Epoch 58/200, Train Loss: 0.005339, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.827572, Val Acc: 84.78%, Val-Class-Acc: {0: '84.78%', 1: '84.78%'}, LR: 0.000656\n",
      "Epoch 59/200, Train Loss: 0.004673, Train-Class-Acc: {0: '99.73%', 1: '100.00%'}\n",
      "Val Loss: 0.820039, Val Acc: 83.70%, Val-Class-Acc: {0: '84.78%', 1: '82.61%'}, LR: 0.000656\n",
      "Epoch 60/200, Train Loss: 0.001942, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.861300, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000656\n",
      "Epoch 61/200, Train Loss: 0.001086, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.871650, Val Acc: 85.60%, Val-Class-Acc: {0: '89.13%', 1: '82.07%'}, LR: 0.000656\n",
      "Epoch 62/200, Train Loss: 0.002657, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.911224, Val Acc: 83.70%, Val-Class-Acc: {0: '84.24%', 1: '83.15%'}, LR: 0.000656\n",
      "Epoch 63/200, Train Loss: 0.000865, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.919205, Val Acc: 85.87%, Val-Class-Acc: {0: '89.67%', 1: '82.07%'}, LR: 0.000656\n",
      "Epoch 64/200, Train Loss: 0.000808, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.917878, Val Acc: 85.87%, Val-Class-Acc: {0: '89.13%', 1: '82.61%'}, LR: 0.000656\n",
      "Epoch 65/200, Train Loss: 0.000532, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.918601, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.000656\n",
      "Epoch 66/200, Train Loss: 0.001081, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.918668, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000656\n",
      "Epoch 67/200, Train Loss: 0.000621, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.915186, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000656\n",
      "Epoch 68/200, Train Loss: 0.001935, Train-Class-Acc: {0: '100.00%', 1: '99.86%'}\n",
      "Val Loss: 0.950872, Val Acc: 85.87%, Val-Class-Acc: {0: '89.13%', 1: '82.61%'}, LR: 0.000590\n",
      "Epoch 69/200, Train Loss: 0.001595, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.945114, Val Acc: 85.05%, Val-Class-Acc: {0: '86.41%', 1: '83.70%'}, LR: 0.000590\n",
      "Epoch 70/200, Train Loss: 0.000611, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.962700, Val Acc: 85.33%, Val-Class-Acc: {0: '89.67%', 1: '80.98%'}, LR: 0.000590\n",
      "Epoch 71/200, Train Loss: 0.000685, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.970612, Val Acc: 85.33%, Val-Class-Acc: {0: '89.13%', 1: '81.52%'}, LR: 0.000590\n",
      "Epoch 72/200, Train Loss: 0.002354, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.018436, Val Acc: 84.78%, Val-Class-Acc: {0: '89.67%', 1: '79.89%'}, LR: 0.000590\n",
      "Epoch 73/200, Train Loss: 0.001262, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.976023, Val Acc: 84.51%, Val-Class-Acc: {0: '87.50%', 1: '81.52%'}, LR: 0.000590\n",
      "Epoch 74/200, Train Loss: 0.000878, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.017941, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 75/200, Train Loss: 0.000172, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.023907, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 76/200, Train Loss: 0.000215, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.032622, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 77/200, Train Loss: 0.000440, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.015276, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 78/200, Train Loss: 0.002157, Train-Class-Acc: {0: '99.86%', 1: '99.86%'}\n",
      "Val Loss: 1.064457, Val Acc: 85.87%, Val-Class-Acc: {0: '91.30%', 1: '80.43%'}, LR: 0.000590\n",
      "Epoch 79/200, Train Loss: 0.001300, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.938675, Val Acc: 85.60%, Val-Class-Acc: {0: '86.96%', 1: '84.24%'}, LR: 0.000531\n",
      "Epoch 80/200, Train Loss: 0.000993, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.979596, Val Acc: 85.87%, Val-Class-Acc: {0: '89.67%', 1: '82.07%'}, LR: 0.000531\n",
      "Epoch 81/200, Train Loss: 0.001455, Train-Class-Acc: {0: '100.00%', 1: '99.86%'}\n",
      "Val Loss: 1.000214, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 82/200, Train Loss: 0.001252, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.018678, Val Acc: 86.41%, Val-Class-Acc: {0: '89.67%', 1: '83.15%'}, LR: 0.000531\n",
      "Epoch 83/200, Train Loss: 0.000704, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.994022, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 84/200, Train Loss: 0.000574, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.017678, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 85/200, Train Loss: 0.000301, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.034467, Val Acc: 85.33%, Val-Class-Acc: {0: '86.96%', 1: '83.70%'}, LR: 0.000531\n",
      "Epoch 86/200, Train Loss: 0.000188, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.041169, Val Acc: 85.60%, Val-Class-Acc: {0: '88.04%', 1: '83.15%'}, LR: 0.000531\n",
      "Epoch 87/200, Train Loss: 0.000319, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.048110, Val Acc: 85.60%, Val-Class-Acc: {0: '88.04%', 1: '83.15%'}, LR: 0.000531\n",
      "Epoch 88/200, Train Loss: 0.000241, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.045626, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 89/200, Train Loss: 0.000257, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.037313, Val Acc: 84.78%, Val-Class-Acc: {0: '85.87%', 1: '83.70%'}, LR: 0.000531\n",
      "Epoch 90/200, Train Loss: 0.000125, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.041219, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000478\n",
      "Epoch 91/200, Train Loss: 0.000108, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.037660, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000478\n",
      "Epoch 92/200, Train Loss: 0.000192, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.048903, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000478\n",
      "Epoch 93/200, Train Loss: 0.000279, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.045101, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000478\n",
      "Epoch 94/200, Train Loss: 0.000237, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.040867, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000478\n",
      "Epoch 95/200, Train Loss: 0.000291, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.055053, Val Acc: 85.87%, Val-Class-Acc: {0: '89.67%', 1: '82.07%'}, LR: 0.000478\n",
      "Epoch 96/200, Train Loss: 0.000099, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.045142, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000478\n",
      "Epoch 97/200, Train Loss: 0.000132, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.055884, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000478\n",
      "Epoch 98/200, Train Loss: 0.000111, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.055613, Val Acc: 85.87%, Val-Class-Acc: {0: '88.59%', 1: '83.15%'}, LR: 0.000478\n",
      "Epoch 99/200, Train Loss: 0.000176, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.052390, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000478\n",
      "Epoch 100/200, Train Loss: 0.000103, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.055038, Val Acc: 85.05%, Val-Class-Acc: {0: '86.41%', 1: '83.70%'}, LR: 0.000478\n",
      "Epoch 101/200, Train Loss: 0.000215, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.055845, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000430\n",
      "Epoch 102/200, Train Loss: 0.000112, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.048127, Val Acc: 85.60%, Val-Class-Acc: {0: '88.04%', 1: '83.15%'}, LR: 0.000430\n",
      "Epoch 103/200, Train Loss: 0.000118, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.048331, Val Acc: 84.51%, Val-Class-Acc: {0: '85.87%', 1: '83.15%'}, LR: 0.000430\n",
      "Epoch 104/200, Train Loss: 0.000083, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.067782, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000430\n",
      "Epoch 105/200, Train Loss: 0.000150, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.067747, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000430\n",
      "Epoch 106/200, Train Loss: 0.000107, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.063607, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000430\n",
      "Epoch 107/200, Train Loss: 0.000161, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.071121, Val Acc: 85.33%, Val-Class-Acc: {0: '89.13%', 1: '81.52%'}, LR: 0.000430\n",
      "Epoch 108/200, Train Loss: 0.000084, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.064690, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000430\n",
      "Epoch 109/200, Train Loss: 0.000101, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.075032, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000430\n",
      "Epoch 110/200, Train Loss: 0.000358, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.059361, Val Acc: 85.87%, Val-Class-Acc: {0: '86.96%', 1: '84.78%'}, LR: 0.000430\n",
      "Epoch 111/200, Train Loss: 0.000168, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.065337, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000430\n",
      "Epoch 112/200, Train Loss: 0.000335, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.043936, Val Acc: 86.41%, Val-Class-Acc: {0: '89.67%', 1: '83.15%'}, LR: 0.000387\n",
      "Epoch 113/200, Train Loss: 0.000565, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.037556, Val Acc: 85.87%, Val-Class-Acc: {0: '85.87%', 1: '85.87%'}, LR: 0.000387\n",
      "Epoch 114/200, Train Loss: 0.000400, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.067027, Val Acc: 86.41%, Val-Class-Acc: {0: '89.67%', 1: '83.15%'}, LR: 0.000387\n",
      "Epoch 115/200, Train Loss: 0.000225, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.066877, Val Acc: 86.41%, Val-Class-Acc: {0: '89.13%', 1: '83.70%'}, LR: 0.000387\n",
      "Epoch 116/200, Train Loss: 0.000114, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.076483, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000387\n",
      "Epoch 117/200, Train Loss: 0.000715, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.234284, Val Acc: 84.24%, Val-Class-Acc: {0: '84.78%', 1: '83.70%'}, LR: 0.000387\n",
      "Epoch 118/200, Train Loss: 0.000634, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.220786, Val Acc: 85.87%, Val-Class-Acc: {0: '88.04%', 1: '83.70%'}, LR: 0.000387\n",
      "Epoch 119/200, Train Loss: 0.000534, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.128243, Val Acc: 84.51%, Val-Class-Acc: {0: '85.87%', 1: '83.15%'}, LR: 0.000387\n",
      "Epoch 120/200, Train Loss: 0.000143, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.139296, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000387\n",
      "Epoch 121/200, Train Loss: 0.000180, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.123488, Val Acc: 84.24%, Val-Class-Acc: {0: '86.96%', 1: '81.52%'}, LR: 0.000387\n",
      "Epoch 122/200, Train Loss: 0.000209, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.141970, Val Acc: 84.24%, Val-Class-Acc: {0: '86.96%', 1: '81.52%'}, LR: 0.000387\n",
      "Epoch 123/200, Train Loss: 0.000085, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.141320, Val Acc: 84.24%, Val-Class-Acc: {0: '86.96%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 124/200, Train Loss: 0.000088, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.156250, Val Acc: 85.05%, Val-Class-Acc: {0: '88.59%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 125/200, Train Loss: 0.000113, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.154933, Val Acc: 84.78%, Val-Class-Acc: {0: '88.04%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 126/200, Train Loss: 0.000124, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.144805, Val Acc: 84.78%, Val-Class-Acc: {0: '86.96%', 1: '82.61%'}, LR: 0.000349\n",
      "Epoch 127/200, Train Loss: 0.000058, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.136729, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000349\n",
      "Epoch 128/200, Train Loss: 0.000088, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.153991, Val Acc: 85.05%, Val-Class-Acc: {0: '88.59%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 129/200, Train Loss: 0.000047, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.131090, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000349\n",
      "Epoch 130/200, Train Loss: 0.000070, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.133575, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000349\n",
      "Epoch 131/200, Train Loss: 0.000126, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.138243, Val Acc: 84.51%, Val-Class-Acc: {0: '85.87%', 1: '83.15%'}, LR: 0.000349\n",
      "Epoch 132/200, Train Loss: 0.000177, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.135520, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000349\n",
      "Epoch 133/200, Train Loss: 0.000134, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.116949, Val Acc: 85.33%, Val-Class-Acc: {0: '86.41%', 1: '84.24%'}, LR: 0.000349\n",
      "Epoch 134/200, Train Loss: 0.000062, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.130571, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000314\n",
      "Epoch 135/200, Train Loss: 0.000063, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.128990, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000314\n",
      "Epoch 136/200, Train Loss: 0.000150, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.138449, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000314\n",
      "Epoch 137/200, Train Loss: 0.000047, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.132131, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000314\n",
      "Epoch 138/200, Train Loss: 0.000046, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.137328, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000314\n",
      "Epoch 139/200, Train Loss: 0.000035, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.131179, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000314\n",
      "Epoch 140/200, Train Loss: 0.000052, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.140157, Val Acc: 85.60%, Val-Class-Acc: {0: '89.13%', 1: '82.07%'}, LR: 0.000314\n",
      "Epoch 141/200, Train Loss: 0.000034, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.139775, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000314\n",
      "Epoch 142/200, Train Loss: 0.000125, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.127082, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000314\n",
      "Epoch 143/200, Train Loss: 0.000061, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.121976, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000314\n",
      "Epoch 144/200, Train Loss: 0.000030, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.135663, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000314\n",
      "Epoch 145/200, Train Loss: 0.000039, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.144466, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000282\n",
      "Epoch 146/200, Train Loss: 0.000157, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.163896, Val Acc: 85.60%, Val-Class-Acc: {0: '89.13%', 1: '82.07%'}, LR: 0.000282\n",
      "Epoch 147/200, Train Loss: 0.000125, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.145491, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000282\n",
      "Epoch 148/200, Train Loss: 0.000059, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.150401, Val Acc: 84.78%, Val-Class-Acc: {0: '86.96%', 1: '82.61%'}, LR: 0.000282\n",
      "Epoch 149/200, Train Loss: 0.000038, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.149407, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000282\n",
      "Epoch 150/200, Train Loss: 0.000084, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.157541, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.000282\n",
      "Epoch 151/200, Train Loss: 0.000037, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.157436, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.000282\n",
      "Epoch 152/200, Train Loss: 0.000062, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.148290, Val Acc: 85.87%, Val-Class-Acc: {0: '89.13%', 1: '82.61%'}, LR: 0.000282\n",
      "Epoch 153/200, Train Loss: 0.000047, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.152683, Val Acc: 86.14%, Val-Class-Acc: {0: '90.22%', 1: '82.07%'}, LR: 0.000282\n",
      "Epoch 154/200, Train Loss: 0.000042, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.151528, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.000282\n",
      "Epoch 155/200, Train Loss: 0.000074, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.151252, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000282\n",
      "Epoch 156/200, Train Loss: 0.000052, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.171390, Val Acc: 86.14%, Val-Class-Acc: {0: '90.22%', 1: '82.07%'}, LR: 0.000254\n",
      "Epoch 157/200, Train Loss: 0.000037, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.149772, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000254\n",
      "Epoch 158/200, Train Loss: 0.000070, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.157452, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000254\n",
      "Epoch 159/200, Train Loss: 0.000036, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.150356, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000254\n",
      "Epoch 160/200, Train Loss: 0.000093, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.151793, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000254\n",
      "Epoch 161/200, Train Loss: 0.000027, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.152743, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000254\n",
      "Epoch 162/200, Train Loss: 0.000091, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.163067, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000254\n",
      "Epoch 163/200, Train Loss: 0.000028, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.157261, Val Acc: 85.87%, Val-Class-Acc: {0: '89.13%', 1: '82.61%'}, LR: 0.000254\n",
      "Epoch 164/200, Train Loss: 0.000012, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.159748, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000254\n",
      "Epoch 165/200, Train Loss: 0.000083, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.170012, Val Acc: 85.60%, Val-Class-Acc: {0: '89.13%', 1: '82.07%'}, LR: 0.000254\n",
      "Epoch 166/200, Train Loss: 0.000038, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.181270, Val Acc: 85.60%, Val-Class-Acc: {0: '89.13%', 1: '82.07%'}, LR: 0.000254\n",
      "Epoch 167/200, Train Loss: 0.000031, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.176625, Val Acc: 85.60%, Val-Class-Acc: {0: '89.13%', 1: '82.07%'}, LR: 0.000229\n",
      "Epoch 168/200, Train Loss: 0.000059, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.165849, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000229\n",
      "Epoch 169/200, Train Loss: 0.000030, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.173649, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000229\n",
      "Epoch 170/200, Train Loss: 0.000114, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.192817, Val Acc: 85.60%, Val-Class-Acc: {0: '89.67%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 171/200, Train Loss: 0.000068, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.167601, Val Acc: 84.78%, Val-Class-Acc: {0: '86.96%', 1: '82.61%'}, LR: 0.000229\n",
      "Epoch 172/200, Train Loss: 0.000034, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.173599, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000229\n",
      "Epoch 173/200, Train Loss: 0.000027, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.171294, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000229\n",
      "Epoch 174/200, Train Loss: 0.000017, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.180500, Val Acc: 85.33%, Val-Class-Acc: {0: '89.67%', 1: '80.98%'}, LR: 0.000229\n",
      "Epoch 175/200, Train Loss: 0.000029, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.180975, Val Acc: 85.33%, Val-Class-Acc: {0: '89.67%', 1: '80.98%'}, LR: 0.000229\n",
      "Epoch 176/200, Train Loss: 0.000021, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.176057, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000229\n",
      "Epoch 177/200, Train Loss: 0.000061, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.188463, Val Acc: 85.33%, Val-Class-Acc: {0: '89.13%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 178/200, Train Loss: 0.000031, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.199025, Val Acc: 85.60%, Val-Class-Acc: {0: '90.76%', 1: '80.43%'}, LR: 0.000206\n",
      "Epoch 179/200, Train Loss: 0.000045, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.189525, Val Acc: 85.05%, Val-Class-Acc: {0: '89.13%', 1: '80.98%'}, LR: 0.000206\n",
      "Epoch 180/200, Train Loss: 0.000027, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.189329, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000206\n",
      "Epoch 181/200, Train Loss: 0.000047, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.177727, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000206\n",
      "Epoch 182/200, Train Loss: 0.000031, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.182786, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000206\n",
      "Epoch 183/200, Train Loss: 0.000024, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.185848, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000206\n",
      "Epoch 184/200, Train Loss: 0.000017, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.186851, Val Acc: 84.78%, Val-Class-Acc: {0: '86.96%', 1: '82.61%'}, LR: 0.000206\n",
      "Epoch 185/200, Train Loss: 0.000024, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.194151, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000206\n",
      "Epoch 186/200, Train Loss: 0.000055, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.193416, Val Acc: 84.24%, Val-Class-Acc: {0: '85.87%', 1: '82.61%'}, LR: 0.000206\n",
      "Epoch 187/200, Train Loss: 0.000026, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.212911, Val Acc: 84.78%, Val-Class-Acc: {0: '88.59%', 1: '80.98%'}, LR: 0.000206\n",
      "Epoch 188/200, Train Loss: 0.000018, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.196820, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000206\n",
      "Epoch 189/200, Train Loss: 0.000039, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.199697, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 190/200, Train Loss: 0.000033, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.197586, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000185\n",
      "Epoch 191/200, Train Loss: 0.000028, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.189886, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 192/200, Train Loss: 0.000016, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.196659, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 193/200, Train Loss: 0.000017, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.189616, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 194/200, Train Loss: 0.000018, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.183972, Val Acc: 84.24%, Val-Class-Acc: {0: '85.87%', 1: '82.61%'}, LR: 0.000185\n",
      "Epoch 195/200, Train Loss: 0.000125, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.193963, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000185\n",
      "Epoch 196/200, Train Loss: 0.000045, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.189666, Val Acc: 84.78%, Val-Class-Acc: {0: '88.04%', 1: '81.52%'}, LR: 0.000185\n",
      "Epoch 197/200, Train Loss: 0.000031, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.195685, Val Acc: 84.78%, Val-Class-Acc: {0: '88.04%', 1: '81.52%'}, LR: 0.000185\n",
      "Epoch 198/200, Train Loss: 0.000014, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.202170, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 199/200, Train Loss: 0.000028, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.210687, Val Acc: 85.05%, Val-Class-Acc: {0: '89.13%', 1: '80.98%'}, LR: 0.000185\n",
      "Epoch 200/200, Train Loss: 0.000014, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.212043, Val Acc: 85.05%, Val-Class-Acc: {0: '89.13%', 1: '80.98%'}, LR: 0.000167\n",
      "\n",
      "🏆 Best model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_best.pth (Val Accuracy: 88.86%)\n",
      "\n",
      "📌 Final model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_final.pth\n",
      "\n",
      "🎯 Top 5 Best Models:\n",
      "Epoch 16, Train Loss: 0.210111, Train-Acc: {0: '92.92%', 1: '89.10%'},\n",
      "Val Loss: 0.347673, Val Acc: 88.86%, Val-Class-Acc: {0: '89.13%', 1: '88.59%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_16.pth\n",
      "Epoch 30, Train Loss: 0.147695, Train-Acc: {0: '95.64%', 1: '93.05%'},\n",
      "Val Loss: 0.486947, Val Acc: 88.04%, Val-Class-Acc: {0: '90.22%', 1: '85.87%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_30.pth\n",
      "Epoch 15, Train Loss: 0.211830, Train-Acc: {0: '93.87%', 1: '89.37%'},\n",
      "Val Loss: 0.367632, Val Acc: 88.04%, Val-Class-Acc: {0: '90.76%', 1: '85.33%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_15.pth\n",
      "Epoch 28, Train Loss: 0.115720, Train-Acc: {0: '96.05%', 1: '94.82%'},\n",
      "Val Loss: 0.518910, Val Acc: 87.50%, Val-Class-Acc: {0: '88.04%', 1: '86.96%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_28.pth\n",
      "Epoch 20, Train Loss: 0.147908, Train-Acc: {0: '95.23%', 1: '92.51%'},\n",
      "Val Loss: 0.410946, Val Acc: 87.50%, Val-Class-Acc: {0: '93.48%', 1: '81.52%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18/ResNet18_1D_epoch_20.pth\n",
      "\n",
      "🧠 Model Summary:\n",
      "Total Parameters: 3,849,858\n",
      "Model Size (float32): 14.69 MB\n",
      "Total Training Time: 128.84 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))  # Shape: (B, 5000, 12)\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# ==== Model Hyperparameters ====\n",
    "input_channels = X_train.shape[2]                  # 12 leads\n",
    "output_size = len(np.unique(y_train))              # Number of classes (e.g., 2 for Period 1)\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "dropout = 0.0                                       # Not needed for ResNet18_1D\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "print(\"✅ input shape:\", X_train.shape)\n",
    "print(\"✅ unique y_train:\", np.unique(y_train))\n",
    "print(\"✅ unique y_test :\", np.unique(y_test))\n",
    "assert np.max(y_train) < output_size\n",
    "assert np.max(y_test) < output_size\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/ResNet18\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Model ====\n",
    "model = ResNet18_1D(input_channels=input_channels, output_size=output_size).to(device)\n",
    "\n",
    "# ==== Optimizer and Training ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# ==== Train ====\n",
    "result_summary = train_model_general_classifier(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name='ResNet18_1D',\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del model, X_train, y_train, X_test, y_test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c4e46",
   "metadata": {},
   "source": [
    "#### Init Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b1b1680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Automatically selected GPU:\n",
      "    - CUDA Device ID : 2\n",
      "    - Memory Used    : 1009 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "✅ input shape: (1468, 5000, 12)\n",
      "✅ unique y_train: [0 1]\n",
      "✅ unique y_test : [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 'train_model_general_classifier' started.\n",
      "✅ Removed existing folder: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init\n",
      "\n",
      "✅ Data Overview:\n",
      "X_train: torch.Size([1468, 5000, 12]), y_train: torch.Size([1468])\n",
      "X_val: torch.Size([368, 5000, 12]), y_val: torch.Size([368])\n",
      "Epoch 1/200, Train Loss: 0.533840, Train-Class-Acc: {0: '80.65%', 1: '72.48%'}\n",
      "Val Loss: 0.531604, Val Acc: 81.79%, Val-Class-Acc: {0: '90.22%', 1: '73.37%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.373846, Train-Class-Acc: {0: '88.28%', 1: '78.47%'}\n",
      "Val Loss: 0.413599, Val Acc: 85.33%, Val-Class-Acc: {0: '83.15%', 1: '87.50%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.326138, Train-Class-Acc: {0: '87.74%', 1: '81.88%'}\n",
      "Val Loss: 0.451216, Val Acc: 77.72%, Val-Class-Acc: {0: '64.67%', 1: '90.76%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.287001, Train-Class-Acc: {0: '89.10%', 1: '84.60%'}\n",
      "Val Loss: 0.475644, Val Acc: 77.45%, Val-Class-Acc: {0: '62.50%', 1: '92.39%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.246575, Train-Class-Acc: {0: '91.55%', 1: '88.01%'}\n",
      "Val Loss: 0.364468, Val Acc: 85.60%, Val-Class-Acc: {0: '89.13%', 1: '82.07%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.198854, Train-Class-Acc: {0: '93.19%', 1: '89.78%'}\n",
      "Val Loss: 0.384643, Val Acc: 84.51%, Val-Class-Acc: {0: '84.78%', 1: '84.24%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_4.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_6.pth\n",
      "Epoch 7/200, Train Loss: 0.206020, Train-Class-Acc: {0: '92.10%', 1: '89.78%'}\n",
      "Val Loss: 0.567279, Val Acc: 82.61%, Val-Class-Acc: {0: '75.00%', 1: '90.22%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_3.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.162378, Train-Class-Acc: {0: '95.10%', 1: '91.83%'}\n",
      "Val Loss: 0.493405, Val Acc: 86.14%, Val-Class-Acc: {0: '92.39%', 1: '79.89%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_1.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_8.pth\n",
      "Epoch 9/200, Train Loss: 0.145994, Train-Class-Acc: {0: '94.69%', 1: '93.19%'}\n",
      "Val Loss: 0.560919, Val Acc: 86.96%, Val-Class-Acc: {0: '85.87%', 1: '88.04%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_7.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.145575, Train-Class-Acc: {0: '94.41%', 1: '93.60%'}\n",
      "Val Loss: 0.516588, Val Acc: 86.96%, Val-Class-Acc: {0: '87.50%', 1: '86.41%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_6.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_10.pth\n",
      "Epoch 11/200, Train Loss: 0.131488, Train-Class-Acc: {0: '97.28%', 1: '94.14%'}\n",
      "Val Loss: 0.536283, Val Acc: 82.07%, Val-Class-Acc: {0: '85.87%', 1: '78.26%'}, LR: 0.001000\n",
      "Epoch 12/200, Train Loss: 0.112987, Train-Class-Acc: {0: '95.78%', 1: '94.82%'}\n",
      "Val Loss: 0.604425, Val Acc: 85.05%, Val-Class-Acc: {0: '81.52%', 1: '88.59%'}, LR: 0.001000\n",
      "Epoch 13/200, Train Loss: 0.159668, Train-Class-Acc: {0: '94.41%', 1: '92.78%'}\n",
      "Val Loss: 0.545270, Val Acc: 84.24%, Val-Class-Acc: {0: '80.43%', 1: '88.04%'}, LR: 0.001000\n",
      "Epoch 14/200, Train Loss: 0.159058, Train-Class-Acc: {0: '94.55%', 1: '92.23%'}\n",
      "Val Loss: 0.569831, Val Acc: 81.52%, Val-Class-Acc: {0: '75.54%', 1: '87.50%'}, LR: 0.001000\n",
      "Epoch 15/200, Train Loss: 0.096812, Train-Class-Acc: {0: '96.59%', 1: '96.05%'}\n",
      "Val Loss: 0.691728, Val Acc: 82.34%, Val-Class-Acc: {0: '94.02%', 1: '70.65%'}, LR: 0.001000\n",
      "Epoch 16/200, Train Loss: 0.047728, Train-Class-Acc: {0: '98.77%', 1: '98.23%'}\n",
      "Val Loss: 0.588648, Val Acc: 84.24%, Val-Class-Acc: {0: '86.96%', 1: '81.52%'}, LR: 0.001000\n",
      "Epoch 17/200, Train Loss: 0.058118, Train-Class-Acc: {0: '98.37%', 1: '97.82%'}\n",
      "Val Loss: 0.711989, Val Acc: 83.15%, Val-Class-Acc: {0: '81.52%', 1: '84.78%'}, LR: 0.000900\n",
      "Epoch 18/200, Train Loss: 0.093402, Train-Class-Acc: {0: '96.05%', 1: '96.46%'}\n",
      "Val Loss: 0.626953, Val Acc: 84.24%, Val-Class-Acc: {0: '90.22%', 1: '78.26%'}, LR: 0.000900\n",
      "Epoch 19/200, Train Loss: 0.052855, Train-Class-Acc: {0: '98.64%', 1: '97.41%'}\n",
      "Val Loss: 0.647660, Val Acc: 84.78%, Val-Class-Acc: {0: '85.87%', 1: '83.70%'}, LR: 0.000900\n",
      "Epoch 20/200, Train Loss: 0.028177, Train-Class-Acc: {0: '99.18%', 1: '98.91%'}\n",
      "Val Loss: 0.881935, Val Acc: 84.78%, Val-Class-Acc: {0: '95.11%', 1: '74.46%'}, LR: 0.000900\n",
      "Epoch 21/200, Train Loss: 0.072951, Train-Class-Acc: {0: '97.96%', 1: '97.55%'}\n",
      "Val Loss: 1.453708, Val Acc: 72.55%, Val-Class-Acc: {0: '48.91%', 1: '96.20%'}, LR: 0.000900\n",
      "Epoch 22/200, Train Loss: 0.064017, Train-Class-Acc: {0: '97.55%', 1: '97.96%'}\n",
      "Val Loss: 0.822470, Val Acc: 84.78%, Val-Class-Acc: {0: '95.11%', 1: '74.46%'}, LR: 0.000900\n",
      "Epoch 23/200, Train Loss: 0.059934, Train-Class-Acc: {0: '97.82%', 1: '97.82%'}\n",
      "Val Loss: 0.501123, Val Acc: 87.50%, Val-Class-Acc: {0: '90.22%', 1: '84.78%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_2.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_23.pth\n",
      "Epoch 24/200, Train Loss: 0.052712, Train-Class-Acc: {0: '98.77%', 1: '97.14%'}\n",
      "Val Loss: 0.699438, Val Acc: 84.24%, Val-Class-Acc: {0: '76.09%', 1: '92.39%'}, LR: 0.000900\n",
      "Epoch 25/200, Train Loss: 0.036655, Train-Class-Acc: {0: '98.23%', 1: '99.46%'}\n",
      "Val Loss: 0.762273, Val Acc: 85.33%, Val-Class-Acc: {0: '92.39%', 1: '78.26%'}, LR: 0.000900\n",
      "Epoch 26/200, Train Loss: 0.032620, Train-Class-Acc: {0: '99.32%', 1: '98.91%'}\n",
      "Val Loss: 0.910509, Val Acc: 84.51%, Val-Class-Acc: {0: '94.02%', 1: '75.00%'}, LR: 0.000900\n",
      "Epoch 27/200, Train Loss: 0.029244, Train-Class-Acc: {0: '99.32%', 1: '98.91%'}\n",
      "Val Loss: 0.756087, Val Acc: 86.14%, Val-Class-Acc: {0: '91.30%', 1: '80.98%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_5.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_27.pth\n",
      "Epoch 28/200, Train Loss: 0.035220, Train-Class-Acc: {0: '99.05%', 1: '98.64%'}\n",
      "Val Loss: 0.725137, Val Acc: 85.87%, Val-Class-Acc: {0: '83.15%', 1: '88.59%'}, LR: 0.000810\n",
      "Epoch 29/200, Train Loss: 0.037787, Train-Class-Acc: {0: '99.32%', 1: '98.50%'}\n",
      "Val Loss: 0.675480, Val Acc: 86.41%, Val-Class-Acc: {0: '87.50%', 1: '85.33%'}, LR: 0.000810\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_8.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_29.pth\n",
      "Epoch 30/200, Train Loss: 0.017664, Train-Class-Acc: {0: '99.05%', 1: '99.46%'}\n",
      "Val Loss: 0.733535, Val Acc: 86.14%, Val-Class-Acc: {0: '91.85%', 1: '80.43%'}, LR: 0.000810\n",
      "Epoch 31/200, Train Loss: 0.012488, Train-Class-Acc: {0: '99.86%', 1: '99.59%'}\n",
      "Val Loss: 0.824595, Val Acc: 86.14%, Val-Class-Acc: {0: '85.87%', 1: '86.41%'}, LR: 0.000810\n",
      "Epoch 32/200, Train Loss: 0.002381, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.901823, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000810\n",
      "Epoch 33/200, Train Loss: 0.004159, Train-Class-Acc: {0: '99.86%', 1: '99.86%'}\n",
      "Val Loss: 0.869812, Val Acc: 84.78%, Val-Class-Acc: {0: '88.59%', 1: '80.98%'}, LR: 0.000810\n",
      "Epoch 34/200, Train Loss: 0.008650, Train-Class-Acc: {0: '99.86%', 1: '99.59%'}\n",
      "Val Loss: 0.912016, Val Acc: 83.70%, Val-Class-Acc: {0: '84.78%', 1: '82.61%'}, LR: 0.000810\n",
      "Epoch 35/200, Train Loss: 0.020147, Train-Class-Acc: {0: '99.46%', 1: '99.05%'}\n",
      "Val Loss: 0.955195, Val Acc: 85.87%, Val-Class-Acc: {0: '90.76%', 1: '80.98%'}, LR: 0.000810\n",
      "Epoch 36/200, Train Loss: 0.018887, Train-Class-Acc: {0: '99.05%', 1: '99.59%'}\n",
      "Val Loss: 0.964895, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000810\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_27.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_36.pth\n",
      "Epoch 37/200, Train Loss: 0.014969, Train-Class-Acc: {0: '99.86%', 1: '99.18%'}\n",
      "Val Loss: 0.939942, Val Acc: 82.88%, Val-Class-Acc: {0: '82.07%', 1: '83.70%'}, LR: 0.000810\n",
      "Epoch 38/200, Train Loss: 0.054923, Train-Class-Acc: {0: '97.96%', 1: '98.37%'}\n",
      "Val Loss: 1.056372, Val Acc: 83.70%, Val-Class-Acc: {0: '76.09%', 1: '91.30%'}, LR: 0.000810\n",
      "Epoch 39/200, Train Loss: 0.035978, Train-Class-Acc: {0: '99.18%', 1: '99.05%'}\n",
      "Val Loss: 0.829963, Val Acc: 85.05%, Val-Class-Acc: {0: '84.24%', 1: '85.87%'}, LR: 0.000729\n",
      "Epoch 40/200, Train Loss: 0.022962, Train-Class-Acc: {0: '99.32%', 1: '98.91%'}\n",
      "Val Loss: 0.683645, Val Acc: 87.50%, Val-Class-Acc: {0: '90.76%', 1: '84.24%'}, LR: 0.000729\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_29.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_40.pth\n",
      "Epoch 41/200, Train Loss: 0.014507, Train-Class-Acc: {0: '99.32%', 1: '99.59%'}\n",
      "Val Loss: 0.810726, Val Acc: 86.14%, Val-Class-Acc: {0: '86.96%', 1: '85.33%'}, LR: 0.000729\n",
      "Epoch 42/200, Train Loss: 0.039783, Train-Class-Acc: {0: '98.64%', 1: '99.05%'}\n",
      "Val Loss: 0.758716, Val Acc: 86.14%, Val-Class-Acc: {0: '91.85%', 1: '80.43%'}, LR: 0.000729\n",
      "Epoch 43/200, Train Loss: 0.061598, Train-Class-Acc: {0: '97.96%', 1: '97.41%'}\n",
      "Val Loss: 1.056473, Val Acc: 83.42%, Val-Class-Acc: {0: '94.57%', 1: '72.28%'}, LR: 0.000729\n",
      "Epoch 44/200, Train Loss: 0.054185, Train-Class-Acc: {0: '98.50%', 1: '98.23%'}\n",
      "Val Loss: 0.834779, Val Acc: 84.24%, Val-Class-Acc: {0: '83.70%', 1: '84.78%'}, LR: 0.000729\n",
      "Epoch 45/200, Train Loss: 0.028682, Train-Class-Acc: {0: '99.32%', 1: '98.91%'}\n",
      "Val Loss: 0.706804, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000729\n",
      "Epoch 46/200, Train Loss: 0.008989, Train-Class-Acc: {0: '99.86%', 1: '99.73%'}\n",
      "Val Loss: 0.819805, Val Acc: 85.60%, Val-Class-Acc: {0: '92.39%', 1: '78.80%'}, LR: 0.000729\n",
      "Epoch 47/200, Train Loss: 0.005101, Train-Class-Acc: {0: '100.00%', 1: '99.86%'}\n",
      "Val Loss: 0.783641, Val Acc: 86.14%, Val-Class-Acc: {0: '86.96%', 1: '85.33%'}, LR: 0.000729\n",
      "Epoch 48/200, Train Loss: 0.002549, Train-Class-Acc: {0: '100.00%', 1: '99.86%'}\n",
      "Val Loss: 0.847209, Val Acc: 87.23%, Val-Class-Acc: {0: '90.22%', 1: '84.24%'}, LR: 0.000729\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_36.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_48.pth\n",
      "Epoch 49/200, Train Loss: 0.000696, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.879296, Val Acc: 86.41%, Val-Class-Acc: {0: '89.13%', 1: '83.70%'}, LR: 0.000729\n",
      "Epoch 50/200, Train Loss: 0.000223, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.896117, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.000656\n",
      "Epoch 51/200, Train Loss: 0.000308, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.893173, Val Acc: 86.41%, Val-Class-Acc: {0: '89.13%', 1: '83.70%'}, LR: 0.000656\n",
      "Epoch 52/200, Train Loss: 0.000215, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.904583, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.000656\n",
      "Epoch 53/200, Train Loss: 0.000214, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.912948, Val Acc: 85.60%, Val-Class-Acc: {0: '89.13%', 1: '82.07%'}, LR: 0.000656\n",
      "Epoch 54/200, Train Loss: 0.000164, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.909695, Val Acc: 85.87%, Val-Class-Acc: {0: '88.59%', 1: '83.15%'}, LR: 0.000656\n",
      "Epoch 55/200, Train Loss: 0.000552, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.887124, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000656\n",
      "Epoch 56/200, Train Loss: 0.000343, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.895215, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000656\n",
      "Epoch 57/200, Train Loss: 0.000222, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.893919, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000656\n",
      "Epoch 58/200, Train Loss: 0.000117, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.891276, Val Acc: 85.87%, Val-Class-Acc: {0: '88.59%', 1: '83.15%'}, LR: 0.000656\n",
      "Epoch 59/200, Train Loss: 0.000087, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.894486, Val Acc: 86.14%, Val-Class-Acc: {0: '88.59%', 1: '83.70%'}, LR: 0.000656\n",
      "Epoch 60/200, Train Loss: 0.000138, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.908225, Val Acc: 85.87%, Val-Class-Acc: {0: '88.59%', 1: '83.15%'}, LR: 0.000656\n",
      "Epoch 61/200, Train Loss: 0.000238, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.915604, Val Acc: 85.87%, Val-Class-Acc: {0: '88.59%', 1: '83.15%'}, LR: 0.000590\n",
      "Epoch 62/200, Train Loss: 0.000109, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.914629, Val Acc: 86.14%, Val-Class-Acc: {0: '89.13%', 1: '83.15%'}, LR: 0.000590\n",
      "Epoch 63/200, Train Loss: 0.000634, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.912719, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.000590\n",
      "Epoch 64/200, Train Loss: 0.000221, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.924567, Val Acc: 86.41%, Val-Class-Acc: {0: '89.67%', 1: '83.15%'}, LR: 0.000590\n",
      "Epoch 65/200, Train Loss: 0.000180, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.923853, Val Acc: 86.41%, Val-Class-Acc: {0: '89.67%', 1: '83.15%'}, LR: 0.000590\n",
      "Epoch 66/200, Train Loss: 0.000122, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.925392, Val Acc: 86.68%, Val-Class-Acc: {0: '90.22%', 1: '83.15%'}, LR: 0.000590\n",
      "Epoch 67/200, Train Loss: 0.000267, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.910700, Val Acc: 86.68%, Val-Class-Acc: {0: '89.67%', 1: '83.70%'}, LR: 0.000590\n",
      "Epoch 68/200, Train Loss: 0.000129, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.903937, Val Acc: 86.41%, Val-Class-Acc: {0: '89.67%', 1: '83.15%'}, LR: 0.000590\n",
      "Epoch 69/200, Train Loss: 0.000136, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.895649, Val Acc: 86.68%, Val-Class-Acc: {0: '89.13%', 1: '84.24%'}, LR: 0.000590\n",
      "Epoch 70/200, Train Loss: 0.000066, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.903468, Val Acc: 86.68%, Val-Class-Acc: {0: '89.67%', 1: '83.70%'}, LR: 0.000590\n",
      "Epoch 71/200, Train Loss: 0.000183, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.895388, Val Acc: 86.96%, Val-Class-Acc: {0: '89.13%', 1: '84.78%'}, LR: 0.000590\n",
      "Epoch 72/200, Train Loss: 0.000095, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.896062, Val Acc: 86.68%, Val-Class-Acc: {0: '90.22%', 1: '83.15%'}, LR: 0.000531\n",
      "Epoch 73/200, Train Loss: 0.000072, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.908764, Val Acc: 86.41%, Val-Class-Acc: {0: '91.30%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 74/200, Train Loss: 0.000090, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.907583, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000531\n",
      "Epoch 75/200, Train Loss: 0.000109, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.899142, Val Acc: 86.96%, Val-Class-Acc: {0: '89.67%', 1: '84.24%'}, LR: 0.000531\n",
      "Epoch 76/200, Train Loss: 0.000047, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.896844, Val Acc: 86.41%, Val-Class-Acc: {0: '89.67%', 1: '83.15%'}, LR: 0.000531\n",
      "Epoch 77/200, Train Loss: 0.000074, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.903551, Val Acc: 86.41%, Val-Class-Acc: {0: '89.67%', 1: '83.15%'}, LR: 0.000531\n",
      "Epoch 78/200, Train Loss: 0.000089, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.900331, Val Acc: 86.96%, Val-Class-Acc: {0: '90.22%', 1: '83.70%'}, LR: 0.000531\n",
      "Epoch 79/200, Train Loss: 0.000208, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.921207, Val Acc: 86.14%, Val-Class-Acc: {0: '91.30%', 1: '80.98%'}, LR: 0.000531\n",
      "Epoch 80/200, Train Loss: 0.000070, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.902152, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 81/200, Train Loss: 0.000043, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.918938, Val Acc: 86.68%, Val-Class-Acc: {0: '90.76%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 82/200, Train Loss: 0.000053, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.940703, Val Acc: 86.14%, Val-Class-Acc: {0: '91.30%', 1: '80.98%'}, LR: 0.000531\n",
      "Epoch 83/200, Train Loss: 0.000072, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.930120, Val Acc: 86.14%, Val-Class-Acc: {0: '91.30%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 84/200, Train Loss: 0.000048, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.924198, Val Acc: 85.87%, Val-Class-Acc: {0: '90.76%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 85/200, Train Loss: 0.000090, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.927469, Val Acc: 86.14%, Val-Class-Acc: {0: '90.22%', 1: '82.07%'}, LR: 0.000478\n",
      "Epoch 86/200, Train Loss: 0.000030, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.928738, Val Acc: 86.14%, Val-Class-Acc: {0: '90.22%', 1: '82.07%'}, LR: 0.000478\n",
      "Epoch 87/200, Train Loss: 0.000113, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.938781, Val Acc: 85.60%, Val-Class-Acc: {0: '90.22%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 88/200, Train Loss: 0.000059, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.948095, Val Acc: 86.14%, Val-Class-Acc: {0: '91.30%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 89/200, Train Loss: 0.000040, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.936150, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.000478\n",
      "Epoch 90/200, Train Loss: 0.000050, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.936702, Val Acc: 86.68%, Val-Class-Acc: {0: '90.22%', 1: '83.15%'}, LR: 0.000478\n",
      "Epoch 91/200, Train Loss: 0.000045, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.942623, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.000478\n",
      "Epoch 92/200, Train Loss: 0.000428, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.927200, Val Acc: 87.23%, Val-Class-Acc: {0: '90.22%', 1: '84.24%'}, LR: 0.000478\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_9.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_92.pth\n",
      "Epoch 93/200, Train Loss: 0.000060, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.937443, Val Acc: 87.23%, Val-Class-Acc: {0: '91.30%', 1: '83.15%'}, LR: 0.000478\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_10.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_93.pth\n",
      "Epoch 94/200, Train Loss: 0.000039, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.923155, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000430\n",
      "Epoch 95/200, Train Loss: 0.000063, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.909866, Val Acc: 87.50%, Val-Class-Acc: {0: '90.76%', 1: '84.24%'}, LR: 0.000430\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_48.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_95.pth\n",
      "Epoch 96/200, Train Loss: 0.000147, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.916859, Val Acc: 87.23%, Val-Class-Acc: {0: '90.76%', 1: '83.70%'}, LR: 0.000430\n",
      "Epoch 97/200, Train Loss: 0.000082, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.926628, Val Acc: 86.96%, Val-Class-Acc: {0: '91.30%', 1: '82.61%'}, LR: 0.000430\n",
      "Epoch 98/200, Train Loss: 0.000041, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.932490, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000430\n",
      "Epoch 99/200, Train Loss: 0.000038, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.936445, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000430\n",
      "Epoch 100/200, Train Loss: 0.000027, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.936797, Val Acc: 86.68%, Val-Class-Acc: {0: '91.85%', 1: '81.52%'}, LR: 0.000430\n",
      "Epoch 101/200, Train Loss: 0.000043, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.939891, Val Acc: 86.41%, Val-Class-Acc: {0: '91.30%', 1: '81.52%'}, LR: 0.000430\n",
      "Epoch 102/200, Train Loss: 0.000025, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.947074, Val Acc: 86.68%, Val-Class-Acc: {0: '91.85%', 1: '81.52%'}, LR: 0.000430\n",
      "Epoch 103/200, Train Loss: 0.000032, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.949020, Val Acc: 86.68%, Val-Class-Acc: {0: '91.85%', 1: '81.52%'}, LR: 0.000430\n",
      "Epoch 104/200, Train Loss: 0.000042, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.943128, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000430\n",
      "Epoch 105/200, Train Loss: 0.000046, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.929535, Val Acc: 86.96%, Val-Class-Acc: {0: '90.76%', 1: '83.15%'}, LR: 0.000387\n",
      "Epoch 106/200, Train Loss: 0.000537, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.993582, Val Acc: 87.23%, Val-Class-Acc: {0: '91.85%', 1: '82.61%'}, LR: 0.000387\n",
      "Epoch 107/200, Train Loss: 0.000214, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.014717, Val Acc: 86.41%, Val-Class-Acc: {0: '91.85%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 108/200, Train Loss: 0.000079, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.962773, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000387\n",
      "Epoch 109/200, Train Loss: 0.000027, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.966624, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000387\n",
      "Epoch 110/200, Train Loss: 0.000058, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.972631, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000387\n",
      "Epoch 111/200, Train Loss: 0.000033, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.970312, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000387\n",
      "Epoch 112/200, Train Loss: 0.000031, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.975281, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000387\n",
      "Epoch 113/200, Train Loss: 0.000065, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.968338, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000387\n",
      "Epoch 114/200, Train Loss: 0.000037, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.972499, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000387\n",
      "Epoch 115/200, Train Loss: 0.000060, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.967031, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000387\n",
      "Epoch 116/200, Train Loss: 0.000037, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.963285, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000349\n",
      "Epoch 117/200, Train Loss: 0.000146, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.959741, Val Acc: 86.41%, Val-Class-Acc: {0: '91.30%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 118/200, Train Loss: 0.000042, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.953959, Val Acc: 86.68%, Val-Class-Acc: {0: '90.22%', 1: '83.15%'}, LR: 0.000349\n",
      "Epoch 119/200, Train Loss: 0.000080, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.964500, Val Acc: 86.14%, Val-Class-Acc: {0: '90.76%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 120/200, Train Loss: 0.000060, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.951763, Val Acc: 86.68%, Val-Class-Acc: {0: '90.22%', 1: '83.15%'}, LR: 0.000349\n",
      "Epoch 121/200, Train Loss: 0.000016, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.972246, Val Acc: 86.41%, Val-Class-Acc: {0: '91.30%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 122/200, Train Loss: 0.000052, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.963916, Val Acc: 86.68%, Val-Class-Acc: {0: '90.22%', 1: '83.15%'}, LR: 0.000349\n",
      "Epoch 123/200, Train Loss: 0.000103, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.973765, Val Acc: 86.68%, Val-Class-Acc: {0: '91.85%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 124/200, Train Loss: 0.000023, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.973477, Val Acc: 86.14%, Val-Class-Acc: {0: '90.22%', 1: '82.07%'}, LR: 0.000349\n",
      "Epoch 125/200, Train Loss: 0.000023, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.997028, Val Acc: 86.41%, Val-Class-Acc: {0: '91.85%', 1: '80.98%'}, LR: 0.000349\n",
      "Epoch 126/200, Train Loss: 0.000024, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.974061, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000349\n",
      "Epoch 127/200, Train Loss: 0.000025, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.981559, Val Acc: 86.68%, Val-Class-Acc: {0: '91.85%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 128/200, Train Loss: 0.000028, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.992770, Val Acc: 86.68%, Val-Class-Acc: {0: '91.85%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 129/200, Train Loss: 0.000023, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.978813, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000314\n",
      "Epoch 130/200, Train Loss: 0.000055, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.976592, Val Acc: 86.14%, Val-Class-Acc: {0: '90.76%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 131/200, Train Loss: 0.000021, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.977518, Val Acc: 86.14%, Val-Class-Acc: {0: '90.76%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 132/200, Train Loss: 0.000037, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.983560, Val Acc: 86.14%, Val-Class-Acc: {0: '90.76%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 133/200, Train Loss: 0.000052, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.995698, Val Acc: 86.41%, Val-Class-Acc: {0: '91.30%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 134/200, Train Loss: 0.000024, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.992839, Val Acc: 86.68%, Val-Class-Acc: {0: '91.85%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 135/200, Train Loss: 0.000020, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.995636, Val Acc: 86.41%, Val-Class-Acc: {0: '91.85%', 1: '80.98%'}, LR: 0.000314\n",
      "Epoch 136/200, Train Loss: 0.000029, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.980352, Val Acc: 86.14%, Val-Class-Acc: {0: '90.76%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 137/200, Train Loss: 0.000030, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.980349, Val Acc: 86.14%, Val-Class-Acc: {0: '90.76%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 138/200, Train Loss: 0.000017, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.981267, Val Acc: 86.14%, Val-Class-Acc: {0: '90.76%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 139/200, Train Loss: 0.000012, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.979604, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000282\n",
      "Epoch 140/200, Train Loss: 0.000038, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.997476, Val Acc: 86.41%, Val-Class-Acc: {0: '91.85%', 1: '80.98%'}, LR: 0.000282\n",
      "Epoch 141/200, Train Loss: 0.000029, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.977924, Val Acc: 85.87%, Val-Class-Acc: {0: '90.22%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 142/200, Train Loss: 0.000061, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.977396, Val Acc: 85.87%, Val-Class-Acc: {0: '90.22%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 143/200, Train Loss: 0.000017, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.991085, Val Acc: 86.41%, Val-Class-Acc: {0: '91.85%', 1: '80.98%'}, LR: 0.000282\n",
      "Epoch 144/200, Train Loss: 0.000035, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.993991, Val Acc: 86.14%, Val-Class-Acc: {0: '91.30%', 1: '80.98%'}, LR: 0.000282\n",
      "Epoch 145/200, Train Loss: 0.000009, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.980684, Val Acc: 85.87%, Val-Class-Acc: {0: '90.22%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 146/200, Train Loss: 0.000092, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.000673, Val Acc: 86.41%, Val-Class-Acc: {0: '91.85%', 1: '80.98%'}, LR: 0.000282\n",
      "Epoch 147/200, Train Loss: 0.000009, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.983232, Val Acc: 86.41%, Val-Class-Acc: {0: '91.30%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 148/200, Train Loss: 0.000033, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.968727, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000282\n",
      "Epoch 149/200, Train Loss: 0.000136, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.999231, Val Acc: 86.41%, Val-Class-Acc: {0: '91.30%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 150/200, Train Loss: 0.000088, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.982014, Val Acc: 86.96%, Val-Class-Acc: {0: '90.22%', 1: '83.70%'}, LR: 0.000254\n",
      "Epoch 151/200, Train Loss: 0.000009, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.983584, Val Acc: 86.68%, Val-Class-Acc: {0: '90.76%', 1: '82.61%'}, LR: 0.000254\n",
      "Epoch 152/200, Train Loss: 0.000021, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.009357, Val Acc: 85.87%, Val-Class-Acc: {0: '91.30%', 1: '80.43%'}, LR: 0.000254\n",
      "Epoch 153/200, Train Loss: 0.000006, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.980850, Val Acc: 86.68%, Val-Class-Acc: {0: '90.76%', 1: '82.61%'}, LR: 0.000254\n",
      "Epoch 154/200, Train Loss: 0.000011, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.984022, Val Acc: 86.68%, Val-Class-Acc: {0: '90.76%', 1: '82.61%'}, LR: 0.000254\n",
      "Epoch 155/200, Train Loss: 0.000050, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.980043, Val Acc: 86.68%, Val-Class-Acc: {0: '90.22%', 1: '83.15%'}, LR: 0.000254\n",
      "Epoch 156/200, Train Loss: 0.000015, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.994493, Val Acc: 86.96%, Val-Class-Acc: {0: '90.76%', 1: '83.15%'}, LR: 0.000254\n",
      "Epoch 157/200, Train Loss: 0.000016, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.011515, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000254\n",
      "Epoch 158/200, Train Loss: 0.000012, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.999630, Val Acc: 86.14%, Val-Class-Acc: {0: '90.76%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 159/200, Train Loss: 0.000015, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.998516, Val Acc: 86.68%, Val-Class-Acc: {0: '90.76%', 1: '82.61%'}, LR: 0.000254\n",
      "Epoch 160/200, Train Loss: 0.000030, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.996519, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000229\n",
      "Epoch 161/200, Train Loss: 0.000032, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.975335, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.000229\n",
      "Epoch 162/200, Train Loss: 0.000021, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.991955, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000229\n",
      "Epoch 163/200, Train Loss: 0.000037, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.973176, Val Acc: 86.96%, Val-Class-Acc: {0: '90.22%', 1: '83.70%'}, LR: 0.000229\n",
      "Epoch 164/200, Train Loss: 0.000052, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.987043, Val Acc: 86.68%, Val-Class-Acc: {0: '90.76%', 1: '82.61%'}, LR: 0.000229\n",
      "Epoch 165/200, Train Loss: 0.000019, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.987682, Val Acc: 86.68%, Val-Class-Acc: {0: '90.76%', 1: '82.61%'}, LR: 0.000229\n",
      "Epoch 166/200, Train Loss: 0.000013, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.001004, Val Acc: 86.68%, Val-Class-Acc: {0: '90.76%', 1: '82.61%'}, LR: 0.000229\n",
      "Epoch 167/200, Train Loss: 0.000025, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.998646, Val Acc: 86.68%, Val-Class-Acc: {0: '90.76%', 1: '82.61%'}, LR: 0.000229\n",
      "Epoch 168/200, Train Loss: 0.000049, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.997512, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000229\n",
      "Epoch 169/200, Train Loss: 0.000008, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.998987, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000229\n",
      "Epoch 170/200, Train Loss: 0.000010, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.004114, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000229\n",
      "Epoch 171/200, Train Loss: 0.000006, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.001101, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000206\n",
      "Epoch 172/200, Train Loss: 0.000012, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.015562, Val Acc: 86.68%, Val-Class-Acc: {0: '91.85%', 1: '81.52%'}, LR: 0.000206\n",
      "Epoch 173/200, Train Loss: 0.000009, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.997305, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000206\n",
      "Epoch 174/200, Train Loss: 0.000015, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.003408, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000206\n",
      "Epoch 175/200, Train Loss: 0.000012, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.004274, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000206\n",
      "Epoch 176/200, Train Loss: 0.000009, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.012675, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000206\n",
      "Epoch 177/200, Train Loss: 0.000005, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.006353, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000206\n",
      "Epoch 178/200, Train Loss: 0.000016, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.013227, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000206\n",
      "Epoch 179/200, Train Loss: 0.000012, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.017900, Val Acc: 86.41%, Val-Class-Acc: {0: '91.85%', 1: '80.98%'}, LR: 0.000206\n",
      "Epoch 180/200, Train Loss: 0.000013, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.992056, Val Acc: 86.68%, Val-Class-Acc: {0: '90.76%', 1: '82.61%'}, LR: 0.000206\n",
      "Epoch 181/200, Train Loss: 0.000040, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.013047, Val Acc: 86.14%, Val-Class-Acc: {0: '90.76%', 1: '81.52%'}, LR: 0.000206\n",
      "Epoch 182/200, Train Loss: 0.000007, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.003269, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 183/200, Train Loss: 0.000048, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.009155, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 184/200, Train Loss: 0.000007, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.009708, Val Acc: 86.41%, Val-Class-Acc: {0: '91.85%', 1: '80.98%'}, LR: 0.000185\n",
      "Epoch 185/200, Train Loss: 0.000012, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.005289, Val Acc: 86.96%, Val-Class-Acc: {0: '91.30%', 1: '82.61%'}, LR: 0.000185\n",
      "Epoch 186/200, Train Loss: 0.000031, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.014543, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 187/200, Train Loss: 0.000018, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.004473, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 188/200, Train Loss: 0.000013, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.022464, Val Acc: 86.68%, Val-Class-Acc: {0: '91.85%', 1: '81.52%'}, LR: 0.000185\n",
      "Epoch 189/200, Train Loss: 0.000007, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.010626, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 190/200, Train Loss: 0.000024, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.012644, Val Acc: 86.68%, Val-Class-Acc: {0: '91.85%', 1: '81.52%'}, LR: 0.000185\n",
      "Epoch 191/200, Train Loss: 0.000007, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.995599, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.000185\n",
      "Epoch 192/200, Train Loss: 0.000010, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.993895, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.000185\n",
      "Epoch 193/200, Train Loss: 0.000012, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.013520, Val Acc: 86.41%, Val-Class-Acc: {0: '91.85%', 1: '80.98%'}, LR: 0.000167\n",
      "Epoch 194/200, Train Loss: 0.000008, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.014522, Val Acc: 86.68%, Val-Class-Acc: {0: '91.85%', 1: '81.52%'}, LR: 0.000167\n",
      "Epoch 195/200, Train Loss: 0.000012, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.007053, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000167\n",
      "Epoch 196/200, Train Loss: 0.000016, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.026533, Val Acc: 86.41%, Val-Class-Acc: {0: '91.85%', 1: '80.98%'}, LR: 0.000167\n",
      "Epoch 197/200, Train Loss: 0.000004, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.013429, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000167\n",
      "Epoch 198/200, Train Loss: 0.000013, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.009300, Val Acc: 86.41%, Val-Class-Acc: {0: '91.30%', 1: '81.52%'}, LR: 0.000167\n",
      "Epoch 199/200, Train Loss: 0.000006, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.011174, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000167\n",
      "Epoch 200/200, Train Loss: 0.000019, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.017798, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000167\n",
      "\n",
      "🏆 Best model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_best.pth (Val Accuracy: 87.50%)\n",
      "\n",
      "📌 Final model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_final.pth\n",
      "\n",
      "🎯 Top 5 Best Models:\n",
      "Epoch 95, Train Loss: 0.000063, Train-Acc: {0: '100.00%', 1: '100.00%'},\n",
      "Val Loss: 0.909866, Val Acc: 87.50%, Val-Class-Acc: {0: '90.76%', 1: '84.24%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_95.pth\n",
      "Epoch 40, Train Loss: 0.022962, Train-Acc: {0: '99.32%', 1: '98.91%'},\n",
      "Val Loss: 0.683645, Val Acc: 87.50%, Val-Class-Acc: {0: '90.76%', 1: '84.24%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_40.pth\n",
      "Epoch 23, Train Loss: 0.059934, Train-Acc: {0: '97.82%', 1: '97.82%'},\n",
      "Val Loss: 0.501123, Val Acc: 87.50%, Val-Class-Acc: {0: '90.22%', 1: '84.78%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_23.pth\n",
      "Epoch 93, Train Loss: 0.000060, Train-Acc: {0: '100.00%', 1: '100.00%'},\n",
      "Val Loss: 0.937443, Val Acc: 87.23%, Val-Class-Acc: {0: '91.30%', 1: '83.15%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_93.pth\n",
      "Epoch 92, Train Loss: 0.000428, Train-Acc: {0: '100.00%', 1: '100.00%'},\n",
      "Val Loss: 0.927200, Val Acc: 87.23%, Val-Class-Acc: {0: '90.22%', 1: '84.24%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_init/ResNet18_1D_epoch_92.pth\n",
      "\n",
      "🧠 Model Summary:\n",
      "Total Parameters: 3,849,858\n",
      "Model Size (float32): 14.69 MB\n",
      "Total Training Time: 128.80 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))  # Shape: (B, 5000, 12)\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# ==== Model Hyperparameters ====\n",
    "input_channels = X_train.shape[2]                  # 12 leads\n",
    "output_size = len(np.unique(y_train))              # Number of classes (e.g., 2 for Period 1)\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "dropout = 0.0                                       # Not needed for ResNet18_1D\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "print(\"✅ input shape:\", X_train.shape)\n",
    "print(\"✅ unique y_train:\", np.unique(y_train))\n",
    "print(\"✅ unique y_test :\", np.unique(y_test))\n",
    "assert np.max(y_train) < output_size\n",
    "assert np.max(y_test) < output_size\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/ResNet18_init\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Model ====\n",
    "model = ResNet18_1D(input_channels=input_channels, output_size=output_size).to(device)\n",
    "\n",
    "# ==== Optimizer and Training ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# ==== Train ====\n",
    "result_summary = train_model_general_classifier(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name='ResNet18_1D',\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del model, X_train, y_train, X_test, y_test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb648be",
   "metadata": {},
   "source": [
    "#### No init Version + Arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dd4d1aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Automatically selected GPU:\n",
      "    - CUDA Device ID : 1\n",
      "    - Memory Used    : 743 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "✅ input shape: (1468, 5000, 12)\n",
      "✅ unique y_train: [0 1]\n",
      "✅ unique y_test : [0 1]\n",
      "\n",
      "🚀 'train_model_general_classifier' started.\n",
      "✅ Removed existing folder: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg\n",
      "\n",
      "✅ Data Overview:\n",
      "X_train: (1468, 5000, 12), y_train: (1468,)\n",
      "X_val: (368, 5000, 12), y_val: (368,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 0.548911, Train-Class-Acc: {0: '80.11%', 1: '70.71%'}\n",
      "Val Loss: 0.452734, Val Acc: 79.62%, Val-Class-Acc: {0: '93.48%', 1: '65.76%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.390326, Train-Class-Acc: {0: '87.19%', 1: '77.66%'}\n",
      "Val Loss: 0.455185, Val Acc: 80.43%, Val-Class-Acc: {0: '89.67%', 1: '71.20%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.352090, Train-Class-Acc: {0: '88.42%', 1: '80.79%'}\n",
      "Val Loss: 0.434934, Val Acc: 78.26%, Val-Class-Acc: {0: '66.30%', 1: '90.22%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.357478, Train-Class-Acc: {0: '87.60%', 1: '79.84%'}\n",
      "Val Loss: 0.584488, Val Acc: 79.62%, Val-Class-Acc: {0: '71.20%', 1: '88.04%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.337951, Train-Class-Acc: {0: '87.06%', 1: '82.70%'}\n",
      "Val Loss: 0.389103, Val Acc: 85.05%, Val-Class-Acc: {0: '89.67%', 1: '80.43%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.302468, Train-Class-Acc: {0: '89.92%', 1: '83.51%'}\n",
      "Val Loss: 0.570381, Val Acc: 72.83%, Val-Class-Acc: {0: '50.00%', 1: '95.65%'}, LR: 0.001000\n",
      "Epoch 7/200, Train Loss: 0.302873, Train-Class-Acc: {0: '87.19%', 1: '87.06%'}\n",
      "Val Loss: 0.508062, Val Acc: 80.16%, Val-Class-Acc: {0: '93.48%', 1: '66.85%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_3.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.299584, Train-Class-Acc: {0: '90.33%', 1: '81.06%'}\n",
      "Val Loss: 0.380554, Val Acc: 84.24%, Val-Class-Acc: {0: '95.65%', 1: '72.83%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_1.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_8.pth\n",
      "Epoch 9/200, Train Loss: 0.272649, Train-Class-Acc: {0: '89.92%', 1: '85.97%'}\n",
      "Val Loss: 0.396101, Val Acc: 83.70%, Val-Class-Acc: {0: '93.48%', 1: '73.91%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_4.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.249648, Train-Class-Acc: {0: '93.60%', 1: '85.83%'}\n",
      "Val Loss: 0.382138, Val Acc: 84.24%, Val-Class-Acc: {0: '87.50%', 1: '80.98%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_7.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_10.pth\n",
      "Epoch 11/200, Train Loss: 0.249325, Train-Class-Acc: {0: '91.01%', 1: '88.69%'}\n",
      "Val Loss: 0.437941, Val Acc: 83.97%, Val-Class-Acc: {0: '95.11%', 1: '72.83%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_2.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_11.pth\n",
      "Epoch 12/200, Train Loss: 0.241847, Train-Class-Acc: {0: '91.14%', 1: '87.74%'}\n",
      "Val Loss: 0.438206, Val Acc: 83.15%, Val-Class-Acc: {0: '94.02%', 1: '72.28%'}, LR: 0.001000\n",
      "Epoch 13/200, Train Loss: 0.239347, Train-Class-Acc: {0: '93.32%', 1: '87.06%'}\n",
      "Val Loss: 0.527944, Val Acc: 79.89%, Val-Class-Acc: {0: '67.93%', 1: '91.85%'}, LR: 0.001000\n",
      "Epoch 14/200, Train Loss: 0.258368, Train-Class-Acc: {0: '88.83%', 1: '88.69%'}\n",
      "Val Loss: 0.400192, Val Acc: 83.70%, Val-Class-Acc: {0: '84.78%', 1: '82.61%'}, LR: 0.001000\n",
      "Epoch 15/200, Train Loss: 0.223098, Train-Class-Acc: {0: '92.37%', 1: '88.28%'}\n",
      "Val Loss: 0.531052, Val Acc: 80.43%, Val-Class-Acc: {0: '94.02%', 1: '66.85%'}, LR: 0.001000\n",
      "Epoch 16/200, Train Loss: 0.230613, Train-Class-Acc: {0: '92.51%', 1: '88.56%'}\n",
      "Val Loss: 0.399114, Val Acc: 83.70%, Val-Class-Acc: {0: '77.72%', 1: '89.67%'}, LR: 0.001000\n",
      "Epoch 17/200, Train Loss: 0.211821, Train-Class-Acc: {0: '92.51%', 1: '90.33%'}\n",
      "Val Loss: 0.418578, Val Acc: 84.24%, Val-Class-Acc: {0: '80.43%', 1: '88.04%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_9.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_17.pth\n",
      "Epoch 18/200, Train Loss: 0.195805, Train-Class-Acc: {0: '94.96%', 1: '88.96%'}\n",
      "Val Loss: 0.429893, Val Acc: 83.97%, Val-Class-Acc: {0: '92.93%', 1: '75.00%'}, LR: 0.001000\n",
      "Epoch 19/200, Train Loss: 0.181009, Train-Class-Acc: {0: '93.32%', 1: '91.28%'}\n",
      "Val Loss: 0.407230, Val Acc: 85.33%, Val-Class-Acc: {0: '92.39%', 1: '78.26%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_11.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_19.pth\n",
      "Epoch 20/200, Train Loss: 0.181504, Train-Class-Acc: {0: '94.41%', 1: '91.69%'}\n",
      "Val Loss: 0.474644, Val Acc: 83.42%, Val-Class-Acc: {0: '79.89%', 1: '86.96%'}, LR: 0.000900\n",
      "Epoch 21/200, Train Loss: 0.164973, Train-Class-Acc: {0: '93.87%', 1: '92.51%'}\n",
      "Val Loss: 0.495873, Val Acc: 83.97%, Val-Class-Acc: {0: '95.11%', 1: '72.83%'}, LR: 0.000900\n",
      "Epoch 22/200, Train Loss: 0.154199, Train-Class-Acc: {0: '94.28%', 1: '93.19%'}\n",
      "Val Loss: 0.419620, Val Acc: 85.05%, Val-Class-Acc: {0: '86.41%', 1: '83.70%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_8.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_22.pth\n",
      "Epoch 23/200, Train Loss: 0.148276, Train-Class-Acc: {0: '94.55%', 1: '92.37%'}\n",
      "Val Loss: 0.498838, Val Acc: 85.33%, Val-Class-Acc: {0: '90.22%', 1: '80.43%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_10.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_23.pth\n",
      "Epoch 24/200, Train Loss: 0.170923, Train-Class-Acc: {0: '94.55%', 1: '91.69%'}\n",
      "Val Loss: 0.530025, Val Acc: 85.60%, Val-Class-Acc: {0: '85.87%', 1: '85.33%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_17.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_24.pth\n",
      "Epoch 25/200, Train Loss: 0.144324, Train-Class-Acc: {0: '95.10%', 1: '93.46%'}\n",
      "Val Loss: 0.398978, Val Acc: 86.14%, Val-Class-Acc: {0: '86.96%', 1: '85.33%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_5.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_25.pth\n",
      "Epoch 26/200, Train Loss: 0.152655, Train-Class-Acc: {0: '94.82%', 1: '92.51%'}\n",
      "Val Loss: 0.499758, Val Acc: 83.15%, Val-Class-Acc: {0: '86.96%', 1: '79.35%'}, LR: 0.000900\n",
      "Epoch 27/200, Train Loss: 0.133633, Train-Class-Acc: {0: '95.91%', 1: '93.46%'}\n",
      "Val Loss: 0.553245, Val Acc: 85.33%, Val-Class-Acc: {0: '81.52%', 1: '89.13%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_22.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_27.pth\n",
      "Epoch 28/200, Train Loss: 0.150829, Train-Class-Acc: {0: '94.14%', 1: '93.46%'}\n",
      "Val Loss: 0.444469, Val Acc: 82.88%, Val-Class-Acc: {0: '85.87%', 1: '79.89%'}, LR: 0.000900\n",
      "Epoch 29/200, Train Loss: 0.111472, Train-Class-Acc: {0: '96.59%', 1: '95.10%'}\n",
      "Val Loss: 0.538746, Val Acc: 83.70%, Val-Class-Acc: {0: '84.24%', 1: '83.15%'}, LR: 0.000900\n",
      "Epoch 30/200, Train Loss: 0.128594, Train-Class-Acc: {0: '96.46%', 1: '94.69%'}\n",
      "Val Loss: 0.545022, Val Acc: 84.24%, Val-Class-Acc: {0: '89.67%', 1: '78.80%'}, LR: 0.000900\n",
      "Epoch 31/200, Train Loss: 0.084974, Train-Class-Acc: {0: '97.68%', 1: '96.19%'}\n",
      "Val Loss: 0.517907, Val Acc: 85.60%, Val-Class-Acc: {0: '85.87%', 1: '85.33%'}, LR: 0.000810\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_19.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_31.pth\n",
      "Epoch 32/200, Train Loss: 0.084191, Train-Class-Acc: {0: '96.32%', 1: '97.14%'}\n",
      "Val Loss: 0.702040, Val Acc: 81.79%, Val-Class-Acc: {0: '71.74%', 1: '91.85%'}, LR: 0.000810\n",
      "Epoch 33/200, Train Loss: 0.116283, Train-Class-Acc: {0: '95.91%', 1: '94.55%'}\n",
      "Val Loss: 0.751176, Val Acc: 84.24%, Val-Class-Acc: {0: '97.83%', 1: '70.65%'}, LR: 0.000810\n",
      "Epoch 34/200, Train Loss: 0.179882, Train-Class-Acc: {0: '93.87%', 1: '92.23%'}\n",
      "Val Loss: 0.714246, Val Acc: 76.63%, Val-Class-Acc: {0: '57.61%', 1: '95.65%'}, LR: 0.000810\n",
      "Epoch 35/200, Train Loss: 0.135975, Train-Class-Acc: {0: '96.87%', 1: '93.19%'}\n",
      "Val Loss: 0.497174, Val Acc: 86.41%, Val-Class-Acc: {0: '91.30%', 1: '81.52%'}, LR: 0.000810\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_23.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_35.pth\n",
      "Epoch 36/200, Train Loss: 0.076470, Train-Class-Acc: {0: '97.41%', 1: '96.32%'}\n",
      "Val Loss: 0.590945, Val Acc: 82.88%, Val-Class-Acc: {0: '86.96%', 1: '78.80%'}, LR: 0.000810\n",
      "Epoch 37/200, Train Loss: 0.052254, Train-Class-Acc: {0: '98.50%', 1: '97.68%'}\n",
      "Val Loss: 0.621695, Val Acc: 84.78%, Val-Class-Acc: {0: '84.24%', 1: '85.33%'}, LR: 0.000810\n",
      "Epoch 38/200, Train Loss: 0.049541, Train-Class-Acc: {0: '98.09%', 1: '97.82%'}\n",
      "Val Loss: 0.849715, Val Acc: 83.15%, Val-Class-Acc: {0: '92.39%', 1: '73.91%'}, LR: 0.000810\n",
      "Epoch 39/200, Train Loss: 0.058890, Train-Class-Acc: {0: '98.23%', 1: '98.23%'}\n",
      "Val Loss: 0.726028, Val Acc: 85.05%, Val-Class-Acc: {0: '88.59%', 1: '81.52%'}, LR: 0.000810\n",
      "Epoch 40/200, Train Loss: 0.064821, Train-Class-Acc: {0: '96.87%', 1: '96.87%'}\n",
      "Val Loss: 0.793494, Val Acc: 83.15%, Val-Class-Acc: {0: '75.54%', 1: '90.76%'}, LR: 0.000810\n",
      "Epoch 41/200, Train Loss: 0.078326, Train-Class-Acc: {0: '97.14%', 1: '96.05%'}\n",
      "Val Loss: 0.730145, Val Acc: 84.78%, Val-Class-Acc: {0: '89.67%', 1: '79.89%'}, LR: 0.000810\n",
      "Epoch 42/200, Train Loss: 0.065864, Train-Class-Acc: {0: '98.23%', 1: '97.00%'}\n",
      "Val Loss: 0.710967, Val Acc: 84.51%, Val-Class-Acc: {0: '91.85%', 1: '77.17%'}, LR: 0.000729\n",
      "Epoch 43/200, Train Loss: 0.048217, Train-Class-Acc: {0: '98.91%', 1: '97.82%'}\n",
      "Val Loss: 0.921503, Val Acc: 79.89%, Val-Class-Acc: {0: '70.65%', 1: '89.13%'}, LR: 0.000729\n",
      "Epoch 44/200, Train Loss: 0.064321, Train-Class-Acc: {0: '97.68%', 1: '98.09%'}\n",
      "Val Loss: 0.751663, Val Acc: 82.88%, Val-Class-Acc: {0: '83.70%', 1: '82.07%'}, LR: 0.000729\n",
      "Epoch 45/200, Train Loss: 0.073320, Train-Class-Acc: {0: '97.82%', 1: '96.87%'}\n",
      "Val Loss: 0.808662, Val Acc: 85.87%, Val-Class-Acc: {0: '85.87%', 1: '85.87%'}, LR: 0.000729\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_27.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_45.pth\n",
      "Epoch 46/200, Train Loss: 0.083121, Train-Class-Acc: {0: '97.82%', 1: '96.32%'}\n",
      "Val Loss: 0.843364, Val Acc: 83.42%, Val-Class-Acc: {0: '92.39%', 1: '74.46%'}, LR: 0.000729\n",
      "Epoch 47/200, Train Loss: 0.055519, Train-Class-Acc: {0: '97.82%', 1: '97.96%'}\n",
      "Val Loss: 0.696789, Val Acc: 83.97%, Val-Class-Acc: {0: '85.33%', 1: '82.61%'}, LR: 0.000729\n",
      "Epoch 48/200, Train Loss: 0.086049, Train-Class-Acc: {0: '97.28%', 1: '95.10%'}\n",
      "Val Loss: 0.552420, Val Acc: 86.41%, Val-Class-Acc: {0: '86.41%', 1: '86.41%'}, LR: 0.000729\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_24.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_48.pth\n",
      "Epoch 49/200, Train Loss: 0.054302, Train-Class-Acc: {0: '97.82%', 1: '98.23%'}\n",
      "Val Loss: 0.636485, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000729\n",
      "Epoch 50/200, Train Loss: 0.029641, Train-Class-Acc: {0: '99.32%', 1: '98.77%'}\n",
      "Val Loss: 0.699004, Val Acc: 84.78%, Val-Class-Acc: {0: '86.96%', 1: '82.61%'}, LR: 0.000729\n",
      "Epoch 51/200, Train Loss: 0.028229, Train-Class-Acc: {0: '98.91%', 1: '99.18%'}\n",
      "Val Loss: 0.776223, Val Acc: 84.78%, Val-Class-Acc: {0: '90.76%', 1: '78.80%'}, LR: 0.000729\n",
      "Epoch 52/200, Train Loss: 0.019285, Train-Class-Acc: {0: '99.73%', 1: '99.46%'}\n",
      "Val Loss: 0.823080, Val Acc: 84.78%, Val-Class-Acc: {0: '88.59%', 1: '80.98%'}, LR: 0.000729\n",
      "Epoch 53/200, Train Loss: 0.026176, Train-Class-Acc: {0: '99.46%', 1: '99.18%'}\n",
      "Val Loss: 1.065180, Val Acc: 83.42%, Val-Class-Acc: {0: '91.85%', 1: '75.00%'}, LR: 0.000656\n",
      "Epoch 54/200, Train Loss: 0.049059, Train-Class-Acc: {0: '98.77%', 1: '97.82%'}\n",
      "Val Loss: 0.798214, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000656\n",
      "Epoch 55/200, Train Loss: 0.032416, Train-Class-Acc: {0: '98.37%', 1: '99.46%'}\n",
      "Val Loss: 0.780530, Val Acc: 84.51%, Val-Class-Acc: {0: '91.85%', 1: '77.17%'}, LR: 0.000656\n",
      "Epoch 56/200, Train Loss: 0.030619, Train-Class-Acc: {0: '98.77%', 1: '98.64%'}\n",
      "Val Loss: 0.913541, Val Acc: 82.88%, Val-Class-Acc: {0: '89.67%', 1: '76.09%'}, LR: 0.000656\n",
      "Epoch 57/200, Train Loss: 0.026480, Train-Class-Acc: {0: '99.05%', 1: '99.05%'}\n",
      "Val Loss: 0.883822, Val Acc: 81.79%, Val-Class-Acc: {0: '77.17%', 1: '86.41%'}, LR: 0.000656\n",
      "Epoch 58/200, Train Loss: 0.021003, Train-Class-Acc: {0: '99.18%', 1: '99.46%'}\n",
      "Val Loss: 0.912637, Val Acc: 87.23%, Val-Class-Acc: {0: '90.76%', 1: '83.70%'}, LR: 0.000656\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_31.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_58.pth\n",
      "Epoch 59/200, Train Loss: 0.021894, Train-Class-Acc: {0: '99.05%', 1: '99.59%'}\n",
      "Val Loss: 0.989624, Val Acc: 84.51%, Val-Class-Acc: {0: '88.59%', 1: '80.43%'}, LR: 0.000656\n",
      "Epoch 60/200, Train Loss: 0.015767, Train-Class-Acc: {0: '99.59%', 1: '99.46%'}\n",
      "Val Loss: 0.946740, Val Acc: 82.07%, Val-Class-Acc: {0: '80.98%', 1: '83.15%'}, LR: 0.000656\n",
      "Epoch 61/200, Train Loss: 0.011801, Train-Class-Acc: {0: '99.73%', 1: '99.73%'}\n",
      "Val Loss: 1.034997, Val Acc: 84.24%, Val-Class-Acc: {0: '85.33%', 1: '83.15%'}, LR: 0.000656\n",
      "Epoch 62/200, Train Loss: 0.014323, Train-Class-Acc: {0: '99.86%', 1: '99.73%'}\n",
      "Val Loss: 1.065938, Val Acc: 82.88%, Val-Class-Acc: {0: '90.76%', 1: '75.00%'}, LR: 0.000656\n",
      "Epoch 63/200, Train Loss: 0.024071, Train-Class-Acc: {0: '99.18%', 1: '99.05%'}\n",
      "Val Loss: 1.140022, Val Acc: 85.33%, Val-Class-Acc: {0: '86.41%', 1: '84.24%'}, LR: 0.000656\n",
      "Epoch 64/200, Train Loss: 0.036624, Train-Class-Acc: {0: '98.09%', 1: '98.91%'}\n",
      "Val Loss: 1.029403, Val Acc: 87.23%, Val-Class-Acc: {0: '88.59%', 1: '85.87%'}, LR: 0.000590\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_45.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_64.pth\n",
      "Epoch 65/200, Train Loss: 0.043600, Train-Class-Acc: {0: '98.23%', 1: '98.50%'}\n",
      "Val Loss: 0.821691, Val Acc: 88.32%, Val-Class-Acc: {0: '90.76%', 1: '85.87%'}, LR: 0.000590\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_25.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_65.pth\n",
      "Epoch 66/200, Train Loss: 0.060166, Train-Class-Acc: {0: '97.96%', 1: '97.14%'}\n",
      "Val Loss: 1.006512, Val Acc: 84.24%, Val-Class-Acc: {0: '89.67%', 1: '78.80%'}, LR: 0.000590\n",
      "Epoch 67/200, Train Loss: 0.069711, Train-Class-Acc: {0: '98.23%', 1: '97.28%'}\n",
      "Val Loss: 0.799135, Val Acc: 85.60%, Val-Class-Acc: {0: '90.76%', 1: '80.43%'}, LR: 0.000590\n",
      "Epoch 68/200, Train Loss: 0.041763, Train-Class-Acc: {0: '97.82%', 1: '98.64%'}\n",
      "Val Loss: 0.935104, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000590\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_35.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_68.pth\n",
      "Epoch 69/200, Train Loss: 0.028098, Train-Class-Acc: {0: '99.05%', 1: '98.91%'}\n",
      "Val Loss: 0.814353, Val Acc: 88.32%, Val-Class-Acc: {0: '89.67%', 1: '86.96%'}, LR: 0.000590\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_48.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_69.pth\n",
      "Epoch 70/200, Train Loss: 0.024063, Train-Class-Acc: {0: '98.77%', 1: '99.32%'}\n",
      "Val Loss: 1.096823, Val Acc: 84.24%, Val-Class-Acc: {0: '95.11%', 1: '73.37%'}, LR: 0.000590\n",
      "Epoch 71/200, Train Loss: 0.022944, Train-Class-Acc: {0: '99.73%', 1: '98.64%'}\n",
      "Val Loss: 0.935506, Val Acc: 83.97%, Val-Class-Acc: {0: '81.52%', 1: '86.41%'}, LR: 0.000590\n",
      "Epoch 72/200, Train Loss: 0.012121, Train-Class-Acc: {0: '99.32%', 1: '99.86%'}\n",
      "Val Loss: 0.914402, Val Acc: 85.60%, Val-Class-Acc: {0: '89.13%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 73/200, Train Loss: 0.010345, Train-Class-Acc: {0: '99.73%', 1: '99.46%'}\n",
      "Val Loss: 0.922070, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000590\n",
      "Epoch 74/200, Train Loss: 0.009267, Train-Class-Acc: {0: '99.86%', 1: '99.86%'}\n",
      "Val Loss: 0.953311, Val Acc: 85.33%, Val-Class-Acc: {0: '86.96%', 1: '83.70%'}, LR: 0.000590\n",
      "Epoch 75/200, Train Loss: 0.004048, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.967707, Val Acc: 85.05%, Val-Class-Acc: {0: '88.59%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 76/200, Train Loss: 0.003298, Train-Class-Acc: {0: '99.73%', 1: '100.00%'}\n",
      "Val Loss: 0.984972, Val Acc: 85.33%, Val-Class-Acc: {0: '89.13%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 77/200, Train Loss: 0.005271, Train-Class-Acc: {0: '100.00%', 1: '99.59%'}\n",
      "Val Loss: 0.990009, Val Acc: 83.42%, Val-Class-Acc: {0: '83.15%', 1: '83.70%'}, LR: 0.000531\n",
      "Epoch 78/200, Train Loss: 0.004916, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.005484, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000531\n",
      "Epoch 79/200, Train Loss: 0.002214, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.978985, Val Acc: 85.05%, Val-Class-Acc: {0: '84.24%', 1: '85.87%'}, LR: 0.000531\n",
      "Epoch 80/200, Train Loss: 0.001323, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.986194, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 81/200, Train Loss: 0.002115, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.028488, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000531\n",
      "Epoch 82/200, Train Loss: 0.000757, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.047379, Val Acc: 84.51%, Val-Class-Acc: {0: '85.87%', 1: '83.15%'}, LR: 0.000531\n",
      "Epoch 83/200, Train Loss: 0.000896, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.066048, Val Acc: 84.78%, Val-Class-Acc: {0: '86.96%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 84/200, Train Loss: 0.000273, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.063322, Val Acc: 85.33%, Val-Class-Acc: {0: '86.41%', 1: '84.24%'}, LR: 0.000531\n",
      "Epoch 85/200, Train Loss: 0.000940, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.050216, Val Acc: 85.33%, Val-Class-Acc: {0: '85.87%', 1: '84.78%'}, LR: 0.000531\n",
      "Epoch 86/200, Train Loss: 0.000582, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.072622, Val Acc: 85.33%, Val-Class-Acc: {0: '85.87%', 1: '84.78%'}, LR: 0.000478\n",
      "Epoch 87/200, Train Loss: 0.000231, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.078778, Val Acc: 85.33%, Val-Class-Acc: {0: '85.87%', 1: '84.78%'}, LR: 0.000478\n",
      "Epoch 88/200, Train Loss: 0.000753, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.068824, Val Acc: 85.60%, Val-Class-Acc: {0: '86.96%', 1: '84.24%'}, LR: 0.000478\n",
      "Epoch 89/200, Train Loss: 0.000691, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.082834, Val Acc: 84.78%, Val-Class-Acc: {0: '86.96%', 1: '82.61%'}, LR: 0.000478\n",
      "Epoch 90/200, Train Loss: 0.000660, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.084621, Val Acc: 85.05%, Val-Class-Acc: {0: '86.41%', 1: '83.70%'}, LR: 0.000478\n",
      "Epoch 91/200, Train Loss: 0.000556, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.097950, Val Acc: 84.24%, Val-Class-Acc: {0: '86.41%', 1: '82.07%'}, LR: 0.000478\n",
      "Epoch 92/200, Train Loss: 0.000342, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.107515, Val Acc: 84.78%, Val-Class-Acc: {0: '86.96%', 1: '82.61%'}, LR: 0.000478\n",
      "Epoch 93/200, Train Loss: 0.001075, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.166141, Val Acc: 84.24%, Val-Class-Acc: {0: '85.33%', 1: '83.15%'}, LR: 0.000478\n",
      "Epoch 94/200, Train Loss: 0.001509, Train-Class-Acc: {0: '100.00%', 1: '99.86%'}\n",
      "Val Loss: 1.160528, Val Acc: 84.51%, Val-Class-Acc: {0: '87.50%', 1: '81.52%'}, LR: 0.000478\n",
      "Epoch 95/200, Train Loss: 0.000340, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.182396, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000478\n",
      "Epoch 96/200, Train Loss: 0.000450, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.183871, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000478\n",
      "Epoch 97/200, Train Loss: 0.000268, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.178045, Val Acc: 84.51%, Val-Class-Acc: {0: '86.96%', 1: '82.07%'}, LR: 0.000430\n",
      "Epoch 98/200, Train Loss: 0.000194, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.180630, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000430\n",
      "Epoch 99/200, Train Loss: 0.000434, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.174713, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000430\n",
      "Epoch 100/200, Train Loss: 0.000234, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.162852, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000430\n",
      "Epoch 101/200, Train Loss: 0.000678, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.139286, Val Acc: 84.78%, Val-Class-Acc: {0: '85.33%', 1: '84.24%'}, LR: 0.000430\n",
      "Epoch 102/200, Train Loss: 0.000441, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.154155, Val Acc: 85.87%, Val-Class-Acc: {0: '89.67%', 1: '82.07%'}, LR: 0.000430\n",
      "Epoch 103/200, Train Loss: 0.000326, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.175888, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000430\n",
      "Epoch 104/200, Train Loss: 0.000137, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.180091, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000430\n",
      "Epoch 105/200, Train Loss: 0.000400, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.209594, Val Acc: 85.87%, Val-Class-Acc: {0: '89.13%', 1: '82.61%'}, LR: 0.000430\n",
      "Epoch 106/200, Train Loss: 0.000336, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.216039, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000430\n",
      "Epoch 107/200, Train Loss: 0.000102, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.214132, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000430\n",
      "Epoch 108/200, Train Loss: 0.000098, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.218424, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000387\n",
      "Epoch 109/200, Train Loss: 0.000198, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.216528, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000387\n",
      "Epoch 110/200, Train Loss: 0.000133, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.224378, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000387\n",
      "Epoch 111/200, Train Loss: 0.000281, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.235188, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000387\n",
      "Epoch 112/200, Train Loss: 0.000134, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.245165, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000387\n",
      "Epoch 113/200, Train Loss: 0.000577, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.184098, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000387\n",
      "Epoch 114/200, Train Loss: 0.000318, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.166651, Val Acc: 84.24%, Val-Class-Acc: {0: '86.41%', 1: '82.07%'}, LR: 0.000387\n",
      "Epoch 115/200, Train Loss: 0.000289, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.187853, Val Acc: 84.51%, Val-Class-Acc: {0: '88.04%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 116/200, Train Loss: 0.000320, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.209451, Val Acc: 83.97%, Val-Class-Acc: {0: '86.96%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 117/200, Train Loss: 0.000199, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.214067, Val Acc: 84.24%, Val-Class-Acc: {0: '87.50%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 118/200, Train Loss: 0.000283, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.217030, Val Acc: 84.78%, Val-Class-Acc: {0: '88.04%', 1: '81.52%'}, LR: 0.000387\n",
      "Epoch 119/200, Train Loss: 0.000384, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.228415, Val Acc: 84.51%, Val-Class-Acc: {0: '87.50%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 120/200, Train Loss: 0.000110, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.231445, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000349\n",
      "Epoch 121/200, Train Loss: 0.000122, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.221979, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000349\n",
      "Epoch 122/200, Train Loss: 0.001101, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.187780, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000349\n",
      "Epoch 123/200, Train Loss: 0.000402, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.189243, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000349\n",
      "Epoch 124/200, Train Loss: 0.000411, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.167607, Val Acc: 85.60%, Val-Class-Acc: {0: '89.13%', 1: '82.07%'}, LR: 0.000349\n",
      "Epoch 125/200, Train Loss: 0.000280, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.194021, Val Acc: 84.51%, Val-Class-Acc: {0: '85.87%', 1: '83.15%'}, LR: 0.000349\n",
      "Epoch 126/200, Train Loss: 0.000375, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.219374, Val Acc: 84.24%, Val-Class-Acc: {0: '86.41%', 1: '82.07%'}, LR: 0.000349\n",
      "Epoch 127/200, Train Loss: 0.000324, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.230793, Val Acc: 84.51%, Val-Class-Acc: {0: '86.96%', 1: '82.07%'}, LR: 0.000349\n",
      "Epoch 128/200, Train Loss: 0.001020, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.221859, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000349\n",
      "Epoch 129/200, Train Loss: 0.000954, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.229561, Val Acc: 85.05%, Val-Class-Acc: {0: '89.67%', 1: '80.43%'}, LR: 0.000349\n",
      "Epoch 130/200, Train Loss: 0.000790, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.215462, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000314\n",
      "Epoch 131/200, Train Loss: 0.000351, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.206779, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000314\n",
      "Epoch 132/200, Train Loss: 0.000353, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.248691, Val Acc: 85.33%, Val-Class-Acc: {0: '89.13%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 133/200, Train Loss: 0.000166, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.274135, Val Acc: 85.05%, Val-Class-Acc: {0: '89.13%', 1: '80.98%'}, LR: 0.000314\n",
      "Epoch 134/200, Train Loss: 0.000760, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.269944, Val Acc: 84.24%, Val-Class-Acc: {0: '86.96%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 135/200, Train Loss: 0.000568, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.287875, Val Acc: 84.51%, Val-Class-Acc: {0: '87.50%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 136/200, Train Loss: 0.000324, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.308176, Val Acc: 84.24%, Val-Class-Acc: {0: '86.96%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 137/200, Train Loss: 0.000307, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.312439, Val Acc: 84.51%, Val-Class-Acc: {0: '86.96%', 1: '82.07%'}, LR: 0.000314\n",
      "Epoch 138/200, Train Loss: 0.000195, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.290173, Val Acc: 85.33%, Val-Class-Acc: {0: '89.13%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 139/200, Train Loss: 0.000083, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.286975, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000314\n",
      "Epoch 140/200, Train Loss: 0.000068, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.286025, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000314\n",
      "Epoch 141/200, Train Loss: 0.000348, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.288604, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000282\n",
      "Epoch 142/200, Train Loss: 0.000086, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.285910, Val Acc: 84.51%, Val-Class-Acc: {0: '87.50%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 143/200, Train Loss: 0.000220, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.281404, Val Acc: 84.24%, Val-Class-Acc: {0: '88.04%', 1: '80.43%'}, LR: 0.000282\n",
      "Epoch 144/200, Train Loss: 0.000152, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.250212, Val Acc: 84.78%, Val-Class-Acc: {0: '88.04%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 145/200, Train Loss: 0.000081, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.252168, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000282\n",
      "Epoch 146/200, Train Loss: 0.000061, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.255062, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000282\n",
      "Epoch 147/200, Train Loss: 0.012768, Train-Class-Acc: {0: '99.59%', 1: '99.86%'}\n",
      "Val Loss: 1.149268, Val Acc: 82.88%, Val-Class-Acc: {0: '80.43%', 1: '85.33%'}, LR: 0.000282\n",
      "Epoch 148/200, Train Loss: 0.023317, Train-Class-Acc: {0: '98.77%', 1: '99.05%'}\n",
      "Val Loss: 1.306659, Val Acc: 86.14%, Val-Class-Acc: {0: '88.59%', 1: '83.70%'}, LR: 0.000282\n",
      "Epoch 149/200, Train Loss: 0.059224, Train-Class-Acc: {0: '97.96%', 1: '97.55%'}\n",
      "Val Loss: 1.264820, Val Acc: 85.87%, Val-Class-Acc: {0: '88.04%', 1: '83.70%'}, LR: 0.000282\n",
      "Epoch 150/200, Train Loss: 0.044445, Train-Class-Acc: {0: '98.64%', 1: '99.05%'}\n",
      "Val Loss: 1.013844, Val Acc: 88.32%, Val-Class-Acc: {0: '88.59%', 1: '88.04%'}, LR: 0.000282\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_68.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_150.pth\n",
      "Epoch 151/200, Train Loss: 0.026784, Train-Class-Acc: {0: '98.77%', 1: '99.46%'}\n",
      "Val Loss: 1.024529, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000282\n",
      "Epoch 152/200, Train Loss: 0.013708, Train-Class-Acc: {0: '99.59%', 1: '99.46%'}\n",
      "Val Loss: 1.053815, Val Acc: 84.51%, Val-Class-Acc: {0: '90.22%', 1: '78.80%'}, LR: 0.000254\n",
      "Epoch 153/200, Train Loss: 0.013173, Train-Class-Acc: {0: '99.73%', 1: '99.32%'}\n",
      "Val Loss: 1.006537, Val Acc: 86.14%, Val-Class-Acc: {0: '85.87%', 1: '86.41%'}, LR: 0.000254\n",
      "Epoch 154/200, Train Loss: 0.008987, Train-Class-Acc: {0: '99.73%', 1: '99.86%'}\n",
      "Val Loss: 1.021878, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000254\n",
      "Epoch 155/200, Train Loss: 0.003966, Train-Class-Acc: {0: '99.86%', 1: '99.86%'}\n",
      "Val Loss: 1.056583, Val Acc: 85.87%, Val-Class-Acc: {0: '90.76%', 1: '80.98%'}, LR: 0.000254\n",
      "Epoch 156/200, Train Loss: 0.001900, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.069242, Val Acc: 85.87%, Val-Class-Acc: {0: '88.59%', 1: '83.15%'}, LR: 0.000254\n",
      "Epoch 157/200, Train Loss: 0.000646, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.072359, Val Acc: 86.68%, Val-Class-Acc: {0: '89.13%', 1: '84.24%'}, LR: 0.000254\n",
      "Epoch 158/200, Train Loss: 0.000772, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.071704, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000254\n",
      "Epoch 159/200, Train Loss: 0.000510, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.074760, Val Acc: 86.41%, Val-Class-Acc: {0: '87.50%', 1: '85.33%'}, LR: 0.000254\n",
      "Epoch 160/200, Train Loss: 0.000844, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.089386, Val Acc: 86.41%, Val-Class-Acc: {0: '87.50%', 1: '85.33%'}, LR: 0.000254\n",
      "Epoch 161/200, Train Loss: 0.000965, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.133417, Val Acc: 85.60%, Val-Class-Acc: {0: '86.96%', 1: '84.24%'}, LR: 0.000254\n",
      "Epoch 162/200, Train Loss: 0.001879, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.128589, Val Acc: 85.87%, Val-Class-Acc: {0: '88.04%', 1: '83.70%'}, LR: 0.000254\n",
      "Epoch 163/200, Train Loss: 0.000473, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.130519, Val Acc: 85.87%, Val-Class-Acc: {0: '88.04%', 1: '83.70%'}, LR: 0.000229\n",
      "Epoch 164/200, Train Loss: 0.000715, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.118736, Val Acc: 85.87%, Val-Class-Acc: {0: '86.41%', 1: '85.33%'}, LR: 0.000229\n",
      "Epoch 165/200, Train Loss: 0.003205, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.109041, Val Acc: 86.14%, Val-Class-Acc: {0: '86.41%', 1: '85.87%'}, LR: 0.000229\n",
      "Epoch 166/200, Train Loss: 0.004800, Train-Class-Acc: {0: '99.86%', 1: '99.86%'}\n",
      "Val Loss: 1.118538, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000229\n",
      "Epoch 167/200, Train Loss: 0.001653, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.107006, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000229\n",
      "Epoch 168/200, Train Loss: 0.000986, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.080345, Val Acc: 85.87%, Val-Class-Acc: {0: '88.59%', 1: '83.15%'}, LR: 0.000229\n",
      "Epoch 169/200, Train Loss: 0.000598, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.083905, Val Acc: 85.87%, Val-Class-Acc: {0: '88.04%', 1: '83.70%'}, LR: 0.000229\n",
      "Epoch 170/200, Train Loss: 0.000366, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.086834, Val Acc: 85.87%, Val-Class-Acc: {0: '89.13%', 1: '82.61%'}, LR: 0.000229\n",
      "Epoch 171/200, Train Loss: 0.000210, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.086444, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000229\n",
      "Epoch 172/200, Train Loss: 0.000358, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.096212, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000229\n",
      "Epoch 173/200, Train Loss: 0.000235, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.121890, Val Acc: 86.14%, Val-Class-Acc: {0: '88.04%', 1: '84.24%'}, LR: 0.000229\n",
      "Epoch 174/200, Train Loss: 0.000175, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.120551, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000206\n",
      "Epoch 175/200, Train Loss: 0.000412, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.125359, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000206\n",
      "Epoch 176/200, Train Loss: 0.000379, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.124447, Val Acc: 86.41%, Val-Class-Acc: {0: '87.50%', 1: '85.33%'}, LR: 0.000206\n",
      "Epoch 177/200, Train Loss: 0.000186, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.102943, Val Acc: 85.87%, Val-Class-Acc: {0: '88.04%', 1: '83.70%'}, LR: 0.000206\n",
      "Epoch 178/200, Train Loss: 0.000202, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.110244, Val Acc: 86.14%, Val-Class-Acc: {0: '88.59%', 1: '83.70%'}, LR: 0.000206\n",
      "Epoch 179/200, Train Loss: 0.000250, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.117600, Val Acc: 86.14%, Val-Class-Acc: {0: '89.13%', 1: '83.15%'}, LR: 0.000206\n",
      "Epoch 180/200, Train Loss: 0.000430, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.117078, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000206\n",
      "Epoch 181/200, Train Loss: 0.000271, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.131262, Val Acc: 85.60%, Val-Class-Acc: {0: '86.96%', 1: '84.24%'}, LR: 0.000206\n",
      "Epoch 182/200, Train Loss: 0.000269, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.144339, Val Acc: 86.14%, Val-Class-Acc: {0: '88.04%', 1: '84.24%'}, LR: 0.000206\n",
      "Epoch 183/200, Train Loss: 0.000267, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.146111, Val Acc: 85.87%, Val-Class-Acc: {0: '88.04%', 1: '83.70%'}, LR: 0.000206\n",
      "Epoch 184/200, Train Loss: 0.000168, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.142899, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000206\n",
      "Epoch 185/200, Train Loss: 0.000139, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.159166, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000185\n",
      "Epoch 186/200, Train Loss: 0.000123, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.162823, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000185\n",
      "Epoch 187/200, Train Loss: 0.000103, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.152522, Val Acc: 86.41%, Val-Class-Acc: {0: '87.50%', 1: '85.33%'}, LR: 0.000185\n",
      "Epoch 188/200, Train Loss: 0.000252, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.161664, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000185\n",
      "Epoch 189/200, Train Loss: 0.000158, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.171305, Val Acc: 86.14%, Val-Class-Acc: {0: '86.96%', 1: '85.33%'}, LR: 0.000185\n",
      "Epoch 190/200, Train Loss: 0.000136, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.179240, Val Acc: 86.14%, Val-Class-Acc: {0: '86.96%', 1: '85.33%'}, LR: 0.000185\n",
      "Epoch 191/200, Train Loss: 0.000079, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.179887, Val Acc: 86.14%, Val-Class-Acc: {0: '86.96%', 1: '85.33%'}, LR: 0.000185\n",
      "Epoch 192/200, Train Loss: 0.000127, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.191238, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000185\n",
      "Epoch 193/200, Train Loss: 0.000085, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.180350, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000185\n",
      "Epoch 194/200, Train Loss: 0.000895, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.208497, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000185\n",
      "Epoch 195/200, Train Loss: 0.000979, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.222345, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000185\n",
      "Epoch 196/200, Train Loss: 0.000297, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.222131, Val Acc: 85.60%, Val-Class-Acc: {0: '86.41%', 1: '84.78%'}, LR: 0.000167\n",
      "Epoch 197/200, Train Loss: 0.000162, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.220074, Val Acc: 85.60%, Val-Class-Acc: {0: '86.41%', 1: '84.78%'}, LR: 0.000167\n",
      "Epoch 198/200, Train Loss: 0.000138, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.227324, Val Acc: 85.33%, Val-Class-Acc: {0: '85.33%', 1: '85.33%'}, LR: 0.000167\n",
      "Epoch 199/200, Train Loss: 0.000144, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.214109, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000167\n",
      "Epoch 200/200, Train Loss: 0.000151, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.219289, Val Acc: 86.41%, Val-Class-Acc: {0: '87.50%', 1: '85.33%'}, LR: 0.000167\n",
      "\n",
      "🏆 Best model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_best.pth (Val Accuracy: 88.32%)\n",
      "\n",
      "📌 Final model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_final.pth\n",
      "\n",
      "🎯 Top 5 Best Models:\n",
      "Epoch 150, Train Loss: 0.044445, Train-Acc: {0: '98.64%', 1: '99.05%'},\n",
      "Val Loss: 1.013844, Val Acc: 88.32%, Val-Class-Acc: {0: '88.59%', 1: '88.04%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_150.pth\n",
      "Epoch 69, Train Loss: 0.028098, Train-Acc: {0: '99.05%', 1: '98.91%'},\n",
      "Val Loss: 0.814353, Val Acc: 88.32%, Val-Class-Acc: {0: '89.67%', 1: '86.96%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_69.pth\n",
      "Epoch 65, Train Loss: 0.043600, Train-Acc: {0: '98.23%', 1: '98.50%'},\n",
      "Val Loss: 0.821691, Val Acc: 88.32%, Val-Class-Acc: {0: '90.76%', 1: '85.87%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_65.pth\n",
      "Epoch 64, Train Loss: 0.036624, Train-Acc: {0: '98.09%', 1: '98.91%'},\n",
      "Val Loss: 1.029403, Val Acc: 87.23%, Val-Class-Acc: {0: '88.59%', 1: '85.87%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_64.pth\n",
      "Epoch 58, Train Loss: 0.021003, Train-Acc: {0: '99.18%', 1: '99.46%'},\n",
      "Val Loss: 0.912637, Val Acc: 87.23%, Val-Class-Acc: {0: '90.76%', 1: '83.70%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_arg/ResNet18_1D_epoch_58.pth\n",
      "\n",
      "🧠 Model Summary:\n",
      "Total Parameters: 3,849,858\n",
      "Model Size (float32): 14.69 MB\n",
      "Total Training Time: 410.51 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))  # Shape: (B, 5000, 12)\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# ==== Model Hyperparameters ====\n",
    "input_channels = X_train.shape[2]                  # 12 leads\n",
    "output_size = len(np.unique(y_train))              # Number of classes (e.g., 2 for Period 1)\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "dropout = 0.0                                       # Not needed for ResNet18_1D\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "print(\"✅ input shape:\", X_train.shape)\n",
    "print(\"✅ unique y_train:\", np.unique(y_train))\n",
    "print(\"✅ unique y_test :\", np.unique(y_test))\n",
    "assert np.max(y_train) < output_size\n",
    "assert np.max(y_test) < output_size\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/ResNet18_arg\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Model ====\n",
    "model = ResNet18_1D(input_channels=input_channels, output_size=output_size).to(device)\n",
    "\n",
    "# ==== Optimizer and Training ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# ==== Train ====\n",
    "result_summary = train_model_general_classifier(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name='ResNet18_1D',\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del model, X_train, y_train, X_test, y_test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475ec8b2",
   "metadata": {},
   "source": [
    "### ResNet 18 - 1D_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac2cfbc",
   "metadata": {},
   "source": [
    "#### No Init Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be0b8aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Automatically selected GPU:\n",
      "    - CUDA Device ID : 0\n",
      "    - Memory Used    : 4542 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "✅ input shape: (1468, 5000, 12)\n",
      "✅ unique y_train: [0 1]\n",
      "✅ unique y_test : [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 'train_model_general_classifier' started.\n",
      "✅ Removed existing folder: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2\n",
      "\n",
      "✅ Data Overview:\n",
      "X_train: torch.Size([1468, 5000, 12]), y_train: torch.Size([1468])\n",
      "X_val: torch.Size([368, 5000, 12]), y_val: torch.Size([368])\n",
      "Epoch 1/200, Train Loss: 0.504826, Train-Class-Acc: {0: '80.52%', 1: '70.98%'}\n",
      "Val Loss: 0.461798, Val Acc: 79.89%, Val-Class-Acc: {0: '69.02%', 1: '90.76%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.424017, Train-Class-Acc: {0: '82.43%', 1: '77.25%'}\n",
      "Val Loss: 0.964001, Val Acc: 67.39%, Val-Class-Acc: {0: '39.13%', 1: '95.65%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.377516, Train-Class-Acc: {0: '86.78%', 1: '78.34%'}\n",
      "Val Loss: 0.442596, Val Acc: 82.07%, Val-Class-Acc: {0: '78.80%', 1: '85.33%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.359810, Train-Class-Acc: {0: '87.33%', 1: '79.16%'}\n",
      "Val Loss: 0.378165, Val Acc: 84.24%, Val-Class-Acc: {0: '92.93%', 1: '75.54%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.339763, Train-Class-Acc: {0: '88.56%', 1: '81.74%'}\n",
      "Val Loss: 0.576080, Val Acc: 77.99%, Val-Class-Acc: {0: '69.02%', 1: '86.96%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.368058, Train-Class-Acc: {0: '89.65%', 1: '75.48%'}\n",
      "Val Loss: 0.956237, Val Acc: 54.08%, Val-Class-Acc: {0: '8.15%', 1: '100.00%'}, LR: 0.001000\n",
      "Epoch 7/200, Train Loss: 0.361621, Train-Class-Acc: {0: '85.01%', 1: '82.56%'}\n",
      "Val Loss: 0.551067, Val Acc: 76.90%, Val-Class-Acc: {0: '61.96%', 1: '91.85%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_2.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.317404, Train-Class-Acc: {0: '88.96%', 1: '82.56%'}\n",
      "Val Loss: 0.354066, Val Acc: 84.24%, Val-Class-Acc: {0: '92.93%', 1: '75.54%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_7.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_8.pth\n",
      "Epoch 9/200, Train Loss: 0.325272, Train-Class-Acc: {0: '88.28%', 1: '84.74%'}\n",
      "Val Loss: 0.361825, Val Acc: 85.60%, Val-Class-Acc: {0: '85.33%', 1: '85.87%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_5.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.302863, Train-Class-Acc: {0: '92.10%', 1: '83.38%'}\n",
      "Val Loss: 0.325495, Val Acc: 86.96%, Val-Class-Acc: {0: '92.93%', 1: '80.98%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_1.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_10.pth\n",
      "Epoch 11/200, Train Loss: 0.286348, Train-Class-Acc: {0: '90.60%', 1: '83.51%'}\n",
      "Val Loss: 0.407089, Val Acc: 85.60%, Val-Class-Acc: {0: '92.93%', 1: '78.26%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_3.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_11.pth\n",
      "Epoch 12/200, Train Loss: 0.281294, Train-Class-Acc: {0: '90.05%', 1: '84.60%'}\n",
      "Val Loss: 0.525315, Val Acc: 83.15%, Val-Class-Acc: {0: '93.48%', 1: '72.83%'}, LR: 0.001000\n",
      "Epoch 13/200, Train Loss: 0.260580, Train-Class-Acc: {0: '91.28%', 1: '87.74%'}\n",
      "Val Loss: 0.397271, Val Acc: 83.70%, Val-Class-Acc: {0: '88.04%', 1: '79.35%'}, LR: 0.001000\n",
      "Epoch 14/200, Train Loss: 0.256961, Train-Class-Acc: {0: '90.46%', 1: '86.92%'}\n",
      "Val Loss: 0.382293, Val Acc: 85.33%, Val-Class-Acc: {0: '93.48%', 1: '77.17%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_4.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_14.pth\n",
      "Epoch 15/200, Train Loss: 0.249579, Train-Class-Acc: {0: '91.28%', 1: '87.74%'}\n",
      "Val Loss: 0.496199, Val Acc: 85.60%, Val-Class-Acc: {0: '95.11%', 1: '76.09%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_8.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_15.pth\n",
      "Epoch 16/200, Train Loss: 0.282803, Train-Class-Acc: {0: '91.01%', 1: '85.15%'}\n",
      "Val Loss: 0.542207, Val Acc: 76.36%, Val-Class-Acc: {0: '96.74%', 1: '55.98%'}, LR: 0.001000\n",
      "Epoch 17/200, Train Loss: 0.252695, Train-Class-Acc: {0: '91.83%', 1: '87.19%'}\n",
      "Val Loss: 0.620376, Val Acc: 78.80%, Val-Class-Acc: {0: '61.96%', 1: '95.65%'}, LR: 0.001000\n",
      "Epoch 18/200, Train Loss: 0.217651, Train-Class-Acc: {0: '91.42%', 1: '88.69%'}\n",
      "Val Loss: 0.528074, Val Acc: 78.80%, Val-Class-Acc: {0: '65.76%', 1: '91.85%'}, LR: 0.001000\n",
      "Epoch 19/200, Train Loss: 0.239360, Train-Class-Acc: {0: '91.55%', 1: '88.56%'}\n",
      "Val Loss: 0.674407, Val Acc: 70.65%, Val-Class-Acc: {0: '46.74%', 1: '94.57%'}, LR: 0.001000\n",
      "Epoch 20/200, Train Loss: 0.225442, Train-Class-Acc: {0: '92.64%', 1: '89.37%'}\n",
      "Val Loss: 0.479391, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_14.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_20.pth\n",
      "Epoch 21/200, Train Loss: 0.194839, Train-Class-Acc: {0: '92.78%', 1: '90.87%'}\n",
      "Val Loss: 0.433276, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 1: '84.78%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_9.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_21.pth\n",
      "Epoch 22/200, Train Loss: 0.207159, Train-Class-Acc: {0: '92.10%', 1: '88.83%'}\n",
      "Val Loss: 0.440140, Val Acc: 86.68%, Val-Class-Acc: {0: '85.33%', 1: '88.04%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_11.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_22.pth\n",
      "Epoch 23/200, Train Loss: 0.188601, Train-Class-Acc: {0: '93.46%', 1: '90.33%'}\n",
      "Val Loss: 0.461958, Val Acc: 86.41%, Val-Class-Acc: {0: '84.78%', 1: '88.04%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_15.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_23.pth\n",
      "Epoch 24/200, Train Loss: 0.185991, Train-Class-Acc: {0: '93.05%', 1: '90.46%'}\n",
      "Val Loss: 0.486054, Val Acc: 79.89%, Val-Class-Acc: {0: '65.22%', 1: '94.57%'}, LR: 0.000900\n",
      "Epoch 25/200, Train Loss: 0.164186, Train-Class-Acc: {0: '94.69%', 1: '91.14%'}\n",
      "Val Loss: 0.631262, Val Acc: 85.87%, Val-Class-Acc: {0: '91.85%', 1: '79.89%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_20.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_25.pth\n",
      "Epoch 26/200, Train Loss: 0.167438, Train-Class-Acc: {0: '94.01%', 1: '92.23%'}\n",
      "Val Loss: 0.569273, Val Acc: 80.71%, Val-Class-Acc: {0: '67.39%', 1: '94.02%'}, LR: 0.000900\n",
      "Epoch 27/200, Train Loss: 0.179040, Train-Class-Acc: {0: '92.64%', 1: '91.83%'}\n",
      "Val Loss: 0.479036, Val Acc: 84.51%, Val-Class-Acc: {0: '83.15%', 1: '85.87%'}, LR: 0.000900\n",
      "Epoch 28/200, Train Loss: 0.150359, Train-Class-Acc: {0: '93.46%', 1: '93.05%'}\n",
      "Val Loss: 0.519006, Val Acc: 83.15%, Val-Class-Acc: {0: '79.89%', 1: '86.41%'}, LR: 0.000900\n",
      "Epoch 29/200, Train Loss: 0.176778, Train-Class-Acc: {0: '94.69%', 1: '91.55%'}\n",
      "Val Loss: 0.499793, Val Acc: 82.07%, Val-Class-Acc: {0: '75.00%', 1: '89.13%'}, LR: 0.000900\n",
      "Epoch 30/200, Train Loss: 0.170773, Train-Class-Acc: {0: '92.78%', 1: '92.10%'}\n",
      "Val Loss: 0.474019, Val Acc: 85.60%, Val-Class-Acc: {0: '86.96%', 1: '84.24%'}, LR: 0.000900\n",
      "Epoch 31/200, Train Loss: 0.126939, Train-Class-Acc: {0: '94.55%', 1: '93.73%'}\n",
      "Val Loss: 0.609662, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000900\n",
      "Epoch 32/200, Train Loss: 0.143676, Train-Class-Acc: {0: '94.28%', 1: '94.14%'}\n",
      "Val Loss: 0.567612, Val Acc: 86.41%, Val-Class-Acc: {0: '85.33%', 1: '87.50%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_25.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_32.pth\n",
      "Epoch 33/200, Train Loss: 0.121774, Train-Class-Acc: {0: '95.91%', 1: '93.87%'}\n",
      "Val Loss: 0.527166, Val Acc: 85.05%, Val-Class-Acc: {0: '89.67%', 1: '80.43%'}, LR: 0.000810\n",
      "Epoch 34/200, Train Loss: 0.133652, Train-Class-Acc: {0: '95.37%', 1: '93.19%'}\n",
      "Val Loss: 0.931417, Val Acc: 77.72%, Val-Class-Acc: {0: '61.41%', 1: '94.02%'}, LR: 0.000810\n",
      "Epoch 35/200, Train Loss: 0.118042, Train-Class-Acc: {0: '96.32%', 1: '94.55%'}\n",
      "Val Loss: 0.640787, Val Acc: 85.60%, Val-Class-Acc: {0: '86.96%', 1: '84.24%'}, LR: 0.000810\n",
      "Epoch 36/200, Train Loss: 0.125073, Train-Class-Acc: {0: '94.82%', 1: '94.96%'}\n",
      "Val Loss: 0.571594, Val Acc: 87.23%, Val-Class-Acc: {0: '88.04%', 1: '86.41%'}, LR: 0.000810\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_23.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_36.pth\n",
      "Epoch 37/200, Train Loss: 0.088869, Train-Class-Acc: {0: '98.50%', 1: '95.64%'}\n",
      "Val Loss: 0.609821, Val Acc: 85.87%, Val-Class-Acc: {0: '91.30%', 1: '80.43%'}, LR: 0.000810\n",
      "Epoch 38/200, Train Loss: 0.089207, Train-Class-Acc: {0: '97.14%', 1: '94.96%'}\n",
      "Val Loss: 0.667104, Val Acc: 85.87%, Val-Class-Acc: {0: '92.39%', 1: '79.35%'}, LR: 0.000810\n",
      "Epoch 39/200, Train Loss: 0.141479, Train-Class-Acc: {0: '95.78%', 1: '94.01%'}\n",
      "Val Loss: 0.484384, Val Acc: 86.14%, Val-Class-Acc: {0: '89.13%', 1: '83.15%'}, LR: 0.000810\n",
      "Epoch 40/200, Train Loss: 0.095957, Train-Class-Acc: {0: '96.87%', 1: '94.55%'}\n",
      "Val Loss: 0.519273, Val Acc: 88.04%, Val-Class-Acc: {0: '91.85%', 1: '84.24%'}, LR: 0.000810\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_32.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_40.pth\n",
      "Epoch 41/200, Train Loss: 0.106580, Train-Class-Acc: {0: '95.91%', 1: '94.82%'}\n",
      "Val Loss: 0.952555, Val Acc: 83.42%, Val-Class-Acc: {0: '94.57%', 1: '72.28%'}, LR: 0.000810\n",
      "Epoch 42/200, Train Loss: 0.095933, Train-Class-Acc: {0: '96.87%', 1: '95.37%'}\n",
      "Val Loss: 0.717617, Val Acc: 85.05%, Val-Class-Acc: {0: '92.39%', 1: '77.72%'}, LR: 0.000810\n",
      "Epoch 43/200, Train Loss: 0.089211, Train-Class-Acc: {0: '97.14%', 1: '95.91%'}\n",
      "Val Loss: 0.621646, Val Acc: 84.24%, Val-Class-Acc: {0: '78.26%', 1: '90.22%'}, LR: 0.000810\n",
      "Epoch 44/200, Train Loss: 0.046991, Train-Class-Acc: {0: '98.09%', 1: '98.23%'}\n",
      "Val Loss: 0.762059, Val Acc: 84.78%, Val-Class-Acc: {0: '82.61%', 1: '86.96%'}, LR: 0.000729\n",
      "Epoch 45/200, Train Loss: 0.042746, Train-Class-Acc: {0: '98.77%', 1: '97.41%'}\n",
      "Val Loss: 0.795657, Val Acc: 86.41%, Val-Class-Acc: {0: '93.48%', 1: '79.35%'}, LR: 0.000729\n",
      "Epoch 46/200, Train Loss: 0.036901, Train-Class-Acc: {0: '99.05%', 1: '97.96%'}\n",
      "Val Loss: 0.980209, Val Acc: 82.88%, Val-Class-Acc: {0: '77.17%', 1: '88.59%'}, LR: 0.000729\n",
      "Epoch 47/200, Train Loss: 0.070730, Train-Class-Acc: {0: '97.41%', 1: '96.05%'}\n",
      "Val Loss: 0.844549, Val Acc: 84.24%, Val-Class-Acc: {0: '80.98%', 1: '87.50%'}, LR: 0.000729\n",
      "Epoch 48/200, Train Loss: 0.167856, Train-Class-Acc: {0: '94.55%', 1: '93.32%'}\n",
      "Val Loss: 0.508525, Val Acc: 84.51%, Val-Class-Acc: {0: '79.89%', 1: '89.13%'}, LR: 0.000729\n",
      "Epoch 49/200, Train Loss: 0.098096, Train-Class-Acc: {0: '96.05%', 1: '95.78%'}\n",
      "Val Loss: 0.644045, Val Acc: 85.60%, Val-Class-Acc: {0: '90.76%', 1: '80.43%'}, LR: 0.000729\n",
      "Epoch 50/200, Train Loss: 0.049995, Train-Class-Acc: {0: '99.18%', 1: '97.28%'}\n",
      "Val Loss: 0.742258, Val Acc: 85.05%, Val-Class-Acc: {0: '83.15%', 1: '86.96%'}, LR: 0.000729\n",
      "Epoch 51/200, Train Loss: 0.027492, Train-Class-Acc: {0: '99.73%', 1: '98.37%'}\n",
      "Val Loss: 0.884440, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000729\n",
      "Epoch 52/200, Train Loss: 0.028011, Train-Class-Acc: {0: '99.18%', 1: '98.23%'}\n",
      "Val Loss: 0.972597, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000729\n",
      "Epoch 53/200, Train Loss: 0.035405, Train-Class-Acc: {0: '99.18%', 1: '97.41%'}\n",
      "Val Loss: 1.096411, Val Acc: 83.15%, Val-Class-Acc: {0: '79.35%', 1: '86.96%'}, LR: 0.000729\n",
      "Epoch 54/200, Train Loss: 0.073136, Train-Class-Acc: {0: '97.55%', 1: '96.19%'}\n",
      "Val Loss: 1.868599, Val Acc: 70.92%, Val-Class-Acc: {0: '45.11%', 1: '96.74%'}, LR: 0.000729\n",
      "Epoch 55/200, Train Loss: 0.096926, Train-Class-Acc: {0: '97.00%', 1: '95.50%'}\n",
      "Val Loss: 0.743977, Val Acc: 85.87%, Val-Class-Acc: {0: '90.22%', 1: '81.52%'}, LR: 0.000656\n",
      "Epoch 56/200, Train Loss: 0.041141, Train-Class-Acc: {0: '99.05%', 1: '97.55%'}\n",
      "Val Loss: 0.771651, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000656\n",
      "Epoch 57/200, Train Loss: 0.036041, Train-Class-Acc: {0: '98.91%', 1: '98.50%'}\n",
      "Val Loss: 0.933933, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000656\n",
      "Epoch 58/200, Train Loss: 0.029461, Train-Class-Acc: {0: '99.46%', 1: '97.41%'}\n",
      "Val Loss: 0.933850, Val Acc: 83.70%, Val-Class-Acc: {0: '82.61%', 1: '84.78%'}, LR: 0.000656\n",
      "Epoch 59/200, Train Loss: 0.019532, Train-Class-Acc: {0: '99.59%', 1: '99.05%'}\n",
      "Val Loss: 0.999731, Val Acc: 84.51%, Val-Class-Acc: {0: '84.24%', 1: '84.78%'}, LR: 0.000656\n",
      "Epoch 60/200, Train Loss: 0.018550, Train-Class-Acc: {0: '99.59%', 1: '98.50%'}\n",
      "Val Loss: 1.096379, Val Acc: 83.97%, Val-Class-Acc: {0: '87.50%', 1: '80.43%'}, LR: 0.000656\n",
      "Epoch 61/200, Train Loss: 0.012702, Train-Class-Acc: {0: '99.73%', 1: '99.32%'}\n",
      "Val Loss: 1.086137, Val Acc: 85.33%, Val-Class-Acc: {0: '89.67%', 1: '80.98%'}, LR: 0.000656\n",
      "Epoch 62/200, Train Loss: 0.022665, Train-Class-Acc: {0: '99.46%', 1: '98.64%'}\n",
      "Val Loss: 1.165446, Val Acc: 85.87%, Val-Class-Acc: {0: '90.76%', 1: '80.98%'}, LR: 0.000656\n",
      "Epoch 63/200, Train Loss: 0.057644, Train-Class-Acc: {0: '98.23%', 1: '97.41%'}\n",
      "Val Loss: 1.032975, Val Acc: 80.71%, Val-Class-Acc: {0: '75.00%', 1: '86.41%'}, LR: 0.000656\n",
      "Epoch 64/200, Train Loss: 0.089428, Train-Class-Acc: {0: '97.00%', 1: '96.32%'}\n",
      "Val Loss: 0.988210, Val Acc: 87.23%, Val-Class-Acc: {0: '90.76%', 1: '83.70%'}, LR: 0.000656\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_21.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_64.pth\n",
      "Epoch 65/200, Train Loss: 0.060519, Train-Class-Acc: {0: '97.55%', 1: '97.82%'}\n",
      "Val Loss: 0.815606, Val Acc: 84.24%, Val-Class-Acc: {0: '82.61%', 1: '85.87%'}, LR: 0.000656\n",
      "Epoch 66/200, Train Loss: 0.038408, Train-Class-Acc: {0: '99.05%', 1: '97.82%'}\n",
      "Val Loss: 0.912770, Val Acc: 83.70%, Val-Class-Acc: {0: '78.26%', 1: '89.13%'}, LR: 0.000590\n",
      "Epoch 67/200, Train Loss: 0.018811, Train-Class-Acc: {0: '99.73%', 1: '98.91%'}\n",
      "Val Loss: 0.973166, Val Acc: 86.96%, Val-Class-Acc: {0: '90.22%', 1: '83.70%'}, LR: 0.000590\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_22.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_67.pth\n",
      "Epoch 68/200, Train Loss: 0.013124, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 0.974238, Val Acc: 87.23%, Val-Class-Acc: {0: '88.59%', 1: '85.87%'}, LR: 0.000590\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_10.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_68.pth\n",
      "Epoch 69/200, Train Loss: 0.016014, Train-Class-Acc: {0: '99.59%', 1: '98.77%'}\n",
      "Val Loss: 1.031455, Val Acc: 85.87%, Val-Class-Acc: {0: '90.76%', 1: '80.98%'}, LR: 0.000590\n",
      "Epoch 70/200, Train Loss: 0.019209, Train-Class-Acc: {0: '99.05%', 1: '99.05%'}\n",
      "Val Loss: 1.063299, Val Acc: 85.05%, Val-Class-Acc: {0: '84.24%', 1: '85.87%'}, LR: 0.000590\n",
      "Epoch 71/200, Train Loss: 0.018964, Train-Class-Acc: {0: '99.46%', 1: '99.18%'}\n",
      "Val Loss: 1.266945, Val Acc: 85.87%, Val-Class-Acc: {0: '89.67%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 72/200, Train Loss: 0.032710, Train-Class-Acc: {0: '99.18%', 1: '98.23%'}\n",
      "Val Loss: 1.303715, Val Acc: 84.24%, Val-Class-Acc: {0: '84.78%', 1: '83.70%'}, LR: 0.000590\n",
      "Epoch 73/200, Train Loss: 0.061766, Train-Class-Acc: {0: '98.50%', 1: '97.41%'}\n",
      "Val Loss: 0.971097, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000590\n",
      "Epoch 74/200, Train Loss: 0.034048, Train-Class-Acc: {0: '99.05%', 1: '98.64%'}\n",
      "Val Loss: 0.889743, Val Acc: 83.15%, Val-Class-Acc: {0: '80.98%', 1: '85.33%'}, LR: 0.000590\n",
      "Epoch 75/200, Train Loss: 0.023585, Train-Class-Acc: {0: '99.18%', 1: '97.96%'}\n",
      "Val Loss: 1.084032, Val Acc: 84.24%, Val-Class-Acc: {0: '89.67%', 1: '78.80%'}, LR: 0.000590\n",
      "Epoch 76/200, Train Loss: 0.018206, Train-Class-Acc: {0: '99.59%', 1: '98.77%'}\n",
      "Val Loss: 1.063450, Val Acc: 86.41%, Val-Class-Acc: {0: '86.96%', 1: '85.87%'}, LR: 0.000590\n",
      "Epoch 77/200, Train Loss: 0.013116, Train-Class-Acc: {0: '99.73%', 1: '99.18%'}\n",
      "Val Loss: 1.100379, Val Acc: 87.50%, Val-Class-Acc: {0: '91.30%', 1: '83.70%'}, LR: 0.000531\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_67.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_77.pth\n",
      "Epoch 78/200, Train Loss: 0.024736, Train-Class-Acc: {0: '99.59%', 1: '98.23%'}\n",
      "Val Loss: 1.103101, Val Acc: 85.60%, Val-Class-Acc: {0: '85.87%', 1: '85.33%'}, LR: 0.000531\n",
      "Epoch 79/200, Train Loss: 0.017303, Train-Class-Acc: {0: '99.86%', 1: '98.37%'}\n",
      "Val Loss: 1.132800, Val Acc: 83.70%, Val-Class-Acc: {0: '77.17%', 1: '90.22%'}, LR: 0.000531\n",
      "Epoch 80/200, Train Loss: 0.037392, Train-Class-Acc: {0: '99.18%', 1: '97.68%'}\n",
      "Val Loss: 1.118223, Val Acc: 83.15%, Val-Class-Acc: {0: '79.89%', 1: '86.41%'}, LR: 0.000531\n",
      "Epoch 81/200, Train Loss: 0.017404, Train-Class-Acc: {0: '99.73%', 1: '98.50%'}\n",
      "Val Loss: 1.160728, Val Acc: 85.33%, Val-Class-Acc: {0: '90.76%', 1: '79.89%'}, LR: 0.000531\n",
      "Epoch 82/200, Train Loss: 0.012623, Train-Class-Acc: {0: '99.59%', 1: '99.46%'}\n",
      "Val Loss: 1.019671, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000531\n",
      "Epoch 83/200, Train Loss: 0.026392, Train-Class-Acc: {0: '99.18%', 1: '98.37%'}\n",
      "Val Loss: 1.195256, Val Acc: 85.05%, Val-Class-Acc: {0: '80.98%', 1: '89.13%'}, LR: 0.000531\n",
      "Epoch 84/200, Train Loss: 0.026588, Train-Class-Acc: {0: '99.18%', 1: '98.77%'}\n",
      "Val Loss: 1.044434, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 85/200, Train Loss: 0.021565, Train-Class-Acc: {0: '99.73%', 1: '98.37%'}\n",
      "Val Loss: 1.087607, Val Acc: 85.60%, Val-Class-Acc: {0: '82.07%', 1: '89.13%'}, LR: 0.000531\n",
      "Epoch 86/200, Train Loss: 0.022670, Train-Class-Acc: {0: '99.05%', 1: '98.91%'}\n",
      "Val Loss: 1.044445, Val Acc: 86.41%, Val-Class-Acc: {0: '86.96%', 1: '85.87%'}, LR: 0.000531\n",
      "Epoch 87/200, Train Loss: 0.018655, Train-Class-Acc: {0: '99.73%', 1: '98.37%'}\n",
      "Val Loss: 1.134178, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 88/200, Train Loss: 0.013326, Train-Class-Acc: {0: '99.73%', 1: '99.59%'}\n",
      "Val Loss: 1.182965, Val Acc: 84.24%, Val-Class-Acc: {0: '84.78%', 1: '83.70%'}, LR: 0.000478\n",
      "Epoch 89/200, Train Loss: 0.013239, Train-Class-Acc: {0: '99.86%', 1: '98.91%'}\n",
      "Val Loss: 1.423493, Val Acc: 83.70%, Val-Class-Acc: {0: '88.04%', 1: '79.35%'}, LR: 0.000478\n",
      "Epoch 90/200, Train Loss: 0.015487, Train-Class-Acc: {0: '99.86%', 1: '97.96%'}\n",
      "Val Loss: 1.361152, Val Acc: 84.24%, Val-Class-Acc: {0: '87.50%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 91/200, Train Loss: 0.009770, Train-Class-Acc: {0: '100.00%', 1: '98.50%'}\n",
      "Val Loss: 1.412006, Val Acc: 85.05%, Val-Class-Acc: {0: '85.33%', 1: '84.78%'}, LR: 0.000478\n",
      "Epoch 92/200, Train Loss: 0.009218, Train-Class-Acc: {0: '99.86%', 1: '98.91%'}\n",
      "Val Loss: 1.351880, Val Acc: 85.60%, Val-Class-Acc: {0: '86.96%', 1: '84.24%'}, LR: 0.000478\n",
      "Epoch 93/200, Train Loss: 0.009936, Train-Class-Acc: {0: '99.86%', 1: '98.64%'}\n",
      "Val Loss: 1.423689, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000478\n",
      "Epoch 94/200, Train Loss: 0.012504, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 1.369856, Val Acc: 84.78%, Val-Class-Acc: {0: '84.78%', 1: '84.78%'}, LR: 0.000478\n",
      "Epoch 95/200, Train Loss: 0.012274, Train-Class-Acc: {0: '99.46%', 1: '99.46%'}\n",
      "Val Loss: 1.270909, Val Acc: 84.51%, Val-Class-Acc: {0: '84.24%', 1: '84.78%'}, LR: 0.000478\n",
      "Epoch 96/200, Train Loss: 0.036270, Train-Class-Acc: {0: '99.32%', 1: '97.41%'}\n",
      "Val Loss: 1.223235, Val Acc: 84.51%, Val-Class-Acc: {0: '82.61%', 1: '86.41%'}, LR: 0.000478\n",
      "Epoch 97/200, Train Loss: 0.051549, Train-Class-Acc: {0: '98.64%', 1: '97.55%'}\n",
      "Val Loss: 1.447235, Val Acc: 84.24%, Val-Class-Acc: {0: '90.22%', 1: '78.26%'}, LR: 0.000478\n",
      "Epoch 98/200, Train Loss: 0.057344, Train-Class-Acc: {0: '98.37%', 1: '96.73%'}\n",
      "Val Loss: 1.077088, Val Acc: 83.70%, Val-Class-Acc: {0: '84.78%', 1: '82.61%'}, LR: 0.000478\n",
      "Epoch 99/200, Train Loss: 0.024550, Train-Class-Acc: {0: '99.46%', 1: '98.77%'}\n",
      "Val Loss: 1.065681, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000430\n",
      "Epoch 100/200, Train Loss: 0.016859, Train-Class-Acc: {0: '99.73%', 1: '98.50%'}\n",
      "Val Loss: 1.021368, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000430\n",
      "Epoch 101/200, Train Loss: 0.030026, Train-Class-Acc: {0: '98.91%', 1: '98.64%'}\n",
      "Val Loss: 1.103084, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.000430\n",
      "Epoch 102/200, Train Loss: 0.023734, Train-Class-Acc: {0: '99.86%', 1: '98.37%'}\n",
      "Val Loss: 1.065505, Val Acc: 84.51%, Val-Class-Acc: {0: '84.78%', 1: '84.24%'}, LR: 0.000430\n",
      "Epoch 103/200, Train Loss: 0.032561, Train-Class-Acc: {0: '99.18%', 1: '97.55%'}\n",
      "Val Loss: 1.096110, Val Acc: 85.87%, Val-Class-Acc: {0: '89.13%', 1: '82.61%'}, LR: 0.000430\n",
      "Epoch 104/200, Train Loss: 0.024331, Train-Class-Acc: {0: '99.05%', 1: '99.18%'}\n",
      "Val Loss: 1.150904, Val Acc: 85.60%, Val-Class-Acc: {0: '88.04%', 1: '83.15%'}, LR: 0.000430\n",
      "Epoch 105/200, Train Loss: 0.019055, Train-Class-Acc: {0: '99.59%', 1: '99.59%'}\n",
      "Val Loss: 0.936778, Val Acc: 87.50%, Val-Class-Acc: {0: '86.96%', 1: '88.04%'}, LR: 0.000430\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_36.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_105.pth\n",
      "Epoch 106/200, Train Loss: 0.013722, Train-Class-Acc: {0: '99.73%', 1: '99.46%'}\n",
      "Val Loss: 1.081914, Val Acc: 86.96%, Val-Class-Acc: {0: '88.04%', 1: '85.87%'}, LR: 0.000430\n",
      "Epoch 107/200, Train Loss: 0.008222, Train-Class-Acc: {0: '100.00%', 1: '99.32%'}\n",
      "Val Loss: 1.105695, Val Acc: 86.41%, Val-Class-Acc: {0: '86.41%', 1: '86.41%'}, LR: 0.000430\n",
      "Epoch 108/200, Train Loss: 0.008322, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.127630, Val Acc: 86.96%, Val-Class-Acc: {0: '88.59%', 1: '85.33%'}, LR: 0.000430\n",
      "Epoch 109/200, Train Loss: 0.011914, Train-Class-Acc: {0: '99.86%', 1: '99.05%'}\n",
      "Val Loss: 1.209275, Val Acc: 84.24%, Val-Class-Acc: {0: '89.67%', 1: '78.80%'}, LR: 0.000430\n",
      "Epoch 110/200, Train Loss: 0.011761, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.200951, Val Acc: 86.14%, Val-Class-Acc: {0: '85.87%', 1: '86.41%'}, LR: 0.000387\n",
      "Epoch 111/200, Train Loss: 0.005399, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 1.221574, Val Acc: 86.96%, Val-Class-Acc: {0: '88.04%', 1: '85.87%'}, LR: 0.000387\n",
      "Epoch 112/200, Train Loss: 0.005646, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 1.227159, Val Acc: 85.60%, Val-Class-Acc: {0: '85.87%', 1: '85.33%'}, LR: 0.000387\n",
      "Epoch 113/200, Train Loss: 0.008758, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.275906, Val Acc: 85.33%, Val-Class-Acc: {0: '80.98%', 1: '89.67%'}, LR: 0.000387\n",
      "Epoch 114/200, Train Loss: 0.013907, Train-Class-Acc: {0: '99.59%', 1: '99.05%'}\n",
      "Val Loss: 1.315293, Val Acc: 85.33%, Val-Class-Acc: {0: '89.67%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 115/200, Train Loss: 0.014361, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.366232, Val Acc: 85.05%, Val-Class-Acc: {0: '90.22%', 1: '79.89%'}, LR: 0.000387\n",
      "Epoch 116/200, Train Loss: 0.008068, Train-Class-Acc: {0: '100.00%', 1: '98.77%'}\n",
      "Val Loss: 1.300965, Val Acc: 86.14%, Val-Class-Acc: {0: '84.78%', 1: '87.50%'}, LR: 0.000387\n",
      "Epoch 117/200, Train Loss: 0.013959, Train-Class-Acc: {0: '100.00%', 1: '98.23%'}\n",
      "Val Loss: 1.338305, Val Acc: 86.41%, Val-Class-Acc: {0: '86.41%', 1: '86.41%'}, LR: 0.000387\n",
      "Epoch 118/200, Train Loss: 0.008575, Train-Class-Acc: {0: '99.73%', 1: '99.18%'}\n",
      "Val Loss: 1.376711, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000387\n",
      "Epoch 119/200, Train Loss: 0.007223, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.378849, Val Acc: 86.41%, Val-Class-Acc: {0: '87.50%', 1: '85.33%'}, LR: 0.000387\n",
      "Epoch 120/200, Train Loss: 0.005129, Train-Class-Acc: {0: '100.00%', 1: '99.32%'}\n",
      "Val Loss: 1.400368, Val Acc: 86.68%, Val-Class-Acc: {0: '86.41%', 1: '86.96%'}, LR: 0.000387\n",
      "Epoch 121/200, Train Loss: 0.008440, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.371527, Val Acc: 86.41%, Val-Class-Acc: {0: '89.13%', 1: '83.70%'}, LR: 0.000349\n",
      "Epoch 122/200, Train Loss: 0.008134, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.403144, Val Acc: 85.87%, Val-Class-Acc: {0: '89.67%', 1: '82.07%'}, LR: 0.000349\n",
      "Epoch 123/200, Train Loss: 0.006637, Train-Class-Acc: {0: '100.00%', 1: '99.73%'}\n",
      "Val Loss: 1.399437, Val Acc: 86.41%, Val-Class-Acc: {0: '89.13%', 1: '83.70%'}, LR: 0.000349\n",
      "Epoch 124/200, Train Loss: 0.008055, Train-Class-Acc: {0: '100.00%', 1: '98.37%'}\n",
      "Val Loss: 1.414867, Val Acc: 86.41%, Val-Class-Acc: {0: '89.13%', 1: '83.70%'}, LR: 0.000349\n",
      "Epoch 125/200, Train Loss: 0.006678, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.407783, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000349\n",
      "Epoch 126/200, Train Loss: 0.005098, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 1.430898, Val Acc: 86.68%, Val-Class-Acc: {0: '89.13%', 1: '84.24%'}, LR: 0.000349\n",
      "Epoch 127/200, Train Loss: 0.007314, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.427128, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000349\n",
      "Epoch 128/200, Train Loss: 0.009781, Train-Class-Acc: {0: '100.00%', 1: '98.23%'}\n",
      "Val Loss: 1.449192, Val Acc: 86.96%, Val-Class-Acc: {0: '89.13%', 1: '84.78%'}, LR: 0.000349\n",
      "Epoch 129/200, Train Loss: 0.006153, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.453467, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000349\n",
      "Epoch 130/200, Train Loss: 0.007811, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.443777, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000349\n",
      "Epoch 131/200, Train Loss: 0.003091, Train-Class-Acc: {0: '100.00%', 1: '99.59%'}\n",
      "Val Loss: 1.455848, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000349\n",
      "Epoch 132/200, Train Loss: 0.004492, Train-Class-Acc: {0: '100.00%', 1: '99.32%'}\n",
      "Val Loss: 1.460240, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000314\n",
      "Epoch 133/200, Train Loss: 0.007881, Train-Class-Acc: {0: '100.00%', 1: '98.50%'}\n",
      "Val Loss: 1.482166, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000314\n",
      "Epoch 134/200, Train Loss: 0.007747, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.489565, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 1: '84.78%'}, LR: 0.000314\n",
      "Epoch 135/200, Train Loss: 0.009633, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.490495, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000314\n",
      "Epoch 136/200, Train Loss: 0.007315, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 1.504890, Val Acc: 86.68%, Val-Class-Acc: {0: '89.13%', 1: '84.24%'}, LR: 0.000314\n",
      "Epoch 137/200, Train Loss: 0.005920, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.487291, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000314\n",
      "Epoch 138/200, Train Loss: 0.007258, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.504004, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 1: '84.78%'}, LR: 0.000314\n",
      "Epoch 139/200, Train Loss: 0.004442, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.510098, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 1: '84.78%'}, LR: 0.000314\n",
      "Epoch 140/200, Train Loss: 0.008682, Train-Class-Acc: {0: '100.00%', 1: '98.50%'}\n",
      "Val Loss: 1.508713, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 1: '84.78%'}, LR: 0.000314\n",
      "Epoch 141/200, Train Loss: 0.006790, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.521931, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 1: '84.78%'}, LR: 0.000314\n",
      "Epoch 142/200, Train Loss: 0.008147, Train-Class-Acc: {0: '100.00%', 1: '98.37%'}\n",
      "Val Loss: 1.548096, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 1: '84.78%'}, LR: 0.000314\n",
      "Epoch 143/200, Train Loss: 0.006464, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.546886, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000282\n",
      "Epoch 144/200, Train Loss: 0.005579, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 1.559577, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000282\n",
      "Epoch 145/200, Train Loss: 0.007749, Train-Class-Acc: {0: '100.00%', 1: '99.32%'}\n",
      "Val Loss: 1.579837, Val Acc: 86.14%, Val-Class-Acc: {0: '88.59%', 1: '83.70%'}, LR: 0.000282\n",
      "Epoch 146/200, Train Loss: 0.006806, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.562158, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000282\n",
      "Epoch 147/200, Train Loss: 0.008241, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.569933, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 1: '84.78%'}, LR: 0.000282\n",
      "Epoch 148/200, Train Loss: 0.008301, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.571066, Val Acc: 86.14%, Val-Class-Acc: {0: '88.59%', 1: '83.70%'}, LR: 0.000282\n",
      "Epoch 149/200, Train Loss: 0.008170, Train-Class-Acc: {0: '100.00%', 1: '98.77%'}\n",
      "Val Loss: 1.572136, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000282\n",
      "Epoch 150/200, Train Loss: 0.004905, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.594855, Val Acc: 86.14%, Val-Class-Acc: {0: '89.13%', 1: '83.15%'}, LR: 0.000282\n",
      "Epoch 151/200, Train Loss: 0.005285, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.573901, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000282\n",
      "Epoch 152/200, Train Loss: 0.007314, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.582309, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000282\n",
      "Epoch 153/200, Train Loss: 0.006206, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 1.581235, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000282\n",
      "Epoch 154/200, Train Loss: 0.006255, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 1.597244, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000254\n",
      "Epoch 155/200, Train Loss: 0.005796, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.590913, Val Acc: 85.87%, Val-Class-Acc: {0: '86.96%', 1: '84.78%'}, LR: 0.000254\n",
      "Epoch 156/200, Train Loss: 0.009048, Train-Class-Acc: {0: '100.00%', 1: '98.09%'}\n",
      "Val Loss: 1.600686, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000254\n",
      "Epoch 157/200, Train Loss: 0.014922, Train-Class-Acc: {0: '99.59%', 1: '98.50%'}\n",
      "Val Loss: 1.855002, Val Acc: 85.87%, Val-Class-Acc: {0: '88.59%', 1: '83.15%'}, LR: 0.000254\n",
      "Epoch 158/200, Train Loss: 0.018133, Train-Class-Acc: {0: '99.73%', 1: '98.23%'}\n",
      "Val Loss: 2.020277, Val Acc: 83.70%, Val-Class-Acc: {0: '83.70%', 1: '83.70%'}, LR: 0.000254\n",
      "Epoch 159/200, Train Loss: 0.072011, Train-Class-Acc: {0: '98.64%', 1: '97.55%'}\n",
      "Val Loss: 1.562000, Val Acc: 86.14%, Val-Class-Acc: {0: '88.04%', 1: '84.24%'}, LR: 0.000254\n",
      "Epoch 160/200, Train Loss: 0.054083, Train-Class-Acc: {0: '98.64%', 1: '97.14%'}\n",
      "Val Loss: 1.119993, Val Acc: 85.33%, Val-Class-Acc: {0: '84.24%', 1: '86.41%'}, LR: 0.000254\n",
      "Epoch 161/200, Train Loss: 0.015713, Train-Class-Acc: {0: '100.00%', 1: '98.50%'}\n",
      "Val Loss: 1.306152, Val Acc: 85.05%, Val-Class-Acc: {0: '85.87%', 1: '84.24%'}, LR: 0.000254\n",
      "Epoch 162/200, Train Loss: 0.019008, Train-Class-Acc: {0: '99.32%', 1: '99.05%'}\n",
      "Val Loss: 1.282168, Val Acc: 84.78%, Val-Class-Acc: {0: '89.67%', 1: '79.89%'}, LR: 0.000254\n",
      "Epoch 163/200, Train Loss: 0.016715, Train-Class-Acc: {0: '99.59%', 1: '98.91%'}\n",
      "Val Loss: 1.302379, Val Acc: 83.97%, Val-Class-Acc: {0: '89.67%', 1: '78.26%'}, LR: 0.000254\n",
      "Epoch 164/200, Train Loss: 0.015853, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.264598, Val Acc: 84.51%, Val-Class-Acc: {0: '88.59%', 1: '80.43%'}, LR: 0.000254\n",
      "Epoch 165/200, Train Loss: 0.013876, Train-Class-Acc: {0: '99.86%', 1: '98.64%'}\n",
      "Val Loss: 1.245849, Val Acc: 84.51%, Val-Class-Acc: {0: '85.33%', 1: '83.70%'}, LR: 0.000229\n",
      "Epoch 166/200, Train Loss: 0.006212, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 1.265730, Val Acc: 83.97%, Val-Class-Acc: {0: '84.78%', 1: '83.15%'}, LR: 0.000229\n",
      "Epoch 167/200, Train Loss: 0.009892, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.291319, Val Acc: 84.24%, Val-Class-Acc: {0: '85.87%', 1: '82.61%'}, LR: 0.000229\n",
      "Epoch 168/200, Train Loss: 0.008814, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.293981, Val Acc: 83.97%, Val-Class-Acc: {0: '85.87%', 1: '82.07%'}, LR: 0.000229\n",
      "Epoch 169/200, Train Loss: 0.010186, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.331907, Val Acc: 83.70%, Val-Class-Acc: {0: '85.87%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 170/200, Train Loss: 0.007515, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.354082, Val Acc: 84.24%, Val-Class-Acc: {0: '86.96%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 171/200, Train Loss: 0.009961, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.373547, Val Acc: 84.78%, Val-Class-Acc: {0: '88.04%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 172/200, Train Loss: 0.006517, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.355080, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000229\n",
      "Epoch 173/200, Train Loss: 0.006990, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.358375, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000229\n",
      "Epoch 174/200, Train Loss: 0.005743, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.394859, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000229\n",
      "Epoch 175/200, Train Loss: 0.008478, Train-Class-Acc: {0: '100.00%', 1: '99.32%'}\n",
      "Val Loss: 1.404049, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000229\n",
      "Epoch 176/200, Train Loss: 0.010699, Train-Class-Acc: {0: '100.00%', 1: '98.77%'}\n",
      "Val Loss: 1.417522, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000206\n",
      "Epoch 177/200, Train Loss: 0.005500, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.427520, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000206\n",
      "Epoch 178/200, Train Loss: 0.009499, Train-Class-Acc: {0: '100.00%', 1: '98.50%'}\n",
      "Val Loss: 1.459595, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000206\n",
      "Epoch 179/200, Train Loss: 0.007024, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.442909, Val Acc: 84.78%, Val-Class-Acc: {0: '83.15%', 1: '86.41%'}, LR: 0.000206\n",
      "Epoch 180/200, Train Loss: 0.007303, Train-Class-Acc: {0: '100.00%', 1: '98.77%'}\n",
      "Val Loss: 1.451784, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000206\n",
      "Epoch 181/200, Train Loss: 0.006027, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.433662, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000206\n",
      "Epoch 182/200, Train Loss: 0.009318, Train-Class-Acc: {0: '100.00%', 1: '98.77%'}\n",
      "Val Loss: 1.460955, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000206\n",
      "Epoch 183/200, Train Loss: 0.007893, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.450227, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000206\n",
      "Epoch 184/200, Train Loss: 0.005463, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 1.470985, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000206\n",
      "Epoch 185/200, Train Loss: 0.010624, Train-Class-Acc: {0: '100.00%', 1: '98.37%'}\n",
      "Val Loss: 1.477247, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000206\n",
      "Epoch 186/200, Train Loss: 0.007463, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.496417, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000206\n",
      "Epoch 187/200, Train Loss: 0.008761, Train-Class-Acc: {0: '100.00%', 1: '98.23%'}\n",
      "Val Loss: 1.491907, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000185\n",
      "Epoch 188/200, Train Loss: 0.010123, Train-Class-Acc: {0: '100.00%', 1: '97.96%'}\n",
      "Val Loss: 1.497607, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000185\n",
      "Epoch 189/200, Train Loss: 0.007470, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.546247, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 190/200, Train Loss: 0.005389, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.520267, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000185\n",
      "Epoch 191/200, Train Loss: 0.006398, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.546281, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 192/200, Train Loss: 0.006825, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.512161, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000185\n",
      "Epoch 193/200, Train Loss: 0.011019, Train-Class-Acc: {0: '100.00%', 1: '97.96%'}\n",
      "Val Loss: 1.533145, Val Acc: 85.05%, Val-Class-Acc: {0: '87.50%', 1: '82.61%'}, LR: 0.000185\n",
      "Epoch 194/200, Train Loss: 0.009443, Train-Class-Acc: {0: '100.00%', 1: '98.23%'}\n",
      "Val Loss: 1.526751, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000185\n",
      "Epoch 195/200, Train Loss: 0.008681, Train-Class-Acc: {0: '100.00%', 1: '98.77%'}\n",
      "Val Loss: 1.548823, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000185\n",
      "Epoch 196/200, Train Loss: 0.006305, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.566057, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000185\n",
      "Epoch 197/200, Train Loss: 0.004040, Train-Class-Acc: {0: '100.00%', 1: '99.32%'}\n",
      "Val Loss: 1.551852, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000185\n",
      "Epoch 198/200, Train Loss: 0.004471, Train-Class-Acc: {0: '100.00%', 1: '99.32%'}\n",
      "Val Loss: 1.545451, Val Acc: 85.33%, Val-Class-Acc: {0: '86.96%', 1: '83.70%'}, LR: 0.000167\n",
      "Epoch 199/200, Train Loss: 0.009654, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.561933, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000167\n",
      "Epoch 200/200, Train Loss: 0.008189, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.551682, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000167\n",
      "\n",
      "🏆 Best model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_best.pth (Val Accuracy: 88.04%)\n",
      "\n",
      "📌 Final model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_final.pth\n",
      "\n",
      "🎯 Top 5 Best Models:\n",
      "Epoch 40, Train Loss: 0.095957, Train-Acc: {0: '96.87%', 1: '94.55%'},\n",
      "Val Loss: 0.519273, Val Acc: 88.04%, Val-Class-Acc: {0: '91.85%', 1: '84.24%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_40.pth\n",
      "Epoch 105, Train Loss: 0.019055, Train-Acc: {0: '99.59%', 1: '99.59%'},\n",
      "Val Loss: 0.936778, Val Acc: 87.50%, Val-Class-Acc: {0: '86.96%', 1: '88.04%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_105.pth\n",
      "Epoch 77, Train Loss: 0.013116, Train-Acc: {0: '99.73%', 1: '99.18%'},\n",
      "Val Loss: 1.100379, Val Acc: 87.50%, Val-Class-Acc: {0: '91.30%', 1: '83.70%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_77.pth\n",
      "Epoch 68, Train Loss: 0.013124, Train-Acc: {0: '100.00%', 1: '98.91%'},\n",
      "Val Loss: 0.974238, Val Acc: 87.23%, Val-Class-Acc: {0: '88.59%', 1: '85.87%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_68.pth\n",
      "Epoch 64, Train Loss: 0.089428, Train-Acc: {0: '97.00%', 1: '96.32%'},\n",
      "Val Loss: 0.988210, Val Acc: 87.23%, Val-Class-Acc: {0: '90.76%', 1: '83.70%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2/ResNet18_1D_v2_epoch_64.pth\n",
      "\n",
      "🧠 Model Summary:\n",
      "Total Parameters: 3,986,818\n",
      "Model Size (float32): 15.21 MB\n",
      "Total Training Time: 131.16 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))  # Shape: (B, 5000, 12)\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# ==== Model Hyperparameters ====\n",
    "input_channels = X_train.shape[2]                  # 12 leads\n",
    "output_size = len(np.unique(y_train))              # Number of classes (e.g., 2 for Period 1)\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "dropout = 0.0                                       # Not needed for ResNet18_1D\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "print(\"✅ input shape:\", X_train.shape)\n",
    "print(\"✅ unique y_train:\", np.unique(y_train))\n",
    "print(\"✅ unique y_test :\", np.unique(y_test))\n",
    "assert np.max(y_train) < output_size\n",
    "assert np.max(y_test) < output_size\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/ResNet18_v2\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Model ====\n",
    "model = ResNet18_1D_v2(input_channels=input_channels, output_size=output_size).to(device)\n",
    "\n",
    "# ==== Optimizer and Training ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# ==== Train ====\n",
    "result_summary = train_model_general_classifier(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name='ResNet18_1D_v2',\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del model, X_train, y_train, X_test, y_test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eeba82",
   "metadata": {},
   "source": [
    "#### Data Arg Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6cf0032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Automatically selected GPU:\n",
      "    - CUDA Device ID : 1\n",
      "    - Memory Used    : 595 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "✅ input shape: (1468, 5000, 12)\n",
      "✅ unique y_train: [0 1]\n",
      "✅ unique y_test : [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 'train_model_general_classifier' started.\n",
      "✅ Removed existing folder: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg\n",
      "\n",
      "✅ Data Overview:\n",
      "X_train: (1468, 5000, 12), y_train: (1468,)\n",
      "X_val: (368, 5000, 12), y_val: (368,)\n",
      "Epoch 1/200, Train Loss: 0.529950, Train-Class-Acc: {0: '79.56%', 1: '67.71%'}\n",
      "Val Loss: 0.719199, Val Acc: 70.38%, Val-Class-Acc: {0: '47.28%', 1: '93.48%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.405917, Train-Class-Acc: {0: '84.60%', 1: '79.16%'}\n",
      "Val Loss: 1.668743, Val Acc: 53.80%, Val-Class-Acc: {0: '8.15%', 1: '99.46%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.408089, Train-Class-Acc: {0: '81.20%', 1: '79.02%'}\n",
      "Val Loss: 0.478601, Val Acc: 77.45%, Val-Class-Acc: {0: '62.50%', 1: '92.39%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.365762, Train-Class-Acc: {0: '88.69%', 1: '79.02%'}\n",
      "Val Loss: 0.413497, Val Acc: 83.42%, Val-Class-Acc: {0: '91.30%', 1: '75.54%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.326787, Train-Class-Acc: {0: '88.69%', 1: '82.02%'}\n",
      "Val Loss: 0.661142, Val Acc: 74.73%, Val-Class-Acc: {0: '51.63%', 1: '97.83%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.310306, Train-Class-Acc: {0: '87.06%', 1: '82.70%'}\n",
      "Val Loss: 0.407233, Val Acc: 85.05%, Val-Class-Acc: {0: '94.02%', 1: '76.09%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_2.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_6.pth\n",
      "Epoch 7/200, Train Loss: 0.300750, Train-Class-Acc: {0: '91.01%', 1: '84.06%'}\n",
      "Val Loss: 0.371687, Val Acc: 84.51%, Val-Class-Acc: {0: '85.33%', 1: '83.70%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_1.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.279676, Train-Class-Acc: {0: '90.46%', 1: '86.65%'}\n",
      "Val Loss: 0.581656, Val Acc: 83.97%, Val-Class-Acc: {0: '88.59%', 1: '79.35%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_5.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_8.pth\n",
      "Epoch 9/200, Train Loss: 0.291736, Train-Class-Acc: {0: '91.01%', 1: '85.69%'}\n",
      "Val Loss: 0.496857, Val Acc: 81.25%, Val-Class-Acc: {0: '96.74%', 1: '65.76%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_3.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.280027, Train-Class-Acc: {0: '89.37%', 1: '85.83%'}\n",
      "Val Loss: 0.454658, Val Acc: 80.98%, Val-Class-Acc: {0: '67.39%', 1: '94.57%'}, LR: 0.001000\n",
      "Epoch 11/200, Train Loss: 0.266177, Train-Class-Acc: {0: '91.14%', 1: '86.92%'}\n",
      "Val Loss: 0.425220, Val Acc: 85.05%, Val-Class-Acc: {0: '80.98%', 1: '89.13%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_9.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_11.pth\n",
      "Epoch 12/200, Train Loss: 0.262356, Train-Class-Acc: {0: '91.42%', 1: '86.10%'}\n",
      "Val Loss: 0.413209, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_4.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_12.pth\n",
      "Epoch 13/200, Train Loss: 0.241291, Train-Class-Acc: {0: '93.05%', 1: '87.33%'}\n",
      "Val Loss: 0.515556, Val Acc: 80.98%, Val-Class-Acc: {0: '92.39%', 1: '69.57%'}, LR: 0.001000\n",
      "Epoch 14/200, Train Loss: 0.257432, Train-Class-Acc: {0: '91.55%', 1: '87.19%'}\n",
      "Val Loss: 0.436287, Val Acc: 88.04%, Val-Class-Acc: {0: '89.67%', 1: '86.41%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_8.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_14.pth\n",
      "Epoch 15/200, Train Loss: 0.255160, Train-Class-Acc: {0: '92.23%', 1: '87.87%'}\n",
      "Val Loss: 0.413518, Val Acc: 82.07%, Val-Class-Acc: {0: '90.22%', 1: '73.91%'}, LR: 0.001000\n",
      "Epoch 16/200, Train Loss: 0.223027, Train-Class-Acc: {0: '92.51%', 1: '87.47%'}\n",
      "Val Loss: 0.522712, Val Acc: 84.24%, Val-Class-Acc: {0: '94.57%', 1: '73.91%'}, LR: 0.001000\n",
      "Epoch 17/200, Train Loss: 0.230751, Train-Class-Acc: {0: '92.78%', 1: '88.01%'}\n",
      "Val Loss: 0.390234, Val Acc: 84.51%, Val-Class-Acc: {0: '79.35%', 1: '89.67%'}, LR: 0.001000\n",
      "Epoch 18/200, Train Loss: 0.214575, Train-Class-Acc: {0: '92.37%', 1: '90.46%'}\n",
      "Val Loss: 0.404170, Val Acc: 85.33%, Val-Class-Acc: {0: '82.61%', 1: '88.04%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_7.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_18.pth\n",
      "Epoch 19/200, Train Loss: 0.198774, Train-Class-Acc: {0: '93.73%', 1: '88.83%'}\n",
      "Val Loss: 0.450733, Val Acc: 87.23%, Val-Class-Acc: {0: '88.59%', 1: '85.87%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_6.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_19.pth\n",
      "Epoch 20/200, Train Loss: 0.195251, Train-Class-Acc: {0: '94.01%', 1: '88.96%'}\n",
      "Val Loss: 0.513949, Val Acc: 84.24%, Val-Class-Acc: {0: '93.48%', 1: '75.00%'}, LR: 0.000900\n",
      "Epoch 21/200, Train Loss: 0.203261, Train-Class-Acc: {0: '94.55%', 1: '89.65%'}\n",
      "Val Loss: 0.382366, Val Acc: 87.23%, Val-Class-Acc: {0: '90.22%', 1: '84.24%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_11.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_21.pth\n",
      "Epoch 22/200, Train Loss: 0.204399, Train-Class-Acc: {0: '93.05%', 1: '90.87%'}\n",
      "Val Loss: 0.670270, Val Acc: 79.89%, Val-Class-Acc: {0: '65.76%', 1: '94.02%'}, LR: 0.000900\n",
      "Epoch 23/200, Train Loss: 0.178899, Train-Class-Acc: {0: '93.46%', 1: '91.83%'}\n",
      "Val Loss: 0.836626, Val Acc: 80.16%, Val-Class-Acc: {0: '97.83%', 1: '62.50%'}, LR: 0.000900\n",
      "Epoch 24/200, Train Loss: 0.181381, Train-Class-Acc: {0: '94.55%', 1: '91.14%'}\n",
      "Val Loss: 0.445873, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_18.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_24.pth\n",
      "Epoch 25/200, Train Loss: 0.186399, Train-Class-Acc: {0: '93.32%', 1: '89.65%'}\n",
      "Val Loss: 0.445817, Val Acc: 84.78%, Val-Class-Acc: {0: '88.04%', 1: '81.52%'}, LR: 0.000900\n",
      "Epoch 26/200, Train Loss: 0.194514, Train-Class-Acc: {0: '93.73%', 1: '90.19%'}\n",
      "Val Loss: 0.461418, Val Acc: 84.24%, Val-Class-Acc: {0: '78.26%', 1: '90.22%'}, LR: 0.000900\n",
      "Epoch 27/200, Train Loss: 0.178146, Train-Class-Acc: {0: '96.87%', 1: '87.87%'}\n",
      "Val Loss: 0.528353, Val Acc: 82.61%, Val-Class-Acc: {0: '73.37%', 1: '91.85%'}, LR: 0.000900\n",
      "Epoch 28/200, Train Loss: 0.158427, Train-Class-Acc: {0: '94.14%', 1: '92.23%'}\n",
      "Val Loss: 0.486761, Val Acc: 84.24%, Val-Class-Acc: {0: '81.52%', 1: '86.96%'}, LR: 0.000900\n",
      "Epoch 29/200, Train Loss: 0.144797, Train-Class-Acc: {0: '95.10%', 1: '93.32%'}\n",
      "Val Loss: 0.631245, Val Acc: 83.42%, Val-Class-Acc: {0: '88.59%', 1: '78.26%'}, LR: 0.000900\n",
      "Epoch 30/200, Train Loss: 0.123424, Train-Class-Acc: {0: '93.73%', 1: '95.10%'}\n",
      "Val Loss: 0.436004, Val Acc: 88.32%, Val-Class-Acc: {0: '89.13%', 1: '87.50%'}, LR: 0.000810\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_12.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_30.pth\n",
      "Epoch 31/200, Train Loss: 0.143234, Train-Class-Acc: {0: '95.23%', 1: '92.23%'}\n",
      "Val Loss: 0.536902, Val Acc: 82.07%, Val-Class-Acc: {0: '73.91%', 1: '90.22%'}, LR: 0.000810\n",
      "Epoch 32/200, Train Loss: 0.137901, Train-Class-Acc: {0: '95.23%', 1: '94.01%'}\n",
      "Val Loss: 0.475668, Val Acc: 85.60%, Val-Class-Acc: {0: '83.70%', 1: '87.50%'}, LR: 0.000810\n",
      "Epoch 33/200, Train Loss: 0.144416, Train-Class-Acc: {0: '94.01%', 1: '94.14%'}\n",
      "Val Loss: 0.596744, Val Acc: 82.34%, Val-Class-Acc: {0: '82.61%', 1: '82.07%'}, LR: 0.000810\n",
      "Epoch 34/200, Train Loss: 0.144989, Train-Class-Acc: {0: '95.23%', 1: '93.60%'}\n",
      "Val Loss: 0.543855, Val Acc: 84.51%, Val-Class-Acc: {0: '95.11%', 1: '73.91%'}, LR: 0.000810\n",
      "Epoch 35/200, Train Loss: 0.129702, Train-Class-Acc: {0: '96.32%', 1: '92.92%'}\n",
      "Val Loss: 0.467449, Val Acc: 85.33%, Val-Class-Acc: {0: '90.22%', 1: '80.43%'}, LR: 0.000810\n",
      "Epoch 36/200, Train Loss: 0.088440, Train-Class-Acc: {0: '97.00%', 1: '96.05%'}\n",
      "Val Loss: 0.648578, Val Acc: 86.14%, Val-Class-Acc: {0: '89.13%', 1: '83.15%'}, LR: 0.000810\n",
      "Epoch 37/200, Train Loss: 0.113656, Train-Class-Acc: {0: '97.00%', 1: '93.60%'}\n",
      "Val Loss: 1.938277, Val Acc: 75.82%, Val-Class-Acc: {0: '55.43%', 1: '96.20%'}, LR: 0.000810\n",
      "Epoch 38/200, Train Loss: 0.138741, Train-Class-Acc: {0: '95.23%', 1: '92.64%'}\n",
      "Val Loss: 0.514626, Val Acc: 85.05%, Val-Class-Acc: {0: '95.11%', 1: '75.00%'}, LR: 0.000810\n",
      "Epoch 39/200, Train Loss: 0.123418, Train-Class-Acc: {0: '95.78%', 1: '93.60%'}\n",
      "Val Loss: 0.637054, Val Acc: 82.34%, Val-Class-Acc: {0: '80.43%', 1: '84.24%'}, LR: 0.000810\n",
      "Epoch 40/200, Train Loss: 0.115881, Train-Class-Acc: {0: '95.91%', 1: '95.64%'}\n",
      "Val Loss: 0.538212, Val Acc: 86.41%, Val-Class-Acc: {0: '91.30%', 1: '81.52%'}, LR: 0.000810\n",
      "Epoch 41/200, Train Loss: 0.086743, Train-Class-Acc: {0: '98.50%', 1: '95.50%'}\n",
      "Val Loss: 0.556830, Val Acc: 85.60%, Val-Class-Acc: {0: '85.33%', 1: '85.87%'}, LR: 0.000729\n",
      "Epoch 42/200, Train Loss: 0.066840, Train-Class-Acc: {0: '97.55%', 1: '97.00%'}\n",
      "Val Loss: 0.671206, Val Acc: 84.78%, Val-Class-Acc: {0: '84.78%', 1: '84.78%'}, LR: 0.000729\n",
      "Epoch 43/200, Train Loss: 0.075479, Train-Class-Acc: {0: '97.41%', 1: '96.05%'}\n",
      "Val Loss: 0.896532, Val Acc: 83.42%, Val-Class-Acc: {0: '94.57%', 1: '72.28%'}, LR: 0.000729\n",
      "Epoch 44/200, Train Loss: 0.111434, Train-Class-Acc: {0: '96.19%', 1: '94.96%'}\n",
      "Val Loss: 0.593450, Val Acc: 86.96%, Val-Class-Acc: {0: '92.93%', 1: '80.98%'}, LR: 0.000729\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_24.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_44.pth\n",
      "Epoch 45/200, Train Loss: 0.076647, Train-Class-Acc: {0: '97.14%', 1: '96.59%'}\n",
      "Val Loss: 0.729466, Val Acc: 84.51%, Val-Class-Acc: {0: '90.76%', 1: '78.26%'}, LR: 0.000729\n",
      "Epoch 46/200, Train Loss: 0.066256, Train-Class-Acc: {0: '97.28%', 1: '96.87%'}\n",
      "Val Loss: 0.789835, Val Acc: 85.05%, Val-Class-Acc: {0: '88.59%', 1: '81.52%'}, LR: 0.000729\n",
      "Epoch 47/200, Train Loss: 0.128647, Train-Class-Acc: {0: '95.37%', 1: '94.14%'}\n",
      "Val Loss: 0.742113, Val Acc: 86.68%, Val-Class-Acc: {0: '87.50%', 1: '85.87%'}, LR: 0.000729\n",
      "Epoch 48/200, Train Loss: 0.107438, Train-Class-Acc: {0: '97.14%', 1: '94.41%'}\n",
      "Val Loss: 0.599445, Val Acc: 82.61%, Val-Class-Acc: {0: '73.37%', 1: '91.85%'}, LR: 0.000729\n",
      "Epoch 49/200, Train Loss: 0.111612, Train-Class-Acc: {0: '96.32%', 1: '95.64%'}\n",
      "Val Loss: 0.561518, Val Acc: 87.77%, Val-Class-Acc: {0: '94.02%', 1: '81.52%'}, LR: 0.000729\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_44.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_49.pth\n",
      "Epoch 50/200, Train Loss: 0.069603, Train-Class-Acc: {0: '98.77%', 1: '95.23%'}\n",
      "Val Loss: 0.561547, Val Acc: 85.87%, Val-Class-Acc: {0: '85.33%', 1: '86.41%'}, LR: 0.000729\n",
      "Epoch 51/200, Train Loss: 0.063095, Train-Class-Acc: {0: '98.37%', 1: '96.59%'}\n",
      "Val Loss: 0.766297, Val Acc: 83.42%, Val-Class-Acc: {0: '77.17%', 1: '89.67%'}, LR: 0.000729\n",
      "Epoch 52/200, Train Loss: 0.089964, Train-Class-Acc: {0: '97.14%', 1: '96.05%'}\n",
      "Val Loss: 0.708000, Val Acc: 84.24%, Val-Class-Acc: {0: '88.59%', 1: '79.89%'}, LR: 0.000656\n",
      "Epoch 53/200, Train Loss: 0.074370, Train-Class-Acc: {0: '97.28%', 1: '96.46%'}\n",
      "Val Loss: 0.589786, Val Acc: 85.33%, Val-Class-Acc: {0: '84.78%', 1: '85.87%'}, LR: 0.000656\n",
      "Epoch 54/200, Train Loss: 0.044194, Train-Class-Acc: {0: '98.50%', 1: '98.09%'}\n",
      "Val Loss: 0.668172, Val Acc: 85.05%, Val-Class-Acc: {0: '83.70%', 1: '86.41%'}, LR: 0.000656\n",
      "Epoch 55/200, Train Loss: 0.069014, Train-Class-Acc: {0: '98.23%', 1: '96.32%'}\n",
      "Val Loss: 0.658938, Val Acc: 85.87%, Val-Class-Acc: {0: '88.04%', 1: '83.70%'}, LR: 0.000656\n",
      "Epoch 56/200, Train Loss: 0.065128, Train-Class-Acc: {0: '98.23%', 1: '97.14%'}\n",
      "Val Loss: 0.607932, Val Acc: 85.33%, Val-Class-Acc: {0: '85.87%', 1: '84.78%'}, LR: 0.000656\n",
      "Epoch 57/200, Train Loss: 0.037570, Train-Class-Acc: {0: '99.32%', 1: '98.37%'}\n",
      "Val Loss: 0.663274, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000656\n",
      "Epoch 58/200, Train Loss: 0.056982, Train-Class-Acc: {0: '98.37%', 1: '96.46%'}\n",
      "Val Loss: 0.818211, Val Acc: 83.15%, Val-Class-Acc: {0: '83.70%', 1: '82.61%'}, LR: 0.000656\n",
      "Epoch 59/200, Train Loss: 0.062644, Train-Class-Acc: {0: '98.50%', 1: '96.87%'}\n",
      "Val Loss: 0.756043, Val Acc: 85.60%, Val-Class-Acc: {0: '89.67%', 1: '81.52%'}, LR: 0.000656\n",
      "Epoch 60/200, Train Loss: 0.060114, Train-Class-Acc: {0: '98.37%', 1: '96.46%'}\n",
      "Val Loss: 0.705842, Val Acc: 83.70%, Val-Class-Acc: {0: '85.87%', 1: '81.52%'}, LR: 0.000656\n",
      "Epoch 61/200, Train Loss: 0.043538, Train-Class-Acc: {0: '98.50%', 1: '98.50%'}\n",
      "Val Loss: 0.720684, Val Acc: 86.41%, Val-Class-Acc: {0: '89.13%', 1: '83.70%'}, LR: 0.000656\n",
      "Epoch 62/200, Train Loss: 0.051357, Train-Class-Acc: {0: '98.91%', 1: '97.82%'}\n",
      "Val Loss: 0.806817, Val Acc: 86.14%, Val-Class-Acc: {0: '88.04%', 1: '84.24%'}, LR: 0.000656\n",
      "Epoch 63/200, Train Loss: 0.032876, Train-Class-Acc: {0: '99.18%', 1: '98.37%'}\n",
      "Val Loss: 0.965051, Val Acc: 83.70%, Val-Class-Acc: {0: '92.93%', 1: '74.46%'}, LR: 0.000590\n",
      "Epoch 64/200, Train Loss: 0.022260, Train-Class-Acc: {0: '99.59%', 1: '99.18%'}\n",
      "Val Loss: 0.999647, Val Acc: 86.68%, Val-Class-Acc: {0: '91.85%', 1: '81.52%'}, LR: 0.000590\n",
      "Epoch 65/200, Train Loss: 0.030500, Train-Class-Acc: {0: '99.46%', 1: '98.23%'}\n",
      "Val Loss: 1.162100, Val Acc: 85.60%, Val-Class-Acc: {0: '89.67%', 1: '81.52%'}, LR: 0.000590\n",
      "Epoch 66/200, Train Loss: 0.070616, Train-Class-Acc: {0: '97.82%', 1: '97.68%'}\n",
      "Val Loss: 1.074598, Val Acc: 86.68%, Val-Class-Acc: {0: '89.67%', 1: '83.70%'}, LR: 0.000590\n",
      "Epoch 67/200, Train Loss: 0.067432, Train-Class-Acc: {0: '97.41%', 1: '96.19%'}\n",
      "Val Loss: 0.743364, Val Acc: 86.41%, Val-Class-Acc: {0: '89.13%', 1: '83.70%'}, LR: 0.000590\n",
      "Epoch 68/200, Train Loss: 0.073164, Train-Class-Acc: {0: '98.37%', 1: '95.91%'}\n",
      "Val Loss: 0.610163, Val Acc: 87.23%, Val-Class-Acc: {0: '90.76%', 1: '83.70%'}, LR: 0.000590\n",
      "Epoch 69/200, Train Loss: 0.050241, Train-Class-Acc: {0: '98.37%', 1: '97.82%'}\n",
      "Val Loss: 0.852407, Val Acc: 85.87%, Val-Class-Acc: {0: '90.76%', 1: '80.98%'}, LR: 0.000590\n",
      "Epoch 70/200, Train Loss: 0.030419, Train-Class-Acc: {0: '98.91%', 1: '98.37%'}\n",
      "Val Loss: 0.832446, Val Acc: 86.96%, Val-Class-Acc: {0: '92.39%', 1: '81.52%'}, LR: 0.000590\n",
      "Epoch 71/200, Train Loss: 0.031597, Train-Class-Acc: {0: '99.18%', 1: '97.68%'}\n",
      "Val Loss: 1.015823, Val Acc: 84.51%, Val-Class-Acc: {0: '85.33%', 1: '83.70%'}, LR: 0.000590\n",
      "Epoch 72/200, Train Loss: 0.062687, Train-Class-Acc: {0: '97.82%', 1: '97.55%'}\n",
      "Val Loss: 0.949190, Val Acc: 84.24%, Val-Class-Acc: {0: '86.41%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 73/200, Train Loss: 0.035198, Train-Class-Acc: {0: '99.18%', 1: '97.41%'}\n",
      "Val Loss: 0.853618, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000590\n",
      "Epoch 74/200, Train Loss: 0.043856, Train-Class-Acc: {0: '99.05%', 1: '97.41%'}\n",
      "Val Loss: 0.925966, Val Acc: 85.33%, Val-Class-Acc: {0: '90.22%', 1: '80.43%'}, LR: 0.000531\n",
      "Epoch 75/200, Train Loss: 0.038609, Train-Class-Acc: {0: '98.50%', 1: '97.14%'}\n",
      "Val Loss: 0.860645, Val Acc: 84.24%, Val-Class-Acc: {0: '85.33%', 1: '83.15%'}, LR: 0.000531\n",
      "Epoch 76/200, Train Loss: 0.031151, Train-Class-Acc: {0: '99.32%', 1: '98.23%'}\n",
      "Val Loss: 0.848100, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000531\n",
      "Epoch 77/200, Train Loss: 0.022421, Train-Class-Acc: {0: '99.32%', 1: '98.77%'}\n",
      "Val Loss: 0.847693, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000531\n",
      "Epoch 78/200, Train Loss: 0.022036, Train-Class-Acc: {0: '99.73%', 1: '97.55%'}\n",
      "Val Loss: 0.920344, Val Acc: 86.14%, Val-Class-Acc: {0: '85.33%', 1: '86.96%'}, LR: 0.000531\n",
      "Epoch 79/200, Train Loss: 0.014693, Train-Class-Acc: {0: '99.46%', 1: '99.05%'}\n",
      "Val Loss: 0.954886, Val Acc: 86.41%, Val-Class-Acc: {0: '86.41%', 1: '86.41%'}, LR: 0.000531\n",
      "Epoch 80/200, Train Loss: 0.014699, Train-Class-Acc: {0: '100.00%', 1: '98.77%'}\n",
      "Val Loss: 1.006872, Val Acc: 84.78%, Val-Class-Acc: {0: '86.96%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 81/200, Train Loss: 0.028678, Train-Class-Acc: {0: '99.32%', 1: '98.37%'}\n",
      "Val Loss: 1.042411, Val Acc: 84.51%, Val-Class-Acc: {0: '82.61%', 1: '86.41%'}, LR: 0.000531\n",
      "Epoch 82/200, Train Loss: 0.035485, Train-Class-Acc: {0: '98.91%', 1: '98.64%'}\n",
      "Val Loss: 1.127326, Val Acc: 83.70%, Val-Class-Acc: {0: '78.80%', 1: '88.59%'}, LR: 0.000531\n",
      "Epoch 83/200, Train Loss: 0.035838, Train-Class-Acc: {0: '99.32%', 1: '97.82%'}\n",
      "Val Loss: 0.964901, Val Acc: 84.78%, Val-Class-Acc: {0: '88.04%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 84/200, Train Loss: 0.033962, Train-Class-Acc: {0: '99.05%', 1: '97.68%'}\n",
      "Val Loss: 0.822346, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 85/200, Train Loss: 0.031652, Train-Class-Acc: {0: '99.05%', 1: '97.68%'}\n",
      "Val Loss: 1.272534, Val Acc: 82.88%, Val-Class-Acc: {0: '81.52%', 1: '84.24%'}, LR: 0.000478\n",
      "Epoch 86/200, Train Loss: 0.048553, Train-Class-Acc: {0: '99.32%', 1: '96.59%'}\n",
      "Val Loss: 1.314387, Val Acc: 84.78%, Val-Class-Acc: {0: '93.48%', 1: '76.09%'}, LR: 0.000478\n",
      "Epoch 87/200, Train Loss: 0.029688, Train-Class-Acc: {0: '99.18%', 1: '97.96%'}\n",
      "Val Loss: 0.915056, Val Acc: 87.23%, Val-Class-Acc: {0: '90.76%', 1: '83.70%'}, LR: 0.000478\n",
      "Epoch 88/200, Train Loss: 0.017219, Train-Class-Acc: {0: '99.59%', 1: '98.37%'}\n",
      "Val Loss: 0.975622, Val Acc: 87.23%, Val-Class-Acc: {0: '90.76%', 1: '83.70%'}, LR: 0.000478\n",
      "Epoch 89/200, Train Loss: 0.014273, Train-Class-Acc: {0: '99.46%', 1: '99.32%'}\n",
      "Val Loss: 1.118949, Val Acc: 86.14%, Val-Class-Acc: {0: '91.85%', 1: '80.43%'}, LR: 0.000478\n",
      "Epoch 90/200, Train Loss: 0.015189, Train-Class-Acc: {0: '99.73%', 1: '97.96%'}\n",
      "Val Loss: 1.138454, Val Acc: 86.41%, Val-Class-Acc: {0: '91.85%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 91/200, Train Loss: 0.016907, Train-Class-Acc: {0: '99.86%', 1: '98.50%'}\n",
      "Val Loss: 1.170979, Val Acc: 86.14%, Val-Class-Acc: {0: '88.59%', 1: '83.70%'}, LR: 0.000478\n",
      "Epoch 92/200, Train Loss: 0.017347, Train-Class-Acc: {0: '99.46%', 1: '98.50%'}\n",
      "Val Loss: 1.252410, Val Acc: 84.78%, Val-Class-Acc: {0: '83.15%', 1: '86.41%'}, LR: 0.000478\n",
      "Epoch 93/200, Train Loss: 0.028798, Train-Class-Acc: {0: '99.59%', 1: '98.09%'}\n",
      "Val Loss: 1.359319, Val Acc: 84.24%, Val-Class-Acc: {0: '93.48%', 1: '75.00%'}, LR: 0.000478\n",
      "Epoch 94/200, Train Loss: 0.021767, Train-Class-Acc: {0: '99.59%', 1: '98.37%'}\n",
      "Val Loss: 1.099277, Val Acc: 85.87%, Val-Class-Acc: {0: '88.59%', 1: '83.15%'}, LR: 0.000478\n",
      "Epoch 95/200, Train Loss: 0.023015, Train-Class-Acc: {0: '99.46%', 1: '98.77%'}\n",
      "Val Loss: 1.325526, Val Acc: 84.51%, Val-Class-Acc: {0: '85.33%', 1: '83.70%'}, LR: 0.000478\n",
      "Epoch 96/200, Train Loss: 0.032420, Train-Class-Acc: {0: '99.18%', 1: '97.68%'}\n",
      "Val Loss: 1.053942, Val Acc: 83.70%, Val-Class-Acc: {0: '86.41%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 97/200, Train Loss: 0.020322, Train-Class-Acc: {0: '99.46%', 1: '98.91%'}\n",
      "Val Loss: 0.989166, Val Acc: 84.51%, Val-Class-Acc: {0: '83.70%', 1: '85.33%'}, LR: 0.000430\n",
      "Epoch 98/200, Train Loss: 0.017522, Train-Class-Acc: {0: '99.73%', 1: '99.05%'}\n",
      "Val Loss: 1.102026, Val Acc: 83.97%, Val-Class-Acc: {0: '83.15%', 1: '84.78%'}, LR: 0.000430\n",
      "Epoch 99/200, Train Loss: 0.018670, Train-Class-Acc: {0: '99.73%', 1: '98.50%'}\n",
      "Val Loss: 1.111155, Val Acc: 84.78%, Val-Class-Acc: {0: '86.41%', 1: '83.15%'}, LR: 0.000430\n",
      "Epoch 100/200, Train Loss: 0.026077, Train-Class-Acc: {0: '99.59%', 1: '98.23%'}\n",
      "Val Loss: 1.187883, Val Acc: 85.05%, Val-Class-Acc: {0: '89.13%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 101/200, Train Loss: 0.013792, Train-Class-Acc: {0: '99.73%', 1: '98.50%'}\n",
      "Val Loss: 1.120274, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000430\n",
      "Epoch 102/200, Train Loss: 0.009397, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.225240, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000430\n",
      "Epoch 103/200, Train Loss: 0.016458, Train-Class-Acc: {0: '99.86%', 1: '98.64%'}\n",
      "Val Loss: 1.228703, Val Acc: 86.41%, Val-Class-Acc: {0: '91.85%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 104/200, Train Loss: 0.008090, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.247472, Val Acc: 85.33%, Val-Class-Acc: {0: '89.67%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 105/200, Train Loss: 0.007131, Train-Class-Acc: {0: '99.73%', 1: '99.32%'}\n",
      "Val Loss: 1.292812, Val Acc: 85.05%, Val-Class-Acc: {0: '89.13%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 106/200, Train Loss: 0.010023, Train-Class-Acc: {0: '100.00%', 1: '98.77%'}\n",
      "Val Loss: 1.264788, Val Acc: 85.05%, Val-Class-Acc: {0: '88.59%', 1: '81.52%'}, LR: 0.000430\n",
      "Epoch 107/200, Train Loss: 0.008325, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.382774, Val Acc: 85.87%, Val-Class-Acc: {0: '92.39%', 1: '79.35%'}, LR: 0.000387\n",
      "Epoch 108/200, Train Loss: 0.014888, Train-Class-Acc: {0: '99.73%', 1: '98.77%'}\n",
      "Val Loss: 1.316333, Val Acc: 84.24%, Val-Class-Acc: {0: '84.78%', 1: '83.70%'}, LR: 0.000387\n",
      "Epoch 109/200, Train Loss: 0.019559, Train-Class-Acc: {0: '99.59%', 1: '98.09%'}\n",
      "Val Loss: 1.491781, Val Acc: 84.24%, Val-Class-Acc: {0: '86.41%', 1: '82.07%'}, LR: 0.000387\n",
      "Epoch 110/200, Train Loss: 0.027292, Train-Class-Acc: {0: '99.18%', 1: '98.50%'}\n",
      "Val Loss: 1.218266, Val Acc: 83.97%, Val-Class-Acc: {0: '85.33%', 1: '82.61%'}, LR: 0.000387\n",
      "Epoch 111/200, Train Loss: 0.075891, Train-Class-Acc: {0: '98.09%', 1: '97.82%'}\n",
      "Val Loss: 1.329102, Val Acc: 82.61%, Val-Class-Acc: {0: '91.30%', 1: '73.91%'}, LR: 0.000387\n",
      "Epoch 112/200, Train Loss: 0.047897, Train-Class-Acc: {0: '98.64%', 1: '96.87%'}\n",
      "Val Loss: 1.005613, Val Acc: 84.24%, Val-Class-Acc: {0: '90.22%', 1: '78.26%'}, LR: 0.000387\n",
      "Epoch 113/200, Train Loss: 0.024890, Train-Class-Acc: {0: '99.18%', 1: '98.64%'}\n",
      "Val Loss: 0.824541, Val Acc: 84.78%, Val-Class-Acc: {0: '83.15%', 1: '86.41%'}, LR: 0.000387\n",
      "Epoch 114/200, Train Loss: 0.014641, Train-Class-Acc: {0: '99.86%', 1: '98.91%'}\n",
      "Val Loss: 0.906152, Val Acc: 85.05%, Val-Class-Acc: {0: '90.76%', 1: '79.35%'}, LR: 0.000387\n",
      "Epoch 115/200, Train Loss: 0.013245, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.016436, Val Acc: 83.15%, Val-Class-Acc: {0: '83.70%', 1: '82.61%'}, LR: 0.000387\n",
      "Epoch 116/200, Train Loss: 0.015845, Train-Class-Acc: {0: '99.73%', 1: '99.05%'}\n",
      "Val Loss: 1.041095, Val Acc: 85.33%, Val-Class-Acc: {0: '86.41%', 1: '84.24%'}, LR: 0.000387\n",
      "Epoch 117/200, Train Loss: 0.010885, Train-Class-Acc: {0: '99.59%', 1: '98.77%'}\n",
      "Val Loss: 1.112549, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000387\n",
      "Epoch 118/200, Train Loss: 0.007743, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.135538, Val Acc: 84.24%, Val-Class-Acc: {0: '85.87%', 1: '82.61%'}, LR: 0.000349\n",
      "Epoch 119/200, Train Loss: 0.005251, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 1.151917, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000349\n",
      "Epoch 120/200, Train Loss: 0.008063, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.206455, Val Acc: 83.97%, Val-Class-Acc: {0: '85.33%', 1: '82.61%'}, LR: 0.000349\n",
      "Epoch 121/200, Train Loss: 0.009155, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.228113, Val Acc: 83.97%, Val-Class-Acc: {0: '84.78%', 1: '83.15%'}, LR: 0.000349\n",
      "Epoch 122/200, Train Loss: 0.009703, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.245184, Val Acc: 84.24%, Val-Class-Acc: {0: '85.33%', 1: '83.15%'}, LR: 0.000349\n",
      "Epoch 123/200, Train Loss: 0.006182, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.259775, Val Acc: 84.51%, Val-Class-Acc: {0: '85.33%', 1: '83.70%'}, LR: 0.000349\n",
      "Epoch 124/200, Train Loss: 0.008812, Train-Class-Acc: {0: '99.86%', 1: '99.05%'}\n",
      "Val Loss: 1.255935, Val Acc: 84.51%, Val-Class-Acc: {0: '84.78%', 1: '84.24%'}, LR: 0.000349\n",
      "Epoch 125/200, Train Loss: 0.007138, Train-Class-Acc: {0: '100.00%', 1: '99.59%'}\n",
      "Val Loss: 1.296976, Val Acc: 84.78%, Val-Class-Acc: {0: '89.13%', 1: '80.43%'}, LR: 0.000349\n",
      "Epoch 126/200, Train Loss: 0.009443, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.276883, Val Acc: 85.05%, Val-Class-Acc: {0: '88.59%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 127/200, Train Loss: 0.006587, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.253012, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000349\n",
      "Epoch 128/200, Train Loss: 0.007880, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.292080, Val Acc: 84.51%, Val-Class-Acc: {0: '87.50%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 129/200, Train Loss: 0.009381, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.312759, Val Acc: 84.51%, Val-Class-Acc: {0: '87.50%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 130/200, Train Loss: 0.009330, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.312542, Val Acc: 85.87%, Val-Class-Acc: {0: '89.13%', 1: '82.61%'}, LR: 0.000314\n",
      "Epoch 131/200, Train Loss: 0.007932, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.293143, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000314\n",
      "Epoch 132/200, Train Loss: 0.008383, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.318619, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000314\n",
      "Epoch 133/200, Train Loss: 0.009761, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.328800, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000314\n",
      "Epoch 134/200, Train Loss: 0.005929, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 1.335566, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000314\n",
      "Epoch 135/200, Train Loss: 0.007741, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.353686, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000314\n",
      "Epoch 136/200, Train Loss: 0.006875, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.361626, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000314\n",
      "Epoch 137/200, Train Loss: 0.007813, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.377462, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000314\n",
      "Epoch 138/200, Train Loss: 0.005879, Train-Class-Acc: {0: '100.00%', 1: '99.59%'}\n",
      "Val Loss: 1.380300, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000314\n",
      "Epoch 139/200, Train Loss: 0.007736, Train-Class-Acc: {0: '100.00%', 1: '98.37%'}\n",
      "Val Loss: 1.387830, Val Acc: 85.33%, Val-Class-Acc: {0: '86.96%', 1: '83.70%'}, LR: 0.000314\n",
      "Epoch 140/200, Train Loss: 0.022715, Train-Class-Acc: {0: '99.46%', 1: '98.77%'}\n",
      "Val Loss: 1.394711, Val Acc: 84.51%, Val-Class-Acc: {0: '84.78%', 1: '84.24%'}, LR: 0.000282\n",
      "Epoch 141/200, Train Loss: 0.019538, Train-Class-Acc: {0: '99.59%', 1: '98.23%'}\n",
      "Val Loss: 1.161264, Val Acc: 85.33%, Val-Class-Acc: {0: '85.33%', 1: '85.33%'}, LR: 0.000282\n",
      "Epoch 142/200, Train Loss: 0.014685, Train-Class-Acc: {0: '99.73%', 1: '98.64%'}\n",
      "Val Loss: 1.353081, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000282\n",
      "Epoch 143/200, Train Loss: 0.020329, Train-Class-Acc: {0: '99.46%', 1: '98.09%'}\n",
      "Val Loss: 1.205036, Val Acc: 87.77%, Val-Class-Acc: {0: '93.48%', 1: '82.07%'}, LR: 0.000282\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_19.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_143.pth\n",
      "Epoch 144/200, Train Loss: 0.030763, Train-Class-Acc: {0: '99.32%', 1: '97.96%'}\n",
      "Val Loss: 1.354831, Val Acc: 85.60%, Val-Class-Acc: {0: '88.59%', 1: '82.61%'}, LR: 0.000282\n",
      "Epoch 145/200, Train Loss: 0.031281, Train-Class-Acc: {0: '99.46%', 1: '97.96%'}\n",
      "Val Loss: 1.619416, Val Acc: 85.05%, Val-Class-Acc: {0: '93.48%', 1: '76.63%'}, LR: 0.000282\n",
      "Epoch 146/200, Train Loss: 0.031864, Train-Class-Acc: {0: '99.18%', 1: '98.09%'}\n",
      "Val Loss: 1.332620, Val Acc: 83.70%, Val-Class-Acc: {0: '86.41%', 1: '80.98%'}, LR: 0.000282\n",
      "Epoch 147/200, Train Loss: 0.026899, Train-Class-Acc: {0: '99.32%', 1: '97.55%'}\n",
      "Val Loss: 1.347130, Val Acc: 83.42%, Val-Class-Acc: {0: '82.07%', 1: '84.78%'}, LR: 0.000282\n",
      "Epoch 148/200, Train Loss: 0.028869, Train-Class-Acc: {0: '99.46%', 1: '98.09%'}\n",
      "Val Loss: 1.301457, Val Acc: 86.14%, Val-Class-Acc: {0: '90.76%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 149/200, Train Loss: 0.011460, Train-Class-Acc: {0: '99.73%', 1: '99.32%'}\n",
      "Val Loss: 1.002865, Val Acc: 85.60%, Val-Class-Acc: {0: '85.87%', 1: '85.33%'}, LR: 0.000282\n",
      "Epoch 150/200, Train Loss: 0.013622, Train-Class-Acc: {0: '99.86%', 1: '98.91%'}\n",
      "Val Loss: 1.085925, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000282\n",
      "Epoch 151/200, Train Loss: 0.008770, Train-Class-Acc: {0: '99.73%', 1: '99.32%'}\n",
      "Val Loss: 1.097909, Val Acc: 86.96%, Val-Class-Acc: {0: '89.67%', 1: '84.24%'}, LR: 0.000254\n",
      "Epoch 152/200, Train Loss: 0.007987, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.108308, Val Acc: 86.68%, Val-Class-Acc: {0: '89.67%', 1: '83.70%'}, LR: 0.000254\n",
      "Epoch 153/200, Train Loss: 0.006359, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.150653, Val Acc: 86.14%, Val-Class-Acc: {0: '90.22%', 1: '82.07%'}, LR: 0.000254\n",
      "Epoch 154/200, Train Loss: 0.010594, Train-Class-Acc: {0: '99.86%', 1: '98.64%'}\n",
      "Val Loss: 1.228356, Val Acc: 85.87%, Val-Class-Acc: {0: '90.22%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 155/200, Train Loss: 0.015745, Train-Class-Acc: {0: '99.32%', 1: '99.05%'}\n",
      "Val Loss: 1.355809, Val Acc: 84.78%, Val-Class-Acc: {0: '89.67%', 1: '79.89%'}, LR: 0.000254\n",
      "Epoch 156/200, Train Loss: 0.020160, Train-Class-Acc: {0: '99.86%', 1: '98.50%'}\n",
      "Val Loss: 1.213035, Val Acc: 85.05%, Val-Class-Acc: {0: '86.41%', 1: '83.70%'}, LR: 0.000254\n",
      "Epoch 157/200, Train Loss: 0.019106, Train-Class-Acc: {0: '99.59%', 1: '98.91%'}\n",
      "Val Loss: 1.383611, Val Acc: 84.78%, Val-Class-Acc: {0: '90.76%', 1: '78.80%'}, LR: 0.000254\n",
      "Epoch 158/200, Train Loss: 0.019961, Train-Class-Acc: {0: '99.73%', 1: '98.64%'}\n",
      "Val Loss: 1.226236, Val Acc: 85.87%, Val-Class-Acc: {0: '85.33%', 1: '86.41%'}, LR: 0.000254\n",
      "Epoch 159/200, Train Loss: 0.010221, Train-Class-Acc: {0: '99.73%', 1: '98.77%'}\n",
      "Val Loss: 1.218751, Val Acc: 85.87%, Val-Class-Acc: {0: '88.04%', 1: '83.70%'}, LR: 0.000254\n",
      "Epoch 160/200, Train Loss: 0.009706, Train-Class-Acc: {0: '100.00%', 1: '98.37%'}\n",
      "Val Loss: 1.167850, Val Acc: 85.60%, Val-Class-Acc: {0: '86.41%', 1: '84.78%'}, LR: 0.000254\n",
      "Epoch 161/200, Train Loss: 0.012849, Train-Class-Acc: {0: '99.59%', 1: '99.59%'}\n",
      "Val Loss: 1.178761, Val Acc: 86.68%, Val-Class-Acc: {0: '84.78%', 1: '88.59%'}, LR: 0.000254\n",
      "Epoch 162/200, Train Loss: 0.019892, Train-Class-Acc: {0: '99.59%', 1: '98.50%'}\n",
      "Val Loss: 1.182133, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000229\n",
      "Epoch 163/200, Train Loss: 0.010296, Train-Class-Acc: {0: '99.73%', 1: '99.59%'}\n",
      "Val Loss: 1.205629, Val Acc: 85.87%, Val-Class-Acc: {0: '88.04%', 1: '83.70%'}, LR: 0.000229\n",
      "Epoch 164/200, Train Loss: 0.010808, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.263925, Val Acc: 85.60%, Val-Class-Acc: {0: '86.96%', 1: '84.24%'}, LR: 0.000229\n",
      "Epoch 165/200, Train Loss: 0.007497, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.314091, Val Acc: 86.14%, Val-Class-Acc: {0: '86.96%', 1: '85.33%'}, LR: 0.000229\n",
      "Epoch 166/200, Train Loss: 0.006316, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.321921, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000229\n",
      "Epoch 167/200, Train Loss: 0.006958, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.320861, Val Acc: 86.68%, Val-Class-Acc: {0: '87.50%', 1: '85.87%'}, LR: 0.000229\n",
      "Epoch 168/200, Train Loss: 0.008903, Train-Class-Acc: {0: '100.00%', 1: '98.50%'}\n",
      "Val Loss: 1.339964, Val Acc: 86.14%, Val-Class-Acc: {0: '88.04%', 1: '84.24%'}, LR: 0.000229\n",
      "Epoch 169/200, Train Loss: 0.005935, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.352399, Val Acc: 86.41%, Val-Class-Acc: {0: '87.50%', 1: '85.33%'}, LR: 0.000229\n",
      "Epoch 170/200, Train Loss: 0.009660, Train-Class-Acc: {0: '100.00%', 1: '98.23%'}\n",
      "Val Loss: 1.363033, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000229\n",
      "Epoch 171/200, Train Loss: 0.006425, Train-Class-Acc: {0: '100.00%', 1: '98.77%'}\n",
      "Val Loss: 1.375271, Val Acc: 86.41%, Val-Class-Acc: {0: '87.50%', 1: '85.33%'}, LR: 0.000229\n",
      "Epoch 172/200, Train Loss: 0.007806, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.362851, Val Acc: 86.68%, Val-Class-Acc: {0: '87.50%', 1: '85.87%'}, LR: 0.000229\n",
      "Epoch 173/200, Train Loss: 0.006333, Train-Class-Acc: {0: '99.86%', 1: '99.18%'}\n",
      "Val Loss: 1.303262, Val Acc: 87.50%, Val-Class-Acc: {0: '89.67%', 1: '85.33%'}, LR: 0.000206\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_21.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_173.pth\n",
      "Epoch 174/200, Train Loss: 0.009588, Train-Class-Acc: {0: '100.00%', 1: '98.23%'}\n",
      "Val Loss: 1.361463, Val Acc: 87.23%, Val-Class-Acc: {0: '90.22%', 1: '84.24%'}, LR: 0.000206\n",
      "Epoch 175/200, Train Loss: 0.007344, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.379436, Val Acc: 87.50%, Val-Class-Acc: {0: '90.76%', 1: '84.24%'}, LR: 0.000206\n",
      "Epoch 176/200, Train Loss: 0.007755, Train-Class-Acc: {0: '99.86%', 1: '99.05%'}\n",
      "Val Loss: 1.310930, Val Acc: 87.23%, Val-Class-Acc: {0: '90.22%', 1: '84.24%'}, LR: 0.000206\n",
      "Epoch 177/200, Train Loss: 0.008779, Train-Class-Acc: {0: '99.86%', 1: '98.91%'}\n",
      "Val Loss: 1.454030, Val Acc: 86.41%, Val-Class-Acc: {0: '91.30%', 1: '81.52%'}, LR: 0.000206\n",
      "Epoch 178/200, Train Loss: 0.011558, Train-Class-Acc: {0: '99.86%', 1: '99.05%'}\n",
      "Val Loss: 1.538838, Val Acc: 85.87%, Val-Class-Acc: {0: '90.22%', 1: '81.52%'}, LR: 0.000206\n",
      "Epoch 179/200, Train Loss: 0.013345, Train-Class-Acc: {0: '99.73%', 1: '98.91%'}\n",
      "Val Loss: 1.520060, Val Acc: 84.51%, Val-Class-Acc: {0: '87.50%', 1: '81.52%'}, LR: 0.000206\n",
      "Epoch 180/200, Train Loss: 0.009782, Train-Class-Acc: {0: '99.73%', 1: '99.32%'}\n",
      "Val Loss: 1.427009, Val Acc: 84.51%, Val-Class-Acc: {0: '85.33%', 1: '83.70%'}, LR: 0.000206\n",
      "Epoch 181/200, Train Loss: 0.023046, Train-Class-Acc: {0: '99.59%', 1: '98.77%'}\n",
      "Val Loss: 1.396239, Val Acc: 85.60%, Val-Class-Acc: {0: '85.87%', 1: '85.33%'}, LR: 0.000206\n",
      "Epoch 182/200, Train Loss: 0.016784, Train-Class-Acc: {0: '99.59%', 1: '99.05%'}\n",
      "Val Loss: 1.325353, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000206\n",
      "Epoch 183/200, Train Loss: 0.014441, Train-Class-Acc: {0: '99.86%', 1: '98.37%'}\n",
      "Val Loss: 1.499343, Val Acc: 84.51%, Val-Class-Acc: {0: '86.96%', 1: '82.07%'}, LR: 0.000206\n",
      "Epoch 184/200, Train Loss: 0.016040, Train-Class-Acc: {0: '99.73%', 1: '99.05%'}\n",
      "Val Loss: 1.546885, Val Acc: 85.05%, Val-Class-Acc: {0: '84.78%', 1: '85.33%'}, LR: 0.000185\n",
      "Epoch 185/200, Train Loss: 0.013753, Train-Class-Acc: {0: '99.46%', 1: '97.82%'}\n",
      "Val Loss: 1.389210, Val Acc: 85.60%, Val-Class-Acc: {0: '89.13%', 1: '82.07%'}, LR: 0.000185\n",
      "Epoch 186/200, Train Loss: 0.006056, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.373464, Val Acc: 85.60%, Val-Class-Acc: {0: '86.41%', 1: '84.78%'}, LR: 0.000185\n",
      "Epoch 187/200, Train Loss: 0.007340, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.394838, Val Acc: 85.87%, Val-Class-Acc: {0: '86.96%', 1: '84.78%'}, LR: 0.000185\n",
      "Epoch 188/200, Train Loss: 0.005471, Train-Class-Acc: {0: '100.00%', 1: '99.73%'}\n",
      "Val Loss: 1.352227, Val Acc: 85.33%, Val-Class-Acc: {0: '85.87%', 1: '84.78%'}, LR: 0.000185\n",
      "Epoch 189/200, Train Loss: 0.007623, Train-Class-Acc: {0: '100.00%', 1: '99.32%'}\n",
      "Val Loss: 1.434085, Val Acc: 85.60%, Val-Class-Acc: {0: '85.87%', 1: '85.33%'}, LR: 0.000185\n",
      "Epoch 190/200, Train Loss: 0.006949, Train-Class-Acc: {0: '100.00%', 1: '98.50%'}\n",
      "Val Loss: 1.477390, Val Acc: 85.33%, Val-Class-Acc: {0: '86.96%', 1: '83.70%'}, LR: 0.000185\n",
      "Epoch 191/200, Train Loss: 0.006830, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.470402, Val Acc: 85.87%, Val-Class-Acc: {0: '86.41%', 1: '85.33%'}, LR: 0.000185\n",
      "Epoch 192/200, Train Loss: 0.010855, Train-Class-Acc: {0: '100.00%', 1: '98.23%'}\n",
      "Val Loss: 1.477220, Val Acc: 85.33%, Val-Class-Acc: {0: '86.96%', 1: '83.70%'}, LR: 0.000185\n",
      "Epoch 193/200, Train Loss: 0.008221, Train-Class-Acc: {0: '99.86%', 1: '99.05%'}\n",
      "Val Loss: 1.463261, Val Acc: 86.14%, Val-Class-Acc: {0: '88.04%', 1: '84.24%'}, LR: 0.000185\n",
      "Epoch 194/200, Train Loss: 0.007772, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.511283, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000185\n",
      "Epoch 195/200, Train Loss: 0.014918, Train-Class-Acc: {0: '100.00%', 1: '98.50%'}\n",
      "Val Loss: 1.446440, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000167\n",
      "Epoch 196/200, Train Loss: 0.008468, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.451046, Val Acc: 85.05%, Val-Class-Acc: {0: '85.87%', 1: '84.24%'}, LR: 0.000167\n",
      "Epoch 197/200, Train Loss: 0.007551, Train-Class-Acc: {0: '100.00%', 1: '98.77%'}\n",
      "Val Loss: 1.457595, Val Acc: 85.60%, Val-Class-Acc: {0: '86.96%', 1: '84.24%'}, LR: 0.000167\n",
      "Epoch 198/200, Train Loss: 0.009382, Train-Class-Acc: {0: '99.86%', 1: '99.18%'}\n",
      "Val Loss: 1.478857, Val Acc: 86.14%, Val-Class-Acc: {0: '88.59%', 1: '83.70%'}, LR: 0.000167\n",
      "Epoch 199/200, Train Loss: 0.012244, Train-Class-Acc: {0: '100.00%', 1: '98.50%'}\n",
      "Val Loss: 1.472205, Val Acc: 85.60%, Val-Class-Acc: {0: '88.04%', 1: '83.15%'}, LR: 0.000167\n",
      "Epoch 200/200, Train Loss: 0.006346, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.493663, Val Acc: 85.60%, Val-Class-Acc: {0: '88.04%', 1: '83.15%'}, LR: 0.000167\n",
      "\n",
      "🏆 Best model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_best.pth (Val Accuracy: 88.32%)\n",
      "\n",
      "📌 Final model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_final.pth\n",
      "\n",
      "🎯 Top 5 Best Models:\n",
      "Epoch 30, Train Loss: 0.123424, Train-Acc: {0: '93.73%', 1: '95.10%'},\n",
      "Val Loss: 0.436004, Val Acc: 88.32%, Val-Class-Acc: {0: '89.13%', 1: '87.50%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_30.pth\n",
      "Epoch 14, Train Loss: 0.257432, Train-Acc: {0: '91.55%', 1: '87.19%'},\n",
      "Val Loss: 0.436287, Val Acc: 88.04%, Val-Class-Acc: {0: '89.67%', 1: '86.41%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_14.pth\n",
      "Epoch 143, Train Loss: 0.020329, Train-Acc: {0: '99.46%', 1: '98.09%'},\n",
      "Val Loss: 1.205036, Val Acc: 87.77%, Val-Class-Acc: {0: '93.48%', 1: '82.07%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_143.pth\n",
      "Epoch 49, Train Loss: 0.111612, Train-Acc: {0: '96.32%', 1: '95.64%'},\n",
      "Val Loss: 0.561518, Val Acc: 87.77%, Val-Class-Acc: {0: '94.02%', 1: '81.52%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_49.pth\n",
      "Epoch 173, Train Loss: 0.006333, Train-Acc: {0: '99.86%', 1: '99.18%'},\n",
      "Val Loss: 1.303262, Val Acc: 87.50%, Val-Class-Acc: {0: '89.67%', 1: '85.33%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg/ResNet18_1D_v2_epoch_173.pth\n",
      "\n",
      "🧠 Model Summary:\n",
      "Total Parameters: 3,986,818\n",
      "Model Size (float32): 15.21 MB\n",
      "Total Training Time: 467.08 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))  # Shape: (B, 5000, 12)\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# ==== Model Hyperparameters ====\n",
    "input_channels = X_train.shape[2]                  # 12 leads\n",
    "output_size = len(np.unique(y_train))              # Number of classes (e.g., 2 for Period 1)\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "dropout = 0.0                                       # Not needed for ResNet18_1D\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "print(\"✅ input shape:\", X_train.shape)\n",
    "print(\"✅ unique y_train:\", np.unique(y_train))\n",
    "print(\"✅ unique y_test :\", np.unique(y_test))\n",
    "assert np.max(y_train) < output_size\n",
    "assert np.max(y_test) < output_size\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/ResNet18_v2_arg\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Model ====\n",
    "model = ResNet18_1D_v2(input_channels=input_channels, output_size=output_size).to(device)\n",
    "\n",
    "# ==== Optimizer and Training ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# ==== Train ====\n",
    "result_summary = train_model_general_classifier(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name='ResNet18_1D_v2',\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del model, X_train, y_train, X_test, y_test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4bf2ea",
   "metadata": {},
   "source": [
    "#### Data Arg + Claude Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61334b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Automatically selected GPU:\n",
      "    - CUDA Device ID : 1\n",
      "    - Memory Used    : 705 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "✅ input shape: (1468, 5000, 12)\n",
      "✅ unique y_train: [0 1]\n",
      "✅ unique y_test : [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 'train_model_general_classifier' started.\n",
      "✅ Removed existing folder: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude\n",
      "\n",
      "✅ Data Overview:\n",
      "X_train: (1468, 5000, 12), y_train: (1468,)\n",
      "X_val: (368, 5000, 12), y_val: (368,)\n",
      "Epoch 1/200, Train Loss: 0.500345, Train-Class-Acc: {0: '79.70%', 1: '70.57%'}\n",
      "Val Loss: 0.468198, Val Acc: 77.17%, Val-Class-Acc: {0: '95.65%', 1: '58.70%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.397528, Train-Class-Acc: {0: '86.51%', 1: '77.11%'}\n",
      "Val Loss: 0.451879, Val Acc: 82.88%, Val-Class-Acc: {0: '84.24%', 1: '81.52%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.358625, Train-Class-Acc: {0: '87.19%', 1: '80.38%'}\n",
      "Val Loss: 0.432713, Val Acc: 82.88%, Val-Class-Acc: {0: '91.30%', 1: '74.46%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.330666, Train-Class-Acc: {0: '86.10%', 1: '83.92%'}\n",
      "Val Loss: 0.388681, Val Acc: 83.15%, Val-Class-Acc: {0: '82.07%', 1: '84.24%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.309669, Train-Class-Acc: {0: '87.74%', 1: '83.79%'}\n",
      "Val Loss: 0.645522, Val Acc: 75.00%, Val-Class-Acc: {0: '55.43%', 1: '94.57%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.304253, Train-Class-Acc: {0: '90.19%', 1: '83.51%'}\n",
      "Val Loss: 0.462537, Val Acc: 80.71%, Val-Class-Acc: {0: '92.93%', 1: '68.48%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_5.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_6.pth\n",
      "Epoch 7/200, Train Loss: 0.290064, Train-Class-Acc: {0: '89.10%', 1: '85.97%'}\n",
      "Val Loss: 0.498362, Val Acc: 76.90%, Val-Class-Acc: {0: '59.78%', 1: '94.02%'}, LR: 0.000400\n",
      "Epoch 8/200, Train Loss: 0.244976, Train-Class-Acc: {0: '90.19%', 1: '90.33%'}\n",
      "Val Loss: 0.445975, Val Acc: 83.70%, Val-Class-Acc: {0: '88.59%', 1: '78.80%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_1.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_8.pth\n",
      "Epoch 9/200, Train Loss: 0.226189, Train-Class-Acc: {0: '90.05%', 1: '89.78%'}\n",
      "Val Loss: 0.350907, Val Acc: 86.14%, Val-Class-Acc: {0: '84.24%', 1: '88.04%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_6.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.230301, Train-Class-Acc: {0: '91.69%', 1: '90.05%'}\n",
      "Val Loss: 0.573307, Val Acc: 82.61%, Val-Class-Acc: {0: '90.22%', 1: '75.00%'}, LR: 0.000400\n",
      "Epoch 11/200, Train Loss: 0.256615, Train-Class-Acc: {0: '91.69%', 1: '87.60%'}\n",
      "Val Loss: 0.365431, Val Acc: 85.33%, Val-Class-Acc: {0: '84.78%', 1: '85.87%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_2.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_11.pth\n",
      "Epoch 12/200, Train Loss: 0.182804, Train-Class-Acc: {0: '93.60%', 1: '92.64%'}\n",
      "Val Loss: 0.535846, Val Acc: 83.70%, Val-Class-Acc: {0: '92.39%', 1: '75.00%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_3.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_12.pth\n",
      "Epoch 13/200, Train Loss: 0.197220, Train-Class-Acc: {0: '93.73%', 1: '89.37%'}\n",
      "Val Loss: 0.761965, Val Acc: 73.10%, Val-Class-Acc: {0: '50.54%', 1: '95.65%'}, LR: 0.000400\n",
      "Epoch 14/200, Train Loss: 0.211836, Train-Class-Acc: {0: '91.14%', 1: '90.87%'}\n",
      "Val Loss: 0.412820, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_4.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_14.pth\n",
      "Epoch 15/200, Train Loss: 0.170830, Train-Class-Acc: {0: '93.60%', 1: '93.19%'}\n",
      "Val Loss: 1.110169, Val Acc: 75.54%, Val-Class-Acc: {0: '98.37%', 1: '52.72%'}, LR: 0.000400\n",
      "Epoch 16/200, Train Loss: 0.174356, Train-Class-Acc: {0: '92.78%', 1: '91.55%'}\n",
      "Val Loss: 0.417837, Val Acc: 85.33%, Val-Class-Acc: {0: '87.50%', 1: '83.15%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_8.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_16.pth\n",
      "Epoch 17/200, Train Loss: 0.142083, Train-Class-Acc: {0: '95.91%', 1: '93.46%'}\n",
      "Val Loss: 0.541203, Val Acc: 83.97%, Val-Class-Acc: {0: '79.89%', 1: '88.04%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_12.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_17.pth\n",
      "Epoch 18/200, Train Loss: 0.148977, Train-Class-Acc: {0: '94.69%', 1: '93.05%'}\n",
      "Val Loss: 0.710104, Val Acc: 81.25%, Val-Class-Acc: {0: '71.74%', 1: '90.76%'}, LR: 0.000400\n",
      "Epoch 19/200, Train Loss: 0.200549, Train-Class-Acc: {0: '93.19%', 1: '88.83%'}\n",
      "Val Loss: 0.496299, Val Acc: 83.42%, Val-Class-Acc: {0: '79.35%', 1: '87.50%'}, LR: 0.000400\n",
      "Epoch 20/200, Train Loss: 0.156159, Train-Class-Acc: {0: '93.60%', 1: '92.92%'}\n",
      "Val Loss: 0.585370, Val Acc: 84.51%, Val-Class-Acc: {0: '91.85%', 1: '77.17%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_17.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_20.pth\n",
      "Epoch 21/200, Train Loss: 0.128732, Train-Class-Acc: {0: '94.82%', 1: '93.46%'}\n",
      "Val Loss: 0.493526, Val Acc: 85.87%, Val-Class-Acc: {0: '89.13%', 1: '82.61%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_20.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_21.pth\n",
      "Epoch 22/200, Train Loss: 0.113970, Train-Class-Acc: {0: '95.23%', 1: '95.23%'}\n",
      "Val Loss: 0.832120, Val Acc: 81.79%, Val-Class-Acc: {0: '94.02%', 1: '69.57%'}, LR: 0.000400\n",
      "Epoch 23/200, Train Loss: 0.122560, Train-Class-Acc: {0: '96.19%', 1: '94.28%'}\n",
      "Val Loss: 0.680714, Val Acc: 83.97%, Val-Class-Acc: {0: '90.76%', 1: '77.17%'}, LR: 0.000400\n",
      "Epoch 24/200, Train Loss: 0.114475, Train-Class-Acc: {0: '95.10%', 1: '95.50%'}\n",
      "Val Loss: 0.612653, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_11.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_24.pth\n",
      "Epoch 25/200, Train Loss: 0.101572, Train-Class-Acc: {0: '95.91%', 1: '95.64%'}\n",
      "Val Loss: 0.616811, Val Acc: 84.51%, Val-Class-Acc: {0: '83.15%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 26/200, Train Loss: 0.112962, Train-Class-Acc: {0: '96.46%', 1: '95.37%'}\n",
      "Val Loss: 0.690846, Val Acc: 80.43%, Val-Class-Acc: {0: '72.28%', 1: '88.59%'}, LR: 0.000400\n",
      "Epoch 27/200, Train Loss: 0.117354, Train-Class-Acc: {0: '95.78%', 1: '94.55%'}\n",
      "Val Loss: 0.562401, Val Acc: 84.78%, Val-Class-Acc: {0: '85.87%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 28/200, Train Loss: 0.078557, Train-Class-Acc: {0: '98.37%', 1: '96.05%'}\n",
      "Val Loss: 0.707032, Val Acc: 83.15%, Val-Class-Acc: {0: '89.13%', 1: '77.17%'}, LR: 0.000400\n",
      "Epoch 29/200, Train Loss: 0.050987, Train-Class-Acc: {0: '98.23%', 1: '98.09%'}\n",
      "Val Loss: 0.755840, Val Acc: 84.24%, Val-Class-Acc: {0: '82.07%', 1: '86.41%'}, LR: 0.000400\n",
      "Epoch 30/200, Train Loss: 0.065087, Train-Class-Acc: {0: '98.37%', 1: '96.05%'}\n",
      "Val Loss: 0.882143, Val Acc: 85.60%, Val-Class-Acc: {0: '83.15%', 1: '88.04%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_14.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_30.pth\n",
      "Epoch 31/200, Train Loss: 0.101007, Train-Class-Acc: {0: '96.73%', 1: '95.50%'}\n",
      "Val Loss: 1.129413, Val Acc: 79.35%, Val-Class-Acc: {0: '67.39%', 1: '91.30%'}, LR: 0.000400\n",
      "Epoch 32/200, Train Loss: 0.129971, Train-Class-Acc: {0: '96.05%', 1: '94.28%'}\n",
      "Val Loss: 0.653033, Val Acc: 83.97%, Val-Class-Acc: {0: '89.13%', 1: '78.80%'}, LR: 0.000400\n",
      "Epoch 33/200, Train Loss: 0.098816, Train-Class-Acc: {0: '96.32%', 1: '94.82%'}\n",
      "Val Loss: 0.732176, Val Acc: 82.07%, Val-Class-Acc: {0: '78.26%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 34/200, Train Loss: 0.066734, Train-Class-Acc: {0: '98.64%', 1: '97.14%'}\n",
      "Val Loss: 0.802301, Val Acc: 82.61%, Val-Class-Acc: {0: '88.04%', 1: '77.17%'}, LR: 0.000400\n",
      "Epoch 35/200, Train Loss: 0.106746, Train-Class-Acc: {0: '96.32%', 1: '94.82%'}\n",
      "Val Loss: 0.880789, Val Acc: 81.79%, Val-Class-Acc: {0: '89.13%', 1: '74.46%'}, LR: 0.000400\n",
      "Epoch 36/200, Train Loss: 0.107317, Train-Class-Acc: {0: '96.87%', 1: '95.23%'}\n",
      "Val Loss: 0.562470, Val Acc: 84.24%, Val-Class-Acc: {0: '83.70%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 37/200, Train Loss: 0.089641, Train-Class-Acc: {0: '97.55%', 1: '96.73%'}\n",
      "Val Loss: 0.755781, Val Acc: 83.97%, Val-Class-Acc: {0: '81.52%', 1: '86.41%'}, LR: 0.000400\n",
      "Epoch 38/200, Train Loss: 0.069470, Train-Class-Acc: {0: '99.05%', 1: '95.91%'}\n",
      "Val Loss: 0.656703, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 39/200, Train Loss: 0.068467, Train-Class-Acc: {0: '97.68%', 1: '97.41%'}\n",
      "Val Loss: 0.675810, Val Acc: 84.78%, Val-Class-Acc: {0: '84.24%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 40/200, Train Loss: 0.046361, Train-Class-Acc: {0: '98.77%', 1: '97.28%'}\n",
      "Val Loss: 0.746892, Val Acc: 84.51%, Val-Class-Acc: {0: '80.98%', 1: '88.04%'}, LR: 0.000400\n",
      "Epoch 41/200, Train Loss: 0.047899, Train-Class-Acc: {0: '97.82%', 1: '97.96%'}\n",
      "Val Loss: 0.796135, Val Acc: 82.34%, Val-Class-Acc: {0: '76.09%', 1: '88.59%'}, LR: 0.000400\n",
      "Epoch 42/200, Train Loss: 0.074485, Train-Class-Acc: {0: '98.09%', 1: '96.73%'}\n",
      "Val Loss: 0.899765, Val Acc: 85.05%, Val-Class-Acc: {0: '85.33%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 43/200, Train Loss: 0.065327, Train-Class-Acc: {0: '97.96%', 1: '96.73%'}\n",
      "Val Loss: 0.812821, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 44/200, Train Loss: 0.051879, Train-Class-Acc: {0: '97.82%', 1: '97.28%'}\n",
      "Val Loss: 0.810696, Val Acc: 83.97%, Val-Class-Acc: {0: '85.33%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 45/200, Train Loss: 0.040945, Train-Class-Acc: {0: '99.05%', 1: '98.23%'}\n",
      "Val Loss: 0.829670, Val Acc: 82.61%, Val-Class-Acc: {0: '89.13%', 1: '76.09%'}, LR: 0.000400\n",
      "Epoch 46/200, Train Loss: 0.045143, Train-Class-Acc: {0: '98.91%', 1: '98.09%'}\n",
      "Val Loss: 0.932544, Val Acc: 83.42%, Val-Class-Acc: {0: '91.85%', 1: '75.00%'}, LR: 0.000400\n",
      "Epoch 47/200, Train Loss: 0.035068, Train-Class-Acc: {0: '98.91%', 1: '97.55%'}\n",
      "Val Loss: 0.891809, Val Acc: 85.87%, Val-Class-Acc: {0: '82.07%', 1: '89.67%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_16.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_47.pth\n",
      "Epoch 48/200, Train Loss: 0.072031, Train-Class-Acc: {0: '98.23%', 1: '97.28%'}\n",
      "Val Loss: 0.967613, Val Acc: 83.15%, Val-Class-Acc: {0: '81.52%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 49/200, Train Loss: 0.082121, Train-Class-Acc: {0: '97.41%', 1: '96.73%'}\n",
      "Val Loss: 0.820707, Val Acc: 82.07%, Val-Class-Acc: {0: '83.15%', 1: '80.98%'}, LR: 0.000400\n",
      "Epoch 50/200, Train Loss: 0.088419, Train-Class-Acc: {0: '98.23%', 1: '95.91%'}\n",
      "Val Loss: 0.737869, Val Acc: 83.15%, Val-Class-Acc: {0: '85.33%', 1: '80.98%'}, LR: 0.000400\n",
      "Epoch 51/200, Train Loss: 0.059042, Train-Class-Acc: {0: '98.09%', 1: '97.28%'}\n",
      "Val Loss: 0.711779, Val Acc: 84.78%, Val-Class-Acc: {0: '89.13%', 1: '80.43%'}, LR: 0.000400\n",
      "Epoch 52/200, Train Loss: 0.049168, Train-Class-Acc: {0: '98.50%', 1: '97.82%'}\n",
      "Val Loss: 0.994937, Val Acc: 82.61%, Val-Class-Acc: {0: '91.30%', 1: '73.91%'}, LR: 0.000400\n",
      "Epoch 53/200, Train Loss: 0.047022, Train-Class-Acc: {0: '98.91%', 1: '97.28%'}\n",
      "Val Loss: 1.008886, Val Acc: 82.88%, Val-Class-Acc: {0: '91.85%', 1: '73.91%'}, LR: 0.000400\n",
      "Epoch 54/200, Train Loss: 0.045263, Train-Class-Acc: {0: '98.91%', 1: '97.14%'}\n",
      "Val Loss: 0.761198, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_30.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_54.pth\n",
      "Epoch 55/200, Train Loss: 0.027261, Train-Class-Acc: {0: '99.73%', 1: '98.23%'}\n",
      "Val Loss: 0.875975, Val Acc: 84.78%, Val-Class-Acc: {0: '85.33%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 56/200, Train Loss: 0.041284, Train-Class-Acc: {0: '98.64%', 1: '97.55%'}\n",
      "Val Loss: 0.841834, Val Acc: 85.33%, Val-Class-Acc: {0: '85.33%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 57/200, Train Loss: 0.056698, Train-Class-Acc: {0: '98.23%', 1: '97.41%'}\n",
      "Val Loss: 0.893428, Val Acc: 83.97%, Val-Class-Acc: {0: '85.33%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 58/200, Train Loss: 0.047476, Train-Class-Acc: {0: '98.77%', 1: '97.68%'}\n",
      "Val Loss: 0.925854, Val Acc: 84.24%, Val-Class-Acc: {0: '86.96%', 1: '81.52%'}, LR: 0.000400\n",
      "Epoch 59/200, Train Loss: 0.049200, Train-Class-Acc: {0: '98.50%', 1: '97.55%'}\n",
      "Val Loss: 0.921482, Val Acc: 84.51%, Val-Class-Acc: {0: '91.30%', 1: '77.72%'}, LR: 0.000400\n",
      "Epoch 60/200, Train Loss: 0.044748, Train-Class-Acc: {0: '98.91%', 1: '97.96%'}\n",
      "Val Loss: 0.906379, Val Acc: 85.33%, Val-Class-Acc: {0: '88.59%', 1: '82.07%'}, LR: 0.000400\n",
      "Epoch 61/200, Train Loss: 0.046898, Train-Class-Acc: {0: '98.91%', 1: '97.55%'}\n",
      "Val Loss: 1.007255, Val Acc: 84.51%, Val-Class-Acc: {0: '79.89%', 1: '89.13%'}, LR: 0.000400\n",
      "Epoch 62/200, Train Loss: 0.037980, Train-Class-Acc: {0: '99.46%', 1: '97.28%'}\n",
      "Val Loss: 0.846759, Val Acc: 84.78%, Val-Class-Acc: {0: '89.13%', 1: '80.43%'}, LR: 0.000400\n",
      "Epoch 63/200, Train Loss: 0.045949, Train-Class-Acc: {0: '98.50%', 1: '98.09%'}\n",
      "Val Loss: 0.962706, Val Acc: 85.05%, Val-Class-Acc: {0: '86.41%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 64/200, Train Loss: 0.052745, Train-Class-Acc: {0: '98.64%', 1: '97.55%'}\n",
      "Val Loss: 1.015522, Val Acc: 84.78%, Val-Class-Acc: {0: '83.15%', 1: '86.41%'}, LR: 0.000400\n",
      "Epoch 65/200, Train Loss: 0.114945, Train-Class-Acc: {0: '96.59%', 1: '95.78%'}\n",
      "Val Loss: 0.810383, Val Acc: 83.97%, Val-Class-Acc: {0: '84.78%', 1: '83.15%'}, LR: 0.000400\n",
      "Epoch 66/200, Train Loss: 0.068939, Train-Class-Acc: {0: '96.19%', 1: '97.68%'}\n",
      "Val Loss: 0.842236, Val Acc: 83.42%, Val-Class-Acc: {0: '91.85%', 1: '75.00%'}, LR: 0.000400\n",
      "Epoch 67/200, Train Loss: 0.048196, Train-Class-Acc: {0: '99.32%', 1: '96.19%'}\n",
      "Val Loss: 0.733361, Val Acc: 83.70%, Val-Class-Acc: {0: '88.04%', 1: '79.35%'}, LR: 0.000400\n",
      "Epoch 68/200, Train Loss: 0.030587, Train-Class-Acc: {0: '98.64%', 1: '98.77%'}\n",
      "Val Loss: 0.831963, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000400\n",
      "Epoch 69/200, Train Loss: 0.039743, Train-Class-Acc: {0: '99.59%', 1: '97.00%'}\n",
      "Val Loss: 0.934895, Val Acc: 83.70%, Val-Class-Acc: {0: '83.15%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 70/200, Train Loss: 0.066212, Train-Class-Acc: {0: '98.23%', 1: '96.32%'}\n",
      "Val Loss: 0.785558, Val Acc: 84.24%, Val-Class-Acc: {0: '82.07%', 1: '86.41%'}, LR: 0.000400\n",
      "Epoch 71/200, Train Loss: 0.050510, Train-Class-Acc: {0: '98.09%', 1: '97.14%'}\n",
      "Val Loss: 0.950043, Val Acc: 85.60%, Val-Class-Acc: {0: '92.93%', 1: '78.26%'}, LR: 0.000400\n",
      "Epoch 72/200, Train Loss: 0.028879, Train-Class-Acc: {0: '99.32%', 1: '98.77%'}\n",
      "Val Loss: 0.826922, Val Acc: 85.05%, Val-Class-Acc: {0: '86.41%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 73/200, Train Loss: 0.018237, Train-Class-Acc: {0: '99.73%', 1: '99.18%'}\n",
      "Val Loss: 0.877441, Val Acc: 85.33%, Val-Class-Acc: {0: '90.22%', 1: '80.43%'}, LR: 0.000400\n",
      "Epoch 74/200, Train Loss: 0.018053, Train-Class-Acc: {0: '99.73%', 1: '98.77%'}\n",
      "Val Loss: 1.018253, Val Acc: 83.70%, Val-Class-Acc: {0: '88.04%', 1: '79.35%'}, LR: 0.000400\n",
      "Epoch 75/200, Train Loss: 0.021762, Train-Class-Acc: {0: '99.59%', 1: '98.37%'}\n",
      "Val Loss: 1.082151, Val Acc: 84.51%, Val-Class-Acc: {0: '88.59%', 1: '80.43%'}, LR: 0.000400\n",
      "Epoch 76/200, Train Loss: 0.033256, Train-Class-Acc: {0: '98.77%', 1: '98.23%'}\n",
      "Val Loss: 1.178673, Val Acc: 83.15%, Val-Class-Acc: {0: '90.76%', 1: '75.54%'}, LR: 0.000400\n",
      "Epoch 77/200, Train Loss: 0.035392, Train-Class-Acc: {0: '99.32%', 1: '98.77%'}\n",
      "Val Loss: 0.942550, Val Acc: 84.51%, Val-Class-Acc: {0: '83.15%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 78/200, Train Loss: 0.031752, Train-Class-Acc: {0: '99.18%', 1: '98.23%'}\n",
      "Val Loss: 0.971919, Val Acc: 83.42%, Val-Class-Acc: {0: '84.24%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 79/200, Train Loss: 0.039217, Train-Class-Acc: {0: '98.77%', 1: '97.55%'}\n",
      "Val Loss: 1.060194, Val Acc: 84.51%, Val-Class-Acc: {0: '94.02%', 1: '75.00%'}, LR: 0.000400\n",
      "Epoch 80/200, Train Loss: 0.039318, Train-Class-Acc: {0: '99.32%', 1: '97.55%'}\n",
      "Val Loss: 1.003450, Val Acc: 83.70%, Val-Class-Acc: {0: '83.70%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 81/200, Train Loss: 0.045352, Train-Class-Acc: {0: '98.37%', 1: '97.82%'}\n",
      "Val Loss: 1.187726, Val Acc: 84.24%, Val-Class-Acc: {0: '79.89%', 1: '88.59%'}, LR: 0.000400\n",
      "Epoch 82/200, Train Loss: 0.046479, Train-Class-Acc: {0: '99.05%', 1: '96.73%'}\n",
      "Val Loss: 1.084780, Val Acc: 83.42%, Val-Class-Acc: {0: '90.22%', 1: '76.63%'}, LR: 0.000400\n",
      "Epoch 83/200, Train Loss: 0.036421, Train-Class-Acc: {0: '99.05%', 1: '97.96%'}\n",
      "Val Loss: 1.053439, Val Acc: 85.33%, Val-Class-Acc: {0: '90.76%', 1: '79.89%'}, LR: 0.000400\n",
      "Epoch 84/200, Train Loss: 0.037282, Train-Class-Acc: {0: '99.05%', 1: '97.96%'}\n",
      "Val Loss: 0.987278, Val Acc: 85.33%, Val-Class-Acc: {0: '82.61%', 1: '88.04%'}, LR: 0.000400\n",
      "Epoch 85/200, Train Loss: 0.025183, Train-Class-Acc: {0: '99.32%', 1: '98.37%'}\n",
      "Val Loss: 0.951690, Val Acc: 84.24%, Val-Class-Acc: {0: '86.96%', 1: '81.52%'}, LR: 0.000400\n",
      "Epoch 86/200, Train Loss: 0.019570, Train-Class-Acc: {0: '99.86%', 1: '98.37%'}\n",
      "Val Loss: 1.043057, Val Acc: 83.42%, Val-Class-Acc: {0: '84.78%', 1: '82.07%'}, LR: 0.000400\n",
      "Epoch 87/200, Train Loss: 0.018656, Train-Class-Acc: {0: '99.59%', 1: '97.82%'}\n",
      "Val Loss: 1.068838, Val Acc: 81.52%, Val-Class-Acc: {0: '78.80%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 88/200, Train Loss: 0.030683, Train-Class-Acc: {0: '99.46%', 1: '97.55%'}\n",
      "Val Loss: 1.190306, Val Acc: 83.15%, Val-Class-Acc: {0: '89.67%', 1: '76.63%'}, LR: 0.000400\n",
      "Epoch 89/200, Train Loss: 0.039760, Train-Class-Acc: {0: '98.91%', 1: '98.09%'}\n",
      "Val Loss: 1.357117, Val Acc: 83.42%, Val-Class-Acc: {0: '86.96%', 1: '79.89%'}, LR: 0.000400\n",
      "Epoch 90/200, Train Loss: 0.083358, Train-Class-Acc: {0: '97.82%', 1: '95.91%'}\n",
      "Val Loss: 0.869153, Val Acc: 83.42%, Val-Class-Acc: {0: '79.89%', 1: '86.96%'}, LR: 0.000400\n",
      "Epoch 91/200, Train Loss: 0.067249, Train-Class-Acc: {0: '97.00%', 1: '97.82%'}\n",
      "Val Loss: 0.786343, Val Acc: 82.61%, Val-Class-Acc: {0: '88.04%', 1: '77.17%'}, LR: 0.000400\n",
      "Epoch 92/200, Train Loss: 0.047399, Train-Class-Acc: {0: '99.18%', 1: '97.82%'}\n",
      "Val Loss: 0.823508, Val Acc: 82.88%, Val-Class-Acc: {0: '84.78%', 1: '80.98%'}, LR: 0.000400\n",
      "Epoch 93/200, Train Loss: 0.028985, Train-Class-Acc: {0: '99.18%', 1: '97.96%'}\n",
      "Val Loss: 0.934167, Val Acc: 83.15%, Val-Class-Acc: {0: '88.04%', 1: '78.26%'}, LR: 0.000400\n",
      "Epoch 94/200, Train Loss: 0.022762, Train-Class-Acc: {0: '99.73%', 1: '98.77%'}\n",
      "Val Loss: 0.972509, Val Acc: 85.33%, Val-Class-Acc: {0: '86.96%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 95/200, Train Loss: 0.014925, Train-Class-Acc: {0: '99.86%', 1: '98.64%'}\n",
      "Val Loss: 0.987837, Val Acc: 85.60%, Val-Class-Acc: {0: '90.22%', 1: '80.98%'}, LR: 0.000400\n",
      "Epoch 96/200, Train Loss: 0.010312, Train-Class-Acc: {0: '99.73%', 1: '99.46%'}\n",
      "Val Loss: 0.974671, Val Acc: 85.60%, Val-Class-Acc: {0: '88.04%', 1: '83.15%'}, LR: 0.000400\n",
      "Epoch 97/200, Train Loss: 0.022435, Train-Class-Acc: {0: '99.86%', 1: '97.68%'}\n",
      "Val Loss: 1.131847, Val Acc: 82.88%, Val-Class-Acc: {0: '79.89%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 98/200, Train Loss: 0.028418, Train-Class-Acc: {0: '99.18%', 1: '98.50%'}\n",
      "Val Loss: 1.142931, Val Acc: 85.87%, Val-Class-Acc: {0: '90.76%', 1: '80.98%'}, LR: 0.000400\n",
      "Epoch 99/200, Train Loss: 0.032471, Train-Class-Acc: {0: '98.77%', 1: '98.37%'}\n",
      "Val Loss: 1.155927, Val Acc: 83.97%, Val-Class-Acc: {0: '88.59%', 1: '79.35%'}, LR: 0.000400\n",
      "Epoch 100/200, Train Loss: 0.035012, Train-Class-Acc: {0: '99.46%', 1: '98.23%'}\n",
      "Val Loss: 1.050531, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_21.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_100.pth\n",
      "Epoch 101/200, Train Loss: 0.064898, Train-Class-Acc: {0: '97.96%', 1: '97.55%'}\n",
      "Val Loss: 0.989184, Val Acc: 84.24%, Val-Class-Acc: {0: '88.59%', 1: '79.89%'}, LR: 0.000400\n",
      "Epoch 102/200, Train Loss: 0.053615, Train-Class-Acc: {0: '99.05%', 1: '97.41%'}\n",
      "Val Loss: 0.802189, Val Acc: 85.05%, Val-Class-Acc: {0: '83.15%', 1: '86.96%'}, LR: 0.000400\n",
      "Epoch 103/200, Train Loss: 0.033435, Train-Class-Acc: {0: '99.18%', 1: '98.09%'}\n",
      "Val Loss: 0.859944, Val Acc: 85.05%, Val-Class-Acc: {0: '85.33%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 104/200, Train Loss: 0.041242, Train-Class-Acc: {0: '98.91%', 1: '98.23%'}\n",
      "Val Loss: 0.945864, Val Acc: 85.33%, Val-Class-Acc: {0: '89.13%', 1: '81.52%'}, LR: 0.000400\n",
      "Epoch 105/200, Train Loss: 0.026285, Train-Class-Acc: {0: '99.32%', 1: '98.50%'}\n",
      "Val Loss: 0.895546, Val Acc: 85.60%, Val-Class-Acc: {0: '89.67%', 1: '81.52%'}, LR: 0.000400\n",
      "Epoch 106/200, Train Loss: 0.029253, Train-Class-Acc: {0: '99.73%', 1: '98.64%'}\n",
      "Val Loss: 0.896441, Val Acc: 83.15%, Val-Class-Acc: {0: '81.52%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 107/200, Train Loss: 0.022403, Train-Class-Acc: {0: '99.18%', 1: '98.23%'}\n",
      "Val Loss: 0.970875, Val Acc: 86.14%, Val-Class-Acc: {0: '84.78%', 1: '87.50%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_47.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_107.pth\n",
      "Epoch 108/200, Train Loss: 0.012916, Train-Class-Acc: {0: '99.86%', 1: '99.05%'}\n",
      "Val Loss: 0.990352, Val Acc: 85.60%, Val-Class-Acc: {0: '85.87%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 109/200, Train Loss: 0.007791, Train-Class-Acc: {0: '99.86%', 1: '99.05%'}\n",
      "Val Loss: 1.056178, Val Acc: 86.14%, Val-Class-Acc: {0: '89.13%', 1: '83.15%'}, LR: 0.000400\n",
      "Epoch 110/200, Train Loss: 0.011373, Train-Class-Acc: {0: '100.00%', 1: '98.50%'}\n",
      "Val Loss: 1.116010, Val Acc: 85.60%, Val-Class-Acc: {0: '88.04%', 1: '83.15%'}, LR: 0.000400\n",
      "Epoch 111/200, Train Loss: 0.006325, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.145232, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 112/200, Train Loss: 0.012673, Train-Class-Acc: {0: '100.00%', 1: '98.23%'}\n",
      "Val Loss: 1.231005, Val Acc: 85.33%, Val-Class-Acc: {0: '86.96%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 113/200, Train Loss: 0.007455, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.211903, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 114/200, Train Loss: 0.005307, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.173514, Val Acc: 86.14%, Val-Class-Acc: {0: '86.96%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 115/200, Train Loss: 0.007596, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.180278, Val Acc: 86.68%, Val-Class-Acc: {0: '89.13%', 1: '84.24%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_9.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_115.pth\n",
      "Epoch 116/200, Train Loss: 0.008968, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.205997, Val Acc: 85.87%, Val-Class-Acc: {0: '88.04%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 117/200, Train Loss: 0.005040, Train-Class-Acc: {0: '100.00%', 1: '99.18%'}\n",
      "Val Loss: 1.220317, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 118/200, Train Loss: 0.007576, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.250716, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 119/200, Train Loss: 0.007373, Train-Class-Acc: {0: '100.00%', 1: '98.64%'}\n",
      "Val Loss: 1.277269, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 120/200, Train Loss: 0.009370, Train-Class-Acc: {0: '100.00%', 1: '99.05%'}\n",
      "Val Loss: 1.299884, Val Acc: 85.33%, Val-Class-Acc: {0: '86.96%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 121/200, Train Loss: 0.007301, Train-Class-Acc: {0: '100.00%', 1: '98.77%'}\n",
      "Val Loss: 1.284177, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 122/200, Train Loss: 0.006717, Train-Class-Acc: {0: '100.00%', 1: '98.91%'}\n",
      "Val Loss: 1.281448, Val Acc: 86.14%, Val-Class-Acc: {0: '88.04%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 123/200, Train Loss: 0.009317, Train-Class-Acc: {0: '100.00%', 1: '98.37%'}\n",
      "Val Loss: 1.330073, Val Acc: 83.70%, Val-Class-Acc: {0: '82.61%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 124/200, Train Loss: 0.016768, Train-Class-Acc: {0: '99.86%', 1: '99.46%'}\n",
      "Val Loss: 1.420281, Val Acc: 85.87%, Val-Class-Acc: {0: '91.30%', 1: '80.43%'}, LR: 0.000400\n",
      "Epoch 125/200, Train Loss: 0.045738, Train-Class-Acc: {0: '99.32%', 1: '98.23%'}\n",
      "Val Loss: 1.159972, Val Acc: 85.05%, Val-Class-Acc: {0: '88.59%', 1: '81.52%'}, LR: 0.000400\n",
      "Epoch 126/200, Train Loss: 0.056624, Train-Class-Acc: {0: '98.77%', 1: '97.28%'}\n",
      "Val Loss: 1.270031, Val Acc: 83.97%, Val-Class-Acc: {0: '80.43%', 1: '87.50%'}, LR: 0.000400\n",
      "Epoch 127/200, Train Loss: 0.084436, Train-Class-Acc: {0: '97.96%', 1: '95.78%'}\n",
      "Val Loss: 0.903990, Val Acc: 83.97%, Val-Class-Acc: {0: '88.04%', 1: '79.89%'}, LR: 0.000400\n",
      "Epoch 128/200, Train Loss: 0.092571, Train-Class-Acc: {0: '96.59%', 1: '96.59%'}\n",
      "Val Loss: 0.682471, Val Acc: 85.05%, Val-Class-Acc: {0: '90.76%', 1: '79.35%'}, LR: 0.000400\n",
      "Epoch 129/200, Train Loss: 0.065926, Train-Class-Acc: {0: '98.50%', 1: '96.59%'}\n",
      "Val Loss: 0.834005, Val Acc: 84.24%, Val-Class-Acc: {0: '92.39%', 1: '76.09%'}, LR: 0.000400\n",
      "Epoch 130/200, Train Loss: 0.029192, Train-Class-Acc: {0: '99.32%', 1: '98.77%'}\n",
      "Val Loss: 0.760814, Val Acc: 83.70%, Val-Class-Acc: {0: '81.52%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 131/200, Train Loss: 0.036041, Train-Class-Acc: {0: '99.32%', 1: '97.68%'}\n",
      "Val Loss: 1.001710, Val Acc: 85.87%, Val-Class-Acc: {0: '90.22%', 1: '81.52%'}, LR: 0.000400\n",
      "Epoch 132/200, Train Loss: 0.029698, Train-Class-Acc: {0: '99.46%', 1: '98.23%'}\n",
      "Val Loss: 1.116529, Val Acc: 84.24%, Val-Class-Acc: {0: '84.78%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 133/200, Train Loss: 0.041039, Train-Class-Acc: {0: '98.91%', 1: '97.14%'}\n",
      "Val Loss: 1.130169, Val Acc: 86.14%, Val-Class-Acc: {0: '90.22%', 1: '82.07%'}, LR: 0.000400\n",
      "Epoch 134/200, Train Loss: 0.028671, Train-Class-Acc: {0: '99.32%', 1: '98.09%'}\n",
      "Val Loss: 0.916456, Val Acc: 85.05%, Val-Class-Acc: {0: '83.15%', 1: '86.96%'}, LR: 0.000400\n",
      "Epoch 135/200, Train Loss: 0.032296, Train-Class-Acc: {0: '99.18%', 1: '98.91%'}\n",
      "Val Loss: 0.991485, Val Acc: 84.51%, Val-Class-Acc: {0: '87.50%', 1: '81.52%'}, LR: 0.000400\n",
      "Epoch 136/200, Train Loss: 0.026870, Train-Class-Acc: {0: '99.46%', 1: '98.23%'}\n",
      "Val Loss: 1.070800, Val Acc: 84.24%, Val-Class-Acc: {0: '89.13%', 1: '79.35%'}, LR: 0.000400\n",
      "Epoch 137/200, Train Loss: 0.029310, Train-Class-Acc: {0: '99.46%', 1: '99.05%'}\n",
      "Val Loss: 1.066464, Val Acc: 83.97%, Val-Class-Acc: {0: '86.96%', 1: '80.98%'}, LR: 0.000400\n",
      "Epoch 138/200, Train Loss: 0.027341, Train-Class-Acc: {0: '99.73%', 1: '97.68%'}\n",
      "Val Loss: 1.025984, Val Acc: 84.24%, Val-Class-Acc: {0: '84.24%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 139/200, Train Loss: 0.033595, Train-Class-Acc: {0: '99.05%', 1: '98.23%'}\n",
      "Val Loss: 1.007631, Val Acc: 87.50%, Val-Class-Acc: {0: '92.39%', 1: '82.61%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_24.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_139.pth\n",
      "Epoch 140/200, Train Loss: 0.034350, Train-Class-Acc: {0: '99.59%', 1: '97.82%'}\n",
      "Val Loss: 1.050025, Val Acc: 86.96%, Val-Class-Acc: {0: '90.22%', 1: '83.70%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_54.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_140.pth\n",
      "Epoch 141/200, Train Loss: 0.026366, Train-Class-Acc: {0: '99.32%', 1: '98.09%'}\n",
      "Val Loss: 0.824101, Val Acc: 84.51%, Val-Class-Acc: {0: '84.24%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 142/200, Train Loss: 0.040330, Train-Class-Acc: {0: '98.64%', 1: '98.23%'}\n",
      "Val Loss: 1.109337, Val Acc: 85.33%, Val-Class-Acc: {0: '92.39%', 1: '78.26%'}, LR: 0.000400\n",
      "Epoch 143/200, Train Loss: 0.035573, Train-Class-Acc: {0: '98.91%', 1: '97.28%'}\n",
      "Val Loss: 0.935266, Val Acc: 84.78%, Val-Class-Acc: {0: '83.70%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 144/200, Train Loss: 0.024155, Train-Class-Acc: {0: '99.86%', 1: '97.96%'}\n",
      "Val Loss: 1.091640, Val Acc: 84.78%, Val-Class-Acc: {0: '90.76%', 1: '78.80%'}, LR: 0.000400\n",
      "Epoch 145/200, Train Loss: 0.029743, Train-Class-Acc: {0: '99.46%', 1: '98.37%'}\n",
      "Val Loss: 1.161049, Val Acc: 84.24%, Val-Class-Acc: {0: '85.87%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 146/200, Train Loss: 0.020636, Train-Class-Acc: {0: '99.73%', 1: '98.50%'}\n",
      "Val Loss: 1.149672, Val Acc: 84.51%, Val-Class-Acc: {0: '82.07%', 1: '86.96%'}, LR: 0.000400\n",
      "Epoch 147/200, Train Loss: 0.035711, Train-Class-Acc: {0: '98.91%', 1: '98.23%'}\n",
      "Val Loss: 1.176830, Val Acc: 83.97%, Val-Class-Acc: {0: '90.22%', 1: '77.72%'}, LR: 0.000400\n",
      "Epoch 148/200, Train Loss: 0.035445, Train-Class-Acc: {0: '99.32%', 1: '97.82%'}\n",
      "Val Loss: 1.203257, Val Acc: 81.79%, Val-Class-Acc: {0: '76.09%', 1: '87.50%'}, LR: 0.000400\n",
      "\n",
      "🛑 Stop signal detected. Exiting training loop.\n",
      "\n",
      "🏆 Best model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_best.pth (Val Accuracy: 87.50%)\n",
      "\n",
      "📌 Final model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_final.pth\n",
      "\n",
      "🎯 Top 5 Best Models:\n",
      "Epoch 139, Train Loss: 0.033595, Train-Acc: {0: '99.05%', 1: '98.23%'},\n",
      "Val Loss: 1.007631, Val Acc: 87.50%, Val-Class-Acc: {0: '92.39%', 1: '82.61%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_139.pth\n",
      "Epoch 140, Train Loss: 0.034350, Train-Acc: {0: '99.59%', 1: '97.82%'},\n",
      "Val Loss: 1.050025, Val Acc: 86.96%, Val-Class-Acc: {0: '90.22%', 1: '83.70%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_140.pth\n",
      "Epoch 115, Train Loss: 0.007596, Train-Acc: {0: '100.00%', 1: '98.91%'},\n",
      "Val Loss: 1.180278, Val Acc: 86.68%, Val-Class-Acc: {0: '89.13%', 1: '84.24%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_115.pth\n",
      "Epoch 100, Train Loss: 0.035012, Train-Acc: {0: '99.46%', 1: '98.23%'},\n",
      "Val Loss: 1.050531, Val Acc: 86.41%, Val-Class-Acc: {0: '90.76%', 1: '82.07%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_100.pth\n",
      "Epoch 107, Train Loss: 0.022403, Train-Acc: {0: '99.18%', 1: '98.23%'},\n",
      "Val Loss: 0.970875, Val Acc: 86.14%, Val-Class-Acc: {0: '84.78%', 1: '87.50%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude/ResNet18_1D_v2_epoch_107.pth\n",
      "\n",
      "🧠 Model Summary:\n",
      "Total Parameters: 3,986,818\n",
      "Model Size (float32): 15.21 MB\n",
      "Total Training Time: 556.87 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))  # Shape: (B, 5000, 12)\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# ==== Model Hyperparameters ====\n",
    "input_channels = X_train.shape[2]                  # 12 leads\n",
    "output_size = len(np.unique(y_train))              # Number of classes (e.g., 2 for Period 1)\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "dropout = 0.0                                       # Not needed for ResNet18_1D\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "print(\"✅ input shape:\", X_train.shape)\n",
    "print(\"✅ unique y_train:\", np.unique(y_train))\n",
    "print(\"✅ unique y_test :\", np.unique(y_test))\n",
    "assert np.max(y_train) < output_size\n",
    "assert np.max(y_test) < output_size\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Model ====\n",
    "model = ResNet18_1D_v2(input_channels=input_channels, output_size=output_size).to(device)\n",
    "\n",
    "# ==== Optimizer and Training ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3*10,             # 最大學習率為初始學習率的10倍\n",
    "    steps_per_epoch=ceil(X_train.shape[0] / batch_size),\n",
    "    epochs=num_epochs,\n",
    "    pct_start=0.3,                       # 在 30% 的訓練過程中達到最大學習率\n",
    "    div_factor=25,                       # 初始學習率為最大值的 1/25\n",
    "    final_div_factor=1000                # 最終學習率為初始學習率的 1/1000\n",
    ")\n",
    "\n",
    "# ==== Train ====\n",
    "result_summary = train_model_general_classifier(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name='ResNet18_1D_v2',\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del model, X_train, y_train, X_test, y_test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad0c66",
   "metadata": {},
   "source": [
    "#### Data Arg + Claude + use_class_weights (normal data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "57dec6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Automatically selected GPU:\n",
      "    - CUDA Device ID : 0\n",
      "    - Memory Used    : 4544 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "✅ input shape: (5493, 5000, 12)\n",
      "✅ unique y_train: [0 1]\n",
      "✅ unique y_test : [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 'train_model_general_classifier' started.\n",
      "✅ Removed existing folder: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights\n",
      "\n",
      "✅ Data Overview:\n",
      "X_train: (5493, 5000, 12), y_train: (5493,)\n",
      "X_val: (1374, 5000, 12), y_val: (1374,)\n",
      "✅ 使用類別權重: [3.7418256 0.577117 ]\n",
      "Epoch 1/200, Train Loss: 0.455932, Train-Class-Acc: {0: '83.38%', 1: '74.66%'}\n",
      "Val Loss: 0.423869, Val Acc: 81.15%, Val-Class-Acc: {0: '78.80%', 1: '81.51%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.405981, Train-Class-Acc: {0: '85.69%', 1: '78.99%'}\n",
      "Val Loss: 0.364661, Val Acc: 83.19%, Val-Class-Acc: {0: '84.78%', 1: '82.94%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.359642, Train-Class-Acc: {0: '88.42%', 1: '80.79%'}\n",
      "Val Loss: 0.435123, Val Acc: 76.42%, Val-Class-Acc: {0: '91.30%', 1: '74.12%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.339697, Train-Class-Acc: {0: '88.15%', 1: '82.54%'}\n",
      "Val Loss: 0.375694, Val Acc: 84.64%, Val-Class-Acc: {0: '84.78%', 1: '84.62%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.304485, Train-Class-Acc: {0: '90.33%', 1: '84.05%'}\n",
      "Val Loss: 0.596593, Val Acc: 91.34%, Val-Class-Acc: {0: '53.26%', 1: '97.23%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.291203, Train-Class-Acc: {0: '91.14%', 1: '85.00%'}\n",
      "Val Loss: 0.299789, Val Acc: 87.85%, Val-Class-Acc: {0: '88.59%', 1: '87.73%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_3.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_6.pth\n",
      "Epoch 7/200, Train Loss: 0.283222, Train-Class-Acc: {0: '91.69%', 1: '85.46%'}\n",
      "Val Loss: 0.309561, Val Acc: 86.54%, Val-Class-Acc: {0: '86.41%', 1: '86.55%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_1.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.266177, Train-Class-Acc: {0: '93.19%', 1: '85.42%'}\n",
      "Val Loss: 0.384325, Val Acc: 89.01%, Val-Class-Acc: {0: '76.63%', 1: '90.92%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_2.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_8.pth\n",
      "Epoch 9/200, Train Loss: 0.242408, Train-Class-Acc: {0: '92.10%', 1: '88.06%'}\n",
      "Val Loss: 0.349649, Val Acc: 87.92%, Val-Class-Acc: {0: '88.04%', 1: '87.90%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_4.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.254721, Train-Class-Acc: {0: '92.64%', 1: '86.43%'}\n",
      "Val Loss: 0.304408, Val Acc: 84.72%, Val-Class-Acc: {0: '92.39%', 1: '83.53%'}, LR: 0.000400\n",
      "Epoch 11/200, Train Loss: 0.234896, Train-Class-Acc: {0: '94.82%', 1: '88.17%'}\n",
      "Val Loss: 0.361373, Val Acc: 80.42%, Val-Class-Acc: {0: '95.11%', 1: '78.15%'}, LR: 0.000400\n",
      "Epoch 12/200, Train Loss: 0.274634, Train-Class-Acc: {0: '91.96%', 1: '86.01%'}\n",
      "Val Loss: 0.335883, Val Acc: 83.77%, Val-Class-Acc: {0: '89.13%', 1: '82.94%'}, LR: 0.000400\n",
      "Epoch 13/200, Train Loss: 0.231569, Train-Class-Acc: {0: '93.60%', 1: '88.21%'}\n",
      "Val Loss: 0.335244, Val Acc: 82.90%, Val-Class-Acc: {0: '93.48%', 1: '81.26%'}, LR: 0.000400\n",
      "Epoch 14/200, Train Loss: 0.217344, Train-Class-Acc: {0: '94.82%', 1: '89.07%'}\n",
      "Val Loss: 0.325926, Val Acc: 83.33%, Val-Class-Acc: {0: '94.57%', 1: '81.60%'}, LR: 0.000400\n",
      "Epoch 15/200, Train Loss: 0.198662, Train-Class-Acc: {0: '95.50%', 1: '89.60%'}\n",
      "Val Loss: 0.323981, Val Acc: 84.28%, Val-Class-Acc: {0: '93.48%', 1: '82.86%'}, LR: 0.000400\n",
      "Epoch 16/200, Train Loss: 0.213091, Train-Class-Acc: {0: '93.87%', 1: '88.57%'}\n",
      "Val Loss: 0.330456, Val Acc: 85.66%, Val-Class-Acc: {0: '90.76%', 1: '84.87%'}, LR: 0.000400\n",
      "Epoch 17/200, Train Loss: 0.201840, Train-Class-Acc: {0: '95.23%', 1: '89.66%'}\n",
      "Val Loss: 0.357718, Val Acc: 89.67%, Val-Class-Acc: {0: '84.24%', 1: '90.50%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_7.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_17.pth\n",
      "Epoch 18/200, Train Loss: 0.211143, Train-Class-Acc: {0: '94.01%', 1: '88.82%'}\n",
      "Val Loss: 0.382355, Val Acc: 89.08%, Val-Class-Acc: {0: '83.70%', 1: '89.92%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_6.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_18.pth\n",
      "Epoch 19/200, Train Loss: 0.202266, Train-Class-Acc: {0: '96.19%', 1: '88.80%'}\n",
      "Val Loss: 0.638625, Val Acc: 90.61%, Val-Class-Acc: {0: '72.83%', 1: '93.36%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_9.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_19.pth\n",
      "Epoch 20/200, Train Loss: 0.193214, Train-Class-Acc: {0: '95.50%', 1: '89.49%'}\n",
      "Val Loss: 0.704087, Val Acc: 91.34%, Val-Class-Acc: {0: '73.91%', 1: '94.03%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_8.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_20.pth\n",
      "Epoch 21/200, Train Loss: 0.192031, Train-Class-Acc: {0: '96.32%', 1: '89.75%'}\n",
      "Val Loss: 0.390905, Val Acc: 83.41%, Val-Class-Acc: {0: '91.85%', 1: '82.10%'}, LR: 0.000400\n",
      "Epoch 22/200, Train Loss: 0.205719, Train-Class-Acc: {0: '94.41%', 1: '89.39%'}\n",
      "Val Loss: 0.505105, Val Acc: 86.54%, Val-Class-Acc: {0: '83.15%', 1: '87.06%'}, LR: 0.000400\n",
      "Epoch 23/200, Train Loss: 0.203162, Train-Class-Acc: {0: '94.41%', 1: '89.01%'}\n",
      "Val Loss: 0.339492, Val Acc: 86.90%, Val-Class-Acc: {0: '88.04%', 1: '86.72%'}, LR: 0.000400\n",
      "Epoch 24/200, Train Loss: 0.179190, Train-Class-Acc: {0: '96.32%', 1: '90.75%'}\n",
      "Val Loss: 0.419044, Val Acc: 86.75%, Val-Class-Acc: {0: '87.50%', 1: '86.64%'}, LR: 0.000400\n",
      "Epoch 25/200, Train Loss: 0.187801, Train-Class-Acc: {0: '94.55%', 1: '90.06%'}\n",
      "Val Loss: 0.485260, Val Acc: 91.12%, Val-Class-Acc: {0: '71.20%', 1: '94.20%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_18.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_25.pth\n",
      "Epoch 26/200, Train Loss: 0.167908, Train-Class-Acc: {0: '96.87%', 1: '91.49%'}\n",
      "Val Loss: 0.369003, Val Acc: 86.75%, Val-Class-Acc: {0: '91.85%', 1: '85.97%'}, LR: 0.000400\n",
      "Epoch 27/200, Train Loss: 0.164748, Train-Class-Acc: {0: '96.59%', 1: '92.35%'}\n",
      "Val Loss: 0.428616, Val Acc: 87.63%, Val-Class-Acc: {0: '90.22%', 1: '87.23%'}, LR: 0.000400\n",
      "Epoch 28/200, Train Loss: 0.187058, Train-Class-Acc: {0: '96.46%', 1: '90.04%'}\n",
      "Val Loss: 0.503166, Val Acc: 90.83%, Val-Class-Acc: {0: '80.43%', 1: '92.44%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_17.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_28.pth\n",
      "Epoch 29/200, Train Loss: 0.158730, Train-Class-Acc: {0: '96.59%', 1: '92.52%'}\n",
      "Val Loss: 0.423283, Val Acc: 88.21%, Val-Class-Acc: {0: '88.59%', 1: '88.15%'}, LR: 0.000400\n",
      "\n",
      "🛑 Stop signal detected. Exiting training loop.\n",
      "\n",
      "🏆 Best model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_best.pth (Val Accuracy: 91.34%)\n",
      "\n",
      "📌 Final model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_final.pth\n",
      "\n",
      "🎯 Top 5 Best Models:\n",
      "Epoch 20, Train Loss: 0.193214, Train-Acc: {0: '95.50%', 1: '89.49%'},\n",
      "Val Loss: 0.704087, Val Acc: 91.34%, Val-Class-Acc: {0: '73.91%', 1: '94.03%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_20.pth\n",
      "Epoch 5, Train Loss: 0.304485, Train-Acc: {0: '90.33%', 1: '84.05%'},\n",
      "Val Loss: 0.596593, Val Acc: 91.34%, Val-Class-Acc: {0: '53.26%', 1: '97.23%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_5.pth\n",
      "Epoch 25, Train Loss: 0.187801, Train-Acc: {0: '94.55%', 1: '90.06%'},\n",
      "Val Loss: 0.485260, Val Acc: 91.12%, Val-Class-Acc: {0: '71.20%', 1: '94.20%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_25.pth\n",
      "Epoch 28, Train Loss: 0.187058, Train-Acc: {0: '96.46%', 1: '90.04%'},\n",
      "Val Loss: 0.503166, Val Acc: 90.83%, Val-Class-Acc: {0: '80.43%', 1: '92.44%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_28.pth\n",
      "Epoch 19, Train Loss: 0.202266, Train-Acc: {0: '96.19%', 1: '88.80%'},\n",
      "Val Loss: 0.638625, Val Acc: 90.61%, Val-Class-Acc: {0: '72.83%', 1: '93.36%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights/ResNet18_1D_v2_epoch_19.pth\n",
      "\n",
      "🧠 Model Summary:\n",
      "Total Parameters: 3,986,818\n",
      "Model Size (float32): 15.21 MB\n",
      "Total Training Time: 219.96 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "save_dir = os.path.join(BASE_DIR, \"processed_normal\")\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))  # Shape: (B, 5000, 12)\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# ==== Model Hyperparameters ====\n",
    "input_channels = X_train.shape[2]                  # 12 leads\n",
    "output_size = len(np.unique(y_train))              # Number of classes (e.g., 2 for Period 1)\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "dropout = 0.0                                       # Not needed for ResNet18_1D\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "print(\"✅ input shape:\", X_train.shape)\n",
    "print(\"✅ unique y_train:\", np.unique(y_train))\n",
    "print(\"✅ unique y_test :\", np.unique(y_test))\n",
    "assert np.max(y_train) < output_size\n",
    "assert np.max(y_test) < output_size\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/ResNet18_v2_arg_claude_useclass_weights\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Model ====\n",
    "model = ResNet18_1D_v2(input_channels=input_channels, output_size=output_size).to(device)\n",
    "\n",
    "# ==== Optimizer and Training ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3*10,             # 最大學習率為初始學習率的10倍\n",
    "    steps_per_epoch=ceil(X_train.shape[0] / batch_size),\n",
    "    epochs=num_epochs,\n",
    "    pct_start=0.3,                       # 在 30% 的訓練過程中達到最大學習率\n",
    "    div_factor=25,                       # 初始學習率為最大值的 1/25\n",
    "    final_div_factor=1000                # 最終學習率為初始學習率的 1/1000\n",
    ")\n",
    "\n",
    "# ==== Train ====\n",
    "result_summary = train_model_general_classifier_use_class_weights(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name='ResNet18_1D_v2',\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device,\n",
    "    use_class_weights=True\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del model, X_train, y_train, X_test, y_test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeb049b",
   "metadata": {},
   "source": [
    "### ResNet 18 - 1D improve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dad40f",
   "metadata": {},
   "source": [
    "#### My Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "265d1dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Automatically selected GPU:\n",
      "    - CUDA Device ID : 1\n",
      "    - Memory Used    : 665 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "✅ input shape: (1468, 5000, 12)\n",
      "✅ unique y_train: [0 1]\n",
      "✅ unique y_test : [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 'train_model_general_classifier' started.\n",
      "✅ Removed existing folder: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved\n",
      "\n",
      "✅ Data Overview:\n",
      "X_train: torch.Size([1468, 5000, 12]), y_train: torch.Size([1468])\n",
      "X_val: torch.Size([368, 5000, 12]), y_val: torch.Size([368])\n",
      "Epoch 1/200, Train Loss: 0.462742, Train-Class-Acc: {0: '83.51%', 1: '68.12%'}\n",
      "Val Loss: 1.414899, Val Acc: 67.39%, Val-Class-Acc: {0: '98.37%', 1: '36.41%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/anaconda3/envs/CIL_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 0.363058, Train-Class-Acc: {0: '86.10%', 1: '81.06%'}\n",
      "Val Loss: 0.988955, Val Acc: 75.00%, Val-Class-Acc: {0: '53.80%', 1: '96.20%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.325394, Train-Class-Acc: {0: '85.69%', 1: '85.42%'}\n",
      "Val Loss: 0.553363, Val Acc: 79.35%, Val-Class-Acc: {0: '96.74%', 1: '61.96%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.271976, Train-Class-Acc: {0: '88.69%', 1: '87.74%'}\n",
      "Val Loss: 0.424731, Val Acc: 83.42%, Val-Class-Acc: {0: '96.74%', 1: '70.11%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.249831, Train-Class-Acc: {0: '92.78%', 1: '86.51%'}\n",
      "Val Loss: 0.382168, Val Acc: 85.60%, Val-Class-Acc: {0: '88.04%', 1: '83.15%'}, LR: 0.000400\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.234749, Train-Class-Acc: {0: '92.64%', 1: '88.15%'}\n",
      "Val Loss: 0.458859, Val Acc: 80.98%, Val-Class-Acc: {0: '68.48%', 1: '93.48%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_1.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_6.pth\n",
      "Epoch 7/200, Train Loss: 0.218819, Train-Class-Acc: {0: '91.69%', 1: '90.05%'}\n",
      "Val Loss: 0.469742, Val Acc: 85.60%, Val-Class-Acc: {0: '92.93%', 1: '78.26%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_2.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.232292, Train-Class-Acc: {0: '89.92%', 1: '89.10%'}\n",
      "Val Loss: 0.430407, Val Acc: 84.51%, Val-Class-Acc: {0: '91.30%', 1: '77.72%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_3.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_8.pth\n",
      "Epoch 9/200, Train Loss: 0.182922, Train-Class-Acc: {0: '92.10%', 1: '91.69%'}\n",
      "Val Loss: 0.449421, Val Acc: 85.33%, Val-Class-Acc: {0: '81.52%', 1: '89.13%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_6.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.249076, Train-Class-Acc: {0: '89.78%', 1: '87.60%'}\n",
      "Val Loss: 1.108872, Val Acc: 72.83%, Val-Class-Acc: {0: '48.37%', 1: '97.28%'}, LR: 0.000400\n",
      "Epoch 11/200, Train Loss: 0.228843, Train-Class-Acc: {0: '90.87%', 1: '89.24%'}\n",
      "Val Loss: 0.411575, Val Acc: 85.60%, Val-Class-Acc: {0: '92.93%', 1: '78.26%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_4.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_11.pth\n",
      "Epoch 12/200, Train Loss: 0.203132, Train-Class-Acc: {0: '92.51%', 1: '90.74%'}\n",
      "Val Loss: 0.405042, Val Acc: 87.23%, Val-Class-Acc: {0: '95.11%', 1: '79.35%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_8.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_12.pth\n",
      "Epoch 13/200, Train Loss: 0.176339, Train-Class-Acc: {0: '94.14%', 1: '90.05%'}\n",
      "Val Loss: 0.433865, Val Acc: 86.68%, Val-Class-Acc: {0: '86.96%', 1: '86.41%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_9.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_13.pth\n",
      "Epoch 14/200, Train Loss: 0.146829, Train-Class-Acc: {0: '94.28%', 1: '93.05%'}\n",
      "Val Loss: 0.694576, Val Acc: 83.70%, Val-Class-Acc: {0: '94.02%', 1: '73.37%'}, LR: 0.000400\n",
      "Epoch 15/200, Train Loss: 0.154531, Train-Class-Acc: {0: '95.37%', 1: '92.64%'}\n",
      "Val Loss: 0.394124, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_5.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_15.pth\n",
      "Epoch 16/200, Train Loss: 0.141147, Train-Class-Acc: {0: '93.19%', 1: '94.69%'}\n",
      "Val Loss: 0.438691, Val Acc: 87.23%, Val-Class-Acc: {0: '92.93%', 1: '81.52%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_7.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_16.pth\n",
      "Epoch 17/200, Train Loss: 0.102373, Train-Class-Acc: {0: '97.28%', 1: '94.96%'}\n",
      "Val Loss: 0.569585, Val Acc: 84.78%, Val-Class-Acc: {0: '84.24%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 18/200, Train Loss: 0.119567, Train-Class-Acc: {0: '94.69%', 1: '95.50%'}\n",
      "Val Loss: 0.937779, Val Acc: 83.15%, Val-Class-Acc: {0: '96.74%', 1: '69.57%'}, LR: 0.000400\n",
      "Epoch 19/200, Train Loss: 0.159634, Train-Class-Acc: {0: '94.55%', 1: '91.69%'}\n",
      "Val Loss: 0.688739, Val Acc: 82.61%, Val-Class-Acc: {0: '74.46%', 1: '90.76%'}, LR: 0.000400\n",
      "Epoch 20/200, Train Loss: 0.133871, Train-Class-Acc: {0: '95.10%', 1: '94.14%'}\n",
      "Val Loss: 0.456173, Val Acc: 87.23%, Val-Class-Acc: {0: '93.48%', 1: '80.98%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_11.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_20.pth\n",
      "Epoch 21/200, Train Loss: 0.091222, Train-Class-Acc: {0: '96.19%', 1: '95.64%'}\n",
      "Val Loss: 0.559947, Val Acc: 85.60%, Val-Class-Acc: {0: '94.02%', 1: '77.17%'}, LR: 0.000400\n",
      "Epoch 22/200, Train Loss: 0.100624, Train-Class-Acc: {0: '95.64%', 1: '95.78%'}\n",
      "Val Loss: 0.714539, Val Acc: 85.05%, Val-Class-Acc: {0: '84.78%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 23/200, Train Loss: 0.114312, Train-Class-Acc: {0: '96.19%', 1: '94.01%'}\n",
      "Val Loss: 0.488864, Val Acc: 86.14%, Val-Class-Acc: {0: '84.78%', 1: '87.50%'}, LR: 0.000400\n",
      "Epoch 24/200, Train Loss: 0.113538, Train-Class-Acc: {0: '95.64%', 1: '94.14%'}\n",
      "Val Loss: 0.408195, Val Acc: 87.50%, Val-Class-Acc: {0: '86.96%', 1: '88.04%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_15.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_24.pth\n",
      "Epoch 25/200, Train Loss: 0.081664, Train-Class-Acc: {0: '96.87%', 1: '97.28%'}\n",
      "Val Loss: 0.542639, Val Acc: 85.87%, Val-Class-Acc: {0: '83.70%', 1: '88.04%'}, LR: 0.000400\n",
      "Epoch 26/200, Train Loss: 0.072374, Train-Class-Acc: {0: '97.28%', 1: '96.46%'}\n",
      "Val Loss: 0.574781, Val Acc: 83.97%, Val-Class-Acc: {0: '75.54%', 1: '92.39%'}, LR: 0.000400\n",
      "Epoch 27/200, Train Loss: 0.084401, Train-Class-Acc: {0: '96.87%', 1: '96.05%'}\n",
      "Val Loss: 0.630425, Val Acc: 86.68%, Val-Class-Acc: {0: '91.30%', 1: '82.07%'}, LR: 0.000400\n",
      "Epoch 28/200, Train Loss: 0.080444, Train-Class-Acc: {0: '97.14%', 1: '96.19%'}\n",
      "Val Loss: 0.510321, Val Acc: 84.24%, Val-Class-Acc: {0: '79.89%', 1: '88.59%'}, LR: 0.000400\n",
      "Epoch 29/200, Train Loss: 0.075135, Train-Class-Acc: {0: '96.46%', 1: '97.68%'}\n",
      "Val Loss: 0.741100, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 30/200, Train Loss: 0.079960, Train-Class-Acc: {0: '97.82%', 1: '96.05%'}\n",
      "Val Loss: 0.656659, Val Acc: 85.33%, Val-Class-Acc: {0: '83.70%', 1: '86.96%'}, LR: 0.000400\n",
      "Epoch 31/200, Train Loss: 0.062147, Train-Class-Acc: {0: '97.41%', 1: '97.55%'}\n",
      "Val Loss: 0.679259, Val Acc: 83.70%, Val-Class-Acc: {0: '89.67%', 1: '77.72%'}, LR: 0.000400\n",
      "Epoch 32/200, Train Loss: 0.058695, Train-Class-Acc: {0: '97.55%', 1: '97.82%'}\n",
      "Val Loss: 0.763419, Val Acc: 84.78%, Val-Class-Acc: {0: '77.17%', 1: '92.39%'}, LR: 0.000400\n",
      "Epoch 33/200, Train Loss: 0.047646, Train-Class-Acc: {0: '98.64%', 1: '97.96%'}\n",
      "Val Loss: 0.850777, Val Acc: 81.52%, Val-Class-Acc: {0: '72.28%', 1: '90.76%'}, LR: 0.000400\n",
      "Epoch 34/200, Train Loss: 0.037294, Train-Class-Acc: {0: '98.77%', 1: '98.64%'}\n",
      "Val Loss: 0.696572, Val Acc: 85.60%, Val-Class-Acc: {0: '90.76%', 1: '80.43%'}, LR: 0.000400\n",
      "Epoch 35/200, Train Loss: 0.054397, Train-Class-Acc: {0: '97.82%', 1: '98.23%'}\n",
      "Val Loss: 1.030174, Val Acc: 84.78%, Val-Class-Acc: {0: '79.35%', 1: '90.22%'}, LR: 0.000400\n",
      "Epoch 36/200, Train Loss: 0.083189, Train-Class-Acc: {0: '96.19%', 1: '97.55%'}\n",
      "Val Loss: 0.745844, Val Acc: 83.42%, Val-Class-Acc: {0: '82.61%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 37/200, Train Loss: 0.099295, Train-Class-Acc: {0: '96.87%', 1: '95.37%'}\n",
      "Val Loss: 0.618018, Val Acc: 84.78%, Val-Class-Acc: {0: '80.98%', 1: '88.59%'}, LR: 0.000400\n",
      "Epoch 38/200, Train Loss: 0.061398, Train-Class-Acc: {0: '97.96%', 1: '97.96%'}\n",
      "Val Loss: 0.605643, Val Acc: 86.14%, Val-Class-Acc: {0: '90.76%', 1: '81.52%'}, LR: 0.000400\n",
      "Epoch 39/200, Train Loss: 0.037793, Train-Class-Acc: {0: '99.05%', 1: '98.37%'}\n",
      "Val Loss: 0.710482, Val Acc: 86.96%, Val-Class-Acc: {0: '85.33%', 1: '88.59%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_13.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_39.pth\n",
      "Epoch 40/200, Train Loss: 0.034401, Train-Class-Acc: {0: '99.73%', 1: '98.37%'}\n",
      "Val Loss: 0.885681, Val Acc: 84.51%, Val-Class-Acc: {0: '84.24%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 41/200, Train Loss: 0.061484, Train-Class-Acc: {0: '98.37%', 1: '97.41%'}\n",
      "Val Loss: 0.902351, Val Acc: 84.51%, Val-Class-Acc: {0: '86.96%', 1: '82.07%'}, LR: 0.000400\n",
      "Epoch 42/200, Train Loss: 0.036205, Train-Class-Acc: {0: '98.50%', 1: '98.91%'}\n",
      "Val Loss: 0.732334, Val Acc: 84.78%, Val-Class-Acc: {0: '79.89%', 1: '89.67%'}, LR: 0.000400\n",
      "Epoch 43/200, Train Loss: 0.056610, Train-Class-Acc: {0: '98.23%', 1: '97.55%'}\n",
      "Val Loss: 0.713156, Val Acc: 86.96%, Val-Class-Acc: {0: '90.22%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 44/200, Train Loss: 0.040131, Train-Class-Acc: {0: '98.64%', 1: '99.05%'}\n",
      "Val Loss: 0.910006, Val Acc: 84.24%, Val-Class-Acc: {0: '94.02%', 1: '74.46%'}, LR: 0.000400\n",
      "Epoch 45/200, Train Loss: 0.032886, Train-Class-Acc: {0: '99.05%', 1: '98.77%'}\n",
      "Val Loss: 0.948292, Val Acc: 83.97%, Val-Class-Acc: {0: '76.63%', 1: '91.30%'}, LR: 0.000400\n",
      "Epoch 46/200, Train Loss: 0.046784, Train-Class-Acc: {0: '97.96%', 1: '98.09%'}\n",
      "Val Loss: 0.842932, Val Acc: 83.70%, Val-Class-Acc: {0: '77.17%', 1: '90.22%'}, LR: 0.000400\n",
      "Epoch 47/200, Train Loss: 0.037699, Train-Class-Acc: {0: '98.37%', 1: '98.77%'}\n",
      "Val Loss: 0.994983, Val Acc: 84.78%, Val-Class-Acc: {0: '93.48%', 1: '76.09%'}, LR: 0.000400\n",
      "Epoch 48/200, Train Loss: 0.034053, Train-Class-Acc: {0: '99.05%', 1: '98.77%'}\n",
      "Val Loss: 0.699054, Val Acc: 85.33%, Val-Class-Acc: {0: '86.41%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 49/200, Train Loss: 0.017949, Train-Class-Acc: {0: '99.59%', 1: '99.18%'}\n",
      "Val Loss: 1.002001, Val Acc: 82.88%, Val-Class-Acc: {0: '78.80%', 1: '86.96%'}, LR: 0.000400\n",
      "Epoch 50/200, Train Loss: 0.016175, Train-Class-Acc: {0: '99.59%', 1: '99.46%'}\n",
      "Val Loss: 1.109018, Val Acc: 83.70%, Val-Class-Acc: {0: '76.63%', 1: '90.76%'}, LR: 0.000400\n",
      "Epoch 51/200, Train Loss: 0.018663, Train-Class-Acc: {0: '99.18%', 1: '99.05%'}\n",
      "Val Loss: 1.011891, Val Acc: 86.68%, Val-Class-Acc: {0: '89.13%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 52/200, Train Loss: 0.021261, Train-Class-Acc: {0: '99.32%', 1: '98.77%'}\n",
      "Val Loss: 1.015432, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 53/200, Train Loss: 0.035632, Train-Class-Acc: {0: '98.64%', 1: '98.37%'}\n",
      "Val Loss: 1.159210, Val Acc: 82.07%, Val-Class-Acc: {0: '76.09%', 1: '88.04%'}, LR: 0.000400\n",
      "Epoch 54/200, Train Loss: 0.037430, Train-Class-Acc: {0: '98.37%', 1: '99.05%'}\n",
      "Val Loss: 0.969346, Val Acc: 86.14%, Val-Class-Acc: {0: '91.85%', 1: '80.43%'}, LR: 0.000400\n",
      "Epoch 55/200, Train Loss: 0.043076, Train-Class-Acc: {0: '98.50%', 1: '97.96%'}\n",
      "Val Loss: 1.029350, Val Acc: 83.70%, Val-Class-Acc: {0: '90.76%', 1: '76.63%'}, LR: 0.000400\n",
      "Epoch 56/200, Train Loss: 0.076139, Train-Class-Acc: {0: '97.00%', 1: '95.91%'}\n",
      "Val Loss: 0.662563, Val Acc: 84.78%, Val-Class-Acc: {0: '80.98%', 1: '88.59%'}, LR: 0.000400\n",
      "Epoch 57/200, Train Loss: 0.074149, Train-Class-Acc: {0: '97.68%', 1: '97.68%'}\n",
      "Val Loss: 0.521028, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 58/200, Train Loss: 0.041694, Train-Class-Acc: {0: '98.50%', 1: '99.05%'}\n",
      "Val Loss: 0.641988, Val Acc: 85.33%, Val-Class-Acc: {0: '82.61%', 1: '88.04%'}, LR: 0.000400\n",
      "Epoch 59/200, Train Loss: 0.012648, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 0.721791, Val Acc: 85.33%, Val-Class-Acc: {0: '85.87%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 60/200, Train Loss: 0.011258, Train-Class-Acc: {0: '99.73%', 1: '99.73%'}\n",
      "Val Loss: 0.896815, Val Acc: 86.96%, Val-Class-Acc: {0: '89.13%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 61/200, Train Loss: 0.012247, Train-Class-Acc: {0: '99.59%', 1: '99.46%'}\n",
      "Val Loss: 0.886436, Val Acc: 85.87%, Val-Class-Acc: {0: '84.24%', 1: '87.50%'}, LR: 0.000400\n",
      "Epoch 62/200, Train Loss: 0.003370, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.899567, Val Acc: 86.96%, Val-Class-Acc: {0: '88.59%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 63/200, Train Loss: 0.013974, Train-Class-Acc: {0: '99.73%', 1: '99.46%'}\n",
      "Val Loss: 0.986229, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 64/200, Train Loss: 0.021825, Train-Class-Acc: {0: '99.32%', 1: '99.46%'}\n",
      "Val Loss: 1.079000, Val Acc: 85.60%, Val-Class-Acc: {0: '89.13%', 1: '82.07%'}, LR: 0.000400\n",
      "Epoch 65/200, Train Loss: 0.027789, Train-Class-Acc: {0: '98.77%', 1: '99.18%'}\n",
      "Val Loss: 0.851385, Val Acc: 85.05%, Val-Class-Acc: {0: '85.33%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 66/200, Train Loss: 0.015306, Train-Class-Acc: {0: '99.59%', 1: '99.46%'}\n",
      "Val Loss: 0.785198, Val Acc: 87.23%, Val-Class-Acc: {0: '89.13%', 1: '85.33%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_39.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_66.pth\n",
      "Epoch 67/200, Train Loss: 0.027973, Train-Class-Acc: {0: '98.50%', 1: '99.46%'}\n",
      "Val Loss: 0.865118, Val Acc: 86.41%, Val-Class-Acc: {0: '87.50%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 68/200, Train Loss: 0.032499, Train-Class-Acc: {0: '99.59%', 1: '97.96%'}\n",
      "Val Loss: 0.903790, Val Acc: 86.41%, Val-Class-Acc: {0: '86.41%', 1: '86.41%'}, LR: 0.000400\n",
      "Epoch 69/200, Train Loss: 0.015003, Train-Class-Acc: {0: '99.32%', 1: '99.86%'}\n",
      "Val Loss: 0.956088, Val Acc: 84.78%, Val-Class-Acc: {0: '92.39%', 1: '77.17%'}, LR: 0.000400\n",
      "Epoch 70/200, Train Loss: 0.030570, Train-Class-Acc: {0: '98.91%', 1: '98.64%'}\n",
      "Val Loss: 0.847262, Val Acc: 85.87%, Val-Class-Acc: {0: '84.78%', 1: '86.96%'}, LR: 0.000400\n",
      "Epoch 71/200, Train Loss: 0.049909, Train-Class-Acc: {0: '98.23%', 1: '98.64%'}\n",
      "Val Loss: 0.675143, Val Acc: 86.68%, Val-Class-Acc: {0: '85.33%', 1: '88.04%'}, LR: 0.000400\n",
      "Epoch 72/200, Train Loss: 0.025285, Train-Class-Acc: {0: '99.32%', 1: '99.05%'}\n",
      "Val Loss: 0.849300, Val Acc: 86.14%, Val-Class-Acc: {0: '82.61%', 1: '89.67%'}, LR: 0.000400\n",
      "Epoch 73/200, Train Loss: 0.016492, Train-Class-Acc: {0: '99.05%', 1: '99.86%'}\n",
      "Val Loss: 0.820949, Val Acc: 85.05%, Val-Class-Acc: {0: '88.04%', 1: '82.07%'}, LR: 0.000400\n",
      "Epoch 74/200, Train Loss: 0.011859, Train-Class-Acc: {0: '100.00%', 1: '99.46%'}\n",
      "Val Loss: 0.926243, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 75/200, Train Loss: 0.014190, Train-Class-Acc: {0: '99.46%', 1: '99.32%'}\n",
      "Val Loss: 1.001947, Val Acc: 86.41%, Val-Class-Acc: {0: '94.57%', 1: '78.26%'}, LR: 0.000400\n",
      "Epoch 76/200, Train Loss: 0.013833, Train-Class-Acc: {0: '99.32%', 1: '99.73%'}\n",
      "Val Loss: 0.916272, Val Acc: 85.60%, Val-Class-Acc: {0: '90.22%', 1: '80.98%'}, LR: 0.000400\n",
      "Epoch 77/200, Train Loss: 0.013090, Train-Class-Acc: {0: '99.73%', 1: '99.18%'}\n",
      "Val Loss: 0.857441, Val Acc: 85.87%, Val-Class-Acc: {0: '85.87%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 78/200, Train Loss: 0.005853, Train-Class-Acc: {0: '100.00%', 1: '99.59%'}\n",
      "Val Loss: 0.933058, Val Acc: 86.96%, Val-Class-Acc: {0: '90.76%', 1: '83.15%'}, LR: 0.000400\n",
      "Epoch 79/200, Train Loss: 0.004143, Train-Class-Acc: {0: '99.86%', 1: '99.86%'}\n",
      "Val Loss: 0.893547, Val Acc: 85.87%, Val-Class-Acc: {0: '82.07%', 1: '89.67%'}, LR: 0.000400\n",
      "Epoch 80/200, Train Loss: 0.002401, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 0.938669, Val Acc: 86.14%, Val-Class-Acc: {0: '83.15%', 1: '89.13%'}, LR: 0.000400\n",
      "Epoch 81/200, Train Loss: 0.004329, Train-Class-Acc: {0: '100.00%', 1: '99.59%'}\n",
      "Val Loss: 1.014792, Val Acc: 86.14%, Val-Class-Acc: {0: '93.48%', 1: '78.80%'}, LR: 0.000400\n",
      "Epoch 82/200, Train Loss: 0.002542, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.068436, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 83/200, Train Loss: 0.001721, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.091306, Val Acc: 86.14%, Val-Class-Acc: {0: '85.87%', 1: '86.41%'}, LR: 0.000400\n",
      "Epoch 84/200, Train Loss: 0.001156, Train-Class-Acc: {0: '100.00%', 1: '99.86%'}\n",
      "Val Loss: 1.171413, Val Acc: 86.68%, Val-Class-Acc: {0: '86.41%', 1: '86.96%'}, LR: 0.000400\n",
      "Epoch 85/200, Train Loss: 0.000648, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.186225, Val Acc: 86.68%, Val-Class-Acc: {0: '84.78%', 1: '88.59%'}, LR: 0.000400\n",
      "Epoch 86/200, Train Loss: 0.001513, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.160551, Val Acc: 87.23%, Val-Class-Acc: {0: '88.59%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 87/200, Train Loss: 0.007472, Train-Class-Acc: {0: '99.73%', 1: '99.73%'}\n",
      "Val Loss: 1.282568, Val Acc: 83.97%, Val-Class-Acc: {0: '82.07%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 88/200, Train Loss: 0.026830, Train-Class-Acc: {0: '98.64%', 1: '99.46%'}\n",
      "Val Loss: 1.755690, Val Acc: 83.15%, Val-Class-Acc: {0: '96.20%', 1: '70.11%'}, LR: 0.000400\n",
      "Epoch 89/200, Train Loss: 0.057837, Train-Class-Acc: {0: '98.37%', 1: '96.87%'}\n",
      "Val Loss: 1.012841, Val Acc: 85.05%, Val-Class-Acc: {0: '92.39%', 1: '77.72%'}, LR: 0.000400\n",
      "Epoch 90/200, Train Loss: 0.060070, Train-Class-Acc: {0: '98.09%', 1: '97.68%'}\n",
      "Val Loss: 0.842179, Val Acc: 85.60%, Val-Class-Acc: {0: '84.24%', 1: '86.96%'}, LR: 0.000400\n",
      "Epoch 91/200, Train Loss: 0.040381, Train-Class-Acc: {0: '98.09%', 1: '98.50%'}\n",
      "Val Loss: 0.635797, Val Acc: 85.87%, Val-Class-Acc: {0: '85.87%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 92/200, Train Loss: 0.029266, Train-Class-Acc: {0: '98.77%', 1: '99.32%'}\n",
      "Val Loss: 0.865854, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 93/200, Train Loss: 0.026644, Train-Class-Acc: {0: '99.59%', 1: '98.37%'}\n",
      "Val Loss: 0.901653, Val Acc: 83.97%, Val-Class-Acc: {0: '83.15%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 94/200, Train Loss: 0.012842, Train-Class-Acc: {0: '99.32%', 1: '99.73%'}\n",
      "Val Loss: 0.866438, Val Acc: 85.33%, Val-Class-Acc: {0: '89.13%', 1: '81.52%'}, LR: 0.000400\n",
      "Epoch 95/200, Train Loss: 0.007232, Train-Class-Acc: {0: '99.86%', 1: '99.73%'}\n",
      "Val Loss: 1.006405, Val Acc: 84.51%, Val-Class-Acc: {0: '83.15%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 96/200, Train Loss: 0.001483, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.033924, Val Acc: 84.78%, Val-Class-Acc: {0: '85.87%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 97/200, Train Loss: 0.001643, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.090187, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000400\n",
      "Epoch 98/200, Train Loss: 0.000519, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.116235, Val Acc: 84.78%, Val-Class-Acc: {0: '86.96%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 99/200, Train Loss: 0.000416, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.134591, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 100/200, Train Loss: 0.000589, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.164938, Val Acc: 85.33%, Val-Class-Acc: {0: '88.04%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 101/200, Train Loss: 0.000461, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.179743, Val Acc: 84.51%, Val-Class-Acc: {0: '84.24%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 102/200, Train Loss: 0.000207, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.176620, Val Acc: 86.14%, Val-Class-Acc: {0: '88.04%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 103/200, Train Loss: 0.000211, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.208622, Val Acc: 85.33%, Val-Class-Acc: {0: '86.41%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 104/200, Train Loss: 0.000106, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.232457, Val Acc: 84.78%, Val-Class-Acc: {0: '85.87%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 105/200, Train Loss: 0.000198, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.237344, Val Acc: 85.60%, Val-Class-Acc: {0: '87.50%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 106/200, Train Loss: 0.000080, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.243276, Val Acc: 84.51%, Val-Class-Acc: {0: '85.33%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 107/200, Train Loss: 0.000134, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.226941, Val Acc: 85.05%, Val-Class-Acc: {0: '85.33%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 108/200, Train Loss: 0.000100, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.246929, Val Acc: 84.51%, Val-Class-Acc: {0: '85.33%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 109/200, Train Loss: 0.000064, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.253782, Val Acc: 85.05%, Val-Class-Acc: {0: '85.87%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 110/200, Train Loss: 0.000231, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.237620, Val Acc: 85.05%, Val-Class-Acc: {0: '86.41%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 111/200, Train Loss: 0.000063, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.262679, Val Acc: 85.05%, Val-Class-Acc: {0: '85.33%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 112/200, Train Loss: 0.000065, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.273618, Val Acc: 85.33%, Val-Class-Acc: {0: '85.87%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 113/200, Train Loss: 0.000053, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.291454, Val Acc: 85.33%, Val-Class-Acc: {0: '85.87%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 114/200, Train Loss: 0.000064, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.285524, Val Acc: 85.05%, Val-Class-Acc: {0: '85.33%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 115/200, Train Loss: 0.000051, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.284288, Val Acc: 85.60%, Val-Class-Acc: {0: '86.41%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 116/200, Train Loss: 0.000052, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.284728, Val Acc: 85.60%, Val-Class-Acc: {0: '86.41%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 117/200, Train Loss: 0.000084, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.293791, Val Acc: 85.60%, Val-Class-Acc: {0: '86.41%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 118/200, Train Loss: 0.000036, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.293711, Val Acc: 85.60%, Val-Class-Acc: {0: '86.41%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 119/200, Train Loss: 0.000027, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.293647, Val Acc: 85.05%, Val-Class-Acc: {0: '86.96%', 1: '83.15%'}, LR: 0.000400\n",
      "Epoch 120/200, Train Loss: 0.011163, Train-Class-Acc: {0: '99.32%', 1: '99.86%'}\n",
      "Val Loss: 1.274013, Val Acc: 86.14%, Val-Class-Acc: {0: '88.04%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 121/200, Train Loss: 0.076541, Train-Class-Acc: {0: '98.50%', 1: '97.68%'}\n",
      "Val Loss: 2.362214, Val Acc: 83.42%, Val-Class-Acc: {0: '72.83%', 1: '94.02%'}, LR: 0.000400\n",
      "Epoch 122/200, Train Loss: 0.133679, Train-Class-Acc: {0: '96.32%', 1: '94.41%'}\n",
      "Val Loss: 0.657170, Val Acc: 81.79%, Val-Class-Acc: {0: '79.89%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 123/200, Train Loss: 0.146991, Train-Class-Acc: {0: '94.01%', 1: '94.69%'}\n",
      "Val Loss: 0.751245, Val Acc: 76.09%, Val-Class-Acc: {0: '54.35%', 1: '97.83%'}, LR: 0.000400\n",
      "Epoch 124/200, Train Loss: 0.069623, Train-Class-Acc: {0: '97.00%', 1: '97.82%'}\n",
      "Val Loss: 0.584996, Val Acc: 88.04%, Val-Class-Acc: {0: '94.57%', 1: '81.52%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_12.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_124.pth\n",
      "Epoch 125/200, Train Loss: 0.065477, Train-Class-Acc: {0: '98.09%', 1: '96.46%'}\n",
      "Val Loss: 0.828882, Val Acc: 85.33%, Val-Class-Acc: {0: '96.20%', 1: '74.46%'}, LR: 0.000400\n",
      "Epoch 126/200, Train Loss: 0.027802, Train-Class-Acc: {0: '99.32%', 1: '98.64%'}\n",
      "Val Loss: 0.725297, Val Acc: 87.23%, Val-Class-Acc: {0: '89.13%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 127/200, Train Loss: 0.015185, Train-Class-Acc: {0: '99.32%', 1: '99.32%'}\n",
      "Val Loss: 0.755387, Val Acc: 84.78%, Val-Class-Acc: {0: '88.04%', 1: '81.52%'}, LR: 0.000400\n",
      "Epoch 128/200, Train Loss: 0.005438, Train-Class-Acc: {0: '99.86%', 1: '99.73%'}\n",
      "Val Loss: 1.102783, Val Acc: 85.05%, Val-Class-Acc: {0: '94.57%', 1: '75.54%'}, LR: 0.000400\n",
      "Epoch 129/200, Train Loss: 0.005150, Train-Class-Acc: {0: '99.59%', 1: '100.00%'}\n",
      "Val Loss: 0.866209, Val Acc: 86.41%, Val-Class-Acc: {0: '85.87%', 1: '86.96%'}, LR: 0.000400\n",
      "Epoch 130/200, Train Loss: 0.016335, Train-Class-Acc: {0: '99.59%', 1: '99.32%'}\n",
      "Val Loss: 0.983088, Val Acc: 86.96%, Val-Class-Acc: {0: '85.33%', 1: '88.59%'}, LR: 0.000400\n",
      "Epoch 131/200, Train Loss: 0.040577, Train-Class-Acc: {0: '98.37%', 1: '99.32%'}\n",
      "Val Loss: 0.918331, Val Acc: 86.68%, Val-Class-Acc: {0: '86.41%', 1: '86.96%'}, LR: 0.000400\n",
      "Epoch 132/200, Train Loss: 0.037321, Train-Class-Acc: {0: '99.46%', 1: '97.68%'}\n",
      "Val Loss: 0.853111, Val Acc: 83.70%, Val-Class-Acc: {0: '80.43%', 1: '86.96%'}, LR: 0.000400\n",
      "Epoch 133/200, Train Loss: 0.042797, Train-Class-Acc: {0: '98.50%', 1: '99.18%'}\n",
      "Val Loss: 0.887422, Val Acc: 84.51%, Val-Class-Acc: {0: '89.67%', 1: '79.35%'}, LR: 0.000400\n",
      "Epoch 134/200, Train Loss: 0.037112, Train-Class-Acc: {0: '98.91%', 1: '98.09%'}\n",
      "Val Loss: 0.682387, Val Acc: 83.42%, Val-Class-Acc: {0: '81.52%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 135/200, Train Loss: 0.018940, Train-Class-Acc: {0: '99.73%', 1: '98.91%'}\n",
      "Val Loss: 0.668483, Val Acc: 85.87%, Val-Class-Acc: {0: '83.15%', 1: '88.59%'}, LR: 0.000400\n",
      "Epoch 136/200, Train Loss: 0.005915, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 0.763395, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 137/200, Train Loss: 0.009225, Train-Class-Acc: {0: '100.00%', 1: '99.59%'}\n",
      "Val Loss: 0.806328, Val Acc: 86.96%, Val-Class-Acc: {0: '90.22%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 138/200, Train Loss: 0.002686, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.837882, Val Acc: 86.14%, Val-Class-Acc: {0: '89.13%', 1: '83.15%'}, LR: 0.000400\n",
      "Epoch 139/200, Train Loss: 0.001195, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.850154, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 140/200, Train Loss: 0.001241, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.969678, Val Acc: 83.97%, Val-Class-Acc: {0: '86.41%', 1: '81.52%'}, LR: 0.000400\n",
      "Epoch 141/200, Train Loss: 0.001022, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.990415, Val Acc: 85.87%, Val-Class-Acc: {0: '86.96%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 142/200, Train Loss: 0.000562, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.973386, Val Acc: 86.68%, Val-Class-Acc: {0: '90.22%', 1: '83.15%'}, LR: 0.000400\n",
      "Epoch 143/200, Train Loss: 0.000391, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.943557, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 144/200, Train Loss: 0.000091, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.961434, Val Acc: 86.68%, Val-Class-Acc: {0: '89.67%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 145/200, Train Loss: 0.000157, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.965485, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 146/200, Train Loss: 0.000092, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.966149, Val Acc: 85.87%, Val-Class-Acc: {0: '87.50%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 147/200, Train Loss: 0.000391, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.991278, Val Acc: 86.14%, Val-Class-Acc: {0: '89.13%', 1: '83.15%'}, LR: 0.000400\n",
      "Epoch 148/200, Train Loss: 0.000309, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.015682, Val Acc: 85.87%, Val-Class-Acc: {0: '88.59%', 1: '83.15%'}, LR: 0.000400\n",
      "Epoch 149/200, Train Loss: 0.000140, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.024638, Val Acc: 85.87%, Val-Class-Acc: {0: '88.04%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 150/200, Train Loss: 0.000054, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.041701, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 151/200, Train Loss: 0.000081, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.030844, Val Acc: 86.14%, Val-Class-Acc: {0: '87.50%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 152/200, Train Loss: 0.000068, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.046029, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 153/200, Train Loss: 0.000765, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.054339, Val Acc: 86.41%, Val-Class-Acc: {0: '89.67%', 1: '83.15%'}, LR: 0.000400\n",
      "Epoch 154/200, Train Loss: 0.001064, Train-Class-Acc: {0: '100.00%', 1: '99.86%'}\n",
      "Val Loss: 1.098915, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.000400\n",
      "Epoch 155/200, Train Loss: 0.002286, Train-Class-Acc: {0: '100.00%', 1: '99.86%'}\n",
      "Val Loss: 1.074545, Val Acc: 85.60%, Val-Class-Acc: {0: '86.41%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 156/200, Train Loss: 0.002594, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.158646, Val Acc: 86.14%, Val-Class-Acc: {0: '88.04%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 157/200, Train Loss: 0.017401, Train-Class-Acc: {0: '99.46%', 1: '99.32%'}\n",
      "Val Loss: 1.290086, Val Acc: 85.05%, Val-Class-Acc: {0: '90.22%', 1: '79.89%'}, LR: 0.000400\n",
      "Epoch 158/200, Train Loss: 0.068342, Train-Class-Acc: {0: '97.82%', 1: '97.96%'}\n",
      "Val Loss: 1.325820, Val Acc: 82.61%, Val-Class-Acc: {0: '76.63%', 1: '88.59%'}, LR: 0.000400\n",
      "Epoch 159/200, Train Loss: 0.073366, Train-Class-Acc: {0: '97.55%', 1: '97.41%'}\n",
      "Val Loss: 1.220943, Val Acc: 81.25%, Val-Class-Acc: {0: '95.65%', 1: '66.85%'}, LR: 0.000400\n",
      "Epoch 160/200, Train Loss: 0.055229, Train-Class-Acc: {0: '98.77%', 1: '97.41%'}\n",
      "Val Loss: 0.550945, Val Acc: 85.87%, Val-Class-Acc: {0: '81.52%', 1: '90.22%'}, LR: 0.000400\n",
      "Epoch 161/200, Train Loss: 0.030853, Train-Class-Acc: {0: '98.91%', 1: '99.18%'}\n",
      "Val Loss: 0.686976, Val Acc: 85.87%, Val-Class-Acc: {0: '82.61%', 1: '89.13%'}, LR: 0.000400\n",
      "Epoch 162/200, Train Loss: 0.015311, Train-Class-Acc: {0: '99.46%', 1: '99.32%'}\n",
      "Val Loss: 0.760907, Val Acc: 86.96%, Val-Class-Acc: {0: '88.04%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 163/200, Train Loss: 0.010381, Train-Class-Acc: {0: '99.73%', 1: '99.73%'}\n",
      "Val Loss: 0.915746, Val Acc: 86.96%, Val-Class-Acc: {0: '90.22%', 1: '83.70%'}, LR: 0.000400\n",
      "Epoch 164/200, Train Loss: 0.005240, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.030865, Val Acc: 86.68%, Val-Class-Acc: {0: '90.76%', 1: '82.61%'}, LR: 0.000400\n",
      "Epoch 165/200, Train Loss: 0.002654, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.010166, Val Acc: 86.96%, Val-Class-Acc: {0: '89.67%', 1: '84.24%'}, LR: 0.000400\n",
      "Epoch 166/200, Train Loss: 0.005511, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 0.965597, Val Acc: 87.50%, Val-Class-Acc: {0: '89.13%', 1: '85.87%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_16.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_166.pth\n",
      "Epoch 167/200, Train Loss: 0.001763, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.997720, Val Acc: 87.50%, Val-Class-Acc: {0: '88.59%', 1: '86.41%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_20.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_167.pth\n",
      "Epoch 168/200, Train Loss: 0.000823, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.003268, Val Acc: 86.96%, Val-Class-Acc: {0: '86.41%', 1: '87.50%'}, LR: 0.000400\n",
      "Epoch 169/200, Train Loss: 0.000396, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.052014, Val Acc: 86.96%, Val-Class-Acc: {0: '85.87%', 1: '88.04%'}, LR: 0.000400\n",
      "Epoch 170/200, Train Loss: 0.000511, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.087331, Val Acc: 86.41%, Val-Class-Acc: {0: '86.96%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 171/200, Train Loss: 0.000211, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.100256, Val Acc: 86.96%, Val-Class-Acc: {0: '87.50%', 1: '86.41%'}, LR: 0.000400\n",
      "Epoch 172/200, Train Loss: 0.000103, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.121509, Val Acc: 87.23%, Val-Class-Acc: {0: '88.59%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 173/200, Train Loss: 0.000393, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.108502, Val Acc: 86.68%, Val-Class-Acc: {0: '88.04%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 174/200, Train Loss: 0.000536, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.118919, Val Acc: 86.96%, Val-Class-Acc: {0: '88.59%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 175/200, Train Loss: 0.000367, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.149139, Val Acc: 88.04%, Val-Class-Acc: {0: '91.30%', 1: '84.78%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_66.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_175.pth\n",
      "Epoch 176/200, Train Loss: 0.000670, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.142309, Val Acc: 87.77%, Val-Class-Acc: {0: '90.22%', 1: '85.33%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_24.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_176.pth\n",
      "Epoch 177/200, Train Loss: 0.000191, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.174705, Val Acc: 87.77%, Val-Class-Acc: {0: '90.76%', 1: '84.78%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_166.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_177.pth\n",
      "Epoch 178/200, Train Loss: 0.001869, Train-Class-Acc: {0: '100.00%', 1: '99.86%'}\n",
      "Val Loss: 1.204837, Val Acc: 86.68%, Val-Class-Acc: {0: '88.59%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 179/200, Train Loss: 0.001697, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.269142, Val Acc: 87.50%, Val-Class-Acc: {0: '89.13%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 180/200, Train Loss: 0.024327, Train-Class-Acc: {0: '99.59%', 1: '99.05%'}\n",
      "Val Loss: 1.160944, Val Acc: 85.33%, Val-Class-Acc: {0: '82.61%', 1: '88.04%'}, LR: 0.000400\n",
      "Epoch 181/200, Train Loss: 0.046843, Train-Class-Acc: {0: '98.37%', 1: '98.50%'}\n",
      "Val Loss: 1.048999, Val Acc: 84.78%, Val-Class-Acc: {0: '87.50%', 1: '82.07%'}, LR: 0.000400\n",
      "Epoch 182/200, Train Loss: 0.025829, Train-Class-Acc: {0: '98.91%', 1: '99.32%'}\n",
      "Val Loss: 0.899089, Val Acc: 84.78%, Val-Class-Acc: {0: '83.70%', 1: '85.87%'}, LR: 0.000400\n",
      "Epoch 183/200, Train Loss: 0.025343, Train-Class-Acc: {0: '98.91%', 1: '99.05%'}\n",
      "Val Loss: 0.957750, Val Acc: 85.33%, Val-Class-Acc: {0: '90.22%', 1: '80.43%'}, LR: 0.000400\n",
      "Epoch 184/200, Train Loss: 0.023693, Train-Class-Acc: {0: '99.18%', 1: '99.18%'}\n",
      "Val Loss: 0.800260, Val Acc: 85.33%, Val-Class-Acc: {0: '89.67%', 1: '80.98%'}, LR: 0.000400\n",
      "Epoch 185/200, Train Loss: 0.011438, Train-Class-Acc: {0: '99.46%', 1: '99.73%'}\n",
      "Val Loss: 0.765681, Val Acc: 86.96%, Val-Class-Acc: {0: '89.13%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 186/200, Train Loss: 0.008132, Train-Class-Acc: {0: '99.73%', 1: '99.73%'}\n",
      "Val Loss: 0.865276, Val Acc: 86.96%, Val-Class-Acc: {0: '88.59%', 1: '85.33%'}, LR: 0.000400\n",
      "Epoch 187/200, Train Loss: 0.005380, Train-Class-Acc: {0: '99.86%', 1: '99.86%'}\n",
      "Val Loss: 0.919592, Val Acc: 87.23%, Val-Class-Acc: {0: '85.33%', 1: '89.13%'}, LR: 0.000400\n",
      "Epoch 188/200, Train Loss: 0.003120, Train-Class-Acc: {0: '100.00%', 1: '99.73%'}\n",
      "Val Loss: 0.963313, Val Acc: 88.04%, Val-Class-Acc: {0: '92.93%', 1: '83.15%'}, LR: 0.000400\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_167.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_188.pth\n",
      "Epoch 189/200, Train Loss: 0.018958, Train-Class-Acc: {0: '99.05%', 1: '99.73%'}\n",
      "Val Loss: 1.224352, Val Acc: 85.05%, Val-Class-Acc: {0: '94.02%', 1: '76.09%'}, LR: 0.000400\n",
      "Epoch 190/200, Train Loss: 0.012981, Train-Class-Acc: {0: '99.46%', 1: '99.18%'}\n",
      "Val Loss: 1.105750, Val Acc: 86.41%, Val-Class-Acc: {0: '85.33%', 1: '87.50%'}, LR: 0.000400\n",
      "Epoch 191/200, Train Loss: 0.023045, Train-Class-Acc: {0: '99.18%', 1: '99.32%'}\n",
      "Val Loss: 1.373589, Val Acc: 80.98%, Val-Class-Acc: {0: '70.11%', 1: '91.85%'}, LR: 0.000400\n",
      "Epoch 192/200, Train Loss: 0.024691, Train-Class-Acc: {0: '99.18%', 1: '98.91%'}\n",
      "Val Loss: 1.093827, Val Acc: 84.78%, Val-Class-Acc: {0: '82.07%', 1: '87.50%'}, LR: 0.000400\n",
      "Epoch 193/200, Train Loss: 0.025384, Train-Class-Acc: {0: '98.91%', 1: '99.18%'}\n",
      "Val Loss: 0.880980, Val Acc: 85.05%, Val-Class-Acc: {0: '91.30%', 1: '78.80%'}, LR: 0.000400\n",
      "Epoch 194/200, Train Loss: 0.026876, Train-Class-Acc: {0: '99.32%', 1: '98.64%'}\n",
      "Val Loss: 0.944561, Val Acc: 84.51%, Val-Class-Acc: {0: '84.24%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 195/200, Train Loss: 0.016720, Train-Class-Acc: {0: '99.18%', 1: '99.59%'}\n",
      "Val Loss: 0.911006, Val Acc: 84.78%, Val-Class-Acc: {0: '89.13%', 1: '80.43%'}, LR: 0.000400\n",
      "Epoch 196/200, Train Loss: 0.003532, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.012547, Val Acc: 85.60%, Val-Class-Acc: {0: '92.39%', 1: '78.80%'}, LR: 0.000400\n",
      "Epoch 197/200, Train Loss: 0.003340, Train-Class-Acc: {0: '100.00%', 1: '99.86%'}\n",
      "Val Loss: 0.944507, Val Acc: 84.24%, Val-Class-Acc: {0: '87.50%', 1: '80.98%'}, LR: 0.000400\n",
      "Epoch 198/200, Train Loss: 0.005155, Train-Class-Acc: {0: '99.59%', 1: '100.00%'}\n",
      "Val Loss: 0.973813, Val Acc: 86.14%, Val-Class-Acc: {0: '83.70%', 1: '88.59%'}, LR: 0.000400\n",
      "Epoch 199/200, Train Loss: 0.003425, Train-Class-Acc: {0: '100.00%', 1: '99.86%'}\n",
      "Val Loss: 0.949177, Val Acc: 85.33%, Val-Class-Acc: {0: '85.87%', 1: '84.78%'}, LR: 0.000400\n",
      "Epoch 200/200, Train Loss: 0.002524, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.054236, Val Acc: 85.05%, Val-Class-Acc: {0: '88.59%', 1: '81.52%'}, LR: 0.000400\n",
      "\n",
      "🏆 Best model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_best.pth (Val Accuracy: 88.04%)\n",
      "\n",
      "📌 Final model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_final.pth\n",
      "\n",
      "🎯 Top 5 Best Models:\n",
      "Epoch 188, Train Loss: 0.003120, Train-Acc: {0: '100.00%', 1: '99.73%'},\n",
      "Val Loss: 0.963313, Val Acc: 88.04%, Val-Class-Acc: {0: '92.93%', 1: '83.15%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_188.pth\n",
      "Epoch 175, Train Loss: 0.000367, Train-Acc: {0: '100.00%', 1: '100.00%'},\n",
      "Val Loss: 1.149139, Val Acc: 88.04%, Val-Class-Acc: {0: '91.30%', 1: '84.78%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_175.pth\n",
      "Epoch 124, Train Loss: 0.069623, Train-Acc: {0: '97.00%', 1: '97.82%'},\n",
      "Val Loss: 0.584996, Val Acc: 88.04%, Val-Class-Acc: {0: '94.57%', 1: '81.52%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_124.pth\n",
      "Epoch 177, Train Loss: 0.000191, Train-Acc: {0: '100.00%', 1: '100.00%'},\n",
      "Val Loss: 1.174705, Val Acc: 87.77%, Val-Class-Acc: {0: '90.76%', 1: '84.78%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_177.pth\n",
      "Epoch 176, Train Loss: 0.000670, Train-Acc: {0: '100.00%', 1: '100.00%'},\n",
      "Val Loss: 1.142309, Val Acc: 87.77%, Val-Class-Acc: {0: '90.22%', 1: '85.33%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_epoch_176.pth\n",
      "\n",
      "🧠 Model Summary:\n",
      "Total Parameters: 7,509,378\n",
      "Model Size (float32): 28.65 MB\n",
      "Total Training Time: 270.40 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "save_dir = os.path.join(BASE_DIR, \"processed\")\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))  # Shape: (B, 5000, 12)\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# ==== Model Hyperparameters ====\n",
    "input_channels = X_train.shape[2]                  # 12 leads\n",
    "output_size = len(np.unique(y_train))              # Number of classes (e.g., 2 for Period 1)\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "dropout = 0.0                                       # Not needed for ResNet18_1D\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "print(\"✅ input shape:\", X_train.shape)\n",
    "print(\"✅ unique y_train:\", np.unique(y_train))\n",
    "print(\"✅ unique y_test :\", np.unique(y_test))\n",
    "assert np.max(y_train) < output_size\n",
    "assert np.max(y_test) < output_size\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/ResNet18_Improved\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Model ====\n",
    "model = ResNet18_1D_Improved(input_channels=input_channels, output_size=output_size, dropout_rate=0.0).to(device)\n",
    "\n",
    "# ==== Optimizer and Training ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3*10,             # 最大學習率為初始學習率的10倍\n",
    "    steps_per_epoch=ceil(X_train.shape[0] / batch_size),\n",
    "    epochs=num_epochs,\n",
    "    pct_start=0.3,                       # 在 30% 的訓練過程中達到最大學習率\n",
    "    div_factor=25,                       # 初始學習率為最大值的 1/25\n",
    "    final_div_factor=1000                # 最終學習率為初始學習率的 1/1000\n",
    ")\n",
    "\n",
    "# ==== Train ====\n",
    "result_summary = train_model_general_classifier(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name='ResNet18_1D',\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del model, X_train, y_train, X_test, y_test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f40b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "save_dir = os.path.join(BASE_DIR, \"processed\")\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))  # Shape: (B, 5000, 12)\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# ==== Model Hyperparameters ====\n",
    "input_channels = X_train.shape[2]                  # 12 leads\n",
    "output_size = len(np.unique(y_train))              # Number of classes (e.g., 2 for Period 1)\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "dropout = 0.0                                       # Not needed for ResNet18_1D\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "print(\"✅ input shape:\", X_train.shape)\n",
    "print(\"✅ unique y_train:\", np.unique(y_train))\n",
    "print(\"✅ unique y_test :\", np.unique(y_test))\n",
    "assert np.max(y_train) < output_size\n",
    "assert np.max(y_test) < output_size\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/ResNet18_Improved\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Model ====\n",
    "model = ResNet18_1D_Improved(input_channels=input_channels, output_size=output_size, dropout_rate=0.0).to(device)\n",
    "\n",
    "# ==== Optimizer and Training ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3*10,             # 最大學習率為初始學習率的10倍\n",
    "    steps_per_epoch=ceil(X_train.shape[0] / batch_size),\n",
    "    epochs=num_epochs,\n",
    "    pct_start=0.3,                       # 在 30% 的訓練過程中達到最大學習率\n",
    "    div_factor=25,                       # 初始學習率為最大值的 1/25\n",
    "    final_div_factor=1000                # 最終學習率為初始學習率的 1/1000\n",
    ")\n",
    "\n",
    "# ==== Train ====\n",
    "result_summary = train_model_general_classifier(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name='ResNet18_1D',\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del model, X_train, y_train, X_test, y_test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3332971e",
   "metadata": {},
   "source": [
    "#### Claude Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ea9de98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 '整合版訓練函數' 開始運行.\n",
      "✅ 確保模型保存文件夾存在: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved\n",
      "\n",
      "✅ 數據概覽:\n",
      "X_train: (1468, 5000, 12), y_train: (1468,)\n",
      "X_val: (368, 5000, 12), y_val: (368,)\n",
      "✅ 使用類別權重: [1. 1.]\n",
      "✅ 使用OneCycleLR學習率調度器\n",
      "Epoch 1/300, Train Loss: 0.492625, Train-Class-Acc: {0: '82.70%', 1: '71.12%'}\n",
      "Val Loss: 0.430352, Val Acc: 78.80%, Val-Class-Acc: {0: '92.93%', 1: '64.67%'}, LR: 0.000121\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_1.pth\n",
      "驗證準確率從 0.00% 提升到 78.80%\n",
      "Epoch 2/300, Train Loss: 0.404841, Train-Class-Acc: {0: '86.24%', 1: '78.07%'}\n",
      "Val Loss: 0.367357, Val Acc: 85.60%, Val-Class-Acc: {0: '92.93%', 1: '78.26%'}, LR: 0.000124\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_2.pth\n",
      "驗證準確率從 78.80% 提升到 85.60%\n",
      "Epoch 3/300, Train Loss: 0.340290, Train-Class-Acc: {0: '89.24%', 1: '79.56%'}\n",
      "Val Loss: 0.329147, Val Acc: 85.87%, Val-Class-Acc: {0: '85.87%', 1: '85.87%'}, LR: 0.000128\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_3.pth\n",
      "驗證準確率從 85.60% 提升到 85.87%\n",
      "Epoch 4/300, Train Loss: 0.312152, Train-Class-Acc: {0: '89.51%', 1: '84.33%'}\n",
      "Val Loss: 0.469529, Val Acc: 82.88%, Val-Class-Acc: {0: '72.28%', 1: '93.48%'}, LR: 0.000134\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_4.pth\n",
      "驗證未改善。耐心值: 1/30\n",
      "Epoch 5/300, Train Loss: 0.273851, Train-Class-Acc: {0: '92.10%', 1: '85.83%'}\n",
      "Val Loss: 0.411762, Val Acc: 86.96%, Val-Class-Acc: {0: '88.59%', 1: '85.33%'}, LR: 0.000142\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_5.pth\n",
      "驗證準確率從 85.87% 提升到 86.96%\n",
      "Epoch 6/300, Train Loss: 0.261297, Train-Class-Acc: {0: '92.23%', 1: '86.10%'}\n",
      "Val Loss: 0.327187, Val Acc: 87.50%, Val-Class-Acc: {0: '88.04%', 1: '86.96%'}, LR: 0.000151\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_1.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_6.pth\n",
      "驗證準確率從 86.96% 提升到 87.50%\n",
      "Epoch 7/300, Train Loss: 0.276014, Train-Class-Acc: {0: '92.10%', 1: '84.88%'}\n",
      "Val Loss: 0.376640, Val Acc: 85.60%, Val-Class-Acc: {0: '79.89%', 1: '91.30%'}, LR: 0.000163\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_4.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_7.pth\n",
      "驗證未改善。耐心值: 1/30\n",
      "Epoch 8/300, Train Loss: 0.257711, Train-Class-Acc: {0: '94.01%', 1: '86.65%'}\n",
      "Val Loss: 0.544883, Val Acc: 83.42%, Val-Class-Acc: {0: '95.11%', 1: '71.74%'}, LR: 0.000176\n",
      "Epoch 9/300, Train Loss: 0.250565, Train-Class-Acc: {0: '92.23%', 1: '87.06%'}\n",
      "Val Loss: 0.365294, Val Acc: 85.05%, Val-Class-Acc: {0: '94.02%', 1: '76.09%'}, LR: 0.000191\n",
      "Epoch 10/300, Train Loss: 0.227365, Train-Class-Acc: {0: '93.46%', 1: '89.24%'}\n",
      "Val Loss: 0.479952, Val Acc: 82.61%, Val-Class-Acc: {0: '90.22%', 1: '75.00%'}, LR: 0.000207\n",
      "Epoch 11/300, Train Loss: 0.265243, Train-Class-Acc: {0: '90.60%', 1: '85.56%'}\n",
      "Val Loss: 0.433020, Val Acc: 84.24%, Val-Class-Acc: {0: '95.11%', 1: '73.37%'}, LR: 0.000225\n",
      "Epoch 12/300, Train Loss: 0.238735, Train-Class-Acc: {0: '92.64%', 1: '86.92%'}\n",
      "Val Loss: 0.705228, Val Acc: 75.82%, Val-Class-Acc: {0: '57.07%', 1: '94.57%'}, LR: 0.000245\n",
      "Epoch 13/300, Train Loss: 0.257456, Train-Class-Acc: {0: '90.05%', 1: '87.19%'}\n",
      "Val Loss: 0.389005, Val Acc: 86.14%, Val-Class-Acc: {0: '83.70%', 1: '88.59%'}, LR: 0.000266\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_2.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_13.pth\n",
      "驗證未改善。耐心值: 2/30\n",
      "Epoch 14/300, Train Loss: 0.258152, Train-Class-Acc: {0: '91.14%', 1: '86.24%'}\n",
      "Val Loss: 0.355383, Val Acc: 85.60%, Val-Class-Acc: {0: '81.52%', 1: '89.67%'}, LR: 0.000289\n",
      "Epoch 15/300, Train Loss: 0.257955, Train-Class-Acc: {0: '93.05%', 1: '84.60%'}\n",
      "Val Loss: 0.412045, Val Acc: 84.24%, Val-Class-Acc: {0: '91.85%', 1: '76.63%'}, LR: 0.000313\n",
      "Epoch 16/300, Train Loss: 0.268620, Train-Class-Acc: {0: '90.46%', 1: '86.65%'}\n",
      "Val Loss: 0.479605, Val Acc: 80.43%, Val-Class-Acc: {0: '95.11%', 1: '65.76%'}, LR: 0.000339\n",
      "Epoch 17/300, Train Loss: 0.203448, Train-Class-Acc: {0: '93.19%', 1: '89.10%'}\n",
      "Val Loss: 0.470256, Val Acc: 84.24%, Val-Class-Acc: {0: '76.63%', 1: '91.85%'}, LR: 0.000366\n",
      "Epoch 18/300, Train Loss: 0.262156, Train-Class-Acc: {0: '91.01%', 1: '85.29%'}\n",
      "Val Loss: 0.346478, Val Acc: 86.14%, Val-Class-Acc: {0: '84.78%', 1: '87.50%'}, LR: 0.000395\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_7.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_18.pth\n",
      "驗證未改善。耐心值: 3/30\n",
      "Epoch 19/300, Train Loss: 0.233049, Train-Class-Acc: {0: '94.82%', 1: '84.74%'}\n",
      "Val Loss: 0.800163, Val Acc: 79.35%, Val-Class-Acc: {0: '97.28%', 1: '61.41%'}, LR: 0.000425\n",
      "Epoch 20/300, Train Loss: 0.201152, Train-Class-Acc: {0: '92.51%', 1: '90.05%'}\n",
      "Val Loss: 0.523770, Val Acc: 85.05%, Val-Class-Acc: {0: '84.78%', 1: '85.33%'}, LR: 0.000457\n",
      "Epoch 21/300, Train Loss: 0.241598, Train-Class-Acc: {0: '91.42%', 1: '88.96%'}\n",
      "Val Loss: 0.312266, Val Acc: 86.41%, Val-Class-Acc: {0: '92.93%', 1: '79.89%'}, LR: 0.000490\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_3.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_21.pth\n",
      "驗證未改善。耐心值: 4/30\n",
      "Epoch 22/300, Train Loss: 0.236052, Train-Class-Acc: {0: '94.14%', 1: '86.78%'}\n",
      "Val Loss: 0.375442, Val Acc: 86.41%, Val-Class-Acc: {0: '88.04%', 1: '84.78%'}, LR: 0.000524\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_13.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_22.pth\n",
      "驗證未改善。耐心值: 5/30\n",
      "Epoch 23/300, Train Loss: 0.257149, Train-Class-Acc: {0: '92.64%', 1: '88.56%'}\n",
      "Val Loss: 0.336448, Val Acc: 86.41%, Val-Class-Acc: {0: '94.02%', 1: '78.80%'}, LR: 0.000560\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_18.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_23.pth\n",
      "驗證未改善。耐心值: 6/30\n",
      "Epoch 24/300, Train Loss: 0.231778, Train-Class-Acc: {0: '92.37%', 1: '86.92%'}\n",
      "Val Loss: 0.452841, Val Acc: 85.87%, Val-Class-Acc: {0: '95.65%', 1: '76.09%'}, LR: 0.000597\n",
      "Epoch 25/300, Train Loss: 0.206800, Train-Class-Acc: {0: '92.92%', 1: '89.10%'}\n",
      "Val Loss: 0.542505, Val Acc: 78.80%, Val-Class-Acc: {0: '72.83%', 1: '84.78%'}, LR: 0.000635\n",
      "Epoch 26/300, Train Loss: 0.267286, Train-Class-Acc: {0: '92.64%', 1: '85.56%'}\n",
      "Val Loss: 0.410403, Val Acc: 82.34%, Val-Class-Acc: {0: '96.20%', 1: '68.48%'}, LR: 0.000674\n",
      "Epoch 27/300, Train Loss: 0.257231, Train-Class-Acc: {0: '93.87%', 1: '87.33%'}\n",
      "Val Loss: 0.376603, Val Acc: 85.60%, Val-Class-Acc: {0: '90.22%', 1: '80.98%'}, LR: 0.000714\n",
      "Epoch 28/300, Train Loss: 0.231586, Train-Class-Acc: {0: '93.19%', 1: '86.51%'}\n",
      "Val Loss: 0.483992, Val Acc: 87.23%, Val-Class-Acc: {0: '88.59%', 1: '85.87%'}, LR: 0.000755\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_21.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_28.pth\n",
      "驗證未改善。耐心值: 7/30\n",
      "Epoch 29/300, Train Loss: 0.211378, Train-Class-Acc: {0: '93.32%', 1: '88.83%'}\n",
      "Val Loss: 0.628693, Val Acc: 83.97%, Val-Class-Acc: {0: '95.11%', 1: '72.83%'}, LR: 0.000797\n",
      "Epoch 30/300, Train Loss: 0.241518, Train-Class-Acc: {0: '94.01%', 1: '85.69%'}\n",
      "Val Loss: 0.427790, Val Acc: 84.51%, Val-Class-Acc: {0: '78.26%', 1: '90.76%'}, LR: 0.000840\n",
      "Epoch 31/300, Train Loss: 0.247456, Train-Class-Acc: {0: '92.64%', 1: '86.24%'}\n",
      "Val Loss: 0.585418, Val Acc: 79.89%, Val-Class-Acc: {0: '97.83%', 1: '61.96%'}, LR: 0.000884\n",
      "Epoch 32/300, Train Loss: 0.181989, Train-Class-Acc: {0: '93.73%', 1: '90.19%'}\n",
      "Val Loss: 0.467826, Val Acc: 87.77%, Val-Class-Acc: {0: '92.93%', 1: '82.61%'}, LR: 0.000929\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_22.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_32.pth\n",
      "驗證準確率從 87.50% 提升到 87.77%\n",
      "Epoch 33/300, Train Loss: 0.225476, Train-Class-Acc: {0: '93.32%', 1: '87.06%'}\n",
      "Val Loss: 0.394162, Val Acc: 85.87%, Val-Class-Acc: {0: '92.93%', 1: '78.80%'}, LR: 0.000975\n",
      "Epoch 34/300, Train Loss: 0.207252, Train-Class-Acc: {0: '92.64%', 1: '88.42%'}\n",
      "Val Loss: 0.480320, Val Acc: 84.24%, Val-Class-Acc: {0: '94.57%', 1: '73.91%'}, LR: 0.001021\n",
      "Epoch 35/300, Train Loss: 0.206527, Train-Class-Acc: {0: '93.60%', 1: '89.37%'}\n",
      "Val Loss: 0.489502, Val Acc: 85.33%, Val-Class-Acc: {0: '95.65%', 1: '75.00%'}, LR: 0.001068\n",
      "Epoch 36/300, Train Loss: 0.242849, Train-Class-Acc: {0: '92.64%', 1: '86.78%'}\n",
      "Val Loss: 1.004053, Val Acc: 76.09%, Val-Class-Acc: {0: '98.91%', 1: '53.26%'}, LR: 0.001115\n",
      "Epoch 37/300, Train Loss: 0.180303, Train-Class-Acc: {0: '95.10%', 1: '89.24%'}\n",
      "Val Loss: 0.507934, Val Acc: 84.78%, Val-Class-Acc: {0: '88.04%', 1: '81.52%'}, LR: 0.001164\n",
      "Epoch 38/300, Train Loss: 0.236744, Train-Class-Acc: {0: '91.96%', 1: '90.46%'}\n",
      "Val Loss: 0.404577, Val Acc: 84.78%, Val-Class-Acc: {0: '79.35%', 1: '90.22%'}, LR: 0.001212\n",
      "Epoch 39/300, Train Loss: 0.206587, Train-Class-Acc: {0: '94.96%', 1: '89.92%'}\n",
      "Val Loss: 0.376642, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.001261\n",
      "Epoch 40/300, Train Loss: 0.194578, Train-Class-Acc: {0: '93.60%', 1: '89.78%'}\n",
      "Val Loss: 0.463904, Val Acc: 85.60%, Val-Class-Acc: {0: '89.67%', 1: '81.52%'}, LR: 0.001310\n",
      "Epoch 41/300, Train Loss: 0.221698, Train-Class-Acc: {0: '92.23%', 1: '88.96%'}\n",
      "Val Loss: 0.814130, Val Acc: 78.26%, Val-Class-Acc: {0: '62.50%', 1: '94.02%'}, LR: 0.001360\n",
      "Epoch 42/300, Train Loss: 0.210753, Train-Class-Acc: {0: '93.73%', 1: '89.92%'}\n",
      "Val Loss: 0.413880, Val Acc: 85.87%, Val-Class-Acc: {0: '90.76%', 1: '80.98%'}, LR: 0.001410\n",
      "Epoch 43/300, Train Loss: 0.211510, Train-Class-Acc: {0: '94.28%', 1: '88.28%'}\n",
      "Val Loss: 0.463216, Val Acc: 85.33%, Val-Class-Acc: {0: '94.02%', 1: '76.63%'}, LR: 0.001460\n",
      "Epoch 44/300, Train Loss: 0.203280, Train-Class-Acc: {0: '95.23%', 1: '88.69%'}\n",
      "Val Loss: 0.370360, Val Acc: 85.87%, Val-Class-Acc: {0: '90.22%', 1: '81.52%'}, LR: 0.001510\n",
      "Epoch 45/300, Train Loss: 0.180934, Train-Class-Acc: {0: '93.87%', 1: '90.87%'}\n",
      "Val Loss: 0.438808, Val Acc: 85.87%, Val-Class-Acc: {0: '95.65%', 1: '76.09%'}, LR: 0.001561\n",
      "Epoch 46/300, Train Loss: 0.195855, Train-Class-Acc: {0: '94.69%', 1: '89.78%'}\n",
      "Val Loss: 0.571670, Val Acc: 83.15%, Val-Class-Acc: {0: '95.11%', 1: '71.20%'}, LR: 0.001611\n",
      "Epoch 47/300, Train Loss: 0.205532, Train-Class-Acc: {0: '95.37%', 1: '88.28%'}\n",
      "Val Loss: 0.408798, Val Acc: 86.68%, Val-Class-Acc: {0: '84.78%', 1: '88.59%'}, LR: 0.001661\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_23.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_47.pth\n",
      "驗證未改善。耐心值: 1/30\n",
      "Epoch 48/300, Train Loss: 0.202335, Train-Class-Acc: {0: '94.55%', 1: '87.47%'}\n",
      "Val Loss: 0.461840, Val Acc: 86.68%, Val-Class-Acc: {0: '80.98%', 1: '92.39%'}, LR: 0.001711\n",
      "Epoch 49/300, Train Loss: 0.228772, Train-Class-Acc: {0: '92.64%', 1: '88.96%'}\n",
      "Val Loss: 0.486241, Val Acc: 80.16%, Val-Class-Acc: {0: '94.57%', 1: '65.76%'}, LR: 0.001761\n",
      "Epoch 50/300, Train Loss: 0.205992, Train-Class-Acc: {0: '93.73%', 1: '89.37%'}\n",
      "Val Loss: 0.640879, Val Acc: 84.24%, Val-Class-Acc: {0: '95.11%', 1: '73.37%'}, LR: 0.001811\n",
      "Epoch 51/300, Train Loss: 0.184078, Train-Class-Acc: {0: '94.69%', 1: '90.33%'}\n",
      "Val Loss: 0.514778, Val Acc: 84.51%, Val-Class-Acc: {0: '82.07%', 1: '86.96%'}, LR: 0.001860\n",
      "Epoch 52/300, Train Loss: 0.195235, Train-Class-Acc: {0: '92.10%', 1: '90.33%'}\n",
      "Val Loss: 0.352925, Val Acc: 88.04%, Val-Class-Acc: {0: '94.02%', 1: '82.07%'}, LR: 0.001909\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_47.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_52.pth\n",
      "驗證準確率從 87.77% 提升到 88.04%\n",
      "Epoch 53/300, Train Loss: 0.243243, Train-Class-Acc: {0: '91.14%', 1: '87.19%'}\n",
      "Val Loss: 0.358716, Val Acc: 85.60%, Val-Class-Acc: {0: '83.70%', 1: '87.50%'}, LR: 0.001958\n",
      "Epoch 54/300, Train Loss: 0.223440, Train-Class-Acc: {0: '93.60%', 1: '87.87%'}\n",
      "Val Loss: 0.365084, Val Acc: 83.97%, Val-Class-Acc: {0: '86.41%', 1: '81.52%'}, LR: 0.002006\n",
      "Epoch 55/300, Train Loss: 0.204405, Train-Class-Acc: {0: '93.87%', 1: '89.65%'}\n",
      "Val Loss: 0.469807, Val Acc: 86.96%, Val-Class-Acc: {0: '89.67%', 1: '84.24%'}, LR: 0.002053\n",
      "Epoch 56/300, Train Loss: 0.190662, Train-Class-Acc: {0: '95.37%', 1: '90.19%'}\n",
      "Val Loss: 0.386809, Val Acc: 84.24%, Val-Class-Acc: {0: '84.78%', 1: '83.70%'}, LR: 0.002100\n",
      "Epoch 57/300, Train Loss: 0.144033, Train-Class-Acc: {0: '95.64%', 1: '92.51%'}\n",
      "Val Loss: 0.526190, Val Acc: 85.33%, Val-Class-Acc: {0: '83.70%', 1: '86.96%'}, LR: 0.002146\n",
      "Epoch 58/300, Train Loss: 0.193891, Train-Class-Acc: {0: '94.41%', 1: '89.78%'}\n",
      "Val Loss: 0.894721, Val Acc: 72.28%, Val-Class-Acc: {0: '48.37%', 1: '96.20%'}, LR: 0.002192\n",
      "Epoch 59/300, Train Loss: 0.228929, Train-Class-Acc: {0: '93.87%', 1: '87.33%'}\n",
      "Val Loss: 0.355034, Val Acc: 83.15%, Val-Class-Acc: {0: '77.17%', 1: '89.13%'}, LR: 0.002237\n",
      "Epoch 60/300, Train Loss: 0.192046, Train-Class-Acc: {0: '93.60%', 1: '89.65%'}\n",
      "Val Loss: 0.391431, Val Acc: 87.77%, Val-Class-Acc: {0: '88.59%', 1: '86.96%'}, LR: 0.002281\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_5.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_60.pth\n",
      "驗證未改善。耐心值: 1/30\n",
      "Epoch 61/300, Train Loss: 0.193933, Train-Class-Acc: {0: '94.41%', 1: '89.92%'}\n",
      "Val Loss: 0.376438, Val Acc: 85.87%, Val-Class-Acc: {0: '91.85%', 1: '79.89%'}, LR: 0.002324\n",
      "Epoch 62/300, Train Loss: 0.170807, Train-Class-Acc: {0: '95.10%', 1: '89.78%'}\n",
      "Val Loss: 0.413466, Val Acc: 83.97%, Val-Class-Acc: {0: '98.37%', 1: '69.57%'}, LR: 0.002366\n",
      "Epoch 63/300, Train Loss: 0.204020, Train-Class-Acc: {0: '94.55%', 1: '87.19%'}\n",
      "Val Loss: 0.352917, Val Acc: 85.87%, Val-Class-Acc: {0: '94.57%', 1: '77.17%'}, LR: 0.002407\n",
      "Epoch 64/300, Train Loss: 0.173995, Train-Class-Acc: {0: '94.69%', 1: '90.46%'}\n",
      "Val Loss: 0.367513, Val Acc: 88.32%, Val-Class-Acc: {0: '94.57%', 1: '82.07%'}, LR: 0.002447\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_28.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_64.pth\n",
      "驗證準確率從 88.04% 提升到 88.32%\n",
      "Epoch 65/300, Train Loss: 0.154453, Train-Class-Acc: {0: '96.05%', 1: '91.28%'}\n",
      "Val Loss: 0.534793, Val Acc: 86.14%, Val-Class-Acc: {0: '94.57%', 1: '77.72%'}, LR: 0.002486\n",
      "Epoch 66/300, Train Loss: 0.157467, Train-Class-Acc: {0: '94.69%', 1: '92.92%'}\n",
      "Val Loss: 0.395440, Val Acc: 85.33%, Val-Class-Acc: {0: '83.70%', 1: '86.96%'}, LR: 0.002524\n",
      "Epoch 67/300, Train Loss: 0.169487, Train-Class-Acc: {0: '94.82%', 1: '90.05%'}\n",
      "Val Loss: 0.647105, Val Acc: 82.07%, Val-Class-Acc: {0: '74.46%', 1: '89.67%'}, LR: 0.002561\n",
      "Epoch 68/300, Train Loss: 0.226511, Train-Class-Acc: {0: '91.96%', 1: '90.60%'}\n",
      "Val Loss: 0.361238, Val Acc: 85.87%, Val-Class-Acc: {0: '89.13%', 1: '82.61%'}, LR: 0.002596\n",
      "Epoch 69/300, Train Loss: 0.221425, Train-Class-Acc: {0: '93.60%', 1: '89.92%'}\n",
      "Val Loss: 0.482335, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.002631\n",
      "Epoch 70/300, Train Loss: 0.172963, Train-Class-Acc: {0: '95.23%', 1: '89.92%'}\n",
      "Val Loss: 0.321961, Val Acc: 86.14%, Val-Class-Acc: {0: '84.78%', 1: '87.50%'}, LR: 0.002664\n",
      "Epoch 71/300, Train Loss: 0.193449, Train-Class-Acc: {0: '94.96%', 1: '89.78%'}\n",
      "Val Loss: 0.462643, Val Acc: 83.15%, Val-Class-Acc: {0: '75.00%', 1: '91.30%'}, LR: 0.002695\n",
      "Epoch 72/300, Train Loss: 0.159786, Train-Class-Acc: {0: '96.05%', 1: '91.96%'}\n",
      "Val Loss: 0.373815, Val Acc: 86.96%, Val-Class-Acc: {0: '87.50%', 1: '86.41%'}, LR: 0.002725\n",
      "Epoch 73/300, Train Loss: 0.221624, Train-Class-Acc: {0: '92.10%', 1: '87.87%'}\n",
      "Val Loss: 0.524445, Val Acc: 83.70%, Val-Class-Acc: {0: '72.28%', 1: '95.11%'}, LR: 0.002754\n",
      "Epoch 74/300, Train Loss: 0.155484, Train-Class-Acc: {0: '94.82%', 1: '90.87%'}\n",
      "Val Loss: 0.573489, Val Acc: 83.97%, Val-Class-Acc: {0: '74.46%', 1: '93.48%'}, LR: 0.002782\n",
      "Epoch 75/300, Train Loss: 0.138511, Train-Class-Acc: {0: '95.37%', 1: '93.05%'}\n",
      "Val Loss: 0.432946, Val Acc: 85.60%, Val-Class-Acc: {0: '81.52%', 1: '89.67%'}, LR: 0.002808\n",
      "Epoch 76/300, Train Loss: 0.151197, Train-Class-Acc: {0: '96.05%', 1: '90.33%'}\n",
      "Val Loss: 0.455062, Val Acc: 86.41%, Val-Class-Acc: {0: '86.41%', 1: '86.41%'}, LR: 0.002832\n",
      "Epoch 77/300, Train Loss: 0.153235, Train-Class-Acc: {0: '95.50%', 1: '91.28%'}\n",
      "Val Loss: 0.450910, Val Acc: 84.51%, Val-Class-Acc: {0: '83.70%', 1: '85.33%'}, LR: 0.002855\n",
      "Epoch 78/300, Train Loss: 0.168350, Train-Class-Acc: {0: '94.69%', 1: '92.51%'}\n",
      "Val Loss: 0.534219, Val Acc: 84.78%, Val-Class-Acc: {0: '84.78%', 1: '84.78%'}, LR: 0.002876\n",
      "Epoch 79/300, Train Loss: 0.165295, Train-Class-Acc: {0: '95.10%', 1: '91.14%'}\n",
      "Val Loss: 0.416826, Val Acc: 86.41%, Val-Class-Acc: {0: '82.61%', 1: '90.22%'}, LR: 0.002896\n",
      "Epoch 80/300, Train Loss: 0.115655, Train-Class-Acc: {0: '96.46%', 1: '93.46%'}\n",
      "Val Loss: 0.522153, Val Acc: 86.68%, Val-Class-Acc: {0: '83.70%', 1: '89.67%'}, LR: 0.002913\n",
      "Epoch 81/300, Train Loss: 0.123181, Train-Class-Acc: {0: '95.64%', 1: '93.32%'}\n",
      "Val Loss: 0.548267, Val Acc: 86.41%, Val-Class-Acc: {0: '83.15%', 1: '89.67%'}, LR: 0.002930\n",
      "Epoch 82/300, Train Loss: 0.114762, Train-Class-Acc: {0: '95.37%', 1: '93.73%'}\n",
      "Val Loss: 0.411973, Val Acc: 87.77%, Val-Class-Acc: {0: '89.13%', 1: '86.41%'}, LR: 0.002944\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_6.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_82.pth\n",
      "驗證未改善。耐心值: 1/30\n",
      "Epoch 83/300, Train Loss: 0.110679, Train-Class-Acc: {0: '96.87%', 1: '93.05%'}\n",
      "Val Loss: 0.617376, Val Acc: 88.59%, Val-Class-Acc: {0: '88.59%', 1: '88.59%'}, LR: 0.002957\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_32.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_83.pth\n",
      "驗證準確率從 88.32% 提升到 88.59%\n",
      "Epoch 84/300, Train Loss: 0.158420, Train-Class-Acc: {0: '95.37%', 1: '90.33%'}\n",
      "Val Loss: 0.456442, Val Acc: 86.41%, Val-Class-Acc: {0: '82.61%', 1: '90.22%'}, LR: 0.002969\n",
      "Epoch 85/300, Train Loss: 0.142491, Train-Class-Acc: {0: '95.23%', 1: '93.60%'}\n",
      "Val Loss: 0.474552, Val Acc: 87.23%, Val-Class-Acc: {0: '90.76%', 1: '83.70%'}, LR: 0.002978\n",
      "Epoch 86/300, Train Loss: 0.166215, Train-Class-Acc: {0: '95.10%', 1: '92.10%'}\n",
      "Val Loss: 0.323326, Val Acc: 87.77%, Val-Class-Acc: {0: '86.96%', 1: '88.59%'}, LR: 0.002986\n",
      "Epoch 87/300, Train Loss: 0.109329, Train-Class-Acc: {0: '97.82%', 1: '93.32%'}\n",
      "Val Loss: 0.530582, Val Acc: 85.87%, Val-Class-Acc: {0: '83.70%', 1: '88.04%'}, LR: 0.002992\n",
      "Epoch 88/300, Train Loss: 0.103163, Train-Class-Acc: {0: '97.00%', 1: '93.87%'}\n",
      "Val Loss: 0.934601, Val Acc: 77.45%, Val-Class-Acc: {0: '59.78%', 1: '95.11%'}, LR: 0.002997\n",
      "Epoch 89/300, Train Loss: 0.131991, Train-Class-Acc: {0: '95.78%', 1: '93.05%'}\n",
      "Val Loss: 0.776235, Val Acc: 82.88%, Val-Class-Acc: {0: '91.30%', 1: '74.46%'}, LR: 0.002999\n",
      "Epoch 90/300, Train Loss: 0.146906, Train-Class-Acc: {0: '96.05%', 1: '91.69%'}\n",
      "Val Loss: 0.579933, Val Acc: 82.07%, Val-Class-Acc: {0: '69.57%', 1: '94.57%'}, LR: 0.003000\n",
      "Epoch 91/300, Train Loss: 0.177345, Train-Class-Acc: {0: '95.10%', 1: '91.14%'}\n",
      "Val Loss: 0.443444, Val Acc: 89.13%, Val-Class-Acc: {0: '85.33%', 1: '92.93%'}, LR: 0.003000\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_60.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_91.pth\n",
      "驗證準確率從 88.59% 提升到 89.13%\n",
      "Epoch 92/300, Train Loss: 0.137855, Train-Class-Acc: {0: '95.64%', 1: '92.37%'}\n",
      "Val Loss: 0.578306, Val Acc: 81.52%, Val-Class-Acc: {0: '79.89%', 1: '83.15%'}, LR: 0.002999\n",
      "Epoch 93/300, Train Loss: 0.132734, Train-Class-Acc: {0: '95.64%', 1: '93.19%'}\n",
      "Val Loss: 0.417121, Val Acc: 88.04%, Val-Class-Acc: {0: '88.04%', 1: '88.04%'}, LR: 0.002998\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_82.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_93.pth\n",
      "驗證未改善。耐心值: 1/30\n",
      "Epoch 94/300, Train Loss: 0.098139, Train-Class-Acc: {0: '97.14%', 1: '93.46%'}\n",
      "Val Loss: 0.516393, Val Acc: 86.96%, Val-Class-Acc: {0: '88.59%', 1: '85.33%'}, LR: 0.002997\n",
      "Epoch 95/300, Train Loss: 0.088020, Train-Class-Acc: {0: '97.55%', 1: '94.82%'}\n",
      "Val Loss: 0.606546, Val Acc: 83.70%, Val-Class-Acc: {0: '75.00%', 1: '92.39%'}, LR: 0.002996\n",
      "Epoch 96/300, Train Loss: 0.089168, Train-Class-Acc: {0: '97.41%', 1: '94.82%'}\n",
      "Val Loss: 0.506852, Val Acc: 87.77%, Val-Class-Acc: {0: '88.04%', 1: '87.50%'}, LR: 0.002994\n",
      "Epoch 97/300, Train Loss: 0.088072, Train-Class-Acc: {0: '98.09%', 1: '95.91%'}\n",
      "Val Loss: 0.509619, Val Acc: 86.14%, Val-Class-Acc: {0: '88.04%', 1: '84.24%'}, LR: 0.002992\n",
      "Epoch 98/300, Train Loss: 0.094695, Train-Class-Acc: {0: '96.73%', 1: '95.50%'}\n",
      "Val Loss: 0.440943, Val Acc: 88.04%, Val-Class-Acc: {0: '86.41%', 1: '89.67%'}, LR: 0.002989\n",
      "Epoch 99/300, Train Loss: 0.060216, Train-Class-Acc: {0: '98.64%', 1: '96.19%'}\n",
      "Val Loss: 0.633733, Val Acc: 88.59%, Val-Class-Acc: {0: '88.59%', 1: '88.59%'}, LR: 0.002986\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_52.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_99.pth\n",
      "驗證未改善。耐心值: 2/30\n",
      "Epoch 100/300, Train Loss: 0.055718, Train-Class-Acc: {0: '98.37%', 1: '96.87%'}\n",
      "Val Loss: 0.592054, Val Acc: 86.14%, Val-Class-Acc: {0: '85.33%', 1: '86.96%'}, LR: 0.002983\n",
      "Epoch 101/300, Train Loss: 0.114775, Train-Class-Acc: {0: '96.46%', 1: '95.10%'}\n",
      "Val Loss: 0.667818, Val Acc: 87.77%, Val-Class-Acc: {0: '95.11%', 1: '80.43%'}, LR: 0.002980\n",
      "Epoch 102/300, Train Loss: 0.109368, Train-Class-Acc: {0: '97.28%', 1: '94.55%'}\n",
      "Val Loss: 0.439900, Val Acc: 86.96%, Val-Class-Acc: {0: '88.04%', 1: '85.87%'}, LR: 0.002976\n",
      "Epoch 103/300, Train Loss: 0.091367, Train-Class-Acc: {0: '97.68%', 1: '94.41%'}\n",
      "Val Loss: 0.637071, Val Acc: 86.41%, Val-Class-Acc: {0: '94.57%', 1: '78.26%'}, LR: 0.002972\n",
      "Epoch 104/300, Train Loss: 0.081623, Train-Class-Acc: {0: '97.28%', 1: '94.69%'}\n",
      "Val Loss: 0.608836, Val Acc: 85.60%, Val-Class-Acc: {0: '95.11%', 1: '76.09%'}, LR: 0.002967\n",
      "Epoch 105/300, Train Loss: 0.099305, Train-Class-Acc: {0: '96.32%', 1: '94.41%'}\n",
      "Val Loss: 0.514140, Val Acc: 87.50%, Val-Class-Acc: {0: '91.30%', 1: '83.70%'}, LR: 0.002962\n",
      "Epoch 106/300, Train Loss: 0.062092, Train-Class-Acc: {0: '99.05%', 1: '96.32%'}\n",
      "Val Loss: 0.640744, Val Acc: 88.86%, Val-Class-Acc: {0: '91.30%', 1: '86.41%'}, LR: 0.002957\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_93.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_106.pth\n",
      "驗證未改善。耐心值: 3/30\n",
      "Epoch 107/300, Train Loss: 0.092978, Train-Class-Acc: {0: '97.28%', 1: '94.96%'}\n",
      "Val Loss: 1.075118, Val Acc: 86.68%, Val-Class-Acc: {0: '95.65%', 1: '77.72%'}, LR: 0.002952\n",
      "Epoch 108/300, Train Loss: 0.059936, Train-Class-Acc: {0: '98.64%', 1: '96.59%'}\n",
      "Val Loss: 0.834635, Val Acc: 86.96%, Val-Class-Acc: {0: '91.85%', 1: '82.07%'}, LR: 0.002946\n",
      "Epoch 109/300, Train Loss: 0.060932, Train-Class-Acc: {0: '98.77%', 1: '96.05%'}\n",
      "Val Loss: 0.805644, Val Acc: 82.88%, Val-Class-Acc: {0: '72.83%', 1: '92.93%'}, LR: 0.002940\n",
      "Epoch 110/300, Train Loss: 0.087414, Train-Class-Acc: {0: '97.82%', 1: '94.96%'}\n",
      "Val Loss: 0.512585, Val Acc: 87.77%, Val-Class-Acc: {0: '92.39%', 1: '83.15%'}, LR: 0.002933\n",
      "Epoch 111/300, Train Loss: 0.051038, Train-Class-Acc: {0: '99.46%', 1: '95.50%'}\n",
      "Val Loss: 1.045780, Val Acc: 81.79%, Val-Class-Acc: {0: '69.57%', 1: '94.02%'}, LR: 0.002926\n",
      "Epoch 112/300, Train Loss: 0.105699, Train-Class-Acc: {0: '97.96%', 1: '94.14%'}\n",
      "Val Loss: 0.483594, Val Acc: 87.50%, Val-Class-Acc: {0: '87.50%', 1: '87.50%'}, LR: 0.002919\n",
      "Epoch 113/300, Train Loss: 0.045264, Train-Class-Acc: {0: '98.77%', 1: '96.32%'}\n",
      "Val Loss: 1.617835, Val Acc: 84.24%, Val-Class-Acc: {0: '96.74%', 1: '71.74%'}, LR: 0.002912\n",
      "Epoch 114/300, Train Loss: 0.112228, Train-Class-Acc: {0: '96.59%', 1: '93.60%'}\n",
      "Val Loss: 0.525524, Val Acc: 86.14%, Val-Class-Acc: {0: '80.98%', 1: '91.30%'}, LR: 0.002904\n",
      "Epoch 115/300, Train Loss: 0.065434, Train-Class-Acc: {0: '98.09%', 1: '96.59%'}\n",
      "Val Loss: 0.797914, Val Acc: 86.68%, Val-Class-Acc: {0: '96.20%', 1: '77.17%'}, LR: 0.002896\n",
      "Epoch 116/300, Train Loss: 0.092394, Train-Class-Acc: {0: '97.14%', 1: '96.05%'}\n",
      "Val Loss: 0.538740, Val Acc: 88.04%, Val-Class-Acc: {0: '88.04%', 1: '88.04%'}, LR: 0.002888\n",
      "Epoch 117/300, Train Loss: 0.037535, Train-Class-Acc: {0: '99.73%', 1: '95.37%'}\n",
      "Val Loss: 0.642482, Val Acc: 88.86%, Val-Class-Acc: {0: '90.76%', 1: '86.96%'}, LR: 0.002879\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_64.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_117.pth\n",
      "驗證未改善。耐心值: 4/30\n",
      "Epoch 118/300, Train Loss: 0.031177, Train-Class-Acc: {0: '99.73%', 1: '98.09%'}\n",
      "Val Loss: 0.921553, Val Acc: 86.96%, Val-Class-Acc: {0: '91.30%', 1: '82.61%'}, LR: 0.002870\n",
      "Epoch 119/300, Train Loss: 0.050348, Train-Class-Acc: {0: '99.18%', 1: '96.19%'}\n",
      "Val Loss: 0.756999, Val Acc: 83.15%, Val-Class-Acc: {0: '76.09%', 1: '90.22%'}, LR: 0.002861\n",
      "Epoch 120/300, Train Loss: 0.095595, Train-Class-Acc: {0: '96.46%', 1: '94.55%'}\n",
      "Val Loss: 0.529992, Val Acc: 87.50%, Val-Class-Acc: {0: '91.30%', 1: '83.70%'}, LR: 0.002851\n",
      "Epoch 121/300, Train Loss: 0.062646, Train-Class-Acc: {0: '97.68%', 1: '97.28%'}\n",
      "Val Loss: 0.800116, Val Acc: 82.07%, Val-Class-Acc: {0: '71.74%', 1: '92.39%'}, LR: 0.002841\n",
      "Epoch 122/300, Train Loss: 0.070891, Train-Class-Acc: {0: '98.37%', 1: '96.19%'}\n",
      "Val Loss: 0.689639, Val Acc: 85.87%, Val-Class-Acc: {0: '82.61%', 1: '89.13%'}, LR: 0.002831\n",
      "Epoch 123/300, Train Loss: 0.038470, Train-Class-Acc: {0: '99.59%', 1: '97.14%'}\n",
      "Val Loss: 0.856931, Val Acc: 86.96%, Val-Class-Acc: {0: '88.59%', 1: '85.33%'}, LR: 0.002821\n",
      "Epoch 124/300, Train Loss: 0.133782, Train-Class-Acc: {0: '96.73%', 1: '95.37%'}\n",
      "Val Loss: 0.571038, Val Acc: 85.87%, Val-Class-Acc: {0: '82.61%', 1: '89.13%'}, LR: 0.002810\n",
      "Epoch 125/300, Train Loss: 0.074564, Train-Class-Acc: {0: '98.09%', 1: '95.50%'}\n",
      "Val Loss: 0.617302, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.002799\n",
      "Epoch 126/300, Train Loss: 0.066978, Train-Class-Acc: {0: '98.77%', 1: '96.05%'}\n",
      "Val Loss: 0.609107, Val Acc: 84.78%, Val-Class-Acc: {0: '81.52%', 1: '88.04%'}, LR: 0.002787\n",
      "Epoch 127/300, Train Loss: 0.070828, Train-Class-Acc: {0: '98.50%', 1: '95.50%'}\n",
      "Val Loss: 0.830432, Val Acc: 86.14%, Val-Class-Acc: {0: '90.22%', 1: '82.07%'}, LR: 0.002776\n",
      "Epoch 128/300, Train Loss: 0.047469, Train-Class-Acc: {0: '98.91%', 1: '96.87%'}\n",
      "Val Loss: 0.858949, Val Acc: 86.41%, Val-Class-Acc: {0: '90.22%', 1: '82.61%'}, LR: 0.002764\n",
      "Epoch 129/300, Train Loss: 0.030219, Train-Class-Acc: {0: '99.59%', 1: '97.68%'}\n",
      "Val Loss: 0.985617, Val Acc: 86.14%, Val-Class-Acc: {0: '89.67%', 1: '82.61%'}, LR: 0.002752\n",
      "Epoch 130/300, Train Loss: 0.051968, Train-Class-Acc: {0: '98.50%', 1: '96.59%'}\n",
      "Val Loss: 0.826458, Val Acc: 86.96%, Val-Class-Acc: {0: '90.76%', 1: '83.15%'}, LR: 0.002739\n",
      "Epoch 131/300, Train Loss: 0.074569, Train-Class-Acc: {0: '98.09%', 1: '94.69%'}\n",
      "Val Loss: 0.703305, Val Acc: 85.60%, Val-Class-Acc: {0: '84.78%', 1: '86.41%'}, LR: 0.002726\n",
      "Epoch 132/300, Train Loss: 0.061632, Train-Class-Acc: {0: '98.37%', 1: '95.23%'}\n",
      "Val Loss: 0.658512, Val Acc: 88.04%, Val-Class-Acc: {0: '86.41%', 1: '89.67%'}, LR: 0.002713\n",
      "Epoch 133/300, Train Loss: 0.023598, Train-Class-Acc: {0: '99.86%', 1: '97.68%'}\n",
      "Val Loss: 0.938386, Val Acc: 87.50%, Val-Class-Acc: {0: '86.41%', 1: '88.59%'}, LR: 0.002700\n",
      "Epoch 134/300, Train Loss: 0.022286, Train-Class-Acc: {0: '99.86%', 1: '97.14%'}\n",
      "Val Loss: 1.522491, Val Acc: 87.23%, Val-Class-Acc: {0: '89.13%', 1: '85.33%'}, LR: 0.002686\n",
      "Epoch 135/300, Train Loss: 0.179778, Train-Class-Acc: {0: '95.91%', 1: '92.64%'}\n",
      "Val Loss: 0.562967, Val Acc: 85.60%, Val-Class-Acc: {0: '92.93%', 1: '78.26%'}, LR: 0.002672\n",
      "Epoch 136/300, Train Loss: 0.096856, Train-Class-Acc: {0: '97.55%', 1: '94.28%'}\n",
      "Val Loss: 0.772134, Val Acc: 83.42%, Val-Class-Acc: {0: '78.26%', 1: '88.59%'}, LR: 0.002658\n",
      "Epoch 137/300, Train Loss: 0.086938, Train-Class-Acc: {0: '97.41%', 1: '94.96%'}\n",
      "Val Loss: 0.669319, Val Acc: 86.14%, Val-Class-Acc: {0: '80.98%', 1: '91.30%'}, LR: 0.002644\n",
      "Epoch 138/300, Train Loss: 0.063661, Train-Class-Acc: {0: '99.05%', 1: '96.32%'}\n",
      "Val Loss: 0.540840, Val Acc: 88.86%, Val-Class-Acc: {0: '88.04%', 1: '89.67%'}, LR: 0.002629\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_83.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_138.pth\n",
      "驗證未改善。耐心值: 5/30\n",
      "Epoch 139/300, Train Loss: 0.033934, Train-Class-Acc: {0: '99.86%', 1: '96.87%'}\n",
      "Val Loss: 1.207089, Val Acc: 86.41%, Val-Class-Acc: {0: '95.11%', 1: '77.72%'}, LR: 0.002614\n",
      "Epoch 140/300, Train Loss: 0.023096, Train-Class-Acc: {0: '99.86%', 1: '97.00%'}\n",
      "Val Loss: 0.905853, Val Acc: 87.77%, Val-Class-Acc: {0: '90.22%', 1: '85.33%'}, LR: 0.002599\n",
      "Epoch 141/300, Train Loss: 0.026345, Train-Class-Acc: {0: '99.46%', 1: '97.14%'}\n",
      "Val Loss: 0.984478, Val Acc: 87.77%, Val-Class-Acc: {0: '90.22%', 1: '85.33%'}, LR: 0.002584\n",
      "Epoch 142/300, Train Loss: 0.087035, Train-Class-Acc: {0: '97.82%', 1: '95.10%'}\n",
      "Val Loss: 0.633193, Val Acc: 89.13%, Val-Class-Acc: {0: '95.65%', 1: '82.61%'}, LR: 0.002568\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_99.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_142.pth\n",
      "驗證未改善。耐心值: 6/30\n",
      "Epoch 143/300, Train Loss: 0.061883, Train-Class-Acc: {0: '99.05%', 1: '95.78%'}\n",
      "Val Loss: 0.573024, Val Acc: 86.41%, Val-Class-Acc: {0: '82.61%', 1: '90.22%'}, LR: 0.002552\n",
      "Epoch 144/300, Train Loss: 0.040479, Train-Class-Acc: {0: '98.91%', 1: '96.87%'}\n",
      "Val Loss: 0.666260, Val Acc: 86.14%, Val-Class-Acc: {0: '91.85%', 1: '80.43%'}, LR: 0.002536\n",
      "Epoch 145/300, Train Loss: 0.066882, Train-Class-Acc: {0: '98.37%', 1: '95.91%'}\n",
      "Val Loss: 1.548510, Val Acc: 82.34%, Val-Class-Acc: {0: '75.54%', 1: '89.13%'}, LR: 0.002520\n",
      "Epoch 146/300, Train Loss: 0.087867, Train-Class-Acc: {0: '97.96%', 1: '95.64%'}\n",
      "Val Loss: 0.645581, Val Acc: 88.04%, Val-Class-Acc: {0: '91.30%', 1: '84.78%'}, LR: 0.002503\n",
      "Epoch 147/300, Train Loss: 0.045236, Train-Class-Acc: {0: '99.46%', 1: '96.87%'}\n",
      "Val Loss: 0.676173, Val Acc: 86.41%, Val-Class-Acc: {0: '88.59%', 1: '84.24%'}, LR: 0.002487\n",
      "Epoch 148/300, Train Loss: 0.020490, Train-Class-Acc: {0: '100.00%', 1: '97.82%'}\n",
      "Val Loss: 0.845232, Val Acc: 87.50%, Val-Class-Acc: {0: '88.04%', 1: '86.96%'}, LR: 0.002470\n",
      "Epoch 149/300, Train Loss: 0.026884, Train-Class-Acc: {0: '99.59%', 1: '97.55%'}\n",
      "Val Loss: 0.798611, Val Acc: 86.14%, Val-Class-Acc: {0: '85.33%', 1: '86.96%'}, LR: 0.002452\n",
      "Epoch 150/300, Train Loss: 0.032828, Train-Class-Acc: {0: '99.05%', 1: '96.73%'}\n",
      "Val Loss: 0.804816, Val Acc: 86.41%, Val-Class-Acc: {0: '89.13%', 1: '83.70%'}, LR: 0.002435\n",
      "Epoch 151/300, Train Loss: 0.060031, Train-Class-Acc: {0: '98.50%', 1: '96.87%'}\n",
      "Val Loss: 0.835565, Val Acc: 87.23%, Val-Class-Acc: {0: '94.57%', 1: '79.89%'}, LR: 0.002417\n",
      "Epoch 152/300, Train Loss: 0.051138, Train-Class-Acc: {0: '98.37%', 1: '96.73%'}\n",
      "Val Loss: 0.782960, Val Acc: 86.41%, Val-Class-Acc: {0: '86.96%', 1: '85.87%'}, LR: 0.002399\n",
      "Epoch 153/300, Train Loss: 0.026873, Train-Class-Acc: {0: '99.73%', 1: '97.28%'}\n",
      "Val Loss: 0.909911, Val Acc: 88.32%, Val-Class-Acc: {0: '89.13%', 1: '87.50%'}, LR: 0.002381\n",
      "Epoch 154/300, Train Loss: 0.045281, Train-Class-Acc: {0: '98.64%', 1: '96.73%'}\n",
      "Val Loss: 1.137987, Val Acc: 86.96%, Val-Class-Acc: {0: '92.39%', 1: '81.52%'}, LR: 0.002363\n",
      "Epoch 155/300, Train Loss: 0.104083, Train-Class-Acc: {0: '97.41%', 1: '96.05%'}\n",
      "Val Loss: 0.605014, Val Acc: 86.96%, Val-Class-Acc: {0: '95.11%', 1: '78.80%'}, LR: 0.002345\n",
      "Epoch 156/300, Train Loss: 0.050514, Train-Class-Acc: {0: '99.46%', 1: '96.19%'}\n",
      "Val Loss: 0.755740, Val Acc: 86.41%, Val-Class-Acc: {0: '85.33%', 1: '87.50%'}, LR: 0.002326\n",
      "Epoch 157/300, Train Loss: 0.029524, Train-Class-Acc: {0: '99.18%', 1: '97.55%'}\n",
      "Val Loss: 0.860047, Val Acc: 88.32%, Val-Class-Acc: {0: '91.85%', 1: '84.78%'}, LR: 0.002307\n",
      "Epoch 158/300, Train Loss: 0.022952, Train-Class-Acc: {0: '100.00%', 1: '97.41%'}\n",
      "Val Loss: 0.890114, Val Acc: 88.59%, Val-Class-Acc: {0: '89.13%', 1: '88.04%'}, LR: 0.002288\n",
      "Epoch 159/300, Train Loss: 0.020173, Train-Class-Acc: {0: '99.86%', 1: '97.55%'}\n",
      "Val Loss: 1.045177, Val Acc: 86.68%, Val-Class-Acc: {0: '89.67%', 1: '83.70%'}, LR: 0.002269\n",
      "Epoch 160/300, Train Loss: 0.052866, Train-Class-Acc: {0: '99.18%', 1: '96.46%'}\n",
      "Val Loss: 0.976631, Val Acc: 87.77%, Val-Class-Acc: {0: '90.22%', 1: '85.33%'}, LR: 0.002250\n",
      "Epoch 161/300, Train Loss: 0.074081, Train-Class-Acc: {0: '98.50%', 1: '95.91%'}\n",
      "Val Loss: 1.052373, Val Acc: 85.60%, Val-Class-Acc: {0: '95.11%', 1: '76.09%'}, LR: 0.002230\n",
      "Epoch 162/300, Train Loss: 0.057818, Train-Class-Acc: {0: '98.23%', 1: '95.37%'}\n",
      "Val Loss: 0.710675, Val Acc: 86.68%, Val-Class-Acc: {0: '85.87%', 1: '87.50%'}, LR: 0.002210\n",
      "Epoch 163/300, Train Loss: 0.025985, Train-Class-Acc: {0: '99.73%', 1: '97.55%'}\n",
      "Val Loss: 0.864838, Val Acc: 87.77%, Val-Class-Acc: {0: '89.13%', 1: '86.41%'}, LR: 0.002191\n",
      "Epoch 164/300, Train Loss: 0.064416, Train-Class-Acc: {0: '98.64%', 1: '96.46%'}\n",
      "Val Loss: 1.287594, Val Acc: 85.05%, Val-Class-Acc: {0: '95.65%', 1: '74.46%'}, LR: 0.002171\n",
      "Epoch 165/300, Train Loss: 0.062928, Train-Class-Acc: {0: '98.37%', 1: '96.19%'}\n",
      "Val Loss: 0.706854, Val Acc: 88.04%, Val-Class-Acc: {0: '90.76%', 1: '85.33%'}, LR: 0.002150\n",
      "Epoch 166/300, Train Loss: 0.025187, Train-Class-Acc: {0: '100.00%', 1: '97.96%'}\n",
      "Val Loss: 0.753701, Val Acc: 89.40%, Val-Class-Acc: {0: '90.22%', 1: '88.59%'}, LR: 0.002130\n",
      "🗑 移除: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_106.pth\n",
      "✅ 保存模型: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_166.pth\n",
      "驗證準確率從 89.13% 提升到 89.40%\n",
      "Epoch 167/300, Train Loss: 0.026203, Train-Class-Acc: {0: '99.73%', 1: '96.46%'}\n",
      "Val Loss: 1.045436, Val Acc: 86.96%, Val-Class-Acc: {0: '88.04%', 1: '85.87%'}, LR: 0.002110\n",
      "Epoch 168/300, Train Loss: 0.038983, Train-Class-Acc: {0: '99.46%', 1: '97.14%'}\n",
      "Val Loss: 0.786027, Val Acc: 88.32%, Val-Class-Acc: {0: '90.22%', 1: '86.41%'}, LR: 0.002089\n",
      "Epoch 169/300, Train Loss: 0.095381, Train-Class-Acc: {0: '97.96%', 1: '94.82%'}\n",
      "Val Loss: 0.582003, Val Acc: 87.23%, Val-Class-Acc: {0: '91.85%', 1: '82.61%'}, LR: 0.002068\n",
      "Epoch 170/300, Train Loss: 0.058701, Train-Class-Acc: {0: '99.18%', 1: '95.50%'}\n",
      "Val Loss: 0.701382, Val Acc: 87.50%, Val-Class-Acc: {0: '92.39%', 1: '82.61%'}, LR: 0.002048\n",
      "Epoch 171/300, Train Loss: 0.021338, Train-Class-Acc: {0: '99.73%', 1: '97.82%'}\n",
      "Val Loss: 0.943948, Val Acc: 87.77%, Val-Class-Acc: {0: '90.76%', 1: '84.78%'}, LR: 0.002027\n",
      "\n",
      "🛑 檢測到停止信號。退出訓練循環。\n",
      "\n",
      "🏆 最佳模型保存為: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_best.pth (驗證準確率: 89.40%)\n",
      "\n",
      "📌 最終模型保存為: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_final.pth\n",
      "\n",
      "🎯 前5個最佳模型:\n",
      "Epoch 166, Train Loss: 0.025187, Train-Acc: {0: '100.00%', 1: '97.96%'},\n",
      "Val Loss: 0.753701, Val Acc: 89.40%, Val-Class-Acc: {0: '90.22%', 1: '88.59%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_166.pth\n",
      "Epoch 142, Train Loss: 0.087035, Train-Acc: {0: '97.82%', 1: '95.10%'},\n",
      "Val Loss: 0.633193, Val Acc: 89.13%, Val-Class-Acc: {0: '95.65%', 1: '82.61%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_142.pth\n",
      "Epoch 91, Train Loss: 0.177345, Train-Acc: {0: '95.10%', 1: '91.14%'},\n",
      "Val Loss: 0.443444, Val Acc: 89.13%, Val-Class-Acc: {0: '85.33%', 1: '92.93%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_91.pth\n",
      "Epoch 138, Train Loss: 0.063661, Train-Acc: {0: '99.05%', 1: '96.32%'},\n",
      "Val Loss: 0.540840, Val Acc: 88.86%, Val-Class-Acc: {0: '88.04%', 1: '89.67%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_138.pth\n",
      "Epoch 117, Train Loss: 0.037535, Train-Acc: {0: '99.73%', 1: '95.37%'},\n",
      "Val Loss: 0.642482, Val Acc: 88.86%, Val-Class-Acc: {0: '90.76%', 1: '86.96%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_epoch_117.pth\n",
      "\n",
      "🧠 模型摘要:\n",
      "總參數量: 7,509,378\n",
      "模型大小 (float32): 28.65 MB\n",
      "總訓練時間: 494.63 秒\n",
      "最佳驗證準確率: 89.40%\n",
      "最佳模型路徑: Class_Incremental_CL/CPSC_CIL/Model_Selection/ResNet18_Improved/ResNet18_1D_Improved_best.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "save_dir = os.path.join(BASE_DIR, \"processed\")\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))  # Shape: (B, 5000, 12)\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# 從第一個附件保留的數據增強函數\n",
    "def augment_ecg(signal, sigma=0.05, shift_max=20):\n",
    "    \"\"\"\n",
    "    對ECG信號進行數據增強\n",
    "    \n",
    "    Args:\n",
    "        signal: 形狀為 (B, T, C) 的ECG信號\n",
    "        sigma: 噪聲標準差\n",
    "        shift_max: 最大時間偏移量\n",
    "    \n",
    "    Returns:\n",
    "        增強後的信號\n",
    "    \"\"\"\n",
    "    # 添加噪聲\n",
    "    noise = np.random.normal(0, sigma, signal.shape)\n",
    "    signal_noisy = signal + noise\n",
    "    \n",
    "    # 隨機時間偏移\n",
    "    shift = np.random.randint(-shift_max, shift_max)\n",
    "    if shift > 0:\n",
    "        signal_shifted = np.pad(signal_noisy[:, :-shift, :], ((0, 0), (shift, 0), (0, 0)), mode='edge')\n",
    "    elif shift < 0:\n",
    "        signal_shifted = np.pad(signal_noisy[:, -shift:, :], ((0, 0), (0, -shift), (0, 0)), mode='edge')\n",
    "    else:\n",
    "        signal_shifted = signal_noisy\n",
    "        \n",
    "    # 縮放幅度 (±10%)\n",
    "    scale = np.random.uniform(0.9, 1.1)\n",
    "    signal_scaled = signal_shifted * scale\n",
    "    \n",
    "    return signal_scaled\n",
    "\n",
    "# 從第一個附件保留的ECG數據集類\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, X, y, augment=False, device=None):\n",
    "        \"\"\"\n",
    "        ECG數據集類，支持數據增強\n",
    "        \n",
    "        Args:\n",
    "            X: 輸入數據，形狀為 (N, T, C)\n",
    "            y: 標籤\n",
    "            augment: 是否使用數據增強\n",
    "            device: 設備(CPU/GPU)\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.augment = augment\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx].copy()  # 創建副本以避免修改原始數據\n",
    "        \n",
    "        if self.augment and np.random.rand() > 0.5:  # 50% 的概率進行增強\n",
    "            x = augment_ecg(x[np.newaxis, ...])[0]  # 增加和移除 batch 維度\n",
    "            \n",
    "        x_tensor = torch.FloatTensor(x)\n",
    "        y_tensor = torch.LongTensor([self.y[idx]])[0]\n",
    "        \n",
    "        if self.device:\n",
    "            x_tensor = x_tensor.to(self.device)\n",
    "            y_tensor = y_tensor.to(self.device)\n",
    "            \n",
    "        return x_tensor, y_tensor\n",
    "\n",
    "# 從第二個附件保留的計算類別精度函數\n",
    "def compute_classwise_accuracy(student_logits_flat, y_batch, class_correct, class_total):\n",
    "    \"\"\"\n",
    "    計算每個類別的準確率\n",
    "    \n",
    "    Args:\n",
    "        student_logits_flat: 模型預測\n",
    "        y_batch: 真實標籤\n",
    "        class_correct: 每個類別正確預測的字典\n",
    "        class_total: 每個類別總樣本的字典\n",
    "    \"\"\"\n",
    "    # 確保輸入在同一設備上\n",
    "    if student_logits_flat.device != y_batch.device:\n",
    "        raise ValueError(\"student_logits_flat and y_batch must be on the same device\")\n",
    "\n",
    "    # 轉換logits為預測類別索引\n",
    "    predictions = torch.argmax(student_logits_flat, dim=-1)  # 形狀: [batch_size * seq_len]\n",
    "\n",
    "    # 計算正確預測掩碼\n",
    "    correct_mask = (predictions == y_batch)  # 形狀: [batch_size * seq_len], 布爾值\n",
    "\n",
    "    # 獲取此批次中的唯一標籤\n",
    "    unique_labels = torch.unique(y_batch)\n",
    "\n",
    "    # 使用向量化操作更新class_total和class_correct\n",
    "    for label in unique_labels:\n",
    "        label = label.item()  # 將張量轉換為標量\n",
    "        if label not in class_total:\n",
    "            class_total[label] = 0\n",
    "            class_correct[label] = 0\n",
    "        \n",
    "        # 計算此標籤的總樣本數\n",
    "        label_mask = (y_batch == label)\n",
    "        class_total[label] += label_mask.sum().item()\n",
    "        \n",
    "        # 計算此標籤的正確預測數\n",
    "        class_correct[label] += (label_mask & correct_mask).sum().item()\n",
    "\n",
    "# 從第二個附件保留的獲取模型參數信息函數\n",
    "def get_model_parameter_info(model):\n",
    "    \"\"\"獲取模型的參數數量和大小\"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    param_size_bytes = total_params * 4  # 以float32計算\n",
    "    param_size_MB = param_size_bytes / (1024**2)\n",
    "    return total_params, param_size_MB\n",
    "\n",
    "# 整合後的訓練函數\n",
    "def train_model_with_early_stopping(\n",
    "    model, output_size, \n",
    "    X_train, y_train, X_val, y_val,\n",
    "    num_epochs=300, batch_size=32, \n",
    "    learning_rate=3e-4, weight_decay=1e-4,\n",
    "    dropout_rate=0.3, patience=30,\n",
    "    use_class_weights=True, use_data_augmentation=True,\n",
    "    use_one_cycle_lr=True, model_saving_folder=None,\n",
    "    model_name=None, stop_signal_file=None, device=None):\n",
    "    \"\"\"\n",
    "    整合版的訓練函數，結合了數據增強、早停和詳細日誌功能\n",
    "    \n",
    "    Args:\n",
    "        model: 要訓練的模型\n",
    "        output_size: 輸出類別數\n",
    "        X_train: 訓練數據\n",
    "        y_train: 訓練標籤\n",
    "        X_val: 驗證數據\n",
    "        y_val: 驗證標籤\n",
    "        num_epochs: 訓練輪數\n",
    "        batch_size: 批次大小\n",
    "        learning_rate: 學習率\n",
    "        weight_decay: 權重衰減係數\n",
    "        dropout_rate: Dropout率\n",
    "        patience: 早停耐心值\n",
    "        use_class_weights: 是否使用類別權重\n",
    "        use_data_augmentation: 是否使用數據增強\n",
    "        use_one_cycle_lr: 是否使用OneCycleLR調度器\n",
    "        model_saving_folder: 模型保存路徑\n",
    "        model_name: 模型名稱\n",
    "        stop_signal_file: 停止信號文件路徑\n",
    "        device: 設備(CPU/GPU)\n",
    "    \n",
    "    Returns:\n",
    "        訓練結果信息字典\n",
    "    \"\"\"\n",
    "    print(\"\\n🚀 '整合版訓練函數' 開始運行.\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # === 文件夾設置 ===\n",
    "    if model_saving_folder:\n",
    "        os.makedirs(model_saving_folder, exist_ok=True)\n",
    "        print(f\"✅ 確保模型保存文件夾存在: {model_saving_folder}\")\n",
    "\n",
    "    model_name = model_name or 'model'\n",
    "    model_saving_folder = model_saving_folder or './saved_models'\n",
    "\n",
    "    # === 設備設置 ===\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # === 數據預處理 ===\n",
    "    print(\"\\n✅ 數據概覽:\")\n",
    "    print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "    \n",
    "    # === 計算類別權重 ===\n",
    "    if use_class_weights:\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        print(f\"✅ 使用類別權重: {class_weights.cpu().numpy()}\")\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        print(\"✅ 使用標準交叉熵損失函數(無類別權重)\")\n",
    "    \n",
    "    # === 創建數據集和數據加載器 ===\n",
    "    train_dataset = ECGDataset(X_train, y_train, augment=use_data_augmentation, device=None)\n",
    "    val_dataset = ECGDataset(X_val, y_val, augment=False, device=None)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # === 優化器設置 ===\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # === 學習率調度器設置 ===\n",
    "    if use_one_cycle_lr:\n",
    "        steps_per_epoch = len(train_loader)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=learning_rate*10,             # 最大學習率為初始學習率的10倍\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=num_epochs,\n",
    "            pct_start=0.3,                       # 在 30% 的訓練過程中達到最大學習率\n",
    "            div_factor=25,                       # 初始學習率為最大值的 1/25\n",
    "            final_div_factor=1000                # 最終學習率為初始學習率的 1/1000\n",
    "        )\n",
    "        print(\"✅ 使用OneCycleLR學習率調度器\")\n",
    "    else:\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=10, verbose=True\n",
    "        )\n",
    "        print(\"✅ 使用ReduceLROnPlateau學習率調度器\")\n",
    "    \n",
    "    # === 訓練變量初始化 ===\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = 0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    best_results = []\n",
    "    epoch_history = []\n",
    "    \n",
    "    # === 訓練循環 ===\n",
    "    for epoch in range(num_epochs):\n",
    "        # 檢查是否存在停止信號\n",
    "        if stop_signal_file and os.path.exists(stop_signal_file):\n",
    "            print(\"\\n🛑 檢測到停止信號。退出訓練循環。\")\n",
    "            break\n",
    "        \n",
    "        # 訓練階段\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_class_correct, train_class_total = {}, {}\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if use_one_cycle_lr:\n",
    "                scheduler.step()\n",
    "                \n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "            compute_classwise_accuracy(outputs, y_batch, train_class_correct, train_class_total)\n",
    "        \n",
    "        # 計算訓練指標\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = {int(c): f\"{(train_class_correct[c] / train_class_total[c]) * 100:.2f}%\" \n",
    "                    if train_class_total[c] > 0 else \"0.00%\" \n",
    "                    for c in sorted(train_class_total.keys())}\n",
    "        \n",
    "        # 驗證階段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct, val_total = 0, 0\n",
    "        val_class_correct, val_class_total = {}, {}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                \n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "                predictions = torch.argmax(outputs, dim=-1)\n",
    "                val_correct += (predictions == y_batch).sum().item()\n",
    "                val_total += y_batch.size(0)\n",
    "                compute_classwise_accuracy(outputs, y_batch, val_class_correct, val_class_total)\n",
    "        \n",
    "        # 計算驗證指標\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_acc_cls = {int(c): f\"{(val_class_correct[c] / val_class_total[c]) * 100:.2f}%\" \n",
    "                      if val_class_total[c] > 0 else \"0.00%\" \n",
    "                      for c in sorted(val_class_total.keys())}\n",
    "        \n",
    "        # 更新學習率調度器(如果不是OneCycleLR)\n",
    "        if not use_one_cycle_lr:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        # 打印訓練信息\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}, Train-Class-Acc: {train_acc}\")\n",
    "        print(f\"Val Loss: {val_loss:.6f}, Val Acc: {val_acc * 100:.2f}%, Val-Class-Acc: {val_acc_cls}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # 保存當前模型狀態\n",
    "        model_path = os.path.join(model_saving_folder, f\"{model_name}_epoch_{epoch+1}.pth\")\n",
    "        current = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_acc,\n",
    "            'train_classwise_accuracy': train_acc,\n",
    "            'val_classwise_accuracy': val_acc_cls,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'learning_rate': optimizer.param_groups[0]['lr'],\n",
    "            'model_path': model_path\n",
    "        }\n",
    "        \n",
    "        epoch_history.append(current)\n",
    "        \n",
    "        # 檢查是否需要保存模型\n",
    "        if len(best_results) < 5 or val_acc > best_results[-1]['val_accuracy']:\n",
    "            if len(best_results) == 5:\n",
    "                to_remove = best_results.pop()\n",
    "                if os.path.exists(to_remove['model_path']):\n",
    "                    os.remove(to_remove['model_path'])\n",
    "                    print(f\"🗑 移除: {to_remove['model_path']}\")\n",
    "            best_results.append(current)\n",
    "            best_results.sort(key=lambda x: (x['val_accuracy'], x['epoch']), reverse=True)\n",
    "            torch.save(current, model_path)\n",
    "            print(f\"✅ 保存模型: {model_path}\")\n",
    "            \n",
    "            # 更新最佳模型狀態(用於早停)\n",
    "            if val_acc > best_val_acc or (val_acc == best_val_acc and val_loss < best_val_loss):\n",
    "                print(f'驗證準確率從 {best_val_acc*100:.2f}% 提升到 {val_acc*100:.2f}%')\n",
    "                best_val_acc = val_acc\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = copy.deepcopy(model.state_dict())\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f'驗證未改善。耐心值: {patience_counter}/{patience}')\n",
    "                \n",
    "                if patience_counter >= patience:\n",
    "                    print(f'早停在第 {epoch+1} 輪後觸發')\n",
    "                    break\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    total_params, param_size_MB = get_model_parameter_info(model)\n",
    "    \n",
    "    # 恢復最佳模型\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if best_results:\n",
    "        best = best_results[0]\n",
    "        best_model_path = os.path.join(model_saving_folder, f\"{model_name}_best.pth\")\n",
    "        torch.save(best, best_model_path)\n",
    "        print(f\"\\n🏆 最佳模型保存為: {best_model_path} (驗證準確率: {best['val_accuracy'] * 100:.2f}%)\")\n",
    "    \n",
    "    # 保存最終模型\n",
    "    final_model_path = os.path.join(model_saving_folder, f\"{model_name}_final.pth\")\n",
    "    torch.save(current, final_model_path)\n",
    "    print(f\"\\n📌 最終模型保存為: {final_model_path}\")\n",
    "    \n",
    "    # 打印最佳模型信息\n",
    "    print(\"\\n🎯 前5個最佳模型:\")\n",
    "    for res in best_results:\n",
    "        print(f\"Epoch {res['epoch']}, Train Loss: {res['train_loss']:.6f}, Train-Acc: {res['train_classwise_accuracy']},\\n\"\n",
    "              f\"Val Loss: {res['val_loss']:.6f}, Val Acc: {res['val_accuracy']*100:.2f}%, Val-Class-Acc: {res['val_classwise_accuracy']},\"\n",
    "              f\" Model Path: {res['model_path']}\")\n",
    "    \n",
    "    # 打印模型摘要\n",
    "    print(f\"\\n🧠 模型摘要:\")\n",
    "    print(f\"總參數量: {total_params:,}\")\n",
    "    print(f\"模型大小 (float32): {param_size_MB:.2f} MB\")\n",
    "    print(f\"總訓練時間: {training_time:.2f} 秒\")\n",
    "    \n",
    "    # 清理\n",
    "    del train_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return {\n",
    "        'training_time_sec': training_time,\n",
    "        'total_params': total_params,\n",
    "        'model_size_MB': param_size_MB,\n",
    "        'best_val_accuracy': best_results[0]['val_accuracy'] if best_results else None,\n",
    "        'val_classwise_accuracy': best_results[0]['val_classwise_accuracy'] if best_results else None,\n",
    "        'best_model_path': best_model_path if best_results else None,\n",
    "        'final_model_path': final_model_path,\n",
    "        'epoch_history': epoch_history\n",
    "    }\n",
    "\n",
    "# 使用示例\n",
    "\n",
    "# ==== 改進的訓練代碼 ====\n",
    "model = ResNet18_1D_Improved(\n",
    "    input_channels=X_train.shape[2], \n",
    "    output_size=len(np.unique(y_train)),\n",
    "    dropout_rate=0.3\n",
    ").to(device)\n",
    "\n",
    "# 設置路徑\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/ResNet18_Improved\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# 使用整合版的訓練函數\n",
    "training_result = train_model_with_early_stopping(\n",
    "    model=model,\n",
    "    output_size=len(np.unique(y_train)),\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    num_epochs=300,\n",
    "    batch_size=32,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=1e-4,\n",
    "    dropout_rate=0.3,\n",
    "    patience=30,\n",
    "    use_class_weights=True,\n",
    "    use_data_augmentation=True,\n",
    "    use_one_cycle_lr=True,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name=\"ResNet18_1D_Improved\",\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"最佳驗證準確率: {training_result['best_val_accuracy']*100:.2f}%\")\n",
    "print(f\"最佳模型路徑: {training_result['best_model_path']}\")\n",
    "\n",
    "# 清理\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aaaa1a",
   "metadata": {},
   "source": [
    "### Bi-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43e2289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Automatically selected GPU:\n",
      "    - CUDA Device ID : 0\n",
      "    - Memory Used    : 58 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "✅ input shape: (1468, 5000, 12)\n",
      "✅ unique y_train: [0 1]\n",
      "✅ unique y_test : [0 1]\n",
      "\n",
      "🚀 'train_model_general_classifier' started.\n",
      "✅ Removed existing folder: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU\n",
      "\n",
      "✅ Data Overview:\n",
      "X_train: torch.Size([1468, 5000, 12]), y_train: torch.Size([1468])\n",
      "X_val: torch.Size([368, 5000, 12]), y_val: torch.Size([368])\n",
      "Epoch 1/200, Train Loss: 0.604521, Train-Class-Acc: {0: '83.51%', 1: '48.91%'}\n",
      "Val Loss: 0.556891, Val Acc: 74.73%, Val-Class-Acc: {0: '63.59%', 1: '85.87%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.472392, Train-Class-Acc: {0: '83.24%', 1: '72.21%'}\n",
      "Val Loss: 0.471113, Val Acc: 80.16%, Val-Class-Acc: {0: '74.46%', 1: '85.87%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.429686, Train-Class-Acc: {0: '83.92%', 1: '78.07%'}\n",
      "Val Loss: 0.454914, Val Acc: 80.16%, Val-Class-Acc: {0: '82.07%', 1: '78.26%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.417916, Train-Class-Acc: {0: '86.10%', 1: '75.75%'}\n",
      "Val Loss: 0.433437, Val Acc: 80.98%, Val-Class-Acc: {0: '89.13%', 1: '72.83%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.406579, Train-Class-Acc: {0: '85.15%', 1: '77.25%'}\n",
      "Val Loss: 0.441837, Val Acc: 80.16%, Val-Class-Acc: {0: '88.04%', 1: '72.28%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.390211, Train-Class-Acc: {0: '86.51%', 1: '79.02%'}\n",
      "Val Loss: 0.419367, Val Acc: 81.52%, Val-Class-Acc: {0: '82.07%', 1: '80.98%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_1.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_6.pth\n",
      "Epoch 7/200, Train Loss: 0.379121, Train-Class-Acc: {0: '88.69%', 1: '78.47%'}\n",
      "Val Loss: 0.431146, Val Acc: 80.16%, Val-Class-Acc: {0: '77.17%', 1: '83.15%'}, LR: 0.001000\n",
      "Epoch 8/200, Train Loss: 0.377513, Train-Class-Acc: {0: '86.24%', 1: '79.02%'}\n",
      "Val Loss: 0.415584, Val Acc: 82.07%, Val-Class-Acc: {0: '90.76%', 1: '73.37%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_2.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_8.pth\n",
      "Epoch 9/200, Train Loss: 0.386151, Train-Class-Acc: {0: '86.38%', 1: '78.88%'}\n",
      "Val Loss: 0.446406, Val Acc: 78.26%, Val-Class-Acc: {0: '94.02%', 1: '62.50%'}, LR: 0.001000\n",
      "Epoch 10/200, Train Loss: 0.370077, Train-Class-Acc: {0: '87.06%', 1: '78.47%'}\n",
      "Val Loss: 0.478901, Val Acc: 78.53%, Val-Class-Acc: {0: '94.57%', 1: '62.50%'}, LR: 0.001000\n",
      "Epoch 11/200, Train Loss: 0.350350, Train-Class-Acc: {0: '87.47%', 1: '80.52%'}\n",
      "Val Loss: 0.410566, Val Acc: 82.34%, Val-Class-Acc: {0: '85.87%', 1: '78.80%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_3.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_11.pth\n",
      "Epoch 12/200, Train Loss: 0.338781, Train-Class-Acc: {0: '86.92%', 1: '82.15%'}\n",
      "Val Loss: 0.388694, Val Acc: 83.70%, Val-Class-Acc: {0: '85.87%', 1: '81.52%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_5.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_12.pth\n",
      "Epoch 13/200, Train Loss: 0.326331, Train-Class-Acc: {0: '88.56%', 1: '80.79%'}\n",
      "Val Loss: 0.414874, Val Acc: 82.07%, Val-Class-Acc: {0: '82.07%', 1: '82.07%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_4.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_13.pth\n",
      "Epoch 14/200, Train Loss: 0.320070, Train-Class-Acc: {0: '88.83%', 1: '80.79%'}\n",
      "Val Loss: 0.383085, Val Acc: 83.42%, Val-Class-Acc: {0: '83.70%', 1: '83.15%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_6.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_14.pth\n",
      "Epoch 15/200, Train Loss: 0.295103, Train-Class-Acc: {0: '89.51%', 1: '83.92%'}\n",
      "Val Loss: 0.393686, Val Acc: 83.70%, Val-Class-Acc: {0: '81.52%', 1: '85.87%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_8.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_15.pth\n",
      "Epoch 16/200, Train Loss: 0.317334, Train-Class-Acc: {0: '88.28%', 1: '83.51%'}\n",
      "Val Loss: 0.407642, Val Acc: 81.25%, Val-Class-Acc: {0: '75.00%', 1: '87.50%'}, LR: 0.001000\n",
      "Epoch 17/200, Train Loss: 0.301156, Train-Class-Acc: {0: '89.10%', 1: '84.33%'}\n",
      "Val Loss: 0.382225, Val Acc: 84.24%, Val-Class-Acc: {0: '85.87%', 1: '82.61%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_13.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_17.pth\n",
      "Epoch 18/200, Train Loss: 0.263300, Train-Class-Acc: {0: '90.60%', 1: '85.29%'}\n",
      "Val Loss: 0.404736, Val Acc: 82.61%, Val-Class-Acc: {0: '89.13%', 1: '76.09%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_11.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_18.pth\n",
      "Epoch 19/200, Train Loss: 0.245695, Train-Class-Acc: {0: '91.96%', 1: '87.19%'}\n",
      "Val Loss: 0.447412, Val Acc: 81.79%, Val-Class-Acc: {0: '75.54%', 1: '88.04%'}, LR: 0.001000\n",
      "Epoch 20/200, Train Loss: 0.245960, Train-Class-Acc: {0: '91.14%', 1: '87.87%'}\n",
      "Val Loss: 0.394272, Val Acc: 83.42%, Val-Class-Acc: {0: '84.24%', 1: '82.61%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_18.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_20.pth\n",
      "Epoch 21/200, Train Loss: 0.233072, Train-Class-Acc: {0: '91.96%', 1: '87.87%'}\n",
      "Val Loss: 0.438410, Val Acc: 83.70%, Val-Class-Acc: {0: '87.50%', 1: '79.89%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_14.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_21.pth\n",
      "Epoch 22/200, Train Loss: 0.209163, Train-Class-Acc: {0: '91.55%', 1: '89.10%'}\n",
      "Val Loss: 0.477964, Val Acc: 82.34%, Val-Class-Acc: {0: '90.76%', 1: '73.91%'}, LR: 0.001000\n",
      "Epoch 23/200, Train Loss: 0.201057, Train-Class-Acc: {0: '92.78%', 1: '89.65%'}\n",
      "Val Loss: 0.458556, Val Acc: 82.07%, Val-Class-Acc: {0: '80.98%', 1: '83.15%'}, LR: 0.001000\n",
      "Epoch 24/200, Train Loss: 0.185831, Train-Class-Acc: {0: '93.19%', 1: '90.87%'}\n",
      "Val Loss: 0.478324, Val Acc: 83.42%, Val-Class-Acc: {0: '88.04%', 1: '78.80%'}, LR: 0.001000\n",
      "Epoch 25/200, Train Loss: 0.182934, Train-Class-Acc: {0: '94.28%', 1: '91.01%'}\n",
      "Val Loss: 0.467256, Val Acc: 82.07%, Val-Class-Acc: {0: '88.59%', 1: '75.54%'}, LR: 0.001000\n",
      "Epoch 26/200, Train Loss: 0.171428, Train-Class-Acc: {0: '93.19%', 1: '92.64%'}\n",
      "Val Loss: 0.618652, Val Acc: 80.43%, Val-Class-Acc: {0: '91.85%', 1: '69.02%'}, LR: 0.001000\n",
      "Epoch 27/200, Train Loss: 0.178149, Train-Class-Acc: {0: '93.46%', 1: '90.87%'}\n",
      "Val Loss: 0.496254, Val Acc: 82.88%, Val-Class-Acc: {0: '83.15%', 1: '82.61%'}, LR: 0.001000\n",
      "Epoch 28/200, Train Loss: 0.169482, Train-Class-Acc: {0: '94.14%', 1: '91.83%'}\n",
      "Val Loss: 0.503077, Val Acc: 81.25%, Val-Class-Acc: {0: '86.41%', 1: '76.09%'}, LR: 0.001000\n",
      "Epoch 29/200, Train Loss: 0.130458, Train-Class-Acc: {0: '94.82%', 1: '93.32%'}\n",
      "Val Loss: 0.492215, Val Acc: 84.78%, Val-Class-Acc: {0: '80.98%', 1: '88.59%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_20.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_29.pth\n",
      "Epoch 30/200, Train Loss: 0.093709, Train-Class-Acc: {0: '96.46%', 1: '96.19%'}\n",
      "Val Loss: 0.523017, Val Acc: 83.15%, Val-Class-Acc: {0: '83.70%', 1: '82.61%'}, LR: 0.000900\n",
      "Epoch 31/200, Train Loss: 0.088616, Train-Class-Acc: {0: '97.00%', 1: '96.87%'}\n",
      "Val Loss: 0.682079, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_12.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_31.pth\n",
      "Epoch 32/200, Train Loss: 0.078049, Train-Class-Acc: {0: '97.68%', 1: '97.00%'}\n",
      "Val Loss: 0.678535, Val Acc: 82.61%, Val-Class-Acc: {0: '83.70%', 1: '81.52%'}, LR: 0.000900\n",
      "Epoch 33/200, Train Loss: 0.112208, Train-Class-Acc: {0: '96.32%', 1: '94.69%'}\n",
      "Val Loss: 0.723292, Val Acc: 81.79%, Val-Class-Acc: {0: '77.17%', 1: '86.41%'}, LR: 0.000900\n",
      "Epoch 34/200, Train Loss: 0.095386, Train-Class-Acc: {0: '96.32%', 1: '95.78%'}\n",
      "Val Loss: 0.748534, Val Acc: 81.52%, Val-Class-Acc: {0: '84.24%', 1: '78.80%'}, LR: 0.000900\n",
      "Epoch 35/200, Train Loss: 0.067792, Train-Class-Acc: {0: '98.64%', 1: '96.46%'}\n",
      "Val Loss: 0.746709, Val Acc: 82.34%, Val-Class-Acc: {0: '80.43%', 1: '84.24%'}, LR: 0.000900\n",
      "Epoch 36/200, Train Loss: 0.037009, Train-Class-Acc: {0: '99.32%', 1: '99.18%'}\n",
      "Val Loss: 0.868404, Val Acc: 82.07%, Val-Class-Acc: {0: '77.72%', 1: '86.41%'}, LR: 0.000900\n",
      "Epoch 37/200, Train Loss: 0.038921, Train-Class-Acc: {0: '99.05%', 1: '98.37%'}\n",
      "Val Loss: 0.904652, Val Acc: 81.25%, Val-Class-Acc: {0: '87.50%', 1: '75.00%'}, LR: 0.000900\n",
      "Epoch 38/200, Train Loss: 0.049983, Train-Class-Acc: {0: '98.50%', 1: '98.09%'}\n",
      "Val Loss: 0.776546, Val Acc: 80.98%, Val-Class-Acc: {0: '83.70%', 1: '78.26%'}, LR: 0.000900\n",
      "Epoch 39/200, Train Loss: 0.074752, Train-Class-Acc: {0: '97.68%', 1: '97.41%'}\n",
      "Val Loss: 0.733720, Val Acc: 82.61%, Val-Class-Acc: {0: '79.89%', 1: '85.33%'}, LR: 0.000900\n",
      "Epoch 40/200, Train Loss: 0.077447, Train-Class-Acc: {0: '97.14%', 1: '96.32%'}\n",
      "Val Loss: 0.684095, Val Acc: 81.79%, Val-Class-Acc: {0: '77.72%', 1: '85.87%'}, LR: 0.000810\n",
      "Epoch 41/200, Train Loss: 0.035973, Train-Class-Acc: {0: '99.32%', 1: '98.91%'}\n",
      "Val Loss: 0.758429, Val Acc: 80.98%, Val-Class-Acc: {0: '76.63%', 1: '85.33%'}, LR: 0.000810\n",
      "Epoch 42/200, Train Loss: 0.041370, Train-Class-Acc: {0: '98.37%', 1: '99.18%'}\n",
      "Val Loss: 0.856662, Val Acc: 81.79%, Val-Class-Acc: {0: '86.96%', 1: '76.63%'}, LR: 0.000810\n",
      "Epoch 43/200, Train Loss: 0.038128, Train-Class-Acc: {0: '99.18%', 1: '98.64%'}\n",
      "Val Loss: 0.871544, Val Acc: 82.88%, Val-Class-Acc: {0: '79.89%', 1: '85.87%'}, LR: 0.000810\n",
      "Epoch 44/200, Train Loss: 0.025760, Train-Class-Acc: {0: '99.32%', 1: '99.46%'}\n",
      "Val Loss: 1.009344, Val Acc: 85.33%, Val-Class-Acc: {0: '81.52%', 1: '89.13%'}, LR: 0.000810\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_15.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_44.pth\n",
      "Epoch 45/200, Train Loss: 0.054386, Train-Class-Acc: {0: '98.09%', 1: '98.09%'}\n",
      "Val Loss: 0.744306, Val Acc: 81.79%, Val-Class-Acc: {0: '85.33%', 1: '78.26%'}, LR: 0.000810\n",
      "Epoch 46/200, Train Loss: 0.052317, Train-Class-Acc: {0: '98.09%', 1: '98.09%'}\n",
      "Val Loss: 0.727668, Val Acc: 83.42%, Val-Class-Acc: {0: '79.89%', 1: '86.96%'}, LR: 0.000810\n",
      "Epoch 47/200, Train Loss: 0.030894, Train-Class-Acc: {0: '98.91%', 1: '98.91%'}\n",
      "Val Loss: 0.876289, Val Acc: 81.25%, Val-Class-Acc: {0: '82.61%', 1: '79.89%'}, LR: 0.000810\n",
      "Epoch 48/200, Train Loss: 0.019821, Train-Class-Acc: {0: '99.73%', 1: '99.59%'}\n",
      "Val Loss: 0.837023, Val Acc: 82.34%, Val-Class-Acc: {0: '83.70%', 1: '80.98%'}, LR: 0.000810\n",
      "Epoch 49/200, Train Loss: 0.012443, Train-Class-Acc: {0: '100.00%', 1: '99.73%'}\n",
      "Val Loss: 0.916568, Val Acc: 80.43%, Val-Class-Acc: {0: '79.35%', 1: '81.52%'}, LR: 0.000810\n",
      "Epoch 50/200, Train Loss: 0.006632, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.973245, Val Acc: 83.42%, Val-Class-Acc: {0: '86.41%', 1: '80.43%'}, LR: 0.000810\n",
      "Epoch 51/200, Train Loss: 0.004558, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 1.018494, Val Acc: 82.61%, Val-Class-Acc: {0: '83.70%', 1: '81.52%'}, LR: 0.000729\n",
      "Epoch 52/200, Train Loss: 0.015886, Train-Class-Acc: {0: '99.46%', 1: '99.46%'}\n",
      "Val Loss: 1.122202, Val Acc: 80.98%, Val-Class-Acc: {0: '78.26%', 1: '83.70%'}, LR: 0.000729\n",
      "Epoch 53/200, Train Loss: 0.110985, Train-Class-Acc: {0: '95.64%', 1: '95.91%'}\n",
      "Val Loss: 0.790090, Val Acc: 81.79%, Val-Class-Acc: {0: '80.43%', 1: '83.15%'}, LR: 0.000729\n",
      "Epoch 54/200, Train Loss: 0.123174, Train-Class-Acc: {0: '95.91%', 1: '94.41%'}\n",
      "Val Loss: 0.869869, Val Acc: 75.82%, Val-Class-Acc: {0: '62.50%', 1: '89.13%'}, LR: 0.000729\n",
      "Epoch 55/200, Train Loss: 0.119335, Train-Class-Acc: {0: '95.10%', 1: '95.10%'}\n",
      "Val Loss: 0.598386, Val Acc: 83.42%, Val-Class-Acc: {0: '84.24%', 1: '82.61%'}, LR: 0.000729\n",
      "Epoch 56/200, Train Loss: 0.036960, Train-Class-Acc: {0: '99.32%', 1: '98.77%'}\n",
      "Val Loss: 0.721388, Val Acc: 84.51%, Val-Class-Acc: {0: '85.33%', 1: '83.70%'}, LR: 0.000729\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_21.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_56.pth\n",
      "Epoch 57/200, Train Loss: 0.018878, Train-Class-Acc: {0: '99.73%', 1: '99.73%'}\n",
      "Val Loss: 0.788261, Val Acc: 83.97%, Val-Class-Acc: {0: '84.78%', 1: '83.15%'}, LR: 0.000729\n",
      "Epoch 58/200, Train Loss: 0.009130, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.893537, Val Acc: 82.88%, Val-Class-Acc: {0: '83.70%', 1: '82.07%'}, LR: 0.000729\n",
      "Epoch 59/200, Train Loss: 0.005349, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.985776, Val Acc: 83.70%, Val-Class-Acc: {0: '85.33%', 1: '82.07%'}, LR: 0.000729\n",
      "Epoch 60/200, Train Loss: 0.004695, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.061830, Val Acc: 83.97%, Val-Class-Acc: {0: '84.78%', 1: '83.15%'}, LR: 0.000729\n",
      "Epoch 61/200, Train Loss: 0.003741, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.072816, Val Acc: 83.15%, Val-Class-Acc: {0: '84.24%', 1: '82.07%'}, LR: 0.000729\n",
      "Epoch 62/200, Train Loss: 0.002453, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.103035, Val Acc: 83.70%, Val-Class-Acc: {0: '84.24%', 1: '83.15%'}, LR: 0.000656\n",
      "Epoch 63/200, Train Loss: 0.001949, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.138067, Val Acc: 83.70%, Val-Class-Acc: {0: '84.24%', 1: '83.15%'}, LR: 0.000656\n",
      "Epoch 64/200, Train Loss: 0.001659, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.166504, Val Acc: 83.42%, Val-Class-Acc: {0: '83.70%', 1: '83.15%'}, LR: 0.000656\n",
      "Epoch 65/200, Train Loss: 0.001448, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.194243, Val Acc: 83.15%, Val-Class-Acc: {0: '82.61%', 1: '83.70%'}, LR: 0.000656\n",
      "Epoch 66/200, Train Loss: 0.001309, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.207467, Val Acc: 83.15%, Val-Class-Acc: {0: '83.15%', 1: '83.15%'}, LR: 0.000656\n",
      "Epoch 67/200, Train Loss: 0.001145, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.222967, Val Acc: 83.15%, Val-Class-Acc: {0: '82.61%', 1: '83.70%'}, LR: 0.000656\n",
      "Epoch 68/200, Train Loss: 0.001063, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.237849, Val Acc: 82.88%, Val-Class-Acc: {0: '82.61%', 1: '83.15%'}, LR: 0.000656\n",
      "Epoch 69/200, Train Loss: 0.000968, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.253154, Val Acc: 82.88%, Val-Class-Acc: {0: '82.07%', 1: '83.70%'}, LR: 0.000656\n",
      "Epoch 70/200, Train Loss: 0.000877, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.266293, Val Acc: 82.34%, Val-Class-Acc: {0: '82.07%', 1: '82.61%'}, LR: 0.000656\n",
      "Epoch 71/200, Train Loss: 0.000812, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.282142, Val Acc: 82.61%, Val-Class-Acc: {0: '82.07%', 1: '83.15%'}, LR: 0.000656\n",
      "Epoch 72/200, Train Loss: 0.000763, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.295786, Val Acc: 82.34%, Val-Class-Acc: {0: '82.07%', 1: '82.61%'}, LR: 0.000656\n",
      "Epoch 73/200, Train Loss: 0.000701, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.306567, Val Acc: 82.07%, Val-Class-Acc: {0: '82.07%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 74/200, Train Loss: 0.000663, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.313431, Val Acc: 82.34%, Val-Class-Acc: {0: '82.07%', 1: '82.61%'}, LR: 0.000590\n",
      "Epoch 75/200, Train Loss: 0.000621, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.322638, Val Acc: 82.07%, Val-Class-Acc: {0: '82.07%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 76/200, Train Loss: 0.000589, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.328527, Val Acc: 82.07%, Val-Class-Acc: {0: '82.07%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 77/200, Train Loss: 0.000556, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.342070, Val Acc: 82.07%, Val-Class-Acc: {0: '82.07%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 78/200, Train Loss: 0.000521, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.351799, Val Acc: 82.07%, Val-Class-Acc: {0: '82.07%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 79/200, Train Loss: 0.000499, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.360624, Val Acc: 81.79%, Val-Class-Acc: {0: '81.52%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 80/200, Train Loss: 0.000470, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.368820, Val Acc: 82.07%, Val-Class-Acc: {0: '82.07%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 81/200, Train Loss: 0.000446, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.377794, Val Acc: 82.07%, Val-Class-Acc: {0: '82.07%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 82/200, Train Loss: 0.000424, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.384659, Val Acc: 82.07%, Val-Class-Acc: {0: '82.07%', 1: '82.07%'}, LR: 0.000590\n",
      "Epoch 83/200, Train Loss: 0.000406, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.394843, Val Acc: 81.79%, Val-Class-Acc: {0: '82.07%', 1: '81.52%'}, LR: 0.000590\n",
      "Epoch 84/200, Train Loss: 0.000387, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.400969, Val Acc: 81.79%, Val-Class-Acc: {0: '82.07%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 85/200, Train Loss: 0.000379, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.409853, Val Acc: 82.07%, Val-Class-Acc: {0: '82.61%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 86/200, Train Loss: 0.000374, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.417849, Val Acc: 81.79%, Val-Class-Acc: {0: '82.07%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 87/200, Train Loss: 0.000356, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.422494, Val Acc: 81.79%, Val-Class-Acc: {0: '82.07%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 88/200, Train Loss: 0.000334, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.426850, Val Acc: 81.79%, Val-Class-Acc: {0: '82.07%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 89/200, Train Loss: 0.000322, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.434642, Val Acc: 82.07%, Val-Class-Acc: {0: '82.61%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 90/200, Train Loss: 0.000307, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.444821, Val Acc: 81.79%, Val-Class-Acc: {0: '82.07%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 91/200, Train Loss: 0.000293, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.450783, Val Acc: 82.07%, Val-Class-Acc: {0: '82.61%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 92/200, Train Loss: 0.000281, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.457392, Val Acc: 82.07%, Val-Class-Acc: {0: '82.61%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 93/200, Train Loss: 0.000271, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.463909, Val Acc: 82.07%, Val-Class-Acc: {0: '82.61%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 94/200, Train Loss: 0.000261, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.468589, Val Acc: 82.34%, Val-Class-Acc: {0: '83.15%', 1: '81.52%'}, LR: 0.000531\n",
      "Epoch 95/200, Train Loss: 0.000252, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.475802, Val Acc: 82.34%, Val-Class-Acc: {0: '83.15%', 1: '81.52%'}, LR: 0.000478\n",
      "Epoch 96/200, Train Loss: 0.000243, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.481723, Val Acc: 82.34%, Val-Class-Acc: {0: '83.15%', 1: '81.52%'}, LR: 0.000478\n",
      "Epoch 97/200, Train Loss: 0.000235, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.487721, Val Acc: 82.34%, Val-Class-Acc: {0: '83.15%', 1: '81.52%'}, LR: 0.000478\n",
      "Epoch 98/200, Train Loss: 0.000227, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.494185, Val Acc: 82.07%, Val-Class-Acc: {0: '82.61%', 1: '81.52%'}, LR: 0.000478\n",
      "Epoch 99/200, Train Loss: 0.000221, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.500626, Val Acc: 82.07%, Val-Class-Acc: {0: '82.61%', 1: '81.52%'}, LR: 0.000478\n",
      "Epoch 100/200, Train Loss: 0.000213, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.506708, Val Acc: 82.07%, Val-Class-Acc: {0: '82.61%', 1: '81.52%'}, LR: 0.000478\n",
      "Epoch 101/200, Train Loss: 0.000206, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.522866, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 102/200, Train Loss: 0.000201, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.530270, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 103/200, Train Loss: 0.000194, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.536268, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 104/200, Train Loss: 0.000188, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.540545, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 105/200, Train Loss: 0.000183, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.547869, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 106/200, Train Loss: 0.000178, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.551156, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 107/200, Train Loss: 0.000173, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.554254, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 108/200, Train Loss: 0.000169, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.558583, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 109/200, Train Loss: 0.000165, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.562661, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 110/200, Train Loss: 0.000161, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.567434, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 111/200, Train Loss: 0.000157, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.571836, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 112/200, Train Loss: 0.000153, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.574157, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 113/200, Train Loss: 0.000149, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.578884, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 114/200, Train Loss: 0.000146, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.581869, Val Acc: 81.79%, Val-Class-Acc: {0: '82.61%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 115/200, Train Loss: 0.000142, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.585565, Val Acc: 81.52%, Val-Class-Acc: {0: '82.07%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 116/200, Train Loss: 0.000138, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.592609, Val Acc: 81.52%, Val-Class-Acc: {0: '82.07%', 1: '80.98%'}, LR: 0.000430\n",
      "Epoch 117/200, Train Loss: 0.000135, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.595424, Val Acc: 81.52%, Val-Class-Acc: {0: '82.07%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 118/200, Train Loss: 0.000133, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.598234, Val Acc: 81.25%, Val-Class-Acc: {0: '81.52%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 119/200, Train Loss: 0.000129, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.599612, Val Acc: 81.52%, Val-Class-Acc: {0: '82.07%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 120/200, Train Loss: 0.000127, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.602912, Val Acc: 81.25%, Val-Class-Acc: {0: '81.52%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 121/200, Train Loss: 0.000124, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.605654, Val Acc: 81.52%, Val-Class-Acc: {0: '82.07%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 122/200, Train Loss: 0.000122, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.608208, Val Acc: 81.52%, Val-Class-Acc: {0: '82.07%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 123/200, Train Loss: 0.000119, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.612056, Val Acc: 81.25%, Val-Class-Acc: {0: '81.52%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 124/200, Train Loss: 0.000117, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.614494, Val Acc: 81.25%, Val-Class-Acc: {0: '81.52%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 125/200, Train Loss: 0.000115, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.617586, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000387\n",
      "Epoch 126/200, Train Loss: 0.000113, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.620203, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000387\n",
      "Epoch 127/200, Train Loss: 0.000111, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.622334, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000387\n",
      "Epoch 128/200, Train Loss: 0.000109, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.625878, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 129/200, Train Loss: 0.000107, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.626251, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 130/200, Train Loss: 0.000105, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.629281, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 131/200, Train Loss: 0.000103, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.630789, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 132/200, Train Loss: 0.000102, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.631943, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 133/200, Train Loss: 0.000100, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.634841, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 134/200, Train Loss: 0.000098, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.635821, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 135/200, Train Loss: 0.000097, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.638804, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 136/200, Train Loss: 0.000096, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.640789, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 137/200, Train Loss: 0.000094, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.643157, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 138/200, Train Loss: 0.000092, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.645325, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 139/200, Train Loss: 0.000091, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.648309, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 140/200, Train Loss: 0.000090, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.649152, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 141/200, Train Loss: 0.000089, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.649762, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 142/200, Train Loss: 0.000088, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.652307, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 143/200, Train Loss: 0.000086, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.654029, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 144/200, Train Loss: 0.000085, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.655706, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 145/200, Train Loss: 0.000083, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.657716, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 146/200, Train Loss: 0.000082, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.659855, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 147/200, Train Loss: 0.000081, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.661582, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 148/200, Train Loss: 0.000080, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.663418, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 149/200, Train Loss: 0.000079, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.663925, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000314\n",
      "Epoch 150/200, Train Loss: 0.000078, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.665501, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 151/200, Train Loss: 0.000077, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.667208, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 152/200, Train Loss: 0.000076, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.667756, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 153/200, Train Loss: 0.000075, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.669201, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 154/200, Train Loss: 0.000074, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.670235, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 155/200, Train Loss: 0.000073, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.671319, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 156/200, Train Loss: 0.000072, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.673498, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 157/200, Train Loss: 0.000071, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.673652, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 158/200, Train Loss: 0.000070, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.676459, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 159/200, Train Loss: 0.000069, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.678001, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 160/200, Train Loss: 0.000068, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.680486, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000282\n",
      "Epoch 161/200, Train Loss: 0.000067, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.682253, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 162/200, Train Loss: 0.000066, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.682844, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 163/200, Train Loss: 0.000065, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.684976, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 164/200, Train Loss: 0.000065, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.686975, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 165/200, Train Loss: 0.000064, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.689129, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 166/200, Train Loss: 0.000063, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.691157, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 167/200, Train Loss: 0.000062, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.692739, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 168/200, Train Loss: 0.000062, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.695380, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 169/200, Train Loss: 0.000061, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.696831, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 170/200, Train Loss: 0.000060, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.698849, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 171/200, Train Loss: 0.000060, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.700267, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000254\n",
      "Epoch 172/200, Train Loss: 0.000059, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.702366, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 173/200, Train Loss: 0.000058, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.703364, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 174/200, Train Loss: 0.000057, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.705788, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 175/200, Train Loss: 0.000057, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.707572, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 176/200, Train Loss: 0.000056, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.708047, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 177/200, Train Loss: 0.000056, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.710412, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 178/200, Train Loss: 0.000055, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.711638, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 179/200, Train Loss: 0.000054, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.712949, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 180/200, Train Loss: 0.000054, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.714928, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 181/200, Train Loss: 0.000053, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.716112, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 182/200, Train Loss: 0.000053, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.717387, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000229\n",
      "Epoch 183/200, Train Loss: 0.000052, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.718735, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000206\n",
      "Epoch 184/200, Train Loss: 0.000052, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.720314, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000206\n",
      "Epoch 185/200, Train Loss: 0.000051, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.721546, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000206\n",
      "Epoch 186/200, Train Loss: 0.000051, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.722992, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000206\n",
      "Epoch 187/200, Train Loss: 0.000050, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.724195, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000206\n",
      "Epoch 188/200, Train Loss: 0.000050, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.725609, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000206\n",
      "Epoch 189/200, Train Loss: 0.000049, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.727359, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.000206\n",
      "Epoch 190/200, Train Loss: 0.000049, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.728227, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000206\n",
      "Epoch 191/200, Train Loss: 0.000048, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.729959, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000206\n",
      "Epoch 192/200, Train Loss: 0.000048, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.731573, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000206\n",
      "Epoch 193/200, Train Loss: 0.000047, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.732749, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000206\n",
      "Epoch 194/200, Train Loss: 0.000047, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.733814, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000185\n",
      "Epoch 195/200, Train Loss: 0.000046, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.735210, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000185\n",
      "Epoch 196/200, Train Loss: 0.000046, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.736388, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000185\n",
      "Epoch 197/200, Train Loss: 0.000045, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.737089, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000185\n",
      "Epoch 198/200, Train Loss: 0.000045, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.738285, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000185\n",
      "Epoch 199/200, Train Loss: 0.000044, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.740394, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000185\n",
      "Epoch 200/200, Train Loss: 0.000044, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.741650, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000185\n",
      "\n",
      "🏆 Best model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_best.pth (Val Accuracy: 85.33%)\n",
      "\n",
      "📌 Final model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_final.pth\n",
      "\n",
      "🎯 Top 5 Best Models:\n",
      "Epoch 44, Train Loss: 0.025760, Train-Acc: {0: '99.32%', 1: '99.46%'},\n",
      "Val Loss: 1.009344, Val Acc: 85.33%, Val-Class-Acc: {0: '81.52%', 1: '89.13%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_44.pth\n",
      "Epoch 29, Train Loss: 0.130458, Train-Acc: {0: '94.82%', 1: '93.32%'},\n",
      "Val Loss: 0.492215, Val Acc: 84.78%, Val-Class-Acc: {0: '80.98%', 1: '88.59%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_29.pth\n",
      "Epoch 56, Train Loss: 0.036960, Train-Acc: {0: '99.32%', 1: '98.77%'},\n",
      "Val Loss: 0.721388, Val Acc: 84.51%, Val-Class-Acc: {0: '85.33%', 1: '83.70%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_56.pth\n",
      "Epoch 31, Train Loss: 0.088616, Train-Acc: {0: '97.00%', 1: '96.87%'},\n",
      "Val Loss: 0.682079, Val Acc: 84.51%, Val-Class-Acc: {0: '86.41%', 1: '82.61%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_31.pth\n",
      "Epoch 17, Train Loss: 0.301156, Train-Acc: {0: '89.10%', 1: '84.33%'},\n",
      "Val Loss: 0.382225, Val Acc: 84.24%, Val-Class-Acc: {0: '85.87%', 1: '82.61%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU/BiGRU_epoch_17.pth\n",
      "\n",
      "🧠 Model Summary:\n",
      "Total Parameters: 406,018\n",
      "Model Size (float32): 1.55 MB\n",
      "Total Training Time: 379.19 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))  # Shape: (B, 5000, 12)\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# ==== Model Hyperparameters ====\n",
    "input_size = X_train.shape[2]                      # F = 12 leads\n",
    "hidden_size = 128                                  # 通常 128 或 256 較穩定\n",
    "output_size = len(np.unique(y_train))              # #Classes (P1 = 2)\n",
    "dropout = 0.0\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "print(\"✅ input shape:\", X_train.shape)\n",
    "print(\"✅ unique y_train:\", np.unique(y_train))\n",
    "print(\"✅ unique y_test :\", np.unique(y_test))\n",
    "assert np.max(y_train) < output_size\n",
    "assert np.max(y_test) < output_size\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/BiGRU\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Model ====\n",
    "model = BiGRU(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_classes=output_size,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "# ==== Optimizer and Training ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# ==== Train ====\n",
    "result_summary = train_model_general_classifier(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name='BiGRU',\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ==== Cleanup ====\n",
    "del model, X_train, y_train, X_test, y_test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485ae73c",
   "metadata": {},
   "source": [
    "### Bi-GRU with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c5cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Automatically selected GPU:\n",
      "    - CUDA Device ID : 2\n",
      "    - Memory Used    : 14539 MiB\n",
      "    - Device Name    : NVIDIA RTX A6000\n",
      "✅ input shape: (1468, 5000, 12)\n",
      "✅ unique y_train: [0 1]\n",
      "✅ unique y_test : [0 1]\n",
      "\n",
      "🚀 'train_model_general_classifier' started.\n",
      "✅ Removed existing folder: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn\n",
      "\n",
      "✅ Data Overview:\n",
      "X_train: torch.Size([1468, 5000, 12]), y_train: torch.Size([1468])\n",
      "X_val: torch.Size([368, 5000, 12]), y_val: torch.Size([368])\n",
      "Epoch 1/200, Train Loss: 0.621901, Train-Class-Acc: {0: '69.07%', 1: '64.99%'}\n",
      "Val Loss: 0.530069, Val Acc: 73.64%, Val-Class-Acc: {0: '78.80%', 1: '68.48%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_1.pth\n",
      "Epoch 2/200, Train Loss: 0.483146, Train-Class-Acc: {0: '81.88%', 1: '72.48%'}\n",
      "Val Loss: 0.503447, Val Acc: 74.73%, Val-Class-Acc: {0: '68.48%', 1: '80.98%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_2.pth\n",
      "Epoch 3/200, Train Loss: 0.442151, Train-Class-Acc: {0: '82.56%', 1: '76.29%'}\n",
      "Val Loss: 0.468711, Val Acc: 75.82%, Val-Class-Acc: {0: '80.98%', 1: '70.65%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_3.pth\n",
      "Epoch 4/200, Train Loss: 0.417493, Train-Class-Acc: {0: '85.56%', 1: '74.52%'}\n",
      "Val Loss: 0.459024, Val Acc: 76.09%, Val-Class-Acc: {0: '79.35%', 1: '72.83%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_4.pth\n",
      "Epoch 5/200, Train Loss: 0.411171, Train-Class-Acc: {0: '84.20%', 1: '77.66%'}\n",
      "Val Loss: 0.456823, Val Acc: 76.90%, Val-Class-Acc: {0: '82.07%', 1: '71.74%'}, LR: 0.001000\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_5.pth\n",
      "Epoch 6/200, Train Loss: 0.397752, Train-Class-Acc: {0: '86.51%', 1: '76.70%'}\n",
      "Val Loss: 0.458706, Val Acc: 77.45%, Val-Class-Acc: {0: '74.46%', 1: '80.43%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_1.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_6.pth\n",
      "Epoch 7/200, Train Loss: 0.393768, Train-Class-Acc: {0: '86.10%', 1: '78.20%'}\n",
      "Val Loss: 0.484843, Val Acc: 76.63%, Val-Class-Acc: {0: '65.22%', 1: '88.04%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_2.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_7.pth\n",
      "Epoch 8/200, Train Loss: 0.389320, Train-Class-Acc: {0: '85.97%', 1: '78.20%'}\n",
      "Val Loss: 0.430691, Val Acc: 79.35%, Val-Class-Acc: {0: '85.87%', 1: '72.83%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_3.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_8.pth\n",
      "Epoch 9/200, Train Loss: 0.373985, Train-Class-Acc: {0: '86.65%', 1: '79.84%'}\n",
      "Val Loss: 0.441439, Val Acc: 79.35%, Val-Class-Acc: {0: '76.09%', 1: '82.61%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_4.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_9.pth\n",
      "Epoch 10/200, Train Loss: 0.368016, Train-Class-Acc: {0: '87.47%', 1: '79.84%'}\n",
      "Val Loss: 0.419648, Val Acc: 80.43%, Val-Class-Acc: {0: '80.43%', 1: '80.43%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_7.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_10.pth\n",
      "Epoch 11/200, Train Loss: 0.373158, Train-Class-Acc: {0: '86.78%', 1: '79.43%'}\n",
      "Val Loss: 0.449129, Val Acc: 79.62%, Val-Class-Acc: {0: '92.39%', 1: '66.85%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_5.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_11.pth\n",
      "Epoch 12/200, Train Loss: 0.365760, Train-Class-Acc: {0: '88.28%', 1: '79.43%'}\n",
      "Val Loss: 0.423101, Val Acc: 79.35%, Val-Class-Acc: {0: '83.15%', 1: '75.54%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_6.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_12.pth\n",
      "Epoch 13/200, Train Loss: 0.350712, Train-Class-Acc: {0: '87.33%', 1: '80.25%'}\n",
      "Val Loss: 0.424867, Val Acc: 79.62%, Val-Class-Acc: {0: '89.13%', 1: '70.11%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_8.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_13.pth\n",
      "Epoch 14/200, Train Loss: 0.344909, Train-Class-Acc: {0: '89.24%', 1: '79.84%'}\n",
      "Val Loss: 0.414608, Val Acc: 80.98%, Val-Class-Acc: {0: '87.50%', 1: '74.46%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_9.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_14.pth\n",
      "Epoch 15/200, Train Loss: 0.328283, Train-Class-Acc: {0: '88.28%', 1: '81.74%'}\n",
      "Val Loss: 0.414529, Val Acc: 82.07%, Val-Class-Acc: {0: '82.61%', 1: '81.52%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_12.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_15.pth\n",
      "Epoch 16/200, Train Loss: 0.327386, Train-Class-Acc: {0: '88.15%', 1: '80.65%'}\n",
      "Val Loss: 0.391876, Val Acc: 83.42%, Val-Class-Acc: {0: '88.59%', 1: '78.26%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_11.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_16.pth\n",
      "Epoch 17/200, Train Loss: 0.317220, Train-Class-Acc: {0: '89.92%', 1: '82.43%'}\n",
      "Val Loss: 0.413559, Val Acc: 80.71%, Val-Class-Acc: {0: '87.50%', 1: '73.91%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_13.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_17.pth\n",
      "Epoch 18/200, Train Loss: 0.302030, Train-Class-Acc: {0: '89.51%', 1: '83.51%'}\n",
      "Val Loss: 0.399607, Val Acc: 82.07%, Val-Class-Acc: {0: '84.24%', 1: '79.89%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_10.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_18.pth\n",
      "Epoch 19/200, Train Loss: 0.299750, Train-Class-Acc: {0: '88.96%', 1: '84.88%'}\n",
      "Val Loss: 0.421976, Val Acc: 80.98%, Val-Class-Acc: {0: '90.22%', 1: '71.74%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_17.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_19.pth\n",
      "Epoch 20/200, Train Loss: 0.293917, Train-Class-Acc: {0: '91.42%', 1: '81.74%'}\n",
      "Val Loss: 0.439752, Val Acc: 81.52%, Val-Class-Acc: {0: '87.50%', 1: '75.54%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_14.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_20.pth\n",
      "Epoch 21/200, Train Loss: 0.302469, Train-Class-Acc: {0: '88.83%', 1: '83.51%'}\n",
      "Val Loss: 0.449324, Val Acc: 80.71%, Val-Class-Acc: {0: '75.00%', 1: '86.41%'}, LR: 0.001000\n",
      "Epoch 22/200, Train Loss: 0.274152, Train-Class-Acc: {0: '90.87%', 1: '85.56%'}\n",
      "Val Loss: 0.420585, Val Acc: 81.52%, Val-Class-Acc: {0: '82.07%', 1: '80.98%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_19.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_22.pth\n",
      "Epoch 23/200, Train Loss: 0.263080, Train-Class-Acc: {0: '91.28%', 1: '85.69%'}\n",
      "Val Loss: 0.428576, Val Acc: 81.79%, Val-Class-Acc: {0: '82.07%', 1: '81.52%'}, LR: 0.001000\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_20.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_23.pth\n",
      "Epoch 24/200, Train Loss: 0.259996, Train-Class-Acc: {0: '92.37%', 1: '86.24%'}\n",
      "Val Loss: 0.432133, Val Acc: 81.25%, Val-Class-Acc: {0: '80.98%', 1: '81.52%'}, LR: 0.001000\n",
      "Epoch 25/200, Train Loss: 0.248638, Train-Class-Acc: {0: '91.42%', 1: '87.87%'}\n",
      "Val Loss: 0.460582, Val Acc: 81.52%, Val-Class-Acc: {0: '83.70%', 1: '79.35%'}, LR: 0.001000\n",
      "Epoch 26/200, Train Loss: 0.239319, Train-Class-Acc: {0: '92.37%', 1: '87.74%'}\n",
      "Val Loss: 0.480474, Val Acc: 80.98%, Val-Class-Acc: {0: '90.22%', 1: '71.74%'}, LR: 0.001000\n",
      "Epoch 27/200, Train Loss: 0.262986, Train-Class-Acc: {0: '90.74%', 1: '85.42%'}\n",
      "Val Loss: 0.437169, Val Acc: 81.52%, Val-Class-Acc: {0: '82.07%', 1: '80.98%'}, LR: 0.001000\n",
      "Epoch 28/200, Train Loss: 0.247790, Train-Class-Acc: {0: '91.01%', 1: '86.78%'}\n",
      "Val Loss: 0.452481, Val Acc: 82.34%, Val-Class-Acc: {0: '85.33%', 1: '79.35%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_22.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_28.pth\n",
      "Epoch 29/200, Train Loss: 0.222338, Train-Class-Acc: {0: '92.10%', 1: '88.83%'}\n",
      "Val Loss: 0.478888, Val Acc: 82.34%, Val-Class-Acc: {0: '81.52%', 1: '83.15%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_23.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_29.pth\n",
      "Epoch 30/200, Train Loss: 0.205266, Train-Class-Acc: {0: '93.19%', 1: '88.69%'}\n",
      "Val Loss: 0.458519, Val Acc: 81.25%, Val-Class-Acc: {0: '86.41%', 1: '76.09%'}, LR: 0.000900\n",
      "Epoch 31/200, Train Loss: 0.209041, Train-Class-Acc: {0: '92.10%', 1: '88.83%'}\n",
      "Val Loss: 0.493306, Val Acc: 80.16%, Val-Class-Acc: {0: '85.33%', 1: '75.00%'}, LR: 0.000900\n",
      "Epoch 32/200, Train Loss: 0.237971, Train-Class-Acc: {0: '91.96%', 1: '86.51%'}\n",
      "Val Loss: 0.453171, Val Acc: 83.15%, Val-Class-Acc: {0: '83.70%', 1: '82.61%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_15.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_32.pth\n",
      "Epoch 33/200, Train Loss: 0.191480, Train-Class-Acc: {0: '93.19%', 1: '90.87%'}\n",
      "Val Loss: 0.542142, Val Acc: 81.52%, Val-Class-Acc: {0: '84.24%', 1: '78.80%'}, LR: 0.000900\n",
      "Epoch 34/200, Train Loss: 0.177545, Train-Class-Acc: {0: '93.46%', 1: '91.69%'}\n",
      "Val Loss: 0.514811, Val Acc: 81.25%, Val-Class-Acc: {0: '84.78%', 1: '77.72%'}, LR: 0.000900\n",
      "Epoch 35/200, Train Loss: 0.168310, Train-Class-Acc: {0: '95.50%', 1: '91.28%'}\n",
      "Val Loss: 0.550851, Val Acc: 81.25%, Val-Class-Acc: {0: '81.52%', 1: '80.98%'}, LR: 0.000900\n",
      "Epoch 36/200, Train Loss: 0.183225, Train-Class-Acc: {0: '93.46%', 1: '91.55%'}\n",
      "Val Loss: 0.546707, Val Acc: 80.71%, Val-Class-Acc: {0: '89.13%', 1: '72.28%'}, LR: 0.000900\n",
      "Epoch 37/200, Train Loss: 0.165583, Train-Class-Acc: {0: '94.28%', 1: '92.23%'}\n",
      "Val Loss: 0.528751, Val Acc: 82.34%, Val-Class-Acc: {0: '84.24%', 1: '80.43%'}, LR: 0.000900\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_18.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_37.pth\n",
      "Epoch 38/200, Train Loss: 0.170498, Train-Class-Acc: {0: '94.28%', 1: '91.69%'}\n",
      "Val Loss: 0.507326, Val Acc: 80.43%, Val-Class-Acc: {0: '80.43%', 1: '80.43%'}, LR: 0.000900\n",
      "Epoch 39/200, Train Loss: 0.174418, Train-Class-Acc: {0: '94.41%', 1: '91.69%'}\n",
      "Val Loss: 0.541534, Val Acc: 82.34%, Val-Class-Acc: {0: '84.78%', 1: '79.89%'}, LR: 0.000810\n",
      "Epoch 40/200, Train Loss: 0.137697, Train-Class-Acc: {0: '95.10%', 1: '93.60%'}\n",
      "Val Loss: 0.541970, Val Acc: 83.15%, Val-Class-Acc: {0: '86.41%', 1: '79.89%'}, LR: 0.000810\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_28.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_40.pth\n",
      "Epoch 41/200, Train Loss: 0.134502, Train-Class-Acc: {0: '95.91%', 1: '93.73%'}\n",
      "Val Loss: 0.566764, Val Acc: 81.79%, Val-Class-Acc: {0: '85.33%', 1: '78.26%'}, LR: 0.000810\n",
      "Epoch 42/200, Train Loss: 0.122545, Train-Class-Acc: {0: '96.73%', 1: '94.28%'}\n",
      "Val Loss: 0.623712, Val Acc: 81.52%, Val-Class-Acc: {0: '82.07%', 1: '80.98%'}, LR: 0.000810\n",
      "Epoch 43/200, Train Loss: 0.119559, Train-Class-Acc: {0: '96.73%', 1: '94.01%'}\n",
      "Val Loss: 0.548345, Val Acc: 81.79%, Val-Class-Acc: {0: '83.15%', 1: '80.43%'}, LR: 0.000810\n",
      "Epoch 44/200, Train Loss: 0.106903, Train-Class-Acc: {0: '97.41%', 1: '94.96%'}\n",
      "Val Loss: 0.624197, Val Acc: 82.61%, Val-Class-Acc: {0: '86.96%', 1: '78.26%'}, LR: 0.000810\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_29.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_44.pth\n",
      "Epoch 45/200, Train Loss: 0.109065, Train-Class-Acc: {0: '97.00%', 1: '95.64%'}\n",
      "Val Loss: 0.597773, Val Acc: 82.07%, Val-Class-Acc: {0: '83.70%', 1: '80.43%'}, LR: 0.000810\n",
      "Epoch 46/200, Train Loss: 0.152319, Train-Class-Acc: {0: '94.28%', 1: '92.78%'}\n",
      "Val Loss: 0.548830, Val Acc: 82.61%, Val-Class-Acc: {0: '76.63%', 1: '88.59%'}, LR: 0.000810\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_37.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_46.pth\n",
      "Epoch 47/200, Train Loss: 0.545256, Train-Class-Acc: {0: '79.02%', 1: '75.48%'}\n",
      "Val Loss: 0.535965, Val Acc: 75.27%, Val-Class-Acc: {0: '71.74%', 1: '78.80%'}, LR: 0.000810\n",
      "Epoch 48/200, Train Loss: 0.390606, Train-Class-Acc: {0: '83.79%', 1: '80.93%'}\n",
      "Val Loss: 0.458979, Val Acc: 79.89%, Val-Class-Acc: {0: '78.26%', 1: '81.52%'}, LR: 0.000810\n",
      "Epoch 49/200, Train Loss: 0.341707, Train-Class-Acc: {0: '87.47%', 1: '80.11%'}\n",
      "Val Loss: 0.434404, Val Acc: 80.16%, Val-Class-Acc: {0: '87.50%', 1: '72.83%'}, LR: 0.000810\n",
      "Epoch 50/200, Train Loss: 0.315832, Train-Class-Acc: {0: '88.01%', 1: '83.92%'}\n",
      "Val Loss: 0.420233, Val Acc: 82.61%, Val-Class-Acc: {0: '79.89%', 1: '85.33%'}, LR: 0.000729\n",
      "Epoch 51/200, Train Loss: 0.294768, Train-Class-Acc: {0: '88.56%', 1: '82.97%'}\n",
      "Val Loss: 0.421241, Val Acc: 80.71%, Val-Class-Acc: {0: '87.50%', 1: '73.91%'}, LR: 0.000729\n",
      "Epoch 52/200, Train Loss: 0.277121, Train-Class-Acc: {0: '89.65%', 1: '84.33%'}\n",
      "Val Loss: 0.411299, Val Acc: 83.15%, Val-Class-Acc: {0: '80.98%', 1: '85.33%'}, LR: 0.000729\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_44.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_52.pth\n",
      "Epoch 53/200, Train Loss: 0.268791, Train-Class-Acc: {0: '88.28%', 1: '84.74%'}\n",
      "Val Loss: 0.413229, Val Acc: 83.15%, Val-Class-Acc: {0: '85.33%', 1: '80.98%'}, LR: 0.000729\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_46.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_53.pth\n",
      "Epoch 54/200, Train Loss: 0.253234, Train-Class-Acc: {0: '89.92%', 1: '85.97%'}\n",
      "Val Loss: 0.412508, Val Acc: 82.88%, Val-Class-Acc: {0: '83.15%', 1: '82.61%'}, LR: 0.000729\n",
      "Epoch 55/200, Train Loss: 0.253827, Train-Class-Acc: {0: '89.37%', 1: '86.92%'}\n",
      "Val Loss: 0.431409, Val Acc: 83.42%, Val-Class-Acc: {0: '85.87%', 1: '80.98%'}, LR: 0.000729\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_32.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_55.pth\n",
      "Epoch 56/200, Train Loss: 0.242753, Train-Class-Acc: {0: '91.69%', 1: '85.42%'}\n",
      "Val Loss: 0.415696, Val Acc: 83.70%, Val-Class-Acc: {0: '82.07%', 1: '85.33%'}, LR: 0.000729\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_40.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_56.pth\n",
      "Epoch 57/200, Train Loss: 0.228218, Train-Class-Acc: {0: '91.01%', 1: '89.24%'}\n",
      "Val Loss: 0.434198, Val Acc: 81.79%, Val-Class-Acc: {0: '85.33%', 1: '78.26%'}, LR: 0.000729\n",
      "Epoch 58/200, Train Loss: 0.216685, Train-Class-Acc: {0: '92.37%', 1: '88.69%'}\n",
      "Val Loss: 0.426737, Val Acc: 82.61%, Val-Class-Acc: {0: '85.33%', 1: '79.89%'}, LR: 0.000729\n",
      "Epoch 59/200, Train Loss: 0.219924, Train-Class-Acc: {0: '92.78%', 1: '86.92%'}\n",
      "Val Loss: 0.435414, Val Acc: 82.07%, Val-Class-Acc: {0: '84.24%', 1: '79.89%'}, LR: 0.000729\n",
      "Epoch 60/200, Train Loss: 0.210939, Train-Class-Acc: {0: '91.96%', 1: '89.78%'}\n",
      "Val Loss: 0.452049, Val Acc: 84.24%, Val-Class-Acc: {0: '79.89%', 1: '88.59%'}, LR: 0.000729\n",
      "🗑 Removed: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_52.pth\n",
      "✅ Saved model: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_60.pth\n",
      "Epoch 61/200, Train Loss: 0.199665, Train-Class-Acc: {0: '93.19%', 1: '90.05%'}\n",
      "Val Loss: 0.441931, Val Acc: 82.07%, Val-Class-Acc: {0: '79.89%', 1: '84.24%'}, LR: 0.000656\n",
      "Epoch 62/200, Train Loss: 0.189017, Train-Class-Acc: {0: '93.87%', 1: '90.74%'}\n",
      "Val Loss: 0.450218, Val Acc: 83.15%, Val-Class-Acc: {0: '84.78%', 1: '81.52%'}, LR: 0.000656\n",
      "Epoch 63/200, Train Loss: 0.183257, Train-Class-Acc: {0: '93.32%', 1: '90.74%'}\n",
      "Val Loss: 0.468655, Val Acc: 81.52%, Val-Class-Acc: {0: '85.33%', 1: '77.72%'}, LR: 0.000656\n",
      "Epoch 64/200, Train Loss: 0.172791, Train-Class-Acc: {0: '94.82%', 1: '91.96%'}\n",
      "Val Loss: 0.471121, Val Acc: 82.34%, Val-Class-Acc: {0: '84.78%', 1: '79.89%'}, LR: 0.000656\n",
      "Epoch 65/200, Train Loss: 0.162042, Train-Class-Acc: {0: '94.69%', 1: '93.46%'}\n",
      "Val Loss: 0.526775, Val Acc: 79.08%, Val-Class-Acc: {0: '88.04%', 1: '70.11%'}, LR: 0.000656\n",
      "Epoch 66/200, Train Loss: 0.164571, Train-Class-Acc: {0: '95.37%', 1: '91.96%'}\n",
      "Val Loss: 0.500059, Val Acc: 82.34%, Val-Class-Acc: {0: '84.78%', 1: '79.89%'}, LR: 0.000656\n",
      "Epoch 67/200, Train Loss: 0.160447, Train-Class-Acc: {0: '94.28%', 1: '92.78%'}\n",
      "Val Loss: 0.518456, Val Acc: 82.34%, Val-Class-Acc: {0: '77.72%', 1: '86.96%'}, LR: 0.000656\n",
      "Epoch 68/200, Train Loss: 0.157708, Train-Class-Acc: {0: '95.37%', 1: '91.96%'}\n",
      "Val Loss: 0.495621, Val Acc: 82.34%, Val-Class-Acc: {0: '83.70%', 1: '80.98%'}, LR: 0.000656\n",
      "Epoch 69/200, Train Loss: 0.156134, Train-Class-Acc: {0: '94.82%', 1: '93.46%'}\n",
      "Val Loss: 0.527738, Val Acc: 80.71%, Val-Class-Acc: {0: '84.24%', 1: '77.17%'}, LR: 0.000656\n",
      "Epoch 70/200, Train Loss: 0.163233, Train-Class-Acc: {0: '94.14%', 1: '92.92%'}\n",
      "Val Loss: 0.547271, Val Acc: 80.16%, Val-Class-Acc: {0: '85.33%', 1: '75.00%'}, LR: 0.000656\n",
      "Epoch 71/200, Train Loss: 0.140772, Train-Class-Acc: {0: '96.32%', 1: '93.05%'}\n",
      "Val Loss: 0.503441, Val Acc: 82.34%, Val-Class-Acc: {0: '78.80%', 1: '85.87%'}, LR: 0.000656\n",
      "Epoch 72/200, Train Loss: 0.125269, Train-Class-Acc: {0: '96.59%', 1: '94.55%'}\n",
      "Val Loss: 0.534869, Val Acc: 82.34%, Val-Class-Acc: {0: '82.07%', 1: '82.61%'}, LR: 0.000590\n",
      "Epoch 73/200, Train Loss: 0.117197, Train-Class-Acc: {0: '95.50%', 1: '96.19%'}\n",
      "Val Loss: 0.560339, Val Acc: 80.71%, Val-Class-Acc: {0: '82.61%', 1: '78.80%'}, LR: 0.000590\n",
      "Epoch 74/200, Train Loss: 0.112401, Train-Class-Acc: {0: '96.87%', 1: '95.23%'}\n",
      "Val Loss: 0.593340, Val Acc: 80.71%, Val-Class-Acc: {0: '84.78%', 1: '76.63%'}, LR: 0.000590\n",
      "Epoch 75/200, Train Loss: 0.107981, Train-Class-Acc: {0: '97.28%', 1: '95.64%'}\n",
      "Val Loss: 0.590847, Val Acc: 80.98%, Val-Class-Acc: {0: '82.61%', 1: '79.35%'}, LR: 0.000590\n",
      "Epoch 76/200, Train Loss: 0.119694, Train-Class-Acc: {0: '95.37%', 1: '96.05%'}\n",
      "Val Loss: 0.577333, Val Acc: 82.07%, Val-Class-Acc: {0: '85.33%', 1: '78.80%'}, LR: 0.000590\n",
      "Epoch 77/200, Train Loss: 0.128489, Train-Class-Acc: {0: '96.19%', 1: '92.92%'}\n",
      "Val Loss: 0.591264, Val Acc: 80.71%, Val-Class-Acc: {0: '71.20%', 1: '90.22%'}, LR: 0.000590\n",
      "Epoch 78/200, Train Loss: 0.138003, Train-Class-Acc: {0: '95.37%', 1: '93.87%'}\n",
      "Val Loss: 0.615469, Val Acc: 80.16%, Val-Class-Acc: {0: '80.43%', 1: '79.89%'}, LR: 0.000590\n",
      "Epoch 79/200, Train Loss: 0.112357, Train-Class-Acc: {0: '96.87%', 1: '96.19%'}\n",
      "Val Loss: 0.640735, Val Acc: 78.26%, Val-Class-Acc: {0: '85.33%', 1: '71.20%'}, LR: 0.000590\n",
      "Epoch 80/200, Train Loss: 0.096659, Train-Class-Acc: {0: '97.41%', 1: '96.32%'}\n",
      "Val Loss: 0.615716, Val Acc: 82.07%, Val-Class-Acc: {0: '81.52%', 1: '82.61%'}, LR: 0.000590\n",
      "Epoch 81/200, Train Loss: 0.084491, Train-Class-Acc: {0: '98.09%', 1: '96.87%'}\n",
      "Val Loss: 0.616336, Val Acc: 82.07%, Val-Class-Acc: {0: '80.98%', 1: '83.15%'}, LR: 0.000590\n",
      "Epoch 82/200, Train Loss: 0.079578, Train-Class-Acc: {0: '98.09%', 1: '97.41%'}\n",
      "Val Loss: 0.650127, Val Acc: 82.61%, Val-Class-Acc: {0: '80.98%', 1: '84.24%'}, LR: 0.000590\n",
      "Epoch 83/200, Train Loss: 0.073811, Train-Class-Acc: {0: '97.68%', 1: '97.55%'}\n",
      "Val Loss: 0.665550, Val Acc: 82.07%, Val-Class-Acc: {0: '81.52%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 84/200, Train Loss: 0.075020, Train-Class-Acc: {0: '98.50%', 1: '97.55%'}\n",
      "Val Loss: 0.653492, Val Acc: 82.07%, Val-Class-Acc: {0: '79.89%', 1: '84.24%'}, LR: 0.000531\n",
      "Epoch 85/200, Train Loss: 0.102358, Train-Class-Acc: {0: '96.73%', 1: '95.64%'}\n",
      "Val Loss: 0.656857, Val Acc: 81.52%, Val-Class-Acc: {0: '79.35%', 1: '83.70%'}, LR: 0.000531\n",
      "Epoch 86/200, Train Loss: 0.080980, Train-Class-Acc: {0: '97.55%', 1: '97.28%'}\n",
      "Val Loss: 0.659660, Val Acc: 81.52%, Val-Class-Acc: {0: '82.61%', 1: '80.43%'}, LR: 0.000531\n",
      "Epoch 87/200, Train Loss: 0.066986, Train-Class-Acc: {0: '98.64%', 1: '97.68%'}\n",
      "Val Loss: 0.684922, Val Acc: 81.79%, Val-Class-Acc: {0: '80.98%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 88/200, Train Loss: 0.058682, Train-Class-Acc: {0: '98.64%', 1: '99.05%'}\n",
      "Val Loss: 0.657178, Val Acc: 81.25%, Val-Class-Acc: {0: '82.07%', 1: '80.43%'}, LR: 0.000531\n",
      "Epoch 89/200, Train Loss: 0.055164, Train-Class-Acc: {0: '99.46%', 1: '98.77%'}\n",
      "Val Loss: 0.731305, Val Acc: 81.25%, Val-Class-Acc: {0: '79.89%', 1: '82.61%'}, LR: 0.000531\n",
      "Epoch 90/200, Train Loss: 0.053218, Train-Class-Acc: {0: '99.05%', 1: '98.64%'}\n",
      "Val Loss: 0.724791, Val Acc: 82.07%, Val-Class-Acc: {0: '80.98%', 1: '83.15%'}, LR: 0.000531\n",
      "Epoch 91/200, Train Loss: 0.060686, Train-Class-Acc: {0: '99.32%', 1: '98.09%'}\n",
      "Val Loss: 0.793103, Val Acc: 77.72%, Val-Class-Acc: {0: '83.15%', 1: '72.28%'}, LR: 0.000531\n",
      "Epoch 92/200, Train Loss: 0.144247, Train-Class-Acc: {0: '94.69%', 1: '94.41%'}\n",
      "Val Loss: 0.648956, Val Acc: 80.71%, Val-Class-Acc: {0: '79.35%', 1: '82.07%'}, LR: 0.000531\n",
      "Epoch 93/200, Train Loss: 0.169038, Train-Class-Acc: {0: '96.19%', 1: '90.87%'}\n",
      "Val Loss: 0.637647, Val Acc: 77.17%, Val-Class-Acc: {0: '69.57%', 1: '84.78%'}, LR: 0.000531\n",
      "Epoch 94/200, Train Loss: 0.222989, Train-Class-Acc: {0: '91.42%', 1: '88.69%'}\n",
      "Val Loss: 0.563014, Val Acc: 79.35%, Val-Class-Acc: {0: '75.00%', 1: '83.70%'}, LR: 0.000478\n",
      "Epoch 95/200, Train Loss: 0.161299, Train-Class-Acc: {0: '94.82%', 1: '92.23%'}\n",
      "Val Loss: 0.567192, Val Acc: 79.62%, Val-Class-Acc: {0: '78.26%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 96/200, Train Loss: 0.132065, Train-Class-Acc: {0: '96.05%', 1: '93.32%'}\n",
      "Val Loss: 0.601292, Val Acc: 80.16%, Val-Class-Acc: {0: '78.80%', 1: '81.52%'}, LR: 0.000478\n",
      "Epoch 97/200, Train Loss: 0.115345, Train-Class-Acc: {0: '96.59%', 1: '94.96%'}\n",
      "Val Loss: 0.635759, Val Acc: 79.08%, Val-Class-Acc: {0: '80.98%', 1: '77.17%'}, LR: 0.000478\n",
      "Epoch 98/200, Train Loss: 0.103853, Train-Class-Acc: {0: '97.55%', 1: '95.64%'}\n",
      "Val Loss: 0.637276, Val Acc: 79.62%, Val-Class-Acc: {0: '78.26%', 1: '80.98%'}, LR: 0.000478\n",
      "Epoch 99/200, Train Loss: 0.099070, Train-Class-Acc: {0: '97.14%', 1: '96.32%'}\n",
      "Val Loss: 0.664814, Val Acc: 79.89%, Val-Class-Acc: {0: '82.07%', 1: '77.72%'}, LR: 0.000478\n",
      "Epoch 100/200, Train Loss: 0.090632, Train-Class-Acc: {0: '97.82%', 1: '96.32%'}\n",
      "Val Loss: 0.657660, Val Acc: 79.89%, Val-Class-Acc: {0: '79.89%', 1: '79.89%'}, LR: 0.000478\n",
      "Epoch 101/200, Train Loss: 0.083252, Train-Class-Acc: {0: '97.96%', 1: '97.41%'}\n",
      "Val Loss: 0.683831, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000478\n",
      "Epoch 102/200, Train Loss: 0.074730, Train-Class-Acc: {0: '98.50%', 1: '97.82%'}\n",
      "Val Loss: 0.696569, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000478\n",
      "Epoch 103/200, Train Loss: 0.069832, Train-Class-Acc: {0: '98.64%', 1: '98.09%'}\n",
      "Val Loss: 0.720740, Val Acc: 80.16%, Val-Class-Acc: {0: '80.98%', 1: '79.35%'}, LR: 0.000478\n",
      "Epoch 104/200, Train Loss: 0.066007, Train-Class-Acc: {0: '98.64%', 1: '98.09%'}\n",
      "Val Loss: 0.748483, Val Acc: 79.08%, Val-Class-Acc: {0: '81.52%', 1: '76.63%'}, LR: 0.000478\n",
      "Epoch 105/200, Train Loss: 0.056856, Train-Class-Acc: {0: '98.50%', 1: '98.77%'}\n",
      "Val Loss: 0.762136, Val Acc: 79.89%, Val-Class-Acc: {0: '81.52%', 1: '78.26%'}, LR: 0.000430\n",
      "Epoch 106/200, Train Loss: 0.052270, Train-Class-Acc: {0: '99.05%', 1: '98.77%'}\n",
      "Val Loss: 0.776898, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000430\n",
      "Epoch 107/200, Train Loss: 0.048461, Train-Class-Acc: {0: '99.18%', 1: '99.05%'}\n",
      "Val Loss: 0.795968, Val Acc: 79.89%, Val-Class-Acc: {0: '81.52%', 1: '78.26%'}, LR: 0.000430\n",
      "Epoch 108/200, Train Loss: 0.046523, Train-Class-Acc: {0: '99.18%', 1: '99.46%'}\n",
      "Val Loss: 0.811810, Val Acc: 79.89%, Val-Class-Acc: {0: '81.52%', 1: '78.26%'}, LR: 0.000430\n",
      "Epoch 109/200, Train Loss: 0.044462, Train-Class-Acc: {0: '99.46%', 1: '99.18%'}\n",
      "Val Loss: 0.818336, Val Acc: 79.62%, Val-Class-Acc: {0: '82.07%', 1: '77.17%'}, LR: 0.000430\n",
      "Epoch 110/200, Train Loss: 0.042456, Train-Class-Acc: {0: '99.46%', 1: '99.05%'}\n",
      "Val Loss: 0.822060, Val Acc: 80.16%, Val-Class-Acc: {0: '78.80%', 1: '81.52%'}, LR: 0.000430\n",
      "Epoch 111/200, Train Loss: 0.039084, Train-Class-Acc: {0: '99.59%', 1: '99.46%'}\n",
      "Val Loss: 0.827317, Val Acc: 79.62%, Val-Class-Acc: {0: '81.52%', 1: '77.72%'}, LR: 0.000430\n",
      "Epoch 112/200, Train Loss: 0.037624, Train-Class-Acc: {0: '99.46%', 1: '99.59%'}\n",
      "Val Loss: 0.840313, Val Acc: 80.43%, Val-Class-Acc: {0: '82.07%', 1: '78.80%'}, LR: 0.000430\n",
      "Epoch 113/200, Train Loss: 0.035132, Train-Class-Acc: {0: '99.73%', 1: '99.73%'}\n",
      "Val Loss: 0.860541, Val Acc: 79.08%, Val-Class-Acc: {0: '79.89%', 1: '78.26%'}, LR: 0.000430\n",
      "Epoch 114/200, Train Loss: 0.032599, Train-Class-Acc: {0: '99.73%', 1: '99.86%'}\n",
      "Val Loss: 0.858299, Val Acc: 80.16%, Val-Class-Acc: {0: '82.07%', 1: '78.26%'}, LR: 0.000430\n",
      "Epoch 115/200, Train Loss: 0.029402, Train-Class-Acc: {0: '99.86%', 1: '99.73%'}\n",
      "Val Loss: 0.863253, Val Acc: 80.16%, Val-Class-Acc: {0: '81.52%', 1: '78.80%'}, LR: 0.000430\n",
      "Epoch 116/200, Train Loss: 0.027803, Train-Class-Acc: {0: '99.73%', 1: '99.86%'}\n",
      "Val Loss: 0.881363, Val Acc: 79.89%, Val-Class-Acc: {0: '80.43%', 1: '79.35%'}, LR: 0.000387\n",
      "Epoch 117/200, Train Loss: 0.027303, Train-Class-Acc: {0: '99.73%', 1: '100.00%'}\n",
      "Val Loss: 0.889278, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000387\n",
      "Epoch 118/200, Train Loss: 0.024840, Train-Class-Acc: {0: '99.86%', 1: '99.86%'}\n",
      "Val Loss: 0.906389, Val Acc: 80.43%, Val-Class-Acc: {0: '80.98%', 1: '79.89%'}, LR: 0.000387\n",
      "Epoch 119/200, Train Loss: 0.024195, Train-Class-Acc: {0: '99.86%', 1: '99.86%'}\n",
      "Val Loss: 0.905028, Val Acc: 80.43%, Val-Class-Acc: {0: '80.98%', 1: '79.89%'}, LR: 0.000387\n",
      "Epoch 120/200, Train Loss: 0.023301, Train-Class-Acc: {0: '99.73%', 1: '100.00%'}\n",
      "Val Loss: 0.925774, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000387\n",
      "Epoch 121/200, Train Loss: 0.022191, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.938296, Val Acc: 80.71%, Val-Class-Acc: {0: '82.61%', 1: '78.80%'}, LR: 0.000387\n",
      "Epoch 122/200, Train Loss: 0.021785, Train-Class-Acc: {0: '99.73%', 1: '99.86%'}\n",
      "Val Loss: 0.941691, Val Acc: 79.89%, Val-Class-Acc: {0: '82.07%', 1: '77.72%'}, LR: 0.000387\n",
      "Epoch 123/200, Train Loss: 0.020233, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 0.948199, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000387\n",
      "Epoch 124/200, Train Loss: 0.020138, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 0.958437, Val Acc: 79.62%, Val-Class-Acc: {0: '80.43%', 1: '78.80%'}, LR: 0.000387\n",
      "Epoch 125/200, Train Loss: 0.020701, Train-Class-Acc: {0: '99.86%', 1: '99.73%'}\n",
      "Val Loss: 0.976017, Val Acc: 79.89%, Val-Class-Acc: {0: '82.07%', 1: '77.72%'}, LR: 0.000387\n",
      "Epoch 126/200, Train Loss: 0.018158, Train-Class-Acc: {0: '100.00%', 1: '99.86%'}\n",
      "Val Loss: 0.954894, Val Acc: 79.89%, Val-Class-Acc: {0: '79.89%', 1: '79.89%'}, LR: 0.000387\n",
      "Epoch 127/200, Train Loss: 0.016808, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 0.967659, Val Acc: 79.89%, Val-Class-Acc: {0: '79.89%', 1: '79.89%'}, LR: 0.000349\n",
      "Epoch 128/200, Train Loss: 0.015674, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.988166, Val Acc: 79.89%, Val-Class-Acc: {0: '81.52%', 1: '78.26%'}, LR: 0.000349\n",
      "Epoch 129/200, Train Loss: 0.015283, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.012043, Val Acc: 79.62%, Val-Class-Acc: {0: '83.15%', 1: '76.09%'}, LR: 0.000349\n",
      "Epoch 130/200, Train Loss: 0.022812, Train-Class-Acc: {0: '99.86%', 1: '99.73%'}\n",
      "Val Loss: 0.970152, Val Acc: 79.62%, Val-Class-Acc: {0: '78.80%', 1: '80.43%'}, LR: 0.000349\n",
      "Epoch 131/200, Train Loss: 0.018392, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.997111, Val Acc: 79.08%, Val-Class-Acc: {0: '80.43%', 1: '77.72%'}, LR: 0.000349\n",
      "Epoch 132/200, Train Loss: 0.015897, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.979944, Val Acc: 79.35%, Val-Class-Acc: {0: '80.98%', 1: '77.72%'}, LR: 0.000349\n",
      "Epoch 133/200, Train Loss: 0.014540, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.988975, Val Acc: 78.80%, Val-Class-Acc: {0: '79.89%', 1: '77.72%'}, LR: 0.000349\n",
      "Epoch 134/200, Train Loss: 0.013241, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 0.996280, Val Acc: 79.62%, Val-Class-Acc: {0: '80.98%', 1: '78.26%'}, LR: 0.000349\n",
      "Epoch 135/200, Train Loss: 0.012990, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.002542, Val Acc: 79.62%, Val-Class-Acc: {0: '78.80%', 1: '80.43%'}, LR: 0.000349\n",
      "Epoch 136/200, Train Loss: 0.015963, Train-Class-Acc: {0: '99.86%', 1: '99.86%'}\n",
      "Val Loss: 0.998425, Val Acc: 79.89%, Val-Class-Acc: {0: '78.26%', 1: '81.52%'}, LR: 0.000349\n",
      "Epoch 137/200, Train Loss: 0.013903, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.052497, Val Acc: 79.62%, Val-Class-Acc: {0: '78.80%', 1: '80.43%'}, LR: 0.000349\n",
      "Epoch 138/200, Train Loss: 0.012862, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.031315, Val Acc: 78.53%, Val-Class-Acc: {0: '79.35%', 1: '77.72%'}, LR: 0.000314\n",
      "Epoch 139/200, Train Loss: 0.011621, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.039873, Val Acc: 79.08%, Val-Class-Acc: {0: '79.89%', 1: '78.26%'}, LR: 0.000314\n",
      "Epoch 140/200, Train Loss: 0.011076, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.042860, Val Acc: 79.08%, Val-Class-Acc: {0: '79.89%', 1: '78.26%'}, LR: 0.000314\n",
      "Epoch 141/200, Train Loss: 0.012646, Train-Class-Acc: {0: '99.86%', 1: '100.00%'}\n",
      "Val Loss: 0.989408, Val Acc: 80.16%, Val-Class-Acc: {0: '80.43%', 1: '79.89%'}, LR: 0.000314\n",
      "Epoch 142/200, Train Loss: 0.014999, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.032616, Val Acc: 79.89%, Val-Class-Acc: {0: '78.80%', 1: '80.98%'}, LR: 0.000314\n",
      "Epoch 143/200, Train Loss: 0.011142, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.039833, Val Acc: 79.62%, Val-Class-Acc: {0: '79.35%', 1: '79.89%'}, LR: 0.000314\n",
      "Epoch 144/200, Train Loss: 0.009750, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.052829, Val Acc: 79.89%, Val-Class-Acc: {0: '80.43%', 1: '79.35%'}, LR: 0.000314\n",
      "Epoch 145/200, Train Loss: 0.009094, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.057255, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000314\n",
      "Epoch 146/200, Train Loss: 0.008776, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.084766, Val Acc: 79.08%, Val-Class-Acc: {0: '80.43%', 1: '77.72%'}, LR: 0.000314\n",
      "Epoch 147/200, Train Loss: 0.008605, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.087580, Val Acc: 79.35%, Val-Class-Acc: {0: '80.43%', 1: '78.26%'}, LR: 0.000314\n",
      "Epoch 148/200, Train Loss: 0.008096, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.055305, Val Acc: 80.71%, Val-Class-Acc: {0: '80.43%', 1: '80.98%'}, LR: 0.000314\n",
      "Epoch 149/200, Train Loss: 0.008794, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.041991, Val Acc: 80.43%, Val-Class-Acc: {0: '80.43%', 1: '80.43%'}, LR: 0.000282\n",
      "Epoch 150/200, Train Loss: 0.008530, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.052275, Val Acc: 80.16%, Val-Class-Acc: {0: '80.43%', 1: '79.89%'}, LR: 0.000282\n",
      "Epoch 151/200, Train Loss: 0.008085, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.079457, Val Acc: 79.89%, Val-Class-Acc: {0: '80.43%', 1: '79.35%'}, LR: 0.000282\n",
      "Epoch 152/200, Train Loss: 0.007571, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.077796, Val Acc: 79.62%, Val-Class-Acc: {0: '79.35%', 1: '79.89%'}, LR: 0.000282\n",
      "Epoch 153/200, Train Loss: 0.007159, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.084543, Val Acc: 79.89%, Val-Class-Acc: {0: '79.89%', 1: '79.89%'}, LR: 0.000282\n",
      "Epoch 154/200, Train Loss: 0.007120, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.090451, Val Acc: 79.89%, Val-Class-Acc: {0: '79.89%', 1: '79.89%'}, LR: 0.000282\n",
      "Epoch 155/200, Train Loss: 0.007010, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.101484, Val Acc: 79.62%, Val-Class-Acc: {0: '80.98%', 1: '78.26%'}, LR: 0.000282\n",
      "Epoch 156/200, Train Loss: 0.006656, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.097307, Val Acc: 79.62%, Val-Class-Acc: {0: '79.89%', 1: '79.35%'}, LR: 0.000282\n",
      "Epoch 157/200, Train Loss: 0.006294, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.104848, Val Acc: 79.62%, Val-Class-Acc: {0: '79.89%', 1: '79.35%'}, LR: 0.000282\n",
      "Epoch 158/200, Train Loss: 0.006102, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.122621, Val Acc: 80.16%, Val-Class-Acc: {0: '81.52%', 1: '78.80%'}, LR: 0.000282\n",
      "Epoch 159/200, Train Loss: 0.005932, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.123126, Val Acc: 79.62%, Val-Class-Acc: {0: '80.43%', 1: '78.80%'}, LR: 0.000282\n",
      "Epoch 160/200, Train Loss: 0.005719, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.121297, Val Acc: 79.89%, Val-Class-Acc: {0: '79.89%', 1: '79.89%'}, LR: 0.000254\n",
      "Epoch 161/200, Train Loss: 0.005567, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.124281, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000254\n",
      "Epoch 162/200, Train Loss: 0.005437, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.132565, Val Acc: 79.62%, Val-Class-Acc: {0: '80.43%', 1: '78.80%'}, LR: 0.000254\n",
      "Epoch 163/200, Train Loss: 0.005684, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.122427, Val Acc: 80.71%, Val-Class-Acc: {0: '80.43%', 1: '80.98%'}, LR: 0.000254\n",
      "Epoch 164/200, Train Loss: 0.005404, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.141544, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000254\n",
      "Epoch 165/200, Train Loss: 0.005153, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.148899, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000254\n",
      "Epoch 166/200, Train Loss: 0.005010, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.150481, Val Acc: 80.43%, Val-Class-Acc: {0: '80.98%', 1: '79.89%'}, LR: 0.000254\n",
      "Epoch 167/200, Train Loss: 0.004871, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.158756, Val Acc: 80.43%, Val-Class-Acc: {0: '80.98%', 1: '79.89%'}, LR: 0.000254\n",
      "Epoch 168/200, Train Loss: 0.004690, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.162775, Val Acc: 80.16%, Val-Class-Acc: {0: '80.98%', 1: '79.35%'}, LR: 0.000254\n",
      "Epoch 169/200, Train Loss: 0.004556, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.164566, Val Acc: 80.43%, Val-Class-Acc: {0: '80.98%', 1: '79.89%'}, LR: 0.000254\n",
      "Epoch 170/200, Train Loss: 0.004410, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.175796, Val Acc: 80.43%, Val-Class-Acc: {0: '80.98%', 1: '79.89%'}, LR: 0.000254\n",
      "Epoch 171/200, Train Loss: 0.004171, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.187798, Val Acc: 80.43%, Val-Class-Acc: {0: '80.98%', 1: '79.89%'}, LR: 0.000229\n",
      "Epoch 172/200, Train Loss: 0.004018, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.182646, Val Acc: 80.43%, Val-Class-Acc: {0: '80.98%', 1: '79.89%'}, LR: 0.000229\n",
      "Epoch 173/200, Train Loss: 0.003890, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.179978, Val Acc: 80.43%, Val-Class-Acc: {0: '80.98%', 1: '79.89%'}, LR: 0.000229\n",
      "Epoch 174/200, Train Loss: 0.004032, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.179291, Val Acc: 79.89%, Val-Class-Acc: {0: '79.89%', 1: '79.89%'}, LR: 0.000229\n",
      "Epoch 175/200, Train Loss: 0.004237, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.185122, Val Acc: 80.71%, Val-Class-Acc: {0: '80.98%', 1: '80.43%'}, LR: 0.000229\n",
      "Epoch 176/200, Train Loss: 0.003783, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.205176, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000229\n",
      "Epoch 177/200, Train Loss: 0.003740, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.202890, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000229\n",
      "Epoch 178/200, Train Loss: 0.003526, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.224580, Val Acc: 80.16%, Val-Class-Acc: {0: '80.98%', 1: '79.35%'}, LR: 0.000229\n",
      "Epoch 179/200, Train Loss: 0.003702, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.208773, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000229\n",
      "Epoch 180/200, Train Loss: 0.003614, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.203823, Val Acc: 79.62%, Val-Class-Acc: {0: '80.43%', 1: '78.80%'}, LR: 0.000229\n",
      "Epoch 181/200, Train Loss: 0.003403, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.206974, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000229\n",
      "Epoch 182/200, Train Loss: 0.003331, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.211322, Val Acc: 80.71%, Val-Class-Acc: {0: '80.98%', 1: '80.43%'}, LR: 0.000206\n",
      "Epoch 183/200, Train Loss: 0.003320, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.236287, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000206\n",
      "Epoch 184/200, Train Loss: 0.003164, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.224135, Val Acc: 80.71%, Val-Class-Acc: {0: '80.98%', 1: '80.43%'}, LR: 0.000206\n",
      "Epoch 185/200, Train Loss: 0.003036, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.226914, Val Acc: 80.71%, Val-Class-Acc: {0: '80.98%', 1: '80.43%'}, LR: 0.000206\n",
      "Epoch 186/200, Train Loss: 0.003036, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.233124, Val Acc: 80.16%, Val-Class-Acc: {0: '80.98%', 1: '79.35%'}, LR: 0.000206\n",
      "Epoch 187/200, Train Loss: 0.002932, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.247662, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000206\n",
      "Epoch 188/200, Train Loss: 0.002944, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.231653, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000206\n",
      "Epoch 189/200, Train Loss: 0.003020, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.215534, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000206\n",
      "Epoch 190/200, Train Loss: 0.002859, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.230400, Val Acc: 80.71%, Val-Class-Acc: {0: '80.98%', 1: '80.43%'}, LR: 0.000206\n",
      "Epoch 191/200, Train Loss: 0.002755, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.232906, Val Acc: 80.71%, Val-Class-Acc: {0: '80.98%', 1: '80.43%'}, LR: 0.000206\n",
      "Epoch 192/200, Train Loss: 0.002680, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.235724, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000206\n",
      "Epoch 193/200, Train Loss: 0.002587, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.241530, Val Acc: 80.98%, Val-Class-Acc: {0: '80.98%', 1: '80.98%'}, LR: 0.000185\n",
      "Epoch 194/200, Train Loss: 0.002579, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.258834, Val Acc: 79.89%, Val-Class-Acc: {0: '80.98%', 1: '78.80%'}, LR: 0.000185\n",
      "Epoch 195/200, Train Loss: 0.002537, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.230557, Val Acc: 80.71%, Val-Class-Acc: {0: '80.98%', 1: '80.43%'}, LR: 0.000185\n",
      "Epoch 196/200, Train Loss: 0.002663, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.258373, Val Acc: 80.16%, Val-Class-Acc: {0: '80.43%', 1: '79.89%'}, LR: 0.000185\n",
      "Epoch 197/200, Train Loss: 0.002492, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.233563, Val Acc: 80.43%, Val-Class-Acc: {0: '80.98%', 1: '79.89%'}, LR: 0.000185\n",
      "Epoch 198/200, Train Loss: 0.002495, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.252643, Val Acc: 80.43%, Val-Class-Acc: {0: '80.98%', 1: '79.89%'}, LR: 0.000185\n",
      "Epoch 199/200, Train Loss: 0.002397, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.260499, Val Acc: 80.16%, Val-Class-Acc: {0: '80.43%', 1: '79.89%'}, LR: 0.000185\n",
      "Epoch 200/200, Train Loss: 0.002329, Train-Class-Acc: {0: '100.00%', 1: '100.00%'}\n",
      "Val Loss: 1.263336, Val Acc: 80.16%, Val-Class-Acc: {0: '80.43%', 1: '79.89%'}, LR: 0.000185\n",
      "\n",
      "🏆 Best model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_best.pth (Val Accuracy: 84.24%)\n",
      "\n",
      "📌 Final model saved as: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_final.pth\n",
      "\n",
      "🎯 Top 5 Best Models:\n",
      "Epoch 60, Train Loss: 0.210939, Train-Acc: {0: '91.96%', 1: '89.78%'},\n",
      "Val Loss: 0.452049, Val Acc: 84.24%, Val-Class-Acc: {0: '79.89%', 1: '88.59%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_60.pth\n",
      "Epoch 56, Train Loss: 0.242753, Train-Acc: {0: '91.69%', 1: '85.42%'},\n",
      "Val Loss: 0.415696, Val Acc: 83.70%, Val-Class-Acc: {0: '82.07%', 1: '85.33%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_56.pth\n",
      "Epoch 55, Train Loss: 0.253827, Train-Acc: {0: '89.37%', 1: '86.92%'},\n",
      "Val Loss: 0.431409, Val Acc: 83.42%, Val-Class-Acc: {0: '85.87%', 1: '80.98%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_55.pth\n",
      "Epoch 16, Train Loss: 0.327386, Train-Acc: {0: '88.15%', 1: '80.65%'},\n",
      "Val Loss: 0.391876, Val Acc: 83.42%, Val-Class-Acc: {0: '88.59%', 1: '78.26%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_16.pth\n",
      "Epoch 53, Train Loss: 0.268791, Train-Acc: {0: '88.28%', 1: '84.74%'},\n",
      "Val Loss: 0.413229, Val Acc: 83.15%, Val-Class-Acc: {0: '85.33%', 1: '80.98%'}, Model Path: Class_Incremental_CL/CPSC_CIL/Model_Selection/BiGRU_Attn/BiGRU_Attn_epoch_53.pth\n",
      "\n",
      "🧠 Model Summary:\n",
      "Total Parameters: 121,218\n",
      "Model Size (float32): 0.46 MB\n",
      "Total Training Time: 482.90 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Load Period 1 Data ====\n",
    "X_train = np.load(os.path.join(save_dir, \"X_train_p1.npy\"))  # Shape: (B, 5000, 12)\n",
    "y_train = np.load(os.path.join(save_dir, \"y_train_p1.npy\"))\n",
    "X_test = np.load(os.path.join(save_dir, \"X_test_p1.npy\"))\n",
    "y_test = np.load(os.path.join(save_dir, \"y_test_p1.npy\"))\n",
    "\n",
    "# ==== Model Hyperparameters ====\n",
    "input_size = X_train.shape[2]  # 12 leads\n",
    "output_size = len(np.unique(y_train))\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "dropout = 0.0\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "device = auto_select_cuda_device()\n",
    "\n",
    "print(\"✅ input shape:\", X_train.shape)\n",
    "print(\"✅ unique y_train:\", np.unique(y_train))\n",
    "print(\"✅ unique y_test :\", np.unique(y_test))\n",
    "assert np.max(y_train) < output_size\n",
    "assert np.max(y_test) < output_size\n",
    "\n",
    "# ==== Paths ====\n",
    "stop_signal_file = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', 'CPSC_CIL/stop_training.txt'\n",
    "))\n",
    "model_saving_folder = os.path.normpath(os.path.join(\n",
    "    'Class_Incremental_CL', \"CPSC_CIL/Model_Selection/BiGRU_Attn\"\n",
    "))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# ==== Model ====\n",
    "model = BiGRUWithAttention(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=output_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "# ==== Optimizer and Training ====\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# ==== Train ====\n",
    "result_summary = train_model_general_classifier(\n",
    "    model=model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name='BiGRU_Attn',\n",
    "    stop_signal_file=stop_signal_file,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "del model, X_train, y_train, X_test, y_test\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc52675",
   "metadata": {},
   "source": [
    "## 🧪 CPSC - Model Selection Summary\n",
    "\n",
    "| Model             | Total Params  | Model Size | Training Time (s) | Val Acc | Class-wise Accuracy                 |\n",
    "|------------------|---------------|------------|--------------------|---------|-------------------------------------|\n",
    "| **MLP**           | 62,496,770    | 238.41 MB  | 53.49              | 64.40%  | {0: 61.96%, 1: 66.85%}              |\n",
    "| **ResNet18_1D**   | 3,857,026     | 14.71 MB   | 134.66             | 88.86%  | {0: 91.85%, 1: 85.87%}              |\n",
    "| **Bi-GRU**        | 406,018       | 1.55 MB    | 379.19             | 85.33%  | {0: 81.52%, 1: 89.13%}              |\n",
    "| **Bi-GRU+Attn**   | 121,218       | 0.46 MB    | 482.90             | 84.24%  | {0: 79.89%, 1: 88.59%}              |\n",
    "\n",
    "| ResNet18_1D refer `ResNet_Baseline_Selection_CPSC.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
