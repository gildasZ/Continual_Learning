{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *__Working on BTCUSD predictions with GRU model.__*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *__Check first before starting__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel is working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Do 'pipenv install ipykernel' if you get error.\n",
    "print(\"Kernel is working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: C:\\Users\\gilda\\OneDrive\\Documents\\_NYCU\\MASTER_S_studies\\Master's Thesis\\LABORATORY\\_Global_Pytorch\\Continual_Learning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the working directory to the project root\n",
    "Working_directory = os.path.normpath(\"C:/Users/gilda/OneDrive/Documents/_NYCU/MASTER_S_studies/Master\\'s Thesis/LABORATORY/_Global_Pytorch/Continual_Learning\")\n",
    "os.chdir(Working_directory)\n",
    "print(f\"Working directory: {os.getcwd()}\")  # Prints the current working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **__All imports__**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_interactions import zoom_factory, panhandler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from ta import trend, momentum, volatility, volume\n",
    "import math\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from typing import Callable, Tuple\n",
    "import shutil\n",
    "import contextlib\n",
    "import traceback\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __**All functions (For data processing)**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_folder(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "def plot_with_matplotlib(data: pd.DataFrame, \n",
    "                         title: str, \n",
    "                         interactive: bool = False, \n",
    "                         save_path: str = None, \n",
    "                         show_plot: bool = True, \n",
    "                         save_matplotlib_object: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Plot data using Matplotlib, with optional interactivity using mpl-interactions.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The data to plot, must contain 'close' column.\n",
    "    - title (str): The title of the plot.\n",
    "    - interactive (bool): If True, enables interactive zoom and pan.\n",
    "    - save_path (Optional[str]): If provided, saves the plot to this path.\n",
    "    - show_plot (bool): If True, displays the plot. If False, skips display.\n",
    "    - save_matplotlib_object (Optional[str]): If provided, saves the Matplotlib figure object to this file path.\n",
    "    \"\"\"\n",
    "    if not all(col in data.columns for col in ['close']):\n",
    "        raise ValueError(\"The input DataFrame must contain 'close' column.\")\n",
    "\n",
    "    # Use the default Matplotlib color cycle for the line\n",
    "    default_blue = plt.rcParams['axes.prop_cycle'].by_key()['color'][0]\n",
    "    print(f\"Default blue: {default_blue}\")\n",
    "\n",
    "    # Explicit colors for trends\n",
    "    trend_colors = {\n",
    "        0: 'black',\n",
    "        1: 'yellow',\n",
    "        2: 'red',\n",
    "        3: 'green',\n",
    "        4: default_blue #'purple',\n",
    "    }\n",
    "    # unique_trends = [0, -25, -15, 15, 25]\n",
    "    # colormap = plt.cm.get_cmap('tab10', len(unique_trends))  # Choose 'tab10' or 'Set1' for distinct colors\n",
    "    # trend_colors = {trend: colormap(i) for i, trend in enumerate(unique_trends)}\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Plot data as a single connected line, colored by trend\n",
    "    if 'trend' in data.columns:\n",
    "        legend_added = set() # Track which trends have already been added to the legend\n",
    "        prev_idx = data.index[0]\n",
    "        for idx, row in data.iterrows():\n",
    "            if idx != prev_idx:\n",
    "                trend_key = int(row['trend'])  # Convert trend value to int for lookup\n",
    "                label = f'Trend {trend_key}' if trend_key not in legend_added else None\n",
    "                ax.plot([prev_idx, idx], \n",
    "                        [data.loc[prev_idx, 'close'], row['close']],\n",
    "                        color=trend_colors[trend_key], \n",
    "                        linestyle='-', \n",
    "                        # marker='o', \n",
    "                        linewidth=1,\n",
    "                        label=label  # Add label only if it's not in the legend\n",
    "                )\n",
    "                legend_added.add(trend_key)  # Mark this trend as added to the legend\n",
    "            prev_idx = idx\n",
    "\n",
    "        ax.set_title(f\"{title} (Connected, Colored by Trend)\")\n",
    "    else:\n",
    "        # Default plot if no trend column exists\n",
    "        ax.plot(data.index, data['close'], label='Closing Price', linestyle='-', marker='o', \n",
    "                markersize=2, linewidth=1, color=default_blue, markerfacecolor='green', markeredgecolor='black')\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Closing Price (USD)')\n",
    "    \n",
    "    # Add a legend manually for trends\n",
    "    # for trend, color in trend_colors.items():\n",
    "    #     ax.plot([], [], color=color, label=f'Trend {trend}')\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    \n",
    "    # Enable interactivity if requested\n",
    "    if interactive:\n",
    "        zoom_factory(ax)  # Enable zoom with mouse wheel\n",
    "        panhandler(fig)   # Enable panning with left-click\n",
    "        print(\"Interactive mode enabled. Use mouse wheel to zoom and left click to pan.\")\n",
    "\n",
    "    # Save the plot if a path is provided\n",
    "    if save_path:\n",
    "        fig.tight_layout()  # Ensures the layout is clean\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to: {save_path}\")\n",
    "\n",
    "    # Save the Matplotlib figure object\n",
    "    if save_matplotlib_object:\n",
    "        with open(save_matplotlib_object, 'wb') as f:\n",
    "            pickle.dump(fig, f)\n",
    "        print(f\"Matplotlib figure object saved to: {save_matplotlib_object}\")\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Plot display skipped.\")\n",
    "\n",
    "def load_and_show_pickle(pickle_file_path: str):\n",
    "    \"\"\"\n",
    "    Load a pickled Matplotlib figure object and display it with optional interactivity.\n",
    "\n",
    "    Parameters:\n",
    "    - pickle_file_path (str): Path to the pickled Matplotlib figure file.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the pickle file and load the figure\n",
    "        with open(pickle_file_path, \"rb\") as f:\n",
    "            loaded_fig = pickle.load(f)\n",
    "\n",
    "        print(f\"Figure successfully loaded and displayed from: {pickle_file_path}\")\n",
    "\n",
    "        # Use plt.show() to allow interactivity\n",
    "        plt.show(block=True)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {pickle_file_path}. Please check the path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the pickled figure: {e}\")\n",
    "\n",
    "# Save data to CSV\n",
    "def save_to_csv(df: pd.DataFrame, file_path: str):\n",
    "    \"\"\"\n",
    "    Save a DataFrame to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the data to be saved.\n",
    "        file_path (str): The file path (including the file name) to save the CSV.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df.to_csv(file_path)\n",
    "    # df_to_save = df.copy()\n",
    "    # df_to_save[\"date\"] = df_to_save.index.strftime('%Y-%m-%d %H:%M:%S')  # Add formatted index as a column\n",
    "    \n",
    "    # Save the DataFrame to CSV\n",
    "    # df_to_save.to_csv(file_path)\n",
    "    print(f\"\\nSuccessfully saved data with moving average to CSV: \\n\\t{file_path}\\n\")\n",
    "\n",
    "def read_csv_file(file_path: str, preview_rows: int = 5, \n",
    "                  days_towards_end: int = None, \n",
    "                  days_from_start: int = None, description: str = \"\"):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns a pandas DataFrame filtered by date range.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "        preview_rows (int): Number of rows to preview (default is 5).\n",
    "        days_towards_end (int, optional): Number of days from the most recent date to retrieve data.\n",
    "        days_from_start (int, optional): Number of days from the oldest date of the filtered data to retrieve data.\n",
    "        description (str): A brief description of the dataset being loaded.\n",
    "                           Explanation:\n",
    "                           - To retrieve data from the **end**: Use `days_towards_end`.\n",
    "                           - To retrieve data from the **start of the filtered range**: Use `days_from_start`.\n",
    "                           - To retrieve data from the **middle**: Use both:\n",
    "                             For example, if `days_towards_end=100` and `days_from_start=50`,\n",
    "                             the function will first filter the last 100 days of the dataset,\n",
    "                             and then filter the first 50 days from this range.\n",
    "                             This results in data between the last 100th and the last 50th day.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The loaded and filtered data from the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if description:\n",
    "            print(f\"\\nDescription: {description}\")\n",
    "        print(f\"\\nFile path: {file_path}\")\n",
    "        \n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(file_path, parse_dates=['date'], index_col='date')\n",
    "        \n",
    "        # Filter by days towards the end\n",
    "        if days_towards_end is not None:\n",
    "            last_date = data.index.max()  # Get the most recent date in the dataset\n",
    "            end_cutoff_date = last_date - pd.Timedelta(days=days_towards_end)\n",
    "            data = data[data.index >= end_cutoff_date]\n",
    "            print(f\"\\nRetrieving data from the past {days_towards_end} days (from {end_cutoff_date.date()} onwards):\")\n",
    "        \n",
    "        # Filter by days from the start (from the filtered data)\n",
    "        if days_from_start is not None:\n",
    "            first_date = data.index.min()  # Get the earliest date in the filtered dataset\n",
    "            start_cutoff_date = first_date + pd.Timedelta(days=days_from_start)\n",
    "            data = data[data.index <= start_cutoff_date]\n",
    "            print(f\"\\nRetrieving the first {days_from_start} days from the filtered data (up to {start_cutoff_date.date()}):\")\n",
    "\n",
    "        if preview_rows:\n",
    "            # Print a preview of the data\n",
    "            print(f\"\\nPreview of the first {preview_rows} rows:\")\n",
    "            # print(data.head(preview_rows), '\\n')\n",
    "            display(data.head(preview_rows))\n",
    "            print()\n",
    "\n",
    "            print(f\"\\nPreview of the last {preview_rows} rows:\")\n",
    "            # print(data.tail(preview_rows), '\\n')\n",
    "            display(data.tail(preview_rows))\n",
    "            print()\n",
    "\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found. Please check the file path.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"Error: The file is empty.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(\"Error: The file could not be parsed. Please check the file format.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "def downsample_minute_data(data: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downsample minute data into N-minute intervals by retaining every Nth row.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The original DataFrame with a datetime index.\n",
    "        n (int): The number of minutes for the downsampling interval.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Downsampled DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"\\n========---> Downsampling the data! \\n\")\n",
    "    data = data.copy()\n",
    "    # Ensure the index is a DatetimeIndex\n",
    "    if not isinstance(data.index, pd.DatetimeIndex):\n",
    "        try:\n",
    "            data.index = pd.to_datetime(data.index)  # Convert to DatetimeIndex\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"The DataFrame index could not be converted to DatetimeIndex.\") from e\n",
    "\n",
    "    # Filter rows where the minute index modulo N is 0\n",
    "    downsampled_data = data[data.index.minute % n == 0]\n",
    "\n",
    "    return downsampled_data\n",
    "\n",
    "def add_indicators(data: pd.DataFrame, output_path: str, number_days: int = None, preview_rows: int = 5, freq: str = '1min') -> None:\n",
    "    \"\"\"\n",
    "    Adds technical indicators to a financial dataset, trims the dataset to the last N days, \n",
    "    and saves the enriched dataset to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input financial dataset. Must contain at least the following columns: \n",
    "                             'open', 'high', 'low', 'close', and 'volume'. The index should be a datetime index.\n",
    "        output_path (str): The file path where the enriched dataset will be saved as a CSV file.\n",
    "        number_days (int): The number of days to retain from the most recent date in the dataset.\n",
    "        preview_rows (int, optional): Number of rows to preview during various stages of processing. Default is 5.\n",
    "        freq (str): Frequency for the continuous time index. Default is '1min'.\n",
    "\n",
    "    Returns:\n",
    "        None: The function saves the processed dataset to a file and does not return a value.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"\\n========---> Adding indicators to the data!\")\n",
    "        if number_days is not None:\n",
    "            # Trim data to the last 190 days\n",
    "            last_date = data.index.max()  # Get the most recent date in the dataset\n",
    "            cutoff_date = last_date - pd.Timedelta(days=number_days)  # Calculate the cutoff date\n",
    "            data = data[data.index >= cutoff_date]  # Keep only rows within the last 190 days\n",
    "            print(f\"\\nData trimmed to the last {number_days} days from {cutoff_date} to {last_date}.\\n\")\n",
    "\n",
    "        # Sort data in ascending order by date for proper indicator calculations\n",
    "        data = data.sort_index(ascending=True)\n",
    "        print(f\"\\nPreview of the first {preview_rows} rows after reversing: \\n\")\n",
    "        display(data.head(preview_rows))\n",
    "\n",
    "        # Verify the presence of required columns\n",
    "        required_columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "        if not all(col in data.columns for col in required_columns):\n",
    "            raise ValueError(\"Dataset is missing required columns: 'open', 'high', 'low', 'close', 'volume'.\")\n",
    "\n",
    "        #-----------------------------------------------------------------\n",
    "        # Get missing timestamps\n",
    "        missing_timestamps = pd.date_range(\n",
    "            start=data.index.min(), # Returns smallest/earliest/oldest date\n",
    "            end=data.index.max(),\n",
    "            freq=freq,  # Use 'min' for a frequency of 1 minute, '30s' for a frequency of 30 seconds\n",
    "            tz=data.index.tz,\n",
    "        ).difference(data.index)\n",
    "\n",
    "        # Generate a continuous time index (1-minute frequency)\n",
    "        full_time_index = pd.date_range(\n",
    "            start=data.index.min(),\n",
    "            end=data.index.max(),\n",
    "            freq=freq, \n",
    "            tz=data.index.tz,\n",
    "        )\n",
    "        index_name = data.index.name\n",
    "        \n",
    "        # Reindex the DataFrame to include all timestamps, introducing NaNs for missing timestamps\n",
    "        data = data.reindex(full_time_index)\n",
    "        data.index.name = index_name  # Restore index name after reindexing\n",
    "\n",
    "        # Fill missing data with the previous available value\n",
    "        data = data.ffill()  # Forward-fill missing values\n",
    "\n",
    "        # Check if there are missing timestamps\n",
    "        if missing_timestamps.empty:\n",
    "            print(\"\\nNo missing timestamps.\\n\")\n",
    "        else:\n",
    "            for timestamp in missing_timestamps:\n",
    "                print(f\"\\nMissing timestamp: {timestamp}\")\n",
    "                try:\n",
    "                    # Safely access the row after reindexing and forward-filling\n",
    "                    print(f\"Data at missing timestamp ({timestamp}):\")\n",
    "                    print(data.loc[timestamp], '\\n')\n",
    "                except KeyError:\n",
    "                    print(f\"No data available for timestamp {timestamp}\\n\")\n",
    "\n",
    "        # Get missing timestamps\n",
    "        missing_timestamps = pd.date_range(\n",
    "            start=data.index.min(), # Returns smallest/earliest/oldest date\n",
    "            end=data.index.max(),\n",
    "            freq=freq,  # Use 'min' for a frequency of 1 minute, '30s' for a frequency of 30 seconds\n",
    "            tz=data.index.tz,\n",
    "        ).difference(data.index)\n",
    "        print(f\"\\nMissing timestamps time: \\n{missing_timestamps}\\n\")\n",
    "        #-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "        # Drop unnecessary columns if present\n",
    "        columns_to_drop = ['volume weighted average', 'barCount']  # Adjust if needed\n",
    "        data = data.drop(columns=[col for col in columns_to_drop if col in data.columns], errors='ignore')\n",
    "\n",
    "        # Add Technical Indicators\n",
    "\n",
    "        ## Trend Indicators\n",
    "        # Simple Moving Averages (SMA)\n",
    "        data['SMA_5'] = trend.sma_indicator(data['close'], window=5)\n",
    "        data['SMA_10'] = trend.sma_indicator(data['close'], window=10)\n",
    "        data['SMA_50'] = trend.sma_indicator(data['close'], window=50)\n",
    "\n",
    "        # Exponential Moving Average (EMA)\n",
    "        data['EMA_10'] = trend.ema_indicator(data['close'], window=10)\n",
    "\n",
    "        # Moving Average Convergence Divergence (MACD)\n",
    "        data['MACD'] = trend.macd(data['close'])\n",
    "        data['MACD_signal'] = trend.macd_signal(data['close'])\n",
    "\n",
    "        # Bollinger Bands\n",
    "        data['BB_upper'] = volatility.bollinger_hband(data['close'], window=20, window_dev=2)\n",
    "        data['BB_middle'] = volatility.bollinger_mavg(data['close'], window=20)\n",
    "        data['BB_lower'] = volatility.bollinger_lband(data['close'], window=20)\n",
    "\n",
    "        ## Momentum Indicators\n",
    "        # Relative Strength Index (RSI)\n",
    "        data['RSI_14'] = momentum.rsi(data['close'], window=14)\n",
    "\n",
    "        # Rate of Change (ROC)\n",
    "        data['ROC_10'] = momentum.roc(data['close'], window=10)\n",
    "\n",
    "        ## Volume Indicators\n",
    "        # On-Balance Volume (OBV)\n",
    "        data['OBV'] = volume.on_balance_volume(data['close'], data['volume'])\n",
    "\n",
    "        # Accumulation/Distribution Line (A/D Line)\n",
    "        data['AD_Line'] = volume.acc_dist_index(data['high'], data['low'], data['close'], data['volume'])\n",
    "\n",
    "        ## Volatility Indicators\n",
    "        # Average True Range (ATR)\n",
    "        data['ATR_14'] = volatility.average_true_range(data['high'], data['low'], data['close'], window=14)\n",
    "\n",
    "        # Bollinger Band Width (BBW)\n",
    "        data['BBW'] = (data['BB_upper'] - data['BB_lower']) / data['BB_middle']\n",
    "\n",
    "        # Adjust decimal precision as needed\n",
    "        data = data.round(decimals=9) \n",
    "\n",
    "        # Replace 0 values with NaN to allow forward-fill\n",
    "        data = data.replace(0, pd.NA)\n",
    "        \n",
    "        # Forward-fill to replace NaN (originally 0) with the previous row value\n",
    "        data = data.ffill()\n",
    "\n",
    "        # Drop rows with NaN values (optional, as technical indicators often result in NaN for initial (oldest dates) rows)\n",
    "        data = data.dropna()\n",
    "\n",
    "        # Sort the dataset back to descending order for final output\n",
    "        data = data.sort_index(ascending=False)\n",
    "\n",
    "        print(f\"\\nPreview of the first {preview_rows} rows with indicators: \\n\")\n",
    "        display(data.head(preview_rows))\n",
    "\n",
    "        print(f\"\\nPreview of the last {preview_rows} rows with indicators: \\n\")\n",
    "        display(data.tail(preview_rows))\n",
    "\n",
    "        # Save the enriched dataset\n",
    "        data.to_csv(output_path)\n",
    "        print(f\"\\nEnriched dataset saved to \\n\\t{output_path}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError adding indicators: {e}\\n\")\n",
    "        print(\"\\nDetailed traceback:\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Function to calculate percentage changes\n",
    "def calculate_percentage_changes(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate percentage changes for a given dataset and return the result in ascending order.\n",
    "    The `real_close` column is added after the percentage changes calculation.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The input dataset with a datetime index and numeric values (e.g., closing prices).\n",
    "                              The DataFrame must already have a properly formatted datetime index.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the percentage changes, indexed by date in ascending order.\n",
    "                      The 'real_close' column is added, holding the original close prices.\n",
    "    \"\"\"\n",
    "    data = data.sort_index(ascending=True).copy()  # Ensure chronological order\n",
    "    data_pct_change = data.pct_change() # Calculate percentage changes\n",
    "    data_pct_change['real_close'] = data['close'] # Add the 'real_close' column (copy of original 'close' column)\n",
    "    return data_pct_change.dropna()  # Drop rows with NaN values resulting from pct_change()\n",
    "\n",
    "def calculate_log_returns_all_columns(data: pd.DataFrame, exclude_columns: list = [], dropna: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate log returns for all numeric columns in a pandas DataFrame,\n",
    "    excluding specified columns, and removing excluded columns from the returned DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame containing numeric data.\n",
    "        exclude_columns (list): List of columns to exclude from log return calculations and the result.\n",
    "        dropna (bool): Whether to drop rows with NaN values resulting from the calculation.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with log returns for numeric columns,\n",
    "                      excluding specified columns.\n",
    "    \"\"\"\n",
    "    data = data.copy().drop(columns=exclude_columns)\n",
    "    columns_to_transform = data.select_dtypes(include=[np.number]).columns\n",
    "    print(f\"columns_to_transform = \\n{columns_to_transform}, \\nlen(columns_to_transform) = {len(columns_to_transform)}\")\n",
    "\n",
    "    for col in columns_to_transform:\n",
    "        # Ensure no negative or zero values\n",
    "        if (data[col] <= 0).any():\n",
    "            raise ValueError(f\"Column '{col}' contains non-positive values. Log returns require strictly positive values.\")\n",
    "        data[col] = np.log(data[col] / data[col].shift(1))\n",
    "\n",
    "    # Optionally drop rows with NaN values\n",
    "    return data.dropna() if dropna else data\n",
    "\n",
    "# Prepare the data for the model by creating sequences of input features and output targets.\n",
    "def create_sequences(data: pd.DataFrame, \n",
    "                     input_length: int, \n",
    "                     output_length: int, \n",
    "                     sliding_interval: int = 60) -> tuple[np.ndarray, np.ndarray, pd.Index]:\n",
    "    \"\"\"\n",
    "    Generate input-output sequences with a sliding window.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing features for time-series modeling, indexed by 'date'.\n",
    "        input_length (int): Number of timesteps for input sequences (e.g., 2880 for 2 days).\n",
    "        output_length (int): Number of timesteps for output sequences (e.g., 1440 for 1 day).\n",
    "        sliding_interval (int): Interval to slide the window (e.g., 60 for 1 hour).\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray, pd.Index, list, list]:\n",
    "            - X: Input sequences of shape (num_sequences, input_length, num_features).\n",
    "            - y: Output sequences of shape (num_sequences, output_length, num_features).\n",
    "            - indices: A pandas Index object with the start dates of each input sequence for reference.\n",
    "            - end_start_X: The real end values for each input sequence.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    # Preserve the date index for later reference\n",
    "    original_index = data.index\n",
    "    # print(original_index[:5])\n",
    "\n",
    "    # Reset index to allow slicing by integer position\n",
    "    data = data.reset_index(drop=True)  # Removes the 'date' column which was the index\n",
    "    print(\"\\nColumns after resetting index with drop=True: \\n\", data.columns)\n",
    "    close_column_index = data.columns.get_loc('close')\n",
    "    print(f\"'close' column index: {close_column_index}\")\n",
    "    num_columns = data.shape[1]\n",
    "    print(f\"Number of columns: {num_columns}\")\n",
    "    print('')\n",
    "    \n",
    "    X, y, indices = [], [], []\n",
    "    real_close_X = []\n",
    "    total_length = len(data)\n",
    "\n",
    "    for start in range(0, total_length - input_length - output_length + 1, sliding_interval):\n",
    "        end_input = start + input_length\n",
    "        end_output = end_input + output_length\n",
    "\n",
    "        # Slice input and output sequences, excluding 'real_close' column\n",
    "        X.append(data.iloc[start:end_input].drop(columns=['real_close']).values)\n",
    "        y.append(data.iloc[end_input:end_output].values)\n",
    "        \n",
    "        # Save the start date of the sequence\n",
    "        indices.append(original_index[start])\n",
    "\n",
    "        # Get the real 'close' value at the start of the input and output sequences\n",
    "        real_close_X.append(data.iloc[start:end_input]['real_close'])\n",
    "    \n",
    "    return np.array(X), np.array(y), pd.Index(indices), np.array(real_close_X)\n",
    "\n",
    "def created_sequences_2(data: pd.DataFrame, sequence_length: int = 60, sliding_interval: int = 60) -> list:\n",
    "    \"\"\"\n",
    "    Divide the dataset into sequences based on the sequence_length.\n",
    "    Each sequence must fully cover the window size.\n",
    "\n",
    "    Args:\n",
    "    - data (pd.DataFrame): The input DataFrame.\n",
    "    - sequence_length (int): The window size for sequences.\n",
    "\n",
    "    Returns:\n",
    "    - sequences (list): A list of sequences (as DataFrames).\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    for i in range(0, len(data) - sequence_length + 1, sliding_interval):\n",
    "        # print(f\"Processing sequence starting at index: {i}\")\n",
    "        seq = data.iloc[i:i + sequence_length].copy()\n",
    "        sequences.append(seq)\n",
    "    # print(f\"Total sequences created: {len(sequences)}\")\n",
    "    return sequences\n",
    "\n",
    "def prepare_percentage_change_data(df: pd.DataFrame, \n",
    "                                   features: list, \n",
    "                                   target: str = 'close', \n",
    "                                   window_size: int = 50, \n",
    "                                   test_size: float = 0.25, \n",
    "                                   shuffle: bool = False) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Prepares percentage change stock data for training a sequence-based model.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The percentage change data.\n",
    "        features (list): List of column names to use as input features.\n",
    "        target (str): The column name to predict.\n",
    "        window_size (int): The size of the sliding window.\n",
    "        test_size (float): The proportion of the dataset to include in the test split.\n",
    "        shuffle (bool): Whether to shuffle the data before splitting.\n",
    "\n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test: Prepared train and test datasets.\n",
    "    \"\"\"\n",
    "    # Create sequences\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(df) - window_size):\n",
    "        sequences.append(df[features].iloc[i:i + window_size].values)\n",
    "        targets.append(df[target].iloc[i + window_size])  # Predict the target at the next step\n",
    "    \n",
    "    sequences = np.array(sequences)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(sequences, targets, test_size=test_size, shuffle=shuffle)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def moving_average(data, window_size=5):\n",
    "    data = data.sort_index(ascending=True).copy()\n",
    "    return data.rolling(window=window_size).mean()\n",
    "\n",
    "def exponential_moving_average(data, span=5):\n",
    "    data = data.sort_index(ascending=True).copy()\n",
    "    return data.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def gaussian_smoothing(data: pd.DataFrame, sigma=2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies Gaussian smoothing to numeric columns in a DataFrame and ensures the index is sorted in ascending order.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "        sigma (float): Standard deviation for the Gaussian kernel. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with smoothed numeric columns and sorted index.\n",
    "    \"\"\"\n",
    "    # Sort the DataFrame by index in ascending order\n",
    "    data = data.sort_index(ascending=True).copy()\n",
    "    for column in data.columns:\n",
    "        if pd.api.types.is_numeric_dtype(data[column]):  # Only apply to numeric columns\n",
    "            data[column] = gaussian_filter1d(data[column].values, sigma=sigma)\n",
    "    return data\n",
    "\n",
    "def detect_trends(\n",
    "    dataframe: pd.DataFrame, \n",
    "    column: str = 'close', \n",
    "    lower_threshold: float = 0.10, \n",
    "    upper_threshold: float = 0.20\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes a DataFrame to calculate log returns and categorize trends based on thresholds.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Input DataFrame containing the price data.\n",
    "        column (str): Column name for price data. Defaults to 'close'.\n",
    "        lower_threshold (float): Threshold for categorizing moderate trends. Defaults to 0.10.\n",
    "        upper_threshold (float): Threshold for categorizing strong trends. Defaults to 0.20.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with added columns:\n",
    "                      - 'log_return': Logarithmic returns of the specified column.\n",
    "                      - 'trend': Categorized trend values:\n",
    "                          - -25 for very strong negative trend\n",
    "                          - -15 for moderate negative trend\n",
    "                          - 0 for no trend\n",
    "                          - 15 for moderate positive trend\n",
    "                          - 25 for very strong positive trend\n",
    "    \"\"\"\n",
    "    # Copy to avoid modifying the original DataFrame\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    # Calculate log returns\n",
    "    df['log_return'] = np.log(df[column] / df[column].shift(1))\n",
    "    \n",
    "    # Function to categorize trends\n",
    "    def categorize_trend(log_return):\n",
    "        if log_return < -upper_threshold:\n",
    "            return -25\n",
    "        elif -upper_threshold <= log_return < -lower_threshold:\n",
    "            return -15\n",
    "        elif -lower_threshold <= log_return <= lower_threshold:\n",
    "            return 0\n",
    "        elif lower_threshold < log_return <= upper_threshold:\n",
    "            return 15\n",
    "        else:  # log_return > upper_threshold\n",
    "            return 25\n",
    "    \n",
    "    # Apply trend categorization\n",
    "    df['trend'] = df['log_return'].apply(categorize_trend)\n",
    "\n",
    "    # Drop NaN values caused by shift\n",
    "    return df.dropna()\n",
    "\n",
    "def detect_trends_2(\n",
    "    dataframe: pd.DataFrame, \n",
    "    column: str = 'close', \n",
    "    lower_threshold: float = 0.10, \n",
    "    upper_threshold: float = 0.20\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes a DataFrame to calculate log returns and categorize trends using interval bins.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Input DataFrame containing the price data.\n",
    "        column (str): Column name for price data. Defaults to 'close'.\n",
    "        lower_threshold (float): Threshold for categorizing moderate trends. Defaults to 0.10.\n",
    "        upper_threshold (float): Threshold for categorizing strong trends. Defaults to 0.20.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with added columns:\n",
    "                      - 'log_return': Logarithmic returns of the specified column.\n",
    "                      - 'trend': Categorized trend values:\n",
    "                          - -25 for very strong negative trend\n",
    "                          - -15 for moderate negative trend\n",
    "                          - 0 for no trend\n",
    "                          - 15 for moderate positive trend\n",
    "                          - 25 for very strong positive trend\n",
    "    \"\"\"\n",
    "    # Copy to avoid modifying the original DataFrame\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    # Calculate log returns\n",
    "    df['log_return'] = np.log(df[column] / df[column].shift(1))\n",
    "    \n",
    "    # Define bins and corresponding labels for trends\n",
    "    bins = [-np.inf, -upper_threshold, -lower_threshold, lower_threshold, upper_threshold, np.inf]\n",
    "    labels = [-25, -15, 0, 15, 25]\n",
    "    \n",
    "    # Categorize trends using pd.cut\n",
    "    df['trend'] = pd.cut(df['log_return'], bins=bins, labels=labels, right=True)\n",
    "    \n",
    "    # Replace NaN trends with 0 (default value for no trend)\n",
    "    df['trend'] = df['trend'].fillna(0).astype(int)\n",
    "\n",
    "    # Drop NaN values caused by shift\n",
    "    return df.dropna()\n",
    "\n",
    "def detect_trends_3(\n",
    "    dataframe: pd.DataFrame, \n",
    "    column: str = 'close', \n",
    "    lower_threshold: float = 0.001, \n",
    "    upper_threshold: float = 0.02,\n",
    "    reverse_steps: int = 7\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detects trends based on log return data provided in a specified column and categorizes them into different strength levels.\n",
    "\n",
    "    This function analyzes time-series data by evaluating cumulative trends in log return values provided in the input DataFrame. It uses three dictionaries (`dic1`, `dic2`, `dic3`) to track different phases of trends, handles multi-step reversals, and classifies trends dynamically based on cumulative product thresholds and specified thresholds for trend strengths.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Input DataFrame containing log return data.\n",
    "        column (str): Column name containing log return values. Defaults to 'close'.\n",
    "        lower_threshold (float): Threshold for categorizing moderate trends. Defaults to 0.001.\n",
    "        upper_threshold (float): Threshold for categorizing strong trends. Defaults to 0.02.\n",
    "        reverse_steps (int): Number of consecutive steps to confirm a trend reversal. Defaults to 7.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with an added column:\n",
    "                    - 'trend': Categorized trend values based on the detected phases:\n",
    "                        - 0: No trend\n",
    "                        - 1: Moderate negative trend\n",
    "                        - 2: Very strong negative trend\n",
    "                        - 3: Moderate positive trend\n",
    "                        - 4: Very strong positive trend\n",
    "\n",
    "    Function Details:\n",
    "    1. **Input Assumption**:\n",
    "    - The input DataFrame already contains log return data in the specified column (`column`).\n",
    "\n",
    "    2. **Trend Tracking**:\n",
    "    - Uses dictionaries to monitor trends:\n",
    "        - `dic1`: Tracks the first phase of the trend.\n",
    "        - `dic2`: Tracks the second phase if a reversal occurs.\n",
    "        - `dic3`: Tracks the third phase if another reversal occurs.\n",
    "\n",
    "    3. **Cumulative Product**:\n",
    "    - Calculates the cumulative product of `(1 + log_return)` from the specified column to evaluate the strength of trends.\n",
    "\n",
    "    4. **Reversal Handling**:\n",
    "    - If a trend reversal persists beyond `reverse_steps`, labels are assigned based on the cumulative product tracked in `dic1`.\n",
    "    - Subsequent reversals are merged or labeled independently if conditions are met.\n",
    "\n",
    "    5. **Label Assignment**:\n",
    "    - Labels are dynamically assigned based on cumulative product thresholds for positive and negative trends:\n",
    "        - Positive trends are categorized as moderate (3) or strong (4).\n",
    "        - Negative trends are categorized as moderate (1) or strong (2).\n",
    "\n",
    "    6. **Edge Cases**:\n",
    "    - Properly handles scenarios where data points are insufficient for trend analysis or when trend phases overlap, ensuring all data points are labeled.\n",
    "    \"\"\"\n",
    "    # Copy to avoid modifying the original DataFrame\n",
    "    df = dataframe.copy()\n",
    "    df['trend'] = None  # Default value \n",
    "    \n",
    "    # print(\"\\n#-------------------- Working on 'trend' patterns -----------------------#\")\n",
    "    dic1, dic2, dic3 = None, None, None # Initialize trend tracking dictionaries\n",
    "    # dic1 = None # {'ids': [], 'last_sign': None, 'cumulative': 1.0}\n",
    "    \n",
    "    def assign_label(dictio_, lower_threshold, upper_threshold):\n",
    "        cumulative = dictio_['cumulative']\n",
    "        # print(f\"cumulative = {cumulative}\")\n",
    "        if cumulative > (1 + upper_threshold):\n",
    "            df.iloc[dictio_['ids'], df.columns.get_loc('trend')] = 4  # Very strong positive\n",
    "        elif (1 + lower_threshold) < cumulative <= (1 + upper_threshold):\n",
    "            df.iloc[dictio_['ids'], df.columns.get_loc('trend')] = 3  # Moderate positive\n",
    "        elif (1 - upper_threshold) < cumulative <= (1 - lower_threshold):\n",
    "            df.iloc[dictio_['ids'], df.columns.get_loc('trend')] = 1  # Moderate negative\n",
    "        elif cumulative <= (1 - upper_threshold):\n",
    "            df.iloc[dictio_['ids'], df.columns.get_loc('trend')] = 2  # Very strong negative\n",
    "        else:\n",
    "            df.iloc[dictio_['ids'], df.columns.get_loc('trend')] = 0  # No trend\n",
    "    \n",
    "    #----------------------- For Loop -----------------------#\n",
    "    for idx, log_ret in enumerate(df[column]):\n",
    "        sign = 1 if log_ret > 0 else -1\n",
    "\n",
    "        if dic1 is None:  # Initialize dic1\n",
    "            # print(f\"\\nThis one time condition 'if loop' is running \\n\")\n",
    "            dic1 = {'ids': [idx], 'last_sign': sign, 'cumulative': (1 + log_ret)}\n",
    "            continue\n",
    "        last_sign = dic1['last_sign']\n",
    "        if sign == last_sign and dic2 is None:  # Continue same trend\n",
    "            dic1['ids'].append(idx)\n",
    "            dic1['last_sign'] = sign\n",
    "            dic1['cumulative'] *= (1 + log_ret)\n",
    "            continue\n",
    "\n",
    "        # 1st Reversal occuring\n",
    "        if dic2 is None:  # Start dic2\n",
    "            dic2 = {'ids': [idx], 'last_sign': sign, 'cumulative': (1 + log_ret)}\n",
    "            continue\n",
    "        last_sign = dic2['last_sign']\n",
    "        if sign == last_sign and dic3 is None:  # Continue same trend\n",
    "            dic2['ids'].append(idx)\n",
    "            dic2['last_sign'] = sign\n",
    "            dic2['cumulative'] *= (1 + log_ret)\n",
    "            if len(dic2['ids']) == reverse_steps:\n",
    "                assign_label(dic1, lower_threshold, upper_threshold) # Assign labels in the 'trend' column for ids of dic1\n",
    "                # print(f\"dic1['cumulative'] = {dic1['cumulative']}, and dic1['ids'] = {dic1['ids']}\")\n",
    "                dic1 = dic2\n",
    "                dic2 = None\n",
    "                # print(f\"dic1 after trend reversal persisted and dic1 = dic2 = \\n{dic1}\")\n",
    "                # print(f\"dic2 after being reset: {dic2}\\n\")\n",
    "            continue\n",
    "\n",
    "        # 2nd Reversal occuring\n",
    "        if dic3 is None:  # Start dic3\n",
    "            dic3 = {'ids': [idx], 'last_sign': sign, 'cumulative': (1 + log_ret)}\n",
    "            continue\n",
    "        last_sign = dic3['last_sign']\n",
    "        if sign == last_sign: # Continue same trend, there is no dic4 to check if is None\n",
    "            dic3['ids'].append(idx)\n",
    "            dic3['last_sign'] = sign\n",
    "            dic3['cumulative'] *= (1 + log_ret)\n",
    "            dic_prod = dic2['cumulative'] * dic3['cumulative']\n",
    "            # if (sign == 1 and dic1['cumulative'] * dic_prod > dic1['cumulative']) or (sign == -1 and dic1['cumulative'] * dic_prod < dic1['cumulative'])):\n",
    "            if (sign == 1 and dic_prod > 1) or (sign == -1 and dic_prod < 1): # More beautiful\n",
    "                # Merge dic1, dic2, and dic3\n",
    "                dic1['ids'] += dic2['ids'] + dic3['ids']\n",
    "                dic1['last_sign'] = dic3['last_sign']\n",
    "                dic1['cumulative'] *= dic2['cumulative'] * dic3['cumulative']\n",
    "                dic2, dic3 = None, None\n",
    "                continue\n",
    "\n",
    "            if len(dic3['ids']) == reverse_steps:      \n",
    "                assign_label(dic1, lower_threshold, upper_threshold) # Assign labels in the 'trend' column for ids of dic1\n",
    "                assign_label(dic2, lower_threshold, upper_threshold) # Assign labels in the 'trend' column for ids of dic1\n",
    "                dic1 = dic3\n",
    "                dic2, dic3 = None, None\n",
    "                # print(f\"dic2 after 2nd trend reversal didn't catch up fast enough, and now \\ndic1 = dic3 = {dic1}\")\n",
    "                # print(f\"dic3 and dic2 after being reset: {dic3}\\n\")\n",
    "            continue\n",
    "            \n",
    "        # 3rd Reversal occuring\n",
    "        assign_label(dic1, lower_threshold, upper_threshold) # Assign labels in the 'trend' column for ids of dic1\n",
    "        # Reassign values\n",
    "        dic1 = dic2\n",
    "        dic2 = dic3\n",
    "        dic3 = {'ids': [idx], 'last_sign': sign, 'cumulative': (1 + log_ret)}\n",
    "        # print(f\"There was a 3rd trend reversal, and now \\ndic1 = dic2 = {dic1}, \\ndic2 = dic3 = {dic2}\")\n",
    "        # print(f\"dic3 after being reset: {dic3}\\n\")\n",
    "\n",
    "    # Assign remaining labels\n",
    "    if dic1:\n",
    "        assign_label(dic1, lower_threshold, upper_threshold)\n",
    "    if dic2:\n",
    "        assign_label(dic2, lower_threshold, upper_threshold)\n",
    "    if dic3:\n",
    "        assign_label(dic3, lower_threshold, upper_threshold)\n",
    "    # print(\"\\n#-------------------- Returning 'trend' patterns ------------------------#\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def detect_trends_4(\n",
    "    dataframe: pd.DataFrame, \n",
    "    column: str = 'close', \n",
    "    lower_threshold: float = 0.001, \n",
    "    upper_threshold: float = 0.02,\n",
    "    reverse_steps: int = 7,\n",
    "    trends_to_keep: set = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detects trends based on log return data provided in a specified column and categorizes them into different strength levels.\n",
    "\n",
    "    This function analyzes time-series data by evaluating cumulative trends in log return values provided in the input DataFrame. \n",
    "    It uses three dictionaries (`dic1`, `dic2`, `dic3`) to track different phases of trends, handles multi-step reversals, and \n",
    "    classifies trends dynamically based on cumulative product thresholds and specified thresholds for trend strengths.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Input DataFrame containing log return data.\n",
    "        column (str): Column name containing log return values. Defaults to 'close'.\n",
    "        lower_threshold (float): Threshold for categorizing moderate trends. Defaults to 0.001.\n",
    "        upper_threshold (float): Threshold for categorizing strong trends. Defaults to 0.02.\n",
    "        reverse_steps (int): Number of consecutive steps to confirm a trend reversal. Defaults to 7.\n",
    "        trends_to_keep (set): A set of trend categories to retain; others will be set to 0 (No Trend). Defaults to keeping all trends {0, 1, 2, 3, 4}.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with an added column:\n",
    "                    - 'trend': Categorized trend values based on the detected phases:\n",
    "                        - 0: No trend\n",
    "                        - 1: Moderate negative trend\n",
    "                        - 2: Very strong negative trend\n",
    "                        - 3: Moderate positive trend\n",
    "                        - 4: Very strong positive trend\n",
    "                      Any trends not included in `trends_to_keep` will be reset to 0.\n",
    "\n",
    "    Function Details:\n",
    "    1. **Input Assumption**:\n",
    "    - The input DataFrame already contains log return data in the specified column (`column`).\n",
    "\n",
    "    2. **Trend Tracking**:\n",
    "    - Uses dictionaries to monitor trends:\n",
    "        - `dic1`: Tracks the first phase of the trend.\n",
    "        - `dic2`: Tracks the second phase if a reversal occurs.\n",
    "        - `dic3`: Tracks the third phase if another reversal occurs.\n",
    "\n",
    "    3. **Cumulative Product**:\n",
    "    - Calculates the cumulative product of `(1 + log_return)` from the specified column to evaluate the strength of trends.\n",
    "\n",
    "    4. **Reversal Handling**:\n",
    "    - If a trend reversal persists beyond `reverse_steps`, labels are assigned based on the cumulative product tracked in `dic1`.\n",
    "    - Subsequent reversals are merged or labeled independently if conditions are met.\n",
    "\n",
    "    5. **Label Assignment**:\n",
    "    - Labels are dynamically assigned based on cumulative product thresholds for positive and negative trends:\n",
    "        - Positive trends are categorized as moderate (3) or strong (4).\n",
    "        - Negative trends are categorized as moderate (1) or strong (2).\n",
    "\n",
    "    6. **Trend Filtering**:\n",
    "    - After detecting trends, only those specified in `trends_to_keep` remain unchanged.\n",
    "    - Any trend category not included in `trends_to_keep` is reset to 0 (No Trend).\n",
    "\n",
    "    7. **Edge Cases**:\n",
    "    - Properly handles scenarios where data points are insufficient for trend analysis or when trend phases overlap, ensuring all data points are labeled.\n",
    "    \"\"\"\n",
    "    # Copy to avoid modifying the original DataFrame\n",
    "    df = dataframe.copy()\n",
    "    df['trend'] = None  # Default value \n",
    "    \n",
    "    # print(\"\\n#-------------------- Working on 'trend' patterns -----------------------#\")\n",
    "    dic1, dic2, dic3 = None, None, None # Initialize trend tracking dictionaries\n",
    "    # dic1 = None # {'ids': [], 'last_sign': None, 'cumulative': 1.0}\n",
    "    \n",
    "    def assign_label(dictio_, lower_threshold, upper_threshold):\n",
    "        cumulative = dictio_['cumulative']\n",
    "        # print(f\"cumulative = {cumulative}\")\n",
    "        if cumulative > (1 + upper_threshold):\n",
    "            df.iloc[dictio_['ids'], df.columns.get_loc('trend')] = 4  # Very strong positive\n",
    "        elif (1 + lower_threshold) < cumulative <= (1 + upper_threshold):\n",
    "            df.iloc[dictio_['ids'], df.columns.get_loc('trend')] = 3  # Moderate positive\n",
    "        elif (1 - upper_threshold) < cumulative <= (1 - lower_threshold):\n",
    "            df.iloc[dictio_['ids'], df.columns.get_loc('trend')] = 1  # Moderate negative\n",
    "        elif cumulative <= (1 - upper_threshold):\n",
    "            df.iloc[dictio_['ids'], df.columns.get_loc('trend')] = 2  # Very strong negative\n",
    "        else:\n",
    "            df.iloc[dictio_['ids'], df.columns.get_loc('trend')] = 0  # No trend\n",
    "    \n",
    "    #----------------------- For Loop -----------------------#\n",
    "    for idx, log_ret in enumerate(df[column]):\n",
    "        sign = 1 if log_ret > 0 else -1\n",
    "\n",
    "        if dic1 is None:  # Initialize dic1\n",
    "            # print(f\"\\nThis one time condition 'if loop' is running \\n\")\n",
    "            dic1 = {'ids': [idx], 'last_sign': sign, 'cumulative': (1 + log_ret)}\n",
    "            continue\n",
    "        last_sign = dic1['last_sign']\n",
    "        if sign == last_sign and dic2 is None:  # Continue same trend\n",
    "            dic1['ids'].append(idx)\n",
    "            dic1['last_sign'] = sign\n",
    "            dic1['cumulative'] *= (1 + log_ret)\n",
    "            continue\n",
    "\n",
    "        # 1st Reversal occuring\n",
    "        if dic2 is None:  # Start dic2\n",
    "            dic2 = {'ids': [idx], 'last_sign': sign, 'cumulative': (1 + log_ret)}\n",
    "            continue\n",
    "        last_sign = dic2['last_sign']\n",
    "        if sign == last_sign and dic3 is None:  # Continue same trend\n",
    "            dic2['ids'].append(idx)\n",
    "            dic2['last_sign'] = sign\n",
    "            dic2['cumulative'] *= (1 + log_ret)\n",
    "            if len(dic2['ids']) == reverse_steps:\n",
    "                assign_label(dic1, lower_threshold, upper_threshold) # Assign labels in the 'trend' column for ids of dic1\n",
    "                # print(f\"dic1['cumulative'] = {dic1['cumulative']}, and dic1['ids'] = {dic1['ids']}\")\n",
    "                dic1 = dic2\n",
    "                dic2 = None\n",
    "                # print(f\"dic1 after trend reversal persisted and dic1 = dic2 = \\n{dic1}\")\n",
    "                # print(f\"dic2 after being reset: {dic2}\\n\")\n",
    "            continue\n",
    "\n",
    "        # 2nd Reversal occuring\n",
    "        if dic3 is None:  # Start dic3\n",
    "            dic3 = {'ids': [idx], 'last_sign': sign, 'cumulative': (1 + log_ret)}\n",
    "            continue\n",
    "        last_sign = dic3['last_sign']\n",
    "        if sign == last_sign: # Continue same trend, there is no dic4 to check if is None\n",
    "            dic3['ids'].append(idx)\n",
    "            dic3['last_sign'] = sign\n",
    "            dic3['cumulative'] *= (1 + log_ret)\n",
    "            dic_prod = dic2['cumulative'] * dic3['cumulative']\n",
    "            # if (sign == 1 and dic1['cumulative'] * dic_prod > dic1['cumulative']) or (sign == -1 and dic1['cumulative'] * dic_prod < dic1['cumulative'])):\n",
    "            if (sign == 1 and dic_prod > 1) or (sign == -1 and dic_prod < 1): # More beautiful\n",
    "                # Merge dic1, dic2, and dic3\n",
    "                dic1['ids'] += dic2['ids'] + dic3['ids']\n",
    "                dic1['last_sign'] = dic3['last_sign']\n",
    "                dic1['cumulative'] *= dic2['cumulative'] * dic3['cumulative']\n",
    "                dic2, dic3 = None, None\n",
    "                continue\n",
    "\n",
    "            if len(dic3['ids']) == reverse_steps:      \n",
    "                assign_label(dic1, lower_threshold, upper_threshold) # Assign labels in the 'trend' column for ids of dic1\n",
    "                assign_label(dic2, lower_threshold, upper_threshold) # Assign labels in the 'trend' column for ids of dic1\n",
    "                dic1 = dic3\n",
    "                dic2, dic3 = None, None\n",
    "                # print(f\"dic2 after 2nd trend reversal didn't catch up fast enough, and now \\ndic1 = dic3 = {dic1}\")\n",
    "                # print(f\"dic3 and dic2 after being reset: {dic3}\\n\")\n",
    "            continue\n",
    "            \n",
    "        # 3rd Reversal occuring\n",
    "        assign_label(dic1, lower_threshold, upper_threshold) # Assign labels in the 'trend' column for ids of dic1\n",
    "        # Reassign values\n",
    "        dic1 = dic2\n",
    "        dic2 = dic3\n",
    "        dic3 = {'ids': [idx], 'last_sign': sign, 'cumulative': (1 + log_ret)}\n",
    "        # print(f\"There was a 3rd trend reversal, and now \\ndic1 = dic2 = {dic1}, \\ndic2 = dic3 = {dic2}\")\n",
    "        # print(f\"dic3 after being reset: {dic3}\\n\")\n",
    "\n",
    "    # Assign remaining labels\n",
    "    if dic1:\n",
    "        assign_label(dic1, lower_threshold, upper_threshold)\n",
    "    if dic2:\n",
    "        assign_label(dic2, lower_threshold, upper_threshold)\n",
    "    if dic3:\n",
    "        assign_label(dic3, lower_threshold, upper_threshold)\n",
    "    # print(\"\\n#-------------------- Returning 'trend' patterns ------------------------#\")\n",
    "    \n",
    "    # Apply filtering: Keep only selected trends, set others to 0\n",
    "    df['trend'] = df['trend'].apply(lambda x: x if x in trends_to_keep else 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def split_X_y(sequences: list[pd.DataFrame], \n",
    "              target_column: str = 'trend',\n",
    "              detect_trends_function: Callable[[pd.DataFrame, str, float, float, int, set], pd.DataFrame] = detect_trends_4, \n",
    "              column: str = 'close', \n",
    "              lower_threshold: float = 0.0009, \n",
    "              upper_threshold: float = 0.015,\n",
    "              reverse_steps: int = 7,\n",
    "              trends_to_keep: set = {0, 1, 2, 3, 4}) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Process sequences to generate features (X) and labels (y) while applying trend detection.\n",
    "\n",
    "    Args:\n",
    "    - sequences (list of pd.DataFrame): List of DataFrame sequences.\n",
    "    - lower_threshold (float): Lower threshold for trend detection.\n",
    "    - upper_threshold (float): Upper threshold for trend detection.\n",
    "    - reverse_steps (int): Steps to reverse trends in the sequence.\n",
    "    - target_column (str): Column name to use as the label (default: 'trend').\n",
    "    - detect_trends_function (Callable): Function for detecting trends, defaults to `detect_trends_4`.\n",
    "    - trends_to_keep (set): A set of trend categories to retain; others will be set to 0 (No Trend).\n",
    "\n",
    "    Returns:\n",
    "    - X (np.ndarray): Features array of shape (num_sequences, sequence_length, num_features).\n",
    "    - y (np.ndarray): Labels array of shape (num_sequences,).\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    # count = 0\n",
    "    for seq in sequences:\n",
    "        # Apply trend detection on the sequence\n",
    "        seq = detect_trends_function(seq, column=column, \n",
    "                                     lower_threshold=lower_threshold, \n",
    "                                     upper_threshold=upper_threshold, \n",
    "                                     reverse_steps=reverse_steps,\n",
    "                                     trends_to_keep=trends_to_keep)\n",
    "        # if count == 0:\n",
    "        #     count = 1\n",
    "        #     print(f\"\\nseq.head()\")\n",
    "        #     display(seq.head())\n",
    "        #     print()\n",
    "        # Extract features (X) and labels (y)\n",
    "        X.append(seq.drop(columns=[target_column]).values)  # All but the target column\n",
    "        y.append(seq[target_column].values)  # Target column as labels\n",
    "        \n",
    "    # return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def relabel_split_data(\n",
    "    data: pd.DataFrame, \n",
    "    detect_trends_function: Callable[[pd.DataFrame, str, float, float, int], pd.DataFrame], \n",
    "    column: str = 'close', \n",
    "    lower_threshold: float = 0.0009, \n",
    "    upper_threshold: float = 0.015,\n",
    "    reverse_steps: int = 7\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Relabels the start and end of a DataFrame based on trend consistency.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The DataFrame to relabel.\n",
    "        detect_trends_function (Callable): A callable function to detect trends.\n",
    "        column (str): Column name for trend detection. Defaults to 'close'.\n",
    "        lower_threshold (float): Lower threshold for trend detection.\n",
    "        upper_threshold (float): Upper threshold for trend detection.\n",
    "        reverse_steps (int): Number of steps for reversal detection.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The relabeled DataFrame.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "\n",
    "    # Get the start and end labels\n",
    "    start_label = data['trend'].iloc[0]\n",
    "    end_label = data['trend'].iloc[-1]\n",
    "\n",
    "    # Identify start segment\n",
    "    if start_label != 0:\n",
    "        start_segment = []\n",
    "        for idx, label in enumerate(data['trend']):\n",
    "            if label == start_label:\n",
    "                start_segment.append(idx)\n",
    "            else:\n",
    "                break\n",
    "        start_segment = data.iloc[start_segment][[column]].copy()\n",
    "        print(f\"Start segment's label is not 0, it is {start_label} and data: \")\n",
    "        display(data.loc[start_segment.index])\n",
    "        # Apply trend detection on the start and end segments and Update the 'trend' column for the start and end segments\n",
    "        if not start_segment.empty:\n",
    "            start_segment_relabel = detect_trends_function(start_segment, column, lower_threshold, upper_threshold, reverse_steps)\n",
    "            data.loc[start_segment.index, 'trend'] = start_segment_relabel['trend']\n",
    "        print(\"Start segment after new label added: \")\n",
    "        display(data.loc[start_segment.index])\n",
    "    else:\n",
    "        print(f\"The start segment has a label of '{start_label}', so no operation needed. \")\n",
    "\n",
    "    # Identify end segment\n",
    "    if end_label != 0:\n",
    "        end_segment = []\n",
    "        for idx in range(len(data) - 1, -1, -1):\n",
    "            if data['trend'].iloc[idx] == end_label:\n",
    "                end_segment.append(idx)\n",
    "            else:\n",
    "                break\n",
    "        end_segment = data.iloc[sorted(end_segment)][[column]].copy()\n",
    "        print(f\"End segment's label is not 0, it is {end_label} and data: \")\n",
    "        display(data.loc[end_segment.index])\n",
    "        # Apply trend detection on the start and end segments and Update the 'trend' column for the start and end segments\n",
    "        if not end_segment.empty:\n",
    "            end_segment_relabel = detect_trends_function(end_segment, column, lower_threshold, upper_threshold, reverse_steps)\n",
    "            data.loc[end_segment.index, 'trend'] = end_segment_relabel['trend']\n",
    "        print(\"End segment after new label added: \")\n",
    "        display(data.loc[end_segment.index])\n",
    "    else:\n",
    "        print(f\"The end segment has a label of '{end_label}', so no operation needed. \")\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_and_return_splits(\n",
    "    with_indicators_file_path: str,\n",
    "    downsampled_data_minutes: int,\n",
    "    exclude_columns: list[str],\n",
    "    lower_threshold: float,\n",
    "    upper_threshold: float,\n",
    "    reverse_steps: int,\n",
    "    sequence_length: int,\n",
    "    sliding_interval: int,\n",
    "    trends_to_keep: set = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    ") -> tuple[\n",
    "    list[list[float]],  # X_train: List of sequences, each containing a list of features\n",
    "    list[list[int]],    # y_train: List of sequences, each containing a list of labels\n",
    "    list[list[float]],  # X_val: List of sequences, each containing a list of features\n",
    "    list[list[int]],    # y_val: List of sequences, each containing a list of labels\n",
    "    list[list[float]],  # X_test: List of sequences, each containing a list of features\n",
    "    list[list[int]]     # y_test: List of sequences, each containing a list of labels\n",
    "]:\n",
    "    \"\"\"\n",
    "    Processes time-series data from a CSV file and prepares it for machine learning.\n",
    "\n",
    "    This function performs the following steps:\n",
    "        1. Reads data from the specified CSV file and sorts it by date in descending order.\n",
    "        2. Optionally downsamples the data to a lower frequency (e.g., 5-minute intervals).\n",
    "        3. Applies Gaussian smoothing to reduce noise in the data.\n",
    "        4. Calculates log returns for all numeric columns, excluding specified columns.\n",
    "        5. Detects trends based on defined thresholds (`lower_threshold`, `upper_threshold`, and `reverse_steps`).\n",
    "        6. Filters trends to keep only those specified in `trends_to_keep`, setting others to 0 (No Trend).\n",
    "        7. Converts the processed data into sequences of a fixed length (`sequence_length`) with a sliding interval.\n",
    "        8. Splits the sequences into training (80%), validation (10%), and test (10%) sets.\n",
    "        9. Further splits the sequences into features (`X`) and labels (`y`) for supervised learning.\n",
    "\n",
    "    Args:\n",
    "        with_indicators_file_path (str): Path to the CSV file containing the time-series data.\n",
    "        downsampled_data_minutes (int): Frequency for downsampling the data (e.g., 1 for no downsampling).\n",
    "        exclude_columns (list[str]): List of column names to exclude from log return calculations.\n",
    "        lower_threshold (float): Lower threshold for trend detection.\n",
    "        upper_threshold (float): Upper threshold for trend detection.\n",
    "        reverse_steps (int): Number of steps for reversing trends in trend detection.\n",
    "        sequence_length (int): Length of sequences to create from the data.\n",
    "        sliding_interval (int): Interval for sliding the window when creating sequences.\n",
    "        trends_to_keep (set): A set of trend categories to retain; others will be set to 0 (No Trend). Defaults to keeping all trends {0, 1, 2, 3, 4}.\n",
    "\n",
    "    Returns:\n",
    "        tuple[list[list[float]], list[list[int]], list[list[float]], list[list[int]], list[list[float]], list[list[int]]]:\n",
    "            A tuple containing:\n",
    "            - X_train (list[list[float]]): Input sequences for training.\n",
    "            - y_train (list[list[int]]): Target sequences for training.\n",
    "            - X_val (list[list[float]]): Input sequences for validation.\n",
    "            - y_val (list[list[int]]): Target sequences for validation.\n",
    "            - X_test (list[list[float]]): Input sequences for testing.\n",
    "            - y_test (list[list[int]]): Target sequences for testing.\n",
    "\n",
    "    Example:\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = process_and_return_splits(\n",
    "            with_indicators_file_path=\"data.csv\",\n",
    "            downsampled_data_minutes=5,\n",
    "            exclude_columns=[\"volume\"],\n",
    "            lower_threshold=-0.05,\n",
    "            upper_threshold=0.05,\n",
    "            reverse_steps=3,\n",
    "            sequence_length=50,\n",
    "            sliding_interval=5,\n",
    "            trends_to_keep={1, 2, 3, 4}  # Only keep categorized trends, set others to 0\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    data_retrieved = read_csv_file(with_indicators_file_path, preview_rows=0) # 190 days of data\n",
    "    data_retrieved = data_retrieved.sort_index(ascending=False)\n",
    "\n",
    "    #---------------------------------------------------------------------------------------\n",
    "    if downsampled_data_minutes != 1:\n",
    "        print(\"Downsampling the data! \\n\")\n",
    "        data_retrieved = downsample_minute_data(data_retrieved, downsampled_data_minutes)\n",
    "    #---------------------------------------------------------------------------------------\n",
    "\n",
    "    # Get missing timestamps\n",
    "    missing_timestamps = pd.date_range(\n",
    "        start=data_retrieved.index.min(), # Returns smallest/earliest/oldest date\n",
    "        end=data_retrieved.index.max(),\n",
    "        freq='1min',  # Use 'min' for a frequency of 1 minute, '30s' for a frequency of 30 seconds\n",
    "        tz=data_retrieved.index.tz,\n",
    "    ).difference(data_retrieved.index)\n",
    "    print(f\"\\ndata_retrieved - Missing timestamps time: \\n{missing_timestamps}\") \n",
    "\n",
    "    data_gaussian = gaussian_smoothing(data_retrieved, sigma=7)\n",
    "\n",
    "    # Get missing timestamps\n",
    "    missing_timestamps = pd.date_range(\n",
    "        start=data_gaussian.index.min(), # Returns smallest/earliest/oldest date\n",
    "        end=data_gaussian.index.max(),\n",
    "        freq='1min',  # Use 'min' for a frequency of 1 minute, '30s' for a frequency of 30 seconds\n",
    "        tz=data_gaussian.index.tz,\n",
    "    ).difference(data_gaussian.index)\n",
    "    print(f\"\\ndata_gaussian - Missing timestamps time: \\n{missing_timestamps}\\n\")\n",
    "\n",
    "    data_log_return = calculate_log_returns_all_columns(data_gaussian, exclude_columns=exclude_columns)\n",
    "\n",
    "    # Get missing timestamps\n",
    "    missing_timestamps = pd.date_range(\n",
    "        start=data_log_return.index.min(), # Returns smallest/earliest/oldest date\n",
    "        end=data_log_return.index.max(),\n",
    "        freq='1min',  # Use 'min' for a frequency of 1 minute, '30s' for a frequency of 30 seconds\n",
    "        tz=data_log_return.index.tz,\n",
    "    ).difference(data_log_return.index)\n",
    "    print(f\"\\ndata_log_return - Missing timestamps time: \\n{missing_timestamps}\\n\") \n",
    "\n",
    "    # Check if there are missing timestamps\n",
    "    if missing_timestamps.empty:\n",
    "        print(\"No missing timestamps.\")\n",
    "    else:\n",
    "        for timestamp in missing_timestamps:\n",
    "            print(f\"\\nMissing timestamp: {timestamp}\")\n",
    "            \n",
    "            # Create a placeholder for the missing timestamp\n",
    "            if timestamp not in data_log_return.index:\n",
    "                print('Missing')\n",
    "            \n",
    "            # Get data before and after the missing timestamp\n",
    "            before_data = data_log_return[data_log_return.index < timestamp].tail(5)  # 5 data points before\n",
    "            after_data = data_log_return[data_log_return.index > timestamp].head(5)  # 5 data points after\n",
    "            \n",
    "            # Display surrounding data\n",
    "            if not before_data.empty:\n",
    "                print(\"\\nData before:\")\n",
    "                print(before_data)\n",
    "            else:\n",
    "                print(\"\\nNo data available before the missing timestamp.\")\n",
    "            \n",
    "            if not after_data.empty:\n",
    "                print(\"\\nData after:\")\n",
    "                print(after_data)\n",
    "            else:\n",
    "                print(\"\\nNo data available after the missing timestamp.\")\n",
    "\n",
    "    sequences = created_sequences_2(data_log_return, sequence_length, sliding_interval)\n",
    "\n",
    "    # Split sequences into training, validation, and test sets\n",
    "    train_size = int(len(sequences) * 0.8)\n",
    "    val_size = int(len(sequences) * 0.1)\n",
    "\n",
    "    train_sequences = sequences[:train_size]\n",
    "    val_sequences = sequences[train_size:train_size + val_size]\n",
    "    test_sequences = sequences[train_size + val_size:]\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Number of sequences:\n",
    "        - sequences[0].shape: {sequences[0].shape}\n",
    "        - Total sequences: {len(sequences)}\n",
    "        - Train sequences: {len(train_sequences)}\n",
    "        - Validation sequences: {len(val_sequences)}\n",
    "        - Test sequences: {len(test_sequences)}\n",
    "    \"\"\")\n",
    "\n",
    "    # Process train, validation, and test sets\n",
    "    X_train, y_train = split_X_y(train_sequences, \n",
    "                                target_column='trend',\n",
    "                                detect_trends_function = detect_trends_4,\n",
    "                                column= 'close',\n",
    "                                lower_threshold=lower_threshold, \n",
    "                                upper_threshold=upper_threshold, \n",
    "                                reverse_steps=reverse_steps,\n",
    "                                trends_to_keep=trends_to_keep)\n",
    "\n",
    "    X_val, y_val = split_X_y(val_sequences, \n",
    "                            target_column='trend',\n",
    "                            detect_trends_function = detect_trends_4,\n",
    "                            column= 'close',\n",
    "                            lower_threshold=lower_threshold, \n",
    "                            upper_threshold=upper_threshold, \n",
    "                            reverse_steps=reverse_steps,\n",
    "                            trends_to_keep=trends_to_keep)\n",
    "\n",
    "    X_test, y_test = split_X_y(test_sequences, \n",
    "                            target_column='trend',\n",
    "                            detect_trends_function = detect_trends_4,\n",
    "                            column= 'close',\n",
    "                            lower_threshold=lower_threshold, \n",
    "                            upper_threshold=upper_threshold, \n",
    "                            reverse_steps=reverse_steps,\n",
    "                            trends_to_keep=trends_to_keep)\n",
    "\n",
    "    # Checking X arrays\n",
    "    for idx, seq in enumerate(X_train):  # Loop through sequences\n",
    "        for sub_idx, feature_set in enumerate(seq):  # Loop through data points\n",
    "            for feature_idx, feature in enumerate(feature_set):  # Loop through features\n",
    "                if not isinstance(feature, (float, np.float32)):  # Check each feature\n",
    "                    print(f\"Unexpected type in X_train at sequence {idx}, data point {sub_idx}, feature {feature_idx}: {type(feature)}\")\n",
    "\n",
    "    # Checking y arrays\n",
    "    for idx, seq in enumerate(y_train):  # Loop through sequences\n",
    "        for sub_idx, label in enumerate(seq):  # Loop through data points (labels)\n",
    "            if not isinstance(label, (int, np.int64)):  # Check each label\n",
    "                print(f\"Unexpected type in y_train at sequence {idx}, data point {sub_idx}: {type(label)}\")\n",
    "\n",
    "    # Checking X arrays\n",
    "    for idx, seq in enumerate(X_val):  # Loop through sequences\n",
    "        for sub_idx, feature_set in enumerate(seq):  # Loop through data points\n",
    "            for feature_idx, feature in enumerate(feature_set):  # Loop through features\n",
    "                if not isinstance(feature, (float, np.float32)):  # Check each feature\n",
    "                    print(f\"Unexpected type in X_val at sequence {idx}, data point {sub_idx}, feature {feature_idx}: {type(feature)}\")\n",
    "    # Checking y arrays\n",
    "    for idx, seq in enumerate(y_val):  # Loop through sequences\n",
    "        for sub_idx, label in enumerate(seq):  # Loop through data points (labels)\n",
    "            if not isinstance(label, (int, np.int64)):  # Check each label\n",
    "                print(f\"Unexpected type in y_val at sequence {idx}, data point {sub_idx}: {type(label)}\")\n",
    "\n",
    "    # Checking X arrays\n",
    "    for idx, seq in enumerate(X_test):  # Loop through sequences\n",
    "        for sub_idx, feature_set in enumerate(seq):  # Loop through data points\n",
    "            for feature_idx, feature in enumerate(feature_set):  # Loop through features\n",
    "                if not isinstance(feature, (float, np.float32)):  # Check each feature\n",
    "                    print(f\"Unexpected type in X_test at sequence {idx}, data point {sub_idx}, feature {feature_idx}: {type(feature)}\")\n",
    "    # Checking y arrays\n",
    "    for idx, seq in enumerate(y_test):  # Loop through sequences\n",
    "        for sub_idx, label in enumerate(seq):  # Loop through data points (labels)\n",
    "            if not isinstance(label, (int, np.int64)):  # Check each label\n",
    "                print(f\"Unexpected type in y_test at sequence {idx}, data point {sub_idx}: {type(label)}\")\n",
    "\n",
    "    if isinstance(y_train, np.ndarray) and y_train.dtype == np.object_:\n",
    "        # Convert to numeric if needed\n",
    "        y_train = np.array(y_train, dtype=np.int64)\n",
    "\n",
    "    if isinstance(y_val, np.ndarray) and y_val.dtype == np.object_:\n",
    "        # Convert to numeric if needed\n",
    "        y_val = np.array(y_val, dtype=np.int64)\n",
    "\n",
    "    if isinstance(y_test, np.ndarray) and y_test.dtype == np.object_:\n",
    "        # Convert to numeric if needed\n",
    "        y_test = np.array(y_test, dtype=np.int64)\n",
    "\n",
    "    close_col_index = data_log_return.columns.get_loc('close') # 'date' is set as index so doesnt count as a column\n",
    "    Number_features = X_train.shape[-1]\n",
    "    print(f\"close_col_index = {close_col_index}\")\n",
    "    print(f\"Number_features = {Number_features}\")\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, Number_features\n",
    "\n",
    "def print_class_distribution(y, var_name) -> None:\n",
    "    # Convert to NumPy array and flatten\n",
    "    if isinstance(y, torch.Tensor):\n",
    "        y = y.cpu().numpy()\n",
    "    flattened = np.array(y).flatten()\n",
    "    # Count class occurrences\n",
    "    unique_classes, counts = np.unique(flattened, return_counts=True)\n",
    "    total = counts.sum()\n",
    "    # Create class distribution dictionary\n",
    "    # class_distribution = {\n",
    "    #     int(c): f\"{(count / total) * 100:.2f}%\"\n",
    "    #     for c, count in zip(unique_classes, counts)\n",
    "    # }\n",
    "    # # print(f\"Class Distribution for '{var_name}':\", \", \".join(\n",
    "    # #     [f\"Class {c}: {pct}\" for c, pct in class_distribution.items()]\n",
    "    # # ))\n",
    "    header = f\"Class Distribution for '{var_name}': \"\n",
    "    line_parts = [\n",
    "        f\"Class {int(c):<3} Percent: {(count / total) * 100:>6.2f}%\"\n",
    "        for c, count in zip(unique_classes, counts)\n",
    "    ]\n",
    "    # line_parts = [\n",
    "    #     f\"Class {int(c):<3} | Count: {int(count):>5} | Percent: {(count / total) * 100:>6.2f}%\"\n",
    "    #     for c, count in zip(unique_classes, counts)\n",
    "    # ]\n",
    "    print(header.ljust(40) + \" || \".join(line_parts))\n",
    "    # Print header\n",
    "    # print(f\"\\nClass Distribution for '{var_name}':\")\n",
    "    # print(\"-\" * 40)\n",
    "    # print(f\"{'Class':<10}{'Count':>10}{'Percentage':>15}\")\n",
    "    # print(\"-\" * 40)\n",
    "    # # Print each class\n",
    "    # for c, count in zip(unique_classes, counts):\n",
    "    #     pct = f\"{(count / total) * 100:.2f}%\"\n",
    "    #     print(f\"{str(c):<10}{str(count):>10}{pct:>15}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All(Initial) parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'BTC-USD'\n",
    "downsampled_data_minutes = 1\n",
    "\n",
    "# Step 0 (Again): Identify parameters for trend settings of the loaded data with 1,000 data points\n",
    "lower_threshold = 0.0009 \n",
    "upper_threshold = 0.015\n",
    "reverse_steps = 13\n",
    "\n",
    "\n",
    "exclude_columns= ['MACD', 'MACD_signal', 'ROC_10', 'OBV', 'AD_Line']\n",
    "# exclude_columns= []#['open', 'high', 'low', 'MACD', 'MACD_signal', 'BB_middle', 'ROC_10', 'OBV', 'AD_Line']\n",
    "\n",
    "# Step 3, under ### Correlation Analysis\n",
    "# Compute correlations with the 'trend' column\n",
    "# corr = data_trends.corr()\n",
    "# trend_corr = corr['trend'].sort_values(ascending=False)\n",
    "strongly_correlated = ['close', 'open', 'SMA_5', 'high', 'low', 'EMA_10', 'SMA_10'] # Strongly correlated (correlation > 0.6)\n",
    "moderately_correlated = ['BB_middle', 'BB_lower', 'BB_upper', 'RSI_14'] # Moderately correlated (correlation between 0.3 and 0.6)\n",
    "weakly_correlated = ['SMA_50', 'volume', 'BBW', 'ATR_14'] # Weakly correlated or negligible (correlation <~ 0.3)\n",
    "\n",
    "exclude_columns += weakly_correlated + moderately_correlated\n",
    "# print(exclude_columns)\n",
    "\n",
    "\n",
    "sequence_length = 1000\n",
    "sliding_interval = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_Build the GRU Model_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  2 02:15:39 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.14                 Driver Version: 566.14         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   45C    P8              3W /   95W |    1944MiB /   8188MiB |     11%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1392    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A      5128    C+G   ...m Files\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A      6748    C+G   ..._x64__2p2nqsd0c76g0\\app\\ChatGPT.exe      N/A      |\n",
      "|    0   N/A  N/A      7972    C+G   ...s\\System32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12960    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     13332    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13712    C+G   ...ocal\\Programs\\Windsurf\\Windsurf.exe      N/A      |\n",
      "|    0   N/A  N/A     14996    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     15356    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     15800    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     21612    C+G   ...354.0_x64__dt26b99r8h8gj\\RtkUWP.exe      N/A      |\n",
      "|    0   N/A  N/A     23648    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     25092    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     25456    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     29996    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     30164    C+G   ....0_x64__kzh8wxbdkxb8p\\DCv2\\DCv2.exe      N/A      |\n",
      "|    0   N/A  N/A     34228    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     39356    C+G   ...pp_cw5n1h2txyewy\\CHXSmartScreen.exe      N/A      |\n",
      "|    0   N/A  N/A     40060    C+G   ...m Files\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A     40200    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# If not in Jupyter Notebook\n",
    "# import subprocess\n",
    "# result = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True)\n",
    "# print(result.stdout)\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch and CUDA check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available() True\n",
      "\n",
      "GPU Device Name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Number of GPUs: 1\n",
      "Total CUDA Cores: 3072\n",
      "Current GPU Device: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "gpu_available = torch.cuda.is_available()\n",
    "\n",
    "print(\"torch.cuda.is_available()\", gpu_available)\n",
    "\n",
    "# If GPU is available, print additional information\n",
    "if gpu_available:\n",
    "    print(\"\\nGPU Device Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Total CUDA Cores:\", torch.cuda.get_device_properties(0).multi_processor_count * 128)  # NVIDIA GPUs often have 128 cores/SM\n",
    "    print(\"Current GPU Device:\", torch.cuda.current_device())\n",
    "else:\n",
    "    print(\"No GPU detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bi-Directional GRU with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRUWithAttention(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, num_layers: int, dropout: float = 0.0):\n",
    "        super(BiGRUWithAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # Bi-Directional GRU Layer\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        # Attention layer\n",
    "        self.attention_fc = nn.Linear(hidden_size * 2, hidden_size * 2)  # Hidden size * 2 for bi-directional\n",
    "        # Fully connected layer for classification\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)  # Apply dropout before the fully connected layer\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight_ih' in name or 'weight_hh' in name: # GRU weights\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'weight' in name: # Other weights (attention, fc)\n",
    "                nn.init.xavier_uniform_(param)  # Xavier initialization for weights\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)  # Zero initialization for biases\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)  # Bi-directional: num_layers * 2\n",
    "        # Bi-Directional GRU forward pass\n",
    "        out, _ = self.gru(x, h0)  # Shape: (batch_size, seq_length, hidden_size * 2)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attn_weights = torch.tanh(self.attention_fc(out))  # Shape: (batch_size, seq_length, hidden_size * 2)\n",
    "        out = attn_weights * out  # Element-wise attention application\n",
    "        out = self.dropout(out)  # Apply dropout\n",
    "\n",
    "        # Fully connected layer (applied at each time step)\n",
    "        out = self.fc(out)  # Shape: (batch_size, seq_length, output_size)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EWC Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# EWC Class Definition\n",
    "##############################################\n",
    "\n",
    "class EWC:\n",
    "    \"\"\"\n",
    "    Elastic Weight Consolidation (EWC) for preventing catastrophic forgetting.\n",
    "    This class computes the Fisher Information matrix for each parameter (using a provided dataloader)\n",
    "    and stores a copy of the model parameters after training on the previous task, and\n",
    "    provides a penalty term for the loss function.\n",
    "    \"\"\"\n",
    "    def __init__(self, fisher: dict, params: dict):\n",
    "        \"\"\"\n",
    "        Initializes EWC with pre-computed Fisher matrix and optimal parameters.\n",
    "        Args:\n",
    "            fisher (dict): Dictionary mapping parameter names to Fisher information tensors (on CPU).\n",
    "            params (dict): Dictionary mapping parameter names to optimal parameter tensors from the previous task (on CPU).\n",
    "        \"\"\"\n",
    "        # Store fisher and params, assuming they are passed on CPU\n",
    "        self.fisher = {k: v.cpu() for k, v in fisher.items()} # Ensure CPU\n",
    "        self.params = {k: v.cpu() for k, v in params.items()} # Ensure CPU\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_fisher_and_params(model: nn.Module, dataloader: DataLoader, criterion: nn.Module,\n",
    "                                  device: torch.device, sample_size: int = None):\n",
    "        \"\"\"\n",
    "        Computes the diagonal Fisher Information Matrix (FIM) and copies optimal parameters.\n",
    "        (REVISED VERSION 3: Uses model.train() required by RNN backward, but\n",
    "         temporarily disables dropout during forward pass).\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): The trained model (best model for the task).\n",
    "            dataloader (DataLoader): DataLoader for the task's training data.\n",
    "            criterion (nn.Module): The loss function used for training.\n",
    "            device (torch.device): The device ('cuda' or 'cpu') for computation.\n",
    "            sample_size (int, optional): Max number of samples to use for FIM estimation.\n",
    "\n",
    "        Returns:\n",
    "            tuple(dict, dict): (fisher_dict_cpu, params_dict_cpu) on CPU.\n",
    "        \"\"\"\n",
    "        print(\"Starting Fisher Information Matrix calculation (v3: train mode for RNN backward)...\")\n",
    "\n",
    "        # --- Store optimal parameters ---\n",
    "        try:\n",
    "            params_dict_cpu = {n: p.clone().cpu().detach()\n",
    "                               for n, p in model.named_parameters() if p.requires_grad}\n",
    "        except Exception as e:\n",
    "            print(f\"Error cloning/detaching parameters: {e}\")\n",
    "            return {}, {}\n",
    "\n",
    "        # --- Initialize Fisher dictionary on the computation device ---\n",
    "        fisher_dict = {n: torch.zeros_like(p, device=device)\n",
    "                       for n, p in model.named_parameters() if p.requires_grad and n in params_dict_cpu}\n",
    "\n",
    "        if not fisher_dict:\n",
    "             print(\"Warning: No parameters requiring gradients found.\")\n",
    "             return {}, params_dict_cpu\n",
    "\n",
    "        # --- Store original mode and set model to TRAIN mode (required for RNN backward) ---\n",
    "        original_mode_was_training = model.training\n",
    "        model.train()\n",
    "        print(f\"Model temporarily set to TRAIN mode for Fisher calculation.\")\n",
    "\n",
    "        # --- Temporarily disable Dropout layers ---\n",
    "        # Store original dropout states\n",
    "        dropout_states = {}\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, nn.Dropout):\n",
    "                dropout_states[name] = module.training\n",
    "                module.eval() # Put dropout layer itself in eval mode\n",
    "        if dropout_states:\n",
    "             print(\"Dropout layers temporarily disabled during forward pass.\")\n",
    "\n",
    "        # --- Loop Variables ---\n",
    "        num_samples_processed = 0\n",
    "        num_batches = 0\n",
    "        calculation_successful = True\n",
    "\n",
    "        print(f\"Processing data batches on device: {device}\")\n",
    "        for batch_idx, (x, y) in enumerate(dataloader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            current_batch_size = x.size(0)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            # --- Forward pass ---\n",
    "            # Model is in train() mode globally, but Dropout layers are manually in eval()\n",
    "            try:\n",
    "                 outputs = model(x)\n",
    "                 output_size = outputs.size(-1)\n",
    "                 outputs_flat = outputs.view(-1, output_size)\n",
    "                 y_flat = y.view(-1)\n",
    "            except Exception as e:\n",
    "                 print(f\"----> ERROR during forward pass or reshape in batch {batch_idx}: {e}. Skipping.\")\n",
    "                 calculation_successful = False\n",
    "                 continue # Skip to next batch\n",
    "\n",
    "            # --- Validate labels ---\n",
    "            valid_indices = (y_flat >= 0) & (y_flat < output_size)\n",
    "            if not valid_indices.all():\n",
    "                # Filter labels (optional print)\n",
    "                outputs_flat = outputs_flat[valid_indices]\n",
    "                y_flat = y_flat[valid_indices]\n",
    "                if y_flat.numel() == 0: continue # Skip if batch empty\n",
    "\n",
    "            # --- Calculate loss ---\n",
    "            try:\n",
    "                loss = criterion(outputs_flat, y_flat)\n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(f\"----> WARNING: Loss is {loss} in batch {batch_idx}. Skipping backward pass.\")\n",
    "                    continue # Skip gradient calculation\n",
    "            except Exception as e:\n",
    "                 print(f\"----> ERROR calculating loss in batch {batch_idx}: {e}. Skipping.\")\n",
    "                 calculation_successful = False\n",
    "                 continue\n",
    "\n",
    "            # --- Calculate gradients (Model *must* be in train mode here for RNN) ---\n",
    "            try:\n",
    "                loss.backward()\n",
    "            except Exception as e:\n",
    "                # Catch the specific RNN error if it happens again, though it shouldn't now\n",
    "                if \"RNN backward can only be called in training mode\" in str(e):\n",
    "                     print(f\"----> CRITICAL INTERNAL ERROR: RNN backward error despite model being in train mode? {e}\")\n",
    "                else:\n",
    "                     print(f\"----> ERROR during loss.backward() in batch {batch_idx}: {e}. Skipping accumulation.\")\n",
    "                calculation_successful = False\n",
    "                continue # Skip accumulation for this batch\n",
    "\n",
    "            # --- Accumulate squared gradients ---\n",
    "            for n, p in model.named_parameters():\n",
    "                if p.requires_grad and p.grad is not None and n in fisher_dict:\n",
    "                    grad_data = p.grad.data\n",
    "                    # --- Keep gradient checks ---\n",
    "                    if torch.isnan(grad_data).any() or torch.isinf(grad_data).any(): continue # Skip if NaN/Inf\n",
    "                    try: squared_grad = grad_data.to(device).pow(2)\n",
    "                    except Exception as e: continue # Skip if power fails\n",
    "                    if torch.isnan(squared_grad).any() or torch.isinf(squared_grad).any(): continue # Skip if NaN/Inf after pow\n",
    "                    if squared_grad.min() < 0: # Critical check\n",
    "                        print(f\"----> CRITICAL ERROR: Negative value ({squared_grad.min().item():.4e}) found after .pow(2) for '{n}'.\")\n",
    "                        calculation_successful = False # Mark as failed\n",
    "                        continue # Skip bad value\n",
    "                    # --- Accumulate ---\n",
    "                    fisher_dict[n] += squared_grad * current_batch_size\n",
    "\n",
    "            # --- Update counters ---\n",
    "            num_samples_processed += current_batch_size\n",
    "            num_batches += 1\n",
    "\n",
    "            # --- Check sample size limit ---\n",
    "            if sample_size is not None and num_samples_processed >= sample_size:\n",
    "                print(f\"Stopping Fisher computation early after {num_samples_processed} samples.\")\n",
    "                break\n",
    "\n",
    "        # --- Restore Dropout states ---\n",
    "        if dropout_states:\n",
    "            print(\"Restoring original Dropout layer states...\")\n",
    "            for name, module in model.named_modules():\n",
    "                if name in dropout_states:\n",
    "                    module.train(dropout_states[name]) # Set back to original state (True/False)\n",
    "\n",
    "        # --- Restore original model mode ---\n",
    "        model.train(original_mode_was_training) # Set back to True or False\n",
    "        print(f\"Model mode restored to original state (training={original_mode_was_training}).\")\n",
    "\n",
    "        # --- Post-loop checks and Normalization ---\n",
    "        if num_samples_processed == 0:\n",
    "             print(\"Warning: No samples processed successfully. Fisher matrix will be zeros.\")\n",
    "             fisher_dict_cpu = {n: f.cpu().detach() for n, f in fisher_dict.items()} # Still return zeros\n",
    "             return fisher_dict_cpu, params_dict_cpu\n",
    "\n",
    "        if not calculation_successful:\n",
    "             print(\"ERROR: Issues encountered during calculation. Fisher matrix may be inaccurate or invalid.\")\n",
    "             # Return potentially bad dict but warn user\n",
    "             \n",
    "        print(f\"Finished accumulating gradients over {num_samples_processed} samples.\")\n",
    "        print(\"Normalizing Fisher matrix...\")\n",
    "        fisher_dict_cpu = {}\n",
    "        for n, f_tensor in fisher_dict.items():\n",
    "            if num_samples_processed > 0:\n",
    "                normalized_f = f_tensor / num_samples_processed\n",
    "                # Final check after normalization\n",
    "                if normalized_f.min() < 0: print(f\"----> CRITICAL WARNING: Negative value found AFTER NORM for '{n}'.\")\n",
    "                if torch.isnan(normalized_f).any() or torch.isinf(normalized_f).any(): print(f\"----> WARNING: NaN/Inf found AFTER NORM for '{n}'.\")\n",
    "                fisher_dict_cpu[n] = normalized_f.cpu().detach() # Store on CPU\n",
    "            else:\n",
    "                 fisher_dict_cpu[n] = torch.zeros_like(f_tensor).cpu().detach()\n",
    "\n",
    "        print(\"Fisher Information Matrix calculation complete.\")\n",
    "        return fisher_dict_cpu, params_dict_cpu\n",
    "\n",
    "\n",
    "    def penalty(self, model: nn.Module) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculates the EWC penalty term based on stored Fisher and params.\n",
    "        (Includes optional checks for negative/nan/inf Fisher values)\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'fisher') or not hasattr(self, 'params') or not self.fisher or not self.params:\n",
    "             return torch.tensor(0.0, device=next(model.parameters()).device)\n",
    "\n",
    "        penalty_loss = torch.tensor(0.0, device=next(model.parameters()).device)\n",
    "        model_device = penalty_loss.device # Get model device once\n",
    "\n",
    "        for n, p in model.named_parameters():\n",
    "            # Check if param exists in EWC state and requires grad in current model\n",
    "            if n in self.fisher and n in self.params and p.requires_grad:\n",
    "                stored_fisher_n = self.fisher[n]\n",
    "                stored_params_n = self.params[n]\n",
    "\n",
    "                if p.shape == stored_params_n.shape:\n",
    "                    try:\n",
    "                        # Move stored tensors to model's device\n",
    "                        fisher_n_device = stored_fisher_n.to(model_device)\n",
    "                        params_n_device = stored_params_n.to(model_device)\n",
    "\n",
    "                        # --- Check Fisher validity before using ---\n",
    "                        if fisher_n_device.min() < 0:\n",
    "                             # print(f\"---> Warning: Negative Fisher ({fisher_n_device.min():.4e}) in PENALTY for '{n}'. Skipping.\")\n",
    "                             continue\n",
    "                        if torch.isnan(fisher_n_device).any() or torch.isinf(fisher_n_device).any():\n",
    "                             # print(f\"---> Warning: NaN/Inf Fisher in PENALTY for '{n}'. Skipping.\")\n",
    "                             continue\n",
    "\n",
    "                        diff_sq = (p - params_n_device).pow(2)\n",
    "                        term_penalty = (fisher_n_device * diff_sq).sum()\n",
    "\n",
    "                        # --- Check resulting term ---\n",
    "                        if not torch.isnan(term_penalty) and not torch.isinf(term_penalty):\n",
    "                              penalty_loss += term_penalty\n",
    "                        # else:\n",
    "                              # print(f\"---> Warning: NaN/Inf term_penalty for '{n}'. Skipping addition.\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing penalty for layer {n}: {e}\")\n",
    "                        continue\n",
    "        return penalty_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation function for Period 1.\n",
    "def train_and_validate(model, output_size, criterion, optimizer, \n",
    "                       X_train, y_train, X_val, y_val, scheduler, \n",
    "                       use_scheduler=False, num_epochs=10, batch_size=64, \n",
    "                       model_saving_folder=None, model_name=None, stop_signal_file=None):\n",
    "    \"\"\"\n",
    "    Base training function (Period 1) without EWC.\n",
    "    This is essentially your provided training loop.\n",
    "    \"\"\"\n",
    "    print(\"'train_and_validate' function started. \\n\")\n",
    "    # Ensure model saving folder exists (deleting existing first if there is one)\n",
    "    if model_saving_folder and os.path.exists(model_saving_folder):\n",
    "        # os.rmdir(model_saving_folder) # Only works on empty folders \n",
    "        shutil.rmtree(model_saving_folder) # Safely remove all contents\n",
    "        if not os.path.exists(model_saving_folder):\n",
    "            print(f\"Existing folder has been removed : {model_saving_folder}\\n\")\n",
    "    if model_saving_folder and not os.path.exists(model_saving_folder):\n",
    "        os.makedirs(model_saving_folder)\n",
    "        \n",
    "    if not model_saving_folder:\n",
    "        model_saving_folder = './saved_models'\n",
    "    if not model_name:\n",
    "        model_name = 'model'\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    # Convert data to tensors # Returns a copy, original is safe\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)  # (seqs, seq_len, features)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long).to(device)    # (seqs, seq_len)\n",
    "    X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "    # Create TensorDatasets\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(\"y_train:\")\n",
    "    print(type(y_train))\n",
    "    print(y_train.dtype)\n",
    "    print(y_train.shape)\n",
    "    print(\"X_train:\")\n",
    "    print(type(X_train))\n",
    "    print(X_train.dtype)\n",
    "    print(X_train.shape)\n",
    "    print(\"\\ny_val:\")\n",
    "    print(type(y_val))\n",
    "    print(y_val.dtype)\n",
    "    print(y_val.shape)\n",
    "    print(\"X_val:\")\n",
    "    print(type(X_val))\n",
    "    print(X_val.dtype)\n",
    "    print(X_val.shape)\n",
    "\n",
    "    # Debug prints for TensorDataset and DataLoader\n",
    "    print(\"\\nDataset Lengths:\")\n",
    "    print(f\"Train Dataset Length: {len(train_dataset)}\")\n",
    "    print(f\"Validation Dataset Length: {len(val_dataset)}\")\n",
    "\n",
    "    print(\"\\nDataLoader Batch Sizes:\")\n",
    "    print(f\"Number of Batches in Train DataLoader: {len(train_loader)}\")\n",
    "    print(f\"Number of Batches in Validation DataLoader: {len(val_loader)}\")\n",
    "\n",
    "    # Additional details for y_train, y_val, and y_test\n",
    "    print(\"\\ny_train Unique Values and Stats:\")\n",
    "    print(f\"Unique values in y_train: {y_train.unique()}\")\n",
    "    print(f\"y_train Min: {y_train.min()}, Max: {y_train.max()}\")\n",
    "\n",
    "    print(\"\\ny_val Unique Values and Stats:\")\n",
    "    print(f\"Unique values in y_val: {y_val.unique()}\")\n",
    "    print(f\"y_val Min: {y_val.min()}, Max: {y_val.max()}\")\n",
    "\n",
    "    # Device check\n",
    "    print(\"\\nDevice Info:\")\n",
    "    print(f\"X_train Device: {X_train.device}\")\n",
    "    print(f\"y_train Device: {y_train.device}\")\n",
    "    print(f\"X_val Device: {X_val.device}\")\n",
    "    print(f\"y_val Device: {y_val.device}\\n\")\n",
    "\n",
    "    # Calculate number of batches\n",
    "    # num_batches = (len(X_train) + batch_size - 1) // batch_size\n",
    "\n",
    "    global best_results  # Ensure we can modify the external variable if defined outside.\n",
    "    best_results = []    # Start empty each training run\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if stop_signal_file and os.path.exists(stop_signal_file):\n",
    "            print(\"\\nStop signal detected. Exiting training loop safely.\\n\")\n",
    "            break\n",
    "        epoch_loss = 0\n",
    "        class_correct = {}  # Dictionary to store correct predictions per class\n",
    "        class_total = {}  # Dictionary to store total samples per class\n",
    "        model.train()\n",
    "        i=0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # Reset gradients before forward pass\n",
    "            optimizer.zero_grad()  # Best practice\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(X_batch)\n",
    "            outputs = outputs.view(-1, output_size)\n",
    "            y_batch = y_batch.view(-1)\n",
    "\n",
    "            if epoch == 1 and i < 3:\n",
    "                i += 1\n",
    "                print(f\"\\nUnique target values: {y_batch.unique()}\")\n",
    "                print(f\"Target dtype: {y_batch.dtype}\")\n",
    "                print(f\"Min target: {y_batch.min()}, Max target: {y_batch.max()}\")\n",
    "                print(\"Unique classes in y_train:\", y_train.unique())\n",
    "                print(f\"Unique classes in y_val: {y_val.unique()}\\n\")\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            # Compute class-wise accuracy (Accumulates values in dict)\n",
    "            compute_classwise_accuracy(outputs, y_batch, class_correct, class_total)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            # No longer reset gradients here: optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * X_batch.size(0)  # Scale back to total loss\n",
    "            \n",
    "        train_loss = epoch_loss / len(train_loader.dataset) # Average training loss per sample over an epoch \n",
    "\n",
    "        # Compute per-class training accuracy\n",
    "        # train_classwise_accuracy = {int(c): (class_correct[c] / class_total[c]) * 100 if class_total[c] > 0 else 0 \n",
    "        #                            for c in sorted(class_total.keys())}\n",
    "        train_classwise_accuracy = {int(c): f\"{(class_correct[c] / class_total[c]) * 100:.2f}%\" if class_total[c] > 0 else \"0.00%\" \n",
    "                                    for c in sorted(class_total.keys())}\n",
    "        \n",
    "        # Perform validation at the end of each epoch\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_class_correct = {}\n",
    "        val_class_total = {}\n",
    "        with torch.no_grad():\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                val_outputs = model(X_val_batch).view(-1, output_size)\n",
    "                val_labels = y_val_batch.view(-1)\n",
    "                val_loss += criterion(val_outputs, val_labels).item() * X_val_batch.size(0)  # Scale to total loss\n",
    "                val_predictions = torch.argmax(val_outputs, dim=-1)\n",
    "                val_correct += (val_predictions == val_labels).sum().item()\n",
    "                val_total += val_labels.size(0)\n",
    "                # Compute per-class validation accuracy\n",
    "                compute_classwise_accuracy(val_outputs, val_labels, val_class_correct, val_class_total)\n",
    "        val_loss /= len(val_loader.dataset) # Average validation loss per sample over an epoch \n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        # Compute per-class validation accuracy\n",
    "        # val_classwise_accuracy = {int(c): (val_class_correct[c] / val_class_total[c]) * 100 if val_class_total[c] > 0 else 0 \n",
    "        #                          for c in sorted(val_class_total.keys())}\n",
    "        val_classwise_accuracy = {int(c): f\"{(val_class_correct[c] / val_class_total[c]) * 100:.2f}%\" if val_class_total[c] > 0 else \"0.00%\" \n",
    "                                  for c in sorted(val_class_total.keys())}\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Train Loss: {train_loss:.9f}, \"\n",
    "              f\"Train-Class-Acc: {train_classwise_accuracy}, \"\n",
    "              f\"Val Loss: {val_loss:.9f}, \"\n",
    "              f\"Val Accuracy: {val_accuracy * 100:.2f}%, \"\n",
    "              f\"Val-Class-Acc: {val_classwise_accuracy}, \"\n",
    "              f\"LR: {current_lr:.9f}\")\n",
    "\n",
    "        # Save current model and update best results if applicable\n",
    "        current_epoch_info = {\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_classwise_accuracy\": train_classwise_accuracy,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_classwise_accuracy\": val_classwise_accuracy,\n",
    "            'learning_rate': current_lr, # Optimizer state\n",
    "            \"model_path\": os.path.join(model_saving_folder, f\"{model_name}_epoch_{epoch+1}.pth\")\n",
    "        }\n",
    "\n",
    "        # Insert this epoch if we have fewer than 5 results\n",
    "        # or if it beats the lowest of the top 5\n",
    "        if len(best_results) < 5 or val_accuracy > best_results[-1][\"val_accuracy\"]:\n",
    "            if len(best_results) == 5:\n",
    "                # Remove the worst model from the list, the last (lowest accuracy)\n",
    "                worst = best_results.pop() \n",
    "                if os.path.exists(worst[\"model_path\"]):\n",
    "                    os.remove(worst[\"model_path\"])\n",
    "                    print(f\"Removed old model with accuracy {worst['val_accuracy']*100:.2f}%, and file was at {worst['model_path']}\")\n",
    "            # Just insert and sort by val_accuracy descending\n",
    "            best_results.append(current_epoch_info) \n",
    "            best_results.sort(key=lambda x: x[\"val_accuracy\"], reverse=True)\n",
    "            torch.save({ # Save this model\n",
    "                'epoch': epoch+1,  # Save the current epoch\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'model_state_dict': model.state_dict(),  # Model weights\n",
    "                'optimizer_state_dict': optimizer.state_dict(),  # Optimizer state\n",
    "                'learning_rate': current_lr # Optimizer state\n",
    "            }, current_epoch_info[\"model_path\"])\n",
    "            print(f\"Model saved after epoch {epoch+1} to {current_epoch_info['model_path']} \\n\")\n",
    "\n",
    "        if use_scheduler == True:\n",
    "            # Scheduler step should follow after considering the results (placed after otallher losses)\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "    # Save the final model\n",
    "    if current_epoch_info:\n",
    "        final_model_path = os.path.join(model_saving_folder, f\"{model_name}_final.pth\")\n",
    "        torch.save({ # Save this model\n",
    "            'epoch': epoch+1,  # Save the current epoch\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'model_state_dict': model.state_dict(),  # Model weights\n",
    "            'optimizer_state_dict': optimizer.state_dict(),  # Optimizer state\n",
    "            'learning_rate': current_lr # Optimizer state\n",
    "        }, final_model_path)\n",
    "        print(f\"\\nFinal model saved to {final_model_path}\")\n",
    "\n",
    "    print(\"\\nTraining complete. \\n\\nTop 5 Models Sorted by Validation Accuracy: \")\n",
    "    for res in best_results:        \n",
    "        print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "              f\"Train Loss: {res['train_loss']:.9f}, \"\n",
    "              f\"Train-Class-Acc: {train_classwise_accuracy}, \" \n",
    "              f\"Val Loss: {res['val_loss']:.9f}, \"\n",
    "              f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "              f\"Val-Class-Acc: {val_classwise_accuracy}, \"\n",
    "              f\"Model Path: {res['model_path']}\")\n",
    "    print('\\n')\n",
    "    \n",
    "    del X_train, y_train, X_val, y_val, train_dataset, val_dataset, train_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Load the checkpoint\n",
    "    # checkpoint = torch.load(\"path/to/model_checkpoint.pth\")\n",
    "    # # Restore model state\n",
    "    # model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    # # Restore optimizer state\n",
    "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    # # Restore scheduler state (if used)\n",
    "    # scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    # # Restore epoch and other metadata\n",
    "    # start_epoch = checkpoint['epoch'] + 1  # Resume from the next epoch\n",
    "    # loss = checkpoint['loss']  # Optional\n",
    "    # print(f\"Checkpoint loaded. Resuming from epoch {start_epoch}\")\n",
    "\n",
    "\n",
    "def compute_classwise_accuracy(logits_flat, y_batch, class_correct, class_total):\n",
    "    \"\"\"\n",
    "    Computes per-class accuracy by accumulating correct and total samples for each class.\n",
    "    \n",
    "    logits_flat: Model predictions (logits) in shape [batch_size * seq_len, output_size]\n",
    "    y_batch: True labels in shape [batch_size * seq_len]\n",
    "    class_correct: Dictionary to store correct predictions per class (passed by reference)\n",
    "    class_total: Dictionary to store total samples per class (passed by reference)\n",
    "    \"\"\"\n",
    "    # Convert logits to predicted class indices\n",
    "    predictions = torch.argmax(logits_flat, dim=-1)  # Shape: [batch_size * seq_len]\n",
    "\n",
    "    # Loop through batch elements to track correct/total per class\n",
    "    for label, pred in zip(y_batch.cpu().numpy(), predictions.cpu().numpy()):\n",
    "        if label not in class_total:\n",
    "            class_total[label] = 0\n",
    "            class_correct[label] = 0\n",
    "        class_total[label] += 1\n",
    "        if label == pred:\n",
    "            class_correct[label] += 1\n",
    "\n",
    "def inspect_fisher_info(fisher_dict: dict, label: str = \"Fisher Inspection\"):\n",
    "    # --- !! START INSPECTION !! ---\n",
    "    print(f\"\\n--- Inspecting {label} ---\")\n",
    "    total_fisher_sum = 0.0\n",
    "    max_fisher_val = 0.0\n",
    "    min_positive_fisher = float('inf')\n",
    "    zero_fisher_layers = 0\n",
    "\n",
    "    for n, f_tensor in fisher_dict.items():\n",
    "        if f_tensor.min() < 0:\n",
    "            print(f\"----> ERROR: Negative value found in Fisher for {n}\")\n",
    "        if torch.isnan(f_tensor).any() or torch.isinf(f_tensor).any():\n",
    "            print(f\"----> ERROR: NaN/Inf found in Fisher for {n}\")\n",
    "\n",
    "        layer_sum = f_tensor.sum().item()\n",
    "        layer_max = f_tensor.abs().max().item()\n",
    "        pos_min = f_tensor[f_tensor > 0].min().item() if (f_tensor > 0).any() else float('inf')\n",
    "\n",
    "        total_fisher_sum += layer_sum\n",
    "        max_fisher_val = max(max_fisher_val, layer_max)\n",
    "        min_positive_fisher = min(min_positive_fisher, pos_min)\n",
    "        if layer_max == 0:\n",
    "            zero_fisher_layers += 1\n",
    "        # print(f\"Layer {n}: Sum={layer_sum:.4e}, MaxAbs={layer_max:.4e}\") # Optional detail\n",
    "\n",
    "    print(f\"Total Fisher Sum: {total_fisher_sum:.4e}\")\n",
    "    print(f\"Overall Max Fisher Abs Value: {max_fisher_val:.4e}\")\n",
    "    print(f\"Overall Min Positive Fisher Value: {min_positive_fisher:.4e}\")\n",
    "    print(f\"Number of layers with all-zero Fisher: {zero_fisher_layers} / {len(fisher_dict)}\")\n",
    "    print(f\"--- Finished Inspecting {label} ---\\n\")\n",
    "    # --- !! END INSPECTION !! ---\n",
    "\n",
    "\n",
    "# Training and validation function for Period 2 and beyond \n",
    "def train_and_validate_ewc(model, output_size, criterion, optimizer, \n",
    "                           X_train, y_train, X_val, y_val, scheduler, use_scheduler=False, \n",
    "                           ewc: 'EWC' = None, lambda_ewc: float = 0.4,\n",
    "                           num_epochs=10, batch_size=64, \n",
    "                           model_saving_folder=None, model_name=None, stop_signal_file=None):\n",
    "    \"\"\"\n",
    "    Training function for incremental periods that adds an EWC penalty.\n",
    "    \"\"\"\n",
    "    print(\"'train_and_validate_ewc' function started.\\n\")\n",
    "    # Ensure model saving folder exists (deleting existing first if there is one)\n",
    "    if model_saving_folder and os.path.exists(model_saving_folder):\n",
    "        # os.rmdir(model_saving_folder) # Only works on empty folders \n",
    "        shutil.rmtree(model_saving_folder) # Safely remove all contents\n",
    "        if not os.path.exists(model_saving_folder):\n",
    "            print(f\"Existing folder has been removed : {model_saving_folder}\\n\")\n",
    "    if model_saving_folder and not os.path.exists(model_saving_folder):\n",
    "        os.makedirs(model_saving_folder)\n",
    "    if not model_saving_folder:\n",
    "        model_saving_folder = './saved_models'\n",
    "    if not model_name:\n",
    "        model_name = 'model'\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Convert data to tensors # Returns a copy, original is safe\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)  # (seqs, seq_len, features)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long).to(device)    # (seqs, seq_len)\n",
    "    X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "    # Create TensorDatasets\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(\"y_train:\")\n",
    "    print(type(y_train))\n",
    "    print(y_train.dtype)\n",
    "    print(y_train.shape)\n",
    "    print(\"X_train:\")\n",
    "    print(type(X_train))\n",
    "    print(X_train.dtype)\n",
    "    print(X_train.shape)\n",
    "    print(\"\\ny_val:\")\n",
    "    print(type(y_val))\n",
    "    print(y_val.dtype)\n",
    "    print(y_val.shape)\n",
    "    print(\"X_val:\")\n",
    "    print(type(X_val))\n",
    "    print(X_val.dtype)\n",
    "    print(X_val.shape)\n",
    "\n",
    "    # Debug prints for TensorDataset and DataLoader\n",
    "    print(\"\\nDataset Lengths:\")\n",
    "    print(f\"Train Dataset Length: {len(train_dataset)}\")\n",
    "    print(f\"Validation Dataset Length: {len(val_dataset)}\")\n",
    "\n",
    "    print(\"\\nDataLoader Batch Sizes:\")\n",
    "    print(f\"Number of Batches in Train DataLoader: {len(train_loader)}\")\n",
    "    print(f\"Number of Batches in Validation DataLoader: {len(val_loader)}\")\n",
    "\n",
    "    # Additional details for y_train, y_val, and y_test\n",
    "    print(\"\\ny_train Unique Values and Stats:\")\n",
    "    print(f\"Unique values in y_train: {y_train.unique()}\")\n",
    "    print(f\"y_train Min: {y_train.min()}, Max: {y_train.max()}\")\n",
    "\n",
    "    print(\"\\ny_val Unique Values and Stats:\")\n",
    "    print(f\"Unique values in y_val: {y_val.unique()}\")\n",
    "    print(f\"y_val Min: {y_val.min()}, Max: {y_val.max()}\")\n",
    "\n",
    "    # Device check\n",
    "    print(\"\\nDevice Info:\")\n",
    "    print(f\"X_train Device: {X_train.device}\")\n",
    "    print(f\"y_train Device: {y_train.device}\")\n",
    "    print(f\"X_val Device: {X_val.device}\")\n",
    "    print(f\"y_val Device: {y_val.device}\\n\")\n",
    "\n",
    "    # Calculate number of batches\n",
    "    # num_batches = (len(X_train) + batch_size - 1) // batch_size\n",
    "\n",
    "    global best_results  # Ensure we can modify the external variable if defined outside.\n",
    "    best_results = []    # Start empty each training run\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if stop_signal_file and os.path.exists(stop_signal_file):\n",
    "            print(\"\\nStop signal detected. Exiting training loop safely.\\n\")\n",
    "            break\n",
    "        epoch_train_loss = 0.0\n",
    "        train_class_correct = {}  # Dictionary to store correct predictions per class\n",
    "        train_class_total = {}  # Dictionary to store total samples per class\n",
    "        model.train()\n",
    "        i=0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # Reset gradients before forward pass\n",
    "            optimizer.zero_grad()  # Best practice\n",
    "            # Forward pass\n",
    "            outputs = model(X_batch) # Shape: [batch, seq_len, output_size]\n",
    "            # Reshape for CE loss computation.\n",
    "            outputs = outputs.view(-1, output_size) # Shape: [batch * seq_len, output_size]\n",
    "            y_batch = y_batch.view(-1) # Shape: [batch * seq_len]\n",
    "\n",
    "            if epoch == 1 and i < 3:\n",
    "                i += 1\n",
    "                print(f\"\\nUnique target values: {y_batch.unique()}\")\n",
    "                print(f\"Target dtype: {y_batch.dtype}\")\n",
    "                print(f\"Min target: {y_batch.min()}, Max target: {y_batch.max()}\")\n",
    "                print(\"Unique classes in y_train:\", y_train.unique())\n",
    "                print(f\"Unique classes in y_val: {y_val.unique()}\\n\")\n",
    "            \n",
    "            # Compute Cross-Entropy loss\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            # EWC regularization/penalty term: (lambda/2)*penalty\n",
    "            if ewc is not None and lambda_ewc > 0:\n",
    "                ewc_penalty = ewc.penalty(model)\n",
    "                # print(f\"ewc_penalty = {ewc_penalty}\")\n",
    "                # print(f\"loss = {loss}\")\n",
    "                loss += (lambda_ewc / 2) * ewc_penalty # Factor of 1/2 is common\n",
    "            loss.backward()\n",
    "            # Optional: Gradient clipping\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item() * X_batch.size(0) # Accumulate total loss for the epoch\n",
    "\n",
    "            # Compute class-wise accuracy (Accumulates values in dict)\n",
    "            compute_classwise_accuracy(outputs, y_batch, train_class_correct, train_class_total )\n",
    "            \n",
    "        train_loss = epoch_train_loss / len(train_loader.dataset) # Average training loss per sample over an epoch \n",
    "        train_classwise_accuracy = {int(c): f\"{(train_class_correct[c] / train_class_total[c]) * 100:.2f}%\" if train_class_total[c] > 0 else \"0.00%\" \n",
    "                                    for c in sorted(train_class_total.keys())}\n",
    "\n",
    "        # Perform validation at the end of each epoch (only CE loss and accuracy)\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_class_correct = {}\n",
    "        val_class_total = {}\n",
    "        with torch.no_grad():\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                val_outputs = model(X_val_batch).view(-1, output_size)\n",
    "                val_labels = y_val_batch.view(-1)\n",
    "                val_loss += criterion(val_outputs, val_labels).item() * X_val_batch.size(0)  # Scale to total loss\n",
    "                val_predictions = torch.argmax(val_outputs, dim=-1)\n",
    "                val_correct += (val_predictions == val_labels).sum().item()\n",
    "                val_total += val_labels.size(0)\n",
    "                # Compute per-class validation accuracy\n",
    "                compute_classwise_accuracy(val_outputs, val_labels, val_class_correct, val_class_total)\n",
    "        val_loss /= len(val_loader.dataset) # Average validation loss per sample over an epoch \n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_classwise_accuracy = {int(c): f\"{(val_class_correct[c] / val_class_total[c]) * 100:.2f}%\" if val_class_total[c] > 0 else \"0.00%\" \n",
    "                                  for c in sorted(val_class_total.keys())}\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Train Loss: {train_loss:.9f}, \"\n",
    "              f\"Train-Class-Acc: {train_classwise_accuracy}, \"\n",
    "              f\"Val Loss: {val_loss:.9f}, \"\n",
    "              f\"Val Accuracy: {val_accuracy * 100:.2f}%, \"\n",
    "              f\"Val-Class-Acc: {val_classwise_accuracy}, \"\n",
    "              f\"LR: {current_lr:.9f}\")\n",
    "\n",
    "        # Save current model and update best results if applicable\n",
    "        current_epoch_info = {\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_classwise_accuracy\": train_classwise_accuracy,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_classwise_accuracy\": val_classwise_accuracy,\n",
    "            'learning_rate': current_lr, # Optimizer state\n",
    "            \"model_path\": os.path.join(model_saving_folder, f\"{model_name}_epoch_{epoch+1}.pth\")\n",
    "        }\n",
    "\n",
    "        # Insert this epoch if we have fewer than 5 results\n",
    "        # or if it beats the lowest of the top 5\n",
    "        if len(best_results) < 5 or val_accuracy > best_results[-1][\"val_accuracy\"]:\n",
    "            if len(best_results) == 5:\n",
    "                # Remove the worst model from the list, the last (lowest accuracy)\n",
    "                worst = best_results.pop() \n",
    "                if os.path.exists(worst[\"model_path\"]):\n",
    "                    os.remove(worst[\"model_path\"])\n",
    "                    print(f\"Removed old model with accuracy {worst['val_accuracy']*100:.2f}%, and file was at {worst['model_path']}\")\n",
    "            # Just insert and sort by val_accuracy descending\n",
    "            best_results.append(current_epoch_info) \n",
    "            best_results.sort(key=lambda x: x[\"val_accuracy\"], reverse=True)\n",
    "            torch.save({ # Save this model\n",
    "                'epoch': epoch+1,  # Save the current epoch\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'model_state_dict': model.state_dict(),  # Model weights\n",
    "                'optimizer_state_dict': optimizer.state_dict(),  # Optimizer state\n",
    "                'learning_rate': current_lr # Optimizer state\n",
    "            }, current_epoch_info[\"model_path\"])\n",
    "            print(f\"Model saved after epoch {epoch+1} to {current_epoch_info['model_path']} \\n\")\n",
    "\n",
    "        if use_scheduler == True:\n",
    "            # Scheduler step should follow after considering the results (placed after otallher losses)\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    if current_epoch_info:\n",
    "        final_model_path = os.path.join(model_saving_folder, f\"{model_name}_final.pth\")\n",
    "        torch.save({ # Save this model\n",
    "            'epoch': epoch+1,  # Save the current epoch\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'model_state_dict': model.state_dict(),  # Model weights\n",
    "            'optimizer_state_dict': optimizer.state_dict(),  # Optimizer state\n",
    "            'learning_rate': current_lr # Optimizer state\n",
    "        }, final_model_path)\n",
    "        print(f\"\\nFinal model saved to {final_model_path}\")\n",
    "\n",
    "    print(\"\\nTraining complete. \\n\\nTop 5 Models Sorted by Validation Accuracy: \")\n",
    "    for res in best_results:        \n",
    "        print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "              f\"Train Loss: {res['train_loss']:.9f}, \"\n",
    "              f\"Train-Class-Acc: {train_classwise_accuracy}, \" \n",
    "              f\"Val Loss: {res['val_loss']:.9f}, \"\n",
    "              f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "              f\"Val-Class-Acc: {val_classwise_accuracy}, \"\n",
    "              f\"Model Path: {res['model_path']}\")\n",
    "    print('\\n')\n",
    "    \n",
    "    del X_train, y_train, X_val, y_val, train_dataset, val_dataset, train_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters and initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch compiled CUDA version: 12.4\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch compiled CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cu124\n",
      "CUDA Available: True\n",
      "Num GPUs: 1\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Seeding successful!\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Num GPUs:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "torch.manual_seed(42)\n",
    "print(\"Seeding successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list_period_files_full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data\\\\Polygon_BTCUSD_4Y_1min\\\\_Polygon_BTCUSD_4Y_1min_190_days_with_indicators.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair = 'BTCUSD'\n",
    "file_name = f'Polygon_{pair}_4Y_1min'  # File name for saving data\n",
    "# BASE_FOLDER_PATH = f\"{Working_directory}/Data/{file_name}\"\n",
    "BASE_FOLDER_PATH = f\"Data/{file_name}\"\n",
    "# folder_path=f'{BASE_FOLDER_PATH}/polygon_io/12_USD_Crypto_Pairs/{file_name}'\n",
    "folder_path=f'{BASE_FOLDER_PATH}'\n",
    "if not os.path.isdir(folder_path):\n",
    "    raise FileNotFoundError(f\"Directory '{folder_path}' does not exist.\")\n",
    "file_path=f'{folder_path}/{file_name}.csv'\n",
    "number_days = 190\n",
    "with_indicators_file_path = os.path.normpath(f'{folder_path}/_{file_name}_{number_days}_days_with_indicators.csv')\n",
    "\n",
    "# LABORATORY\\_Global_Pytorch\\Continual_Learning\\Data\\Polygon_BTCUSD_4Y_1min\n",
    "\n",
    "list_period_files_full_path = [\n",
    "    # Period 1\n",
    "    with_indicators_file_path,\n",
    "    # Period 2\n",
    "    os.path.normpath(f\"{folder_path}/Polygon_BTCUSD_4Y_1min_190_days__2020-11-11__2021-05-20__with_indicators.csv\"),\n",
    "    # Period 3\n",
    "    os.path.normpath(f\"{folder_path}/Polygon_BTCUSD_4Y_1min_190_days__2021-05-20__2021-11-26__with_indicators.csv\"),\n",
    "    # Period 4\n",
    "    os.path.normpath(f\"{folder_path}/Polygon_BTCUSD_4Y_1min_190_days__2021-11-26__2022-06-04__with_indicators.csv\"),\n",
    "    # Period 5\n",
    "    os.path.normpath(f\"{folder_path}/Polygon_BTCUSD_4Y_1min_190_days__2022-06-04__2022-12-11__with_indicators.csv\")\n",
    "]\n",
    "\n",
    "with_indicators_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found file: Polygon_BTCUSD_4Y_1min.png\n",
      "Found file: Polygon_BTCUSD_4Y_1min_190_days__2020-11-11__2021-05-20.png\n",
      "Found file: Polygon_BTCUSD_4Y_1min_190_days__2020-11-11__2021-05-20__with_indicators.csv\n",
      "Found file: Polygon_BTCUSD_4Y_1min_190_days__2021-05-20__2021-11-26.png\n",
      "Found file: Polygon_BTCUSD_4Y_1min_190_days__2021-05-20__2021-11-26__with_indicators.csv\n",
      "Found file: Polygon_BTCUSD_4Y_1min_190_days__2021-11-26__2022-06-04.png\n",
      "Found file: Polygon_BTCUSD_4Y_1min_190_days__2021-11-26__2022-06-04__with_indicators.csv\n",
      "Found file: Polygon_BTCUSD_4Y_1min_190_days__2022-06-04__2022-12-11.png\n",
      "Found file: Polygon_BTCUSD_4Y_1min_190_days__2022-06-04__2022-12-11__with_indicators.csv\n",
      "Found file: Polygon_BTCUSD_4Y_1min_525_days.png\n",
      "Found file: _Polygon_BTCUSD_4Y_1min_190_days.png\n",
      "Found file: _Polygon_BTCUSD_4Y_1min_190_days_with_indicators.csv\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(folder_path):\n",
    "    print(f\"Found file: {file}\")\n",
    "\n",
    "# Polygon_BTCUSD_4Y_1min_190_days_with_indicators.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File path: Data\\Polygon_BTCUSD_4Y_1min\\_Polygon_BTCUSD_4Y_1min_190_days_with_indicators.csv\n",
      "\n",
      "data_retrieved - Missing timestamps time: \n",
      "DatetimeIndex([], dtype='datetime64[ns, UTC]', freq='min')\n",
      "\n",
      "data_gaussian - Missing timestamps time: \n",
      "DatetimeIndex([], dtype='datetime64[ns, UTC]', freq='min')\n",
      "\n",
      "columns_to_transform = \n",
      "Index(['open', 'high', 'low', 'close', 'SMA_5', 'SMA_10', 'EMA_10'], dtype='object'), \n",
      "len(columns_to_transform) = 7\n",
      "\n",
      "data_log_return - Missing timestamps time: \n",
      "DatetimeIndex([], dtype='datetime64[ns, UTC]', freq='min')\n",
      "\n",
      "No missing timestamps.\n",
      "\n",
      "    Number of sequences:\n",
      "        - sequences[0].shape: (1000, 7)\n",
      "        - Total sequences: 4543\n",
      "        - Train sequences: 3634\n",
      "        - Validation sequences: 454\n",
      "        - Test sequences: 455\n",
      "    \n",
      "close_col_index = 3\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "    with_indicators_file_path = list_period_files_full_path[0],\n",
    "    downsampled_data_minutes = downsampled_data_minutes,\n",
    "    exclude_columns = exclude_columns,\n",
    "    lower_threshold = lower_threshold,\n",
    "    upper_threshold = upper_threshold,\n",
    "    reverse_steps = reverse_steps,\n",
    "    sequence_length = sequence_length,\n",
    "    sliding_interval = sliding_interval,\n",
    "    trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    ")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "\n",
    "del X_train, y_train, X_val, y_val, X_test, y_test, Number_features\n",
    "del unique_classes, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*All periods data*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 1: \n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n",
      "Class Distribution for 'y_train':       Class 0   Percent:  21.96% || Class 1   Percent:  36.92% || Class 2   Percent:   1.58% || Class 3   Percent:  37.57% || Class 4   Percent:   1.96%\n",
      "Class Distribution for 'y_val':         Class 0   Percent:  12.59% || Class 1   Percent:  39.39% || Class 2   Percent:   1.86% || Class 3   Percent:  42.81% || Class 4   Percent:   3.35%\n",
      "Class Distribution for 'y_test':        Class 0   Percent:  10.84% || Class 1   Percent:  41.96% || Class 2   Percent:   1.60% || Class 3   Percent:  42.11% || Class 4   Percent:   3.49%\n",
      "------------------------\n",
      "Path 2: \n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n",
      "Class Distribution for 'y_train':       Class 0   Percent:   3.57% || Class 1   Percent:  36.03% || Class 2   Percent:  10.55% || Class 3   Percent:  37.07% || Class 4   Percent:  12.78%\n",
      "Class Distribution for 'y_val':         Class 0   Percent:   3.68% || Class 1   Percent:  36.38% || Class 2   Percent:  10.90% || Class 3   Percent:  37.65% || Class 4   Percent:  11.38%\n",
      "Class Distribution for 'y_test':        Class 0   Percent:   2.93% || Class 1   Percent:  32.27% || Class 2   Percent:  18.62% || Class 3   Percent:  34.26% || Class 4   Percent:  11.92%\n",
      "------------------------\n",
      "Path 3: \n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n",
      "Class Distribution for 'y_train':       Class 0   Percent:   4.76% || Class 1   Percent:  37.59% || Class 2   Percent:   8.89% || Class 3   Percent:  39.73% || Class 4   Percent:   9.03%\n",
      "Class Distribution for 'y_val':         Class 0   Percent:   5.21% || Class 1   Percent:  46.19% || Class 2   Percent:   4.21% || Class 3   Percent:  39.34% || Class 4   Percent:   5.05%\n",
      "Class Distribution for 'y_test':        Class 0   Percent:   4.89% || Class 1   Percent:  43.50% || Class 2   Percent:   8.50% || Class 3   Percent:  37.70% || Class 4   Percent:   5.41%\n",
      "------------------------\n",
      "Path 4: \n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n",
      "Class Distribution for 'y_train':       Class 0   Percent:   6.47% || Class 1   Percent:  39.17% || Class 2   Percent:   7.24% || Class 3   Percent:  41.06% || Class 4   Percent:   6.06%\n",
      "Class Distribution for 'y_val':         Class 0   Percent:   5.35% || Class 1   Percent:  36.15% || Class 2   Percent:  14.78% || Class 3   Percent:  34.02% || Class 4   Percent:   9.70%\n",
      "Class Distribution for 'y_test':        Class 0   Percent:   6.63% || Class 1   Percent:  40.53% || Class 2   Percent:   5.48% || Class 3   Percent:  41.29% || Class 4   Percent:   6.08%\n",
      "------------------------\n",
      "Path 5: \n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n",
      "Class Distribution for 'y_train':       Class 0   Percent:   9.22% || Class 1   Percent:  38.87% || Class 2   Percent:   6.11% || Class 3   Percent:  39.40% || Class 4   Percent:   6.40%\n",
      "Class Distribution for 'y_val':         Class 0   Percent:  11.41% || Class 1   Percent:  37.75% || Class 2   Percent:   7.98% || Class 3   Percent:  37.24% || Class 4   Percent:   5.62%\n",
      "Class Distribution for 'y_test':        Class 0   Percent:  23.91% || Class 1   Percent:  35.20% || Class 2   Percent:   0.90% || Class 3   Percent:  38.27% || Class 4   Percent:   1.71%\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "for i in range(5):\n",
    "    print(f\"Path {i+1}: \")\n",
    "    with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "            with_indicators_file_path = list_period_files_full_path[i], # Change\n",
    "            downsampled_data_minutes = downsampled_data_minutes,\n",
    "            exclude_columns = exclude_columns,\n",
    "            lower_threshold = lower_threshold,\n",
    "            upper_threshold = upper_threshold,\n",
    "            reverse_steps = reverse_steps,\n",
    "            sequence_length = sequence_length,\n",
    "            sliding_interval = sliding_interval,\n",
    "            trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "            # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "        )\n",
    "    print(f\"Number_features = {Number_features}\")\n",
    "    unique_classes = np.unique(y_val)\n",
    "    num_classes = len(unique_classes)\n",
    "    print(f\"unique_classes = {unique_classes}\")\n",
    "    print(f\"num_classes = {num_classes}\")\n",
    "\n",
    "    print_class_distribution(y_train, \"y_train\")\n",
    "    print_class_distribution(y_val, \"y_val\")\n",
    "    print_class_distribution(y_test, \"y_test\")\n",
    "    print(\"------------------------\")\n",
    "del X_train, y_train, X_val, y_val, X_test, y_test, Number_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 1 --> Training and saving in __*'1st_try'*__ (BiGRUWithAttention, num_layers = 4) ---> Val acc = 98.35 %\n",
    "### Val-Class-Acc: {0: '98.10%', 1: '97.81%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1]\n",
      "num_classes = 2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[0], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'train_and_validate' function started. \n",
      "\n",
      "Existing folder has been removed : Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\n",
      "\n",
      "y_train:\n",
      "<class 'torch.Tensor'>\n",
      "torch.int64\n",
      "torch.Size([3634, 1000])\n",
      "X_train:\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "torch.Size([3634, 1000, 7])\n",
      "\n",
      "y_val:\n",
      "<class 'torch.Tensor'>\n",
      "torch.int64\n",
      "torch.Size([454, 1000])\n",
      "X_val:\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "torch.Size([454, 1000, 7])\n",
      "\n",
      "Dataset Lengths:\n",
      "Train Dataset Length: 3634\n",
      "Validation Dataset Length: 454\n",
      "\n",
      "DataLoader Batch Sizes:\n",
      "Number of Batches in Train DataLoader: 57\n",
      "Number of Batches in Validation DataLoader: 8\n",
      "\n",
      "y_train Unique Values and Stats:\n",
      "Unique values in y_train: tensor([0, 1], device='cuda:0')\n",
      "y_train Min: 0, Max: 1\n",
      "\n",
      "y_val Unique Values and Stats:\n",
      "Unique values in y_val: tensor([0, 1], device='cuda:0')\n",
      "y_val Min: 0, Max: 1\n",
      "\n",
      "Device Info:\n",
      "X_train Device: cuda:0\n",
      "y_train Device: cuda:0\n",
      "X_val Device: cuda:0\n",
      "y_val Device: cuda:0\n",
      "\n",
      "Epoch 1/2000, Train Loss: 0.681195149, Train-Class-Acc: {0: '98.48%', 1: '1.57%'}, Val Loss: 0.670978806, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Model saved after epoch 1 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1.pth \n",
      "\n",
      "\n",
      "Unique target values: tensor([0, 1], device='cuda:0')\n",
      "Target dtype: torch.int64\n",
      "Min target: 0, Max target: 1\n",
      "Unique classes in y_train: tensor([0, 1], device='cuda:0')\n",
      "Unique classes in y_val: tensor([0, 1], device='cuda:0')\n",
      "\n",
      "\n",
      "Unique target values: tensor([0, 1], device='cuda:0')\n",
      "Target dtype: torch.int64\n",
      "Min target: 0, Max target: 1\n",
      "Unique classes in y_train: tensor([0, 1], device='cuda:0')\n",
      "Unique classes in y_val: tensor([0, 1], device='cuda:0')\n",
      "\n",
      "\n",
      "Unique target values: tensor([0, 1], device='cuda:0')\n",
      "Target dtype: torch.int64\n",
      "Min target: 0, Max target: 1\n",
      "Unique classes in y_train: tensor([0, 1], device='cuda:0')\n",
      "Unique classes in y_val: tensor([0, 1], device='cuda:0')\n",
      "\n",
      "Epoch 2/2000, Train Loss: 0.659097561, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.671626767, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Model saved after epoch 2 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_2.pth \n",
      "\n",
      "Epoch 3/2000, Train Loss: 0.658912126, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.672343892, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Model saved after epoch 3 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_3.pth \n",
      "\n",
      "Epoch 4/2000, Train Loss: 0.658798798, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.670798046, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Model saved after epoch 4 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_4.pth \n",
      "\n",
      "Epoch 5/2000, Train Loss: 0.658789793, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.670712810, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Model saved after epoch 5 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_5.pth \n",
      "\n",
      "Epoch 6/2000, Train Loss: 0.658633200, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.670821638, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Epoch 7/2000, Train Loss: 0.658653052, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.672454676, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Epoch 8/2000, Train Loss: 0.658567325, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.671255033, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Epoch 9/2000, Train Loss: 0.658194496, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.670800413, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Epoch 10/2000, Train Loss: 0.658025196, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.669505533, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Epoch 11/2000, Train Loss: 0.657949901, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.670813681, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Epoch 12/2000, Train Loss: 0.657441564, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.672089164, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Epoch 13/2000, Train Loss: 0.656437984, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.669727216, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Epoch 14/2000, Train Loss: 0.653848377, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.664403139, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Epoch 15/2000, Train Loss: 0.646628344, Train-Class-Acc: {0: '100.00%', 1: '0.00%'}, Val Loss: 0.609726766, Val Accuracy: 60.61%, Val-Class-Acc: {0: '100.00%', 1: '0.00%'}, LR: 0.000100000\n",
      "Epoch 16/2000, Train Loss: 0.614362940, Train-Class-Acc: {0: '99.91%', 1: '1.19%'}, Val Loss: 0.600788087, Val Accuracy: 67.63%, Val-Class-Acc: {0: '99.67%', 1: '18.34%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 60.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_5.pth\n",
      "Model saved after epoch 16 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_16.pth \n",
      "\n",
      "Epoch 17/2000, Train Loss: 0.621365933, Train-Class-Acc: {0: '96.15%', 1: '7.03%'}, Val Loss: 0.818046801, Val Accuracy: 59.62%, Val-Class-Acc: {0: '98.27%', 1: '0.15%'}, LR: 0.000100000\n",
      "Epoch 18/2000, Train Loss: 0.608454279, Train-Class-Acc: {0: '96.24%', 1: '3.97%'}, Val Loss: 0.562103030, Val Accuracy: 60.73%, Val-Class-Acc: {0: '99.43%', 1: '1.19%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 60.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_4.pth\n",
      "Model saved after epoch 18 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_18.pth \n",
      "\n",
      "Epoch 19/2000, Train Loss: 0.514641512, Train-Class-Acc: {0: '99.48%', 1: '8.85%'}, Val Loss: 0.566889348, Val Accuracy: 68.41%, Val-Class-Acc: {0: '76.29%', 1: '56.30%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 60.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_3.pth\n",
      "Model saved after epoch 19 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_19.pth \n",
      "\n",
      "Epoch 20/2000, Train Loss: 0.644582497, Train-Class-Acc: {0: '82.75%', 1: '18.11%'}, Val Loss: 0.504615842, Val Accuracy: 64.25%, Val-Class-Acc: {0: '98.39%', 1: '11.73%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 60.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_2.pth\n",
      "Model saved after epoch 20 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_20.pth \n",
      "\n",
      "Epoch 21/2000, Train Loss: 0.492967396, Train-Class-Acc: {0: '97.49%', 1: '27.76%'}, Val Loss: 0.487886070, Val Accuracy: 68.63%, Val-Class-Acc: {0: '99.16%', 1: '21.65%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 60.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1.pth\n",
      "Model saved after epoch 21 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_21.pth \n",
      "\n",
      "Epoch 22/2000, Train Loss: 0.452352457, Train-Class-Acc: {0: '96.95%', 1: '43.08%'}, Val Loss: 0.487116188, Val Accuracy: 79.81%, Val-Class-Acc: {0: '78.69%', 1: '81.53%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 60.73%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_18.pth\n",
      "Model saved after epoch 22 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_22.pth \n",
      "\n",
      "Epoch 23/2000, Train Loss: 0.434873998, Train-Class-Acc: {0: '95.18%', 1: '58.11%'}, Val Loss: 0.390466562, Val Accuracy: 88.28%, Val-Class-Acc: {0: '88.55%', 1: '87.86%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 64.25%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_20.pth\n",
      "Model saved after epoch 23 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_23.pth \n",
      "\n",
      "Epoch 24/2000, Train Loss: 0.371178092, Train-Class-Acc: {0: '91.24%', 1: '74.65%'}, Val Loss: 0.405491732, Val Accuracy: 80.64%, Val-Class-Acc: {0: '97.23%', 1: '55.13%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 67.63%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_16.pth\n",
      "Model saved after epoch 24 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_24.pth \n",
      "\n",
      "Epoch 25/2000, Train Loss: 0.310568025, Train-Class-Acc: {0: '90.22%', 1: '80.46%'}, Val Loss: 0.291351317, Val Accuracy: 86.98%, Val-Class-Acc: {0: '96.50%', 1: '72.34%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 68.41%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_19.pth\n",
      "Model saved after epoch 25 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_25.pth \n",
      "\n",
      "Epoch 26/2000, Train Loss: 0.297321178, Train-Class-Acc: {0: '90.23%', 1: '81.70%'}, Val Loss: 0.448748425, Val Accuracy: 81.14%, Val-Class-Acc: {0: '97.49%', 1: '55.99%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 68.63%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_21.pth\n",
      "Model saved after epoch 26 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_26.pth \n",
      "\n",
      "Epoch 27/2000, Train Loss: 0.303039434, Train-Class-Acc: {0: '90.36%', 1: '81.03%'}, Val Loss: 0.213425552, Val Accuracy: 91.43%, Val-Class-Acc: {0: '93.11%', 1: '88.84%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 79.81%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_22.pth\n",
      "Model saved after epoch 27 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_27.pth \n",
      "\n",
      "Epoch 28/2000, Train Loss: 0.272568219, Train-Class-Acc: {0: '90.89%', 1: '83.61%'}, Val Loss: 0.222415951, Val Accuracy: 90.64%, Val-Class-Acc: {0: '88.26%', 1: '94.29%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 80.64%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_24.pth\n",
      "Model saved after epoch 28 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_28.pth \n",
      "\n",
      "Epoch 29/2000, Train Loss: 0.264326659, Train-Class-Acc: {0: '91.15%', 1: '83.98%'}, Val Loss: 0.203569631, Val Accuracy: 91.66%, Val-Class-Acc: {0: '93.73%', 1: '88.48%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 81.14%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_26.pth\n",
      "Model saved after epoch 29 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_29.pth \n",
      "\n",
      "Epoch 30/2000, Train Loss: 0.244300543, Train-Class-Acc: {0: '91.83%', 1: '85.53%'}, Val Loss: 0.197122880, Val Accuracy: 91.94%, Val-Class-Acc: {0: '93.34%', 1: '89.79%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 86.98%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_25.pth\n",
      "Model saved after epoch 30 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_30.pth \n",
      "\n",
      "Epoch 31/2000, Train Loss: 0.257247911, Train-Class-Acc: {0: '91.15%', 1: '84.93%'}, Val Loss: 0.209243174, Val Accuracy: 91.30%, Val-Class-Acc: {0: '95.55%', 1: '84.75%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 88.28%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_23.pth\n",
      "Model saved after epoch 31 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_31.pth \n",
      "\n",
      "Epoch 32/2000, Train Loss: 0.238245306, Train-Class-Acc: {0: '91.86%', 1: '86.02%'}, Val Loss: 0.228018277, Val Accuracy: 90.47%, Val-Class-Acc: {0: '96.41%', 1: '81.33%'}, LR: 0.000100000\n",
      "Epoch 33/2000, Train Loss: 0.264013958, Train-Class-Acc: {0: '90.89%', 1: '84.62%'}, Val Loss: 0.233804809, Val Accuracy: 90.09%, Val-Class-Acc: {0: '85.87%', 1: '96.59%'}, LR: 0.000100000\n",
      "Epoch 34/2000, Train Loss: 0.243011474, Train-Class-Acc: {0: '91.73%', 1: '85.68%'}, Val Loss: 0.187668636, Val Accuracy: 92.43%, Val-Class-Acc: {0: '93.27%', 1: '91.13%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 90.64%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_28.pth\n",
      "Model saved after epoch 34 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_34.pth \n",
      "\n",
      "Epoch 35/2000, Train Loss: 0.236420788, Train-Class-Acc: {0: '91.81%', 1: '86.48%'}, Val Loss: 0.184720213, Val Accuracy: 92.62%, Val-Class-Acc: {0: '93.76%', 1: '90.85%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 91.30%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_31.pth\n",
      "Model saved after epoch 35 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_35.pth \n",
      "\n",
      "Epoch 36/2000, Train Loss: 0.217609777, Train-Class-Acc: {0: '92.67%', 1: '87.48%'}, Val Loss: 0.191684678, Val Accuracy: 92.00%, Val-Class-Acc: {0: '90.19%', 1: '94.78%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 91.43%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_27.pth\n",
      "Model saved after epoch 36 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_36.pth \n",
      "\n",
      "Epoch 37/2000, Train Loss: 0.284277942, Train-Class-Acc: {0: '90.44%', 1: '84.33%'}, Val Loss: 0.286707052, Val Accuracy: 87.34%, Val-Class-Acc: {0: '97.40%', 1: '71.85%'}, LR: 0.000100000\n",
      "Epoch 38/2000, Train Loss: 0.265898370, Train-Class-Acc: {0: '91.60%', 1: '83.21%'}, Val Loss: 0.187562795, Val Accuracy: 92.62%, Val-Class-Acc: {0: '94.24%', 1: '90.11%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 91.66%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_29.pth\n",
      "Model saved after epoch 38 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_38.pth \n",
      "\n",
      "Epoch 39/2000, Train Loss: 0.210585040, Train-Class-Acc: {0: '92.97%', 1: '88.04%'}, Val Loss: 0.180045803, Val Accuracy: 92.94%, Val-Class-Acc: {0: '95.34%', 1: '89.24%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 91.94%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_30.pth\n",
      "Model saved after epoch 39 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_39.pth \n",
      "\n",
      "Epoch 40/2000, Train Loss: 0.238094420, Train-Class-Acc: {0: '91.87%', 1: '86.75%'}, Val Loss: 0.178726288, Val Accuracy: 93.09%, Val-Class-Acc: {0: '95.35%', 1: '89.62%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 92.00%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_36.pth\n",
      "Model saved after epoch 40 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_40.pth \n",
      "\n",
      "Epoch 41/2000, Train Loss: 0.207275141, Train-Class-Acc: {0: '93.05%', 1: '88.52%'}, Val Loss: 0.175347696, Val Accuracy: 93.12%, Val-Class-Acc: {0: '92.19%', 1: '94.54%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 92.43%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_34.pth\n",
      "Model saved after epoch 41 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_41.pth \n",
      "\n",
      "Epoch 42/2000, Train Loss: 0.209914956, Train-Class-Acc: {0: '92.97%', 1: '88.55%'}, Val Loss: 0.225025468, Val Accuracy: 90.83%, Val-Class-Acc: {0: '86.54%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 43/2000, Train Loss: 0.220341593, Train-Class-Acc: {0: '92.36%', 1: '88.49%'}, Val Loss: 0.167316595, Val Accuracy: 93.70%, Val-Class-Acc: {0: '95.53%', 1: '90.88%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 92.62%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_35.pth\n",
      "Model saved after epoch 43 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_43.pth \n",
      "\n",
      "Epoch 44/2000, Train Loss: 0.269007935, Train-Class-Acc: {0: '91.00%', 1: '85.73%'}, Val Loss: 0.174062059, Val Accuracy: 93.47%, Val-Class-Acc: {0: '94.09%', 1: '92.52%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 92.62%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_38.pth\n",
      "Model saved after epoch 44 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_44.pth \n",
      "\n",
      "Epoch 45/2000, Train Loss: 0.197333827, Train-Class-Acc: {0: '93.40%', 1: '89.67%'}, Val Loss: 0.164271003, Val Accuracy: 93.83%, Val-Class-Acc: {0: '95.41%', 1: '91.41%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 92.94%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_39.pth\n",
      "Model saved after epoch 45 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_45.pth \n",
      "\n",
      "Epoch 46/2000, Train Loss: 0.189310658, Train-Class-Acc: {0: '93.72%', 1: '90.13%'}, Val Loss: 0.191949290, Val Accuracy: 92.42%, Val-Class-Acc: {0: '97.29%', 1: '84.93%'}, LR: 0.000100000\n",
      "Epoch 47/2000, Train Loss: 0.271163867, Train-Class-Acc: {0: '90.86%', 1: '85.76%'}, Val Loss: 0.169589889, Val Accuracy: 93.54%, Val-Class-Acc: {0: '92.72%', 1: '94.79%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 93.09%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_40.pth\n",
      "Model saved after epoch 47 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_47.pth \n",
      "\n",
      "Epoch 48/2000, Train Loss: 0.194548183, Train-Class-Acc: {0: '93.36%', 1: '90.04%'}, Val Loss: 0.159067444, Val Accuracy: 94.13%, Val-Class-Acc: {0: '95.43%', 1: '92.14%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 93.12%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_41.pth\n",
      "Model saved after epoch 48 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_48.pth \n",
      "\n",
      "Epoch 49/2000, Train Loss: 0.180990097, Train-Class-Acc: {0: '94.09%', 1: '90.59%'}, Val Loss: 0.168373258, Val Accuracy: 93.31%, Val-Class-Acc: {0: '91.55%', 1: '96.01%'}, LR: 0.000100000\n",
      "Epoch 50/2000, Train Loss: 0.239504298, Train-Class-Acc: {0: '92.20%', 1: '88.41%'}, Val Loss: 0.383417705, Val Accuracy: 83.95%, Val-Class-Acc: {0: '74.85%', 1: '97.95%'}, LR: 0.000100000\n",
      "Epoch 51/2000, Train Loss: 0.288683205, Train-Class-Acc: {0: '89.87%', 1: '85.09%'}, Val Loss: 0.169444337, Val Accuracy: 93.85%, Val-Class-Acc: {0: '93.69%', 1: '94.11%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 93.47%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_44.pth\n",
      "Model saved after epoch 51 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_51.pth \n",
      "\n",
      "Epoch 52/2000, Train Loss: 0.191881882, Train-Class-Acc: {0: '93.61%', 1: '90.22%'}, Val Loss: 0.175076038, Val Accuracy: 93.17%, Val-Class-Acc: {0: '97.07%', 1: '87.17%'}, LR: 0.000100000\n",
      "Epoch 53/2000, Train Loss: 0.185404059, Train-Class-Acc: {0: '93.90%', 1: '90.42%'}, Val Loss: 0.152652687, Val Accuracy: 94.45%, Val-Class-Acc: {0: '96.07%', 1: '91.97%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 93.54%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_47.pth\n",
      "Model saved after epoch 53 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_53.pth \n",
      "\n",
      "Epoch 54/2000, Train Loss: 0.191675974, Train-Class-Acc: {0: '93.59%', 1: '90.16%'}, Val Loss: 0.174494223, Val Accuracy: 92.84%, Val-Class-Acc: {0: '90.00%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 55/2000, Train Loss: 0.193448262, Train-Class-Acc: {0: '93.27%', 1: '90.34%'}, Val Loss: 0.145541254, Val Accuracy: 94.62%, Val-Class-Acc: {0: '95.35%', 1: '93.51%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 93.70%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_43.pth\n",
      "Model saved after epoch 55 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_55.pth \n",
      "\n",
      "Epoch 56/2000, Train Loss: 0.182504379, Train-Class-Acc: {0: '93.71%', 1: '90.91%'}, Val Loss: 0.146615895, Val Accuracy: 94.62%, Val-Class-Acc: {0: '96.20%', 1: '92.19%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 93.83%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_45.pth\n",
      "Model saved after epoch 56 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_56.pth \n",
      "\n",
      "Epoch 57/2000, Train Loss: 0.179727800, Train-Class-Acc: {0: '93.88%', 1: '91.00%'}, Val Loss: 0.143332199, Val Accuracy: 94.74%, Val-Class-Acc: {0: '96.10%', 1: '92.65%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 93.85%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_51.pth\n",
      "Model saved after epoch 57 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_57.pth \n",
      "\n",
      "Epoch 58/2000, Train Loss: 0.172354028, Train-Class-Acc: {0: '94.11%', 1: '91.44%'}, Val Loss: 0.188774437, Val Accuracy: 92.26%, Val-Class-Acc: {0: '88.50%', 1: '98.06%'}, LR: 0.000100000\n",
      "Epoch 59/2000, Train Loss: 0.170791950, Train-Class-Acc: {0: '93.99%', 1: '91.76%'}, Val Loss: 0.150424770, Val Accuracy: 94.05%, Val-Class-Acc: {0: '92.23%', 1: '96.85%'}, LR: 0.000100000\n",
      "Epoch 60/2000, Train Loss: 0.237950610, Train-Class-Acc: {0: '92.22%', 1: '88.79%'}, Val Loss: 0.141766477, Val Accuracy: 94.74%, Val-Class-Acc: {0: '95.23%', 1: '93.99%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 94.13%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_48.pth\n",
      "Model saved after epoch 60 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_60.pth \n",
      "\n",
      "Epoch 61/2000, Train Loss: 0.159865226, Train-Class-Acc: {0: '94.46%', 1: '92.36%'}, Val Loss: 0.134701482, Val Accuracy: 95.03%, Val-Class-Acc: {0: '95.34%', 1: '94.57%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 94.45%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_53.pth\n",
      "Model saved after epoch 61 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_61.pth \n",
      "\n",
      "Epoch 62/2000, Train Loss: 0.154645165, Train-Class-Acc: {0: '94.79%', 1: '92.43%'}, Val Loss: 0.131383347, Val Accuracy: 95.01%, Val-Class-Acc: {0: '94.71%', 1: '95.47%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 94.62%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_56.pth\n",
      "Model saved after epoch 62 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_62.pth \n",
      "\n",
      "Epoch 63/2000, Train Loss: 0.173537951, Train-Class-Acc: {0: '93.96%', 1: '91.48%'}, Val Loss: 0.141241268, Val Accuracy: 94.84%, Val-Class-Acc: {0: '97.09%', 1: '91.38%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 94.62%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_55.pth\n",
      "Model saved after epoch 63 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_63.pth \n",
      "\n",
      "Epoch 64/2000, Train Loss: 0.190194924, Train-Class-Acc: {0: '93.68%', 1: '90.57%'}, Val Loss: 0.258897337, Val Accuracy: 89.44%, Val-Class-Acc: {0: '83.42%', 1: '98.72%'}, LR: 0.000100000\n",
      "Epoch 65/2000, Train Loss: 0.203301990, Train-Class-Acc: {0: '92.82%', 1: '90.43%'}, Val Loss: 0.209081068, Val Accuracy: 91.74%, Val-Class-Acc: {0: '97.77%', 1: '82.46%'}, LR: 0.000100000\n",
      "Epoch 66/2000, Train Loss: 0.181119686, Train-Class-Acc: {0: '93.89%', 1: '90.84%'}, Val Loss: 0.131768431, Val Accuracy: 95.32%, Val-Class-Acc: {0: '96.18%', 1: '93.99%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 94.74%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_57.pth\n",
      "Model saved after epoch 66 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_66.pth \n",
      "\n",
      "Epoch 67/2000, Train Loss: 0.147911904, Train-Class-Acc: {0: '95.05%', 1: '92.76%'}, Val Loss: 0.125778688, Val Accuracy: 95.44%, Val-Class-Acc: {0: '96.16%', 1: '94.33%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 94.74%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_60.pth\n",
      "Model saved after epoch 67 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_67.pth \n",
      "\n",
      "Epoch 68/2000, Train Loss: 0.163452386, Train-Class-Acc: {0: '94.38%', 1: '91.96%'}, Val Loss: 0.126433608, Val Accuracy: 95.37%, Val-Class-Acc: {0: '96.67%', 1: '93.38%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 94.84%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_63.pth\n",
      "Model saved after epoch 68 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_68.pth \n",
      "\n",
      "Epoch 69/2000, Train Loss: 0.194460999, Train-Class-Acc: {0: '93.52%', 1: '90.41%'}, Val Loss: 0.124454915, Val Accuracy: 95.45%, Val-Class-Acc: {0: '95.45%', 1: '95.46%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.01%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_62.pth\n",
      "Model saved after epoch 69 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_69.pth \n",
      "\n",
      "Epoch 70/2000, Train Loss: 0.157647210, Train-Class-Acc: {0: '94.58%', 1: '92.27%'}, Val Loss: 0.173349854, Val Accuracy: 93.19%, Val-Class-Acc: {0: '97.90%', 1: '85.95%'}, LR: 0.000100000\n",
      "Epoch 71/2000, Train Loss: 0.165655796, Train-Class-Acc: {0: '94.52%', 1: '91.55%'}, Val Loss: 0.147469963, Val Accuracy: 93.61%, Val-Class-Acc: {0: '90.84%', 1: '97.86%'}, LR: 0.000100000\n",
      "Epoch 72/2000, Train Loss: 0.175070485, Train-Class-Acc: {0: '93.98%', 1: '91.34%'}, Val Loss: 0.121973638, Val Accuracy: 95.63%, Val-Class-Acc: {0: '95.71%', 1: '95.51%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.03%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_61.pth\n",
      "Model saved after epoch 72 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_72.pth \n",
      "\n",
      "Epoch 73/2000, Train Loss: 0.157884207, Train-Class-Acc: {0: '94.75%', 1: '92.25%'}, Val Loss: 0.123220193, Val Accuracy: 95.59%, Val-Class-Acc: {0: '96.92%', 1: '93.55%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.32%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_66.pth\n",
      "Model saved after epoch 73 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_73.pth \n",
      "\n",
      "Epoch 74/2000, Train Loss: 0.153984929, Train-Class-Acc: {0: '94.80%', 1: '92.21%'}, Val Loss: 0.123427186, Val Accuracy: 95.10%, Val-Class-Acc: {0: '94.22%', 1: '96.47%'}, LR: 0.000100000\n",
      "Epoch 75/2000, Train Loss: 0.143387006, Train-Class-Acc: {0: '95.23%', 1: '92.87%'}, Val Loss: 0.121025656, Val Accuracy: 95.23%, Val-Class-Acc: {0: '94.34%', 1: '96.59%'}, LR: 0.000100000\n",
      "Epoch 76/2000, Train Loss: 0.154501641, Train-Class-Acc: {0: '94.79%', 1: '92.39%'}, Val Loss: 0.120860538, Val Accuracy: 95.84%, Val-Class-Acc: {0: '97.26%', 1: '93.66%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.37%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_68.pth\n",
      "Model saved after epoch 76 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_76.pth \n",
      "\n",
      "Epoch 77/2000, Train Loss: 0.177526387, Train-Class-Acc: {0: '94.19%', 1: '91.00%'}, Val Loss: 0.120238038, Val Accuracy: 95.40%, Val-Class-Acc: {0: '94.61%', 1: '96.60%'}, LR: 0.000100000\n",
      "Epoch 78/2000, Train Loss: 0.151011696, Train-Class-Acc: {0: '94.87%', 1: '92.53%'}, Val Loss: 0.115001696, Val Accuracy: 95.91%, Val-Class-Acc: {0: '96.26%', 1: '95.36%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.44%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_67.pth\n",
      "Model saved after epoch 78 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_78.pth \n",
      "\n",
      "Epoch 79/2000, Train Loss: 0.146998496, Train-Class-Acc: {0: '95.08%', 1: '92.72%'}, Val Loss: 0.117006985, Val Accuracy: 95.97%, Val-Class-Acc: {0: '97.17%', 1: '94.12%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.45%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_69.pth\n",
      "Model saved after epoch 79 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_79.pth \n",
      "\n",
      "Epoch 80/2000, Train Loss: 0.166473881, Train-Class-Acc: {0: '94.47%', 1: '91.58%'}, Val Loss: 0.121073520, Val Accuracy: 95.82%, Val-Class-Acc: {0: '97.41%', 1: '93.38%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.59%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_73.pth\n",
      "Model saved after epoch 80 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_80.pth \n",
      "\n",
      "Epoch 81/2000, Train Loss: 0.180372988, Train-Class-Acc: {0: '94.05%', 1: '90.99%'}, Val Loss: 0.117820070, Val Accuracy: 95.66%, Val-Class-Acc: {0: '95.09%', 1: '96.54%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.63%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_72.pth\n",
      "Model saved after epoch 81 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_81.pth \n",
      "\n",
      "Epoch 82/2000, Train Loss: 0.136017267, Train-Class-Acc: {0: '95.53%', 1: '93.26%'}, Val Loss: 0.112264929, Val Accuracy: 95.95%, Val-Class-Acc: {0: '96.70%', 1: '94.79%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.66%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_81.pth\n",
      "Model saved after epoch 82 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_82.pth \n",
      "\n",
      "Epoch 83/2000, Train Loss: 0.134139806, Train-Class-Acc: {0: '95.54%', 1: '93.37%'}, Val Loss: 0.113917039, Val Accuracy: 96.05%, Val-Class-Acc: {0: '97.42%', 1: '93.94%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.82%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_80.pth\n",
      "Model saved after epoch 83 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_83.pth \n",
      "\n",
      "Epoch 84/2000, Train Loss: 0.138436239, Train-Class-Acc: {0: '95.49%', 1: '93.05%'}, Val Loss: 0.121511291, Val Accuracy: 95.07%, Val-Class-Acc: {0: '93.45%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 85/2000, Train Loss: 0.150480056, Train-Class-Acc: {0: '95.06%', 1: '92.50%'}, Val Loss: 0.117400858, Val Accuracy: 95.24%, Val-Class-Acc: {0: '93.97%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 86/2000, Train Loss: 0.143843655, Train-Class-Acc: {0: '95.16%', 1: '93.13%'}, Val Loss: 0.154823640, Val Accuracy: 94.02%, Val-Class-Acc: {0: '98.19%', 1: '87.60%'}, LR: 0.000100000\n",
      "Epoch 87/2000, Train Loss: 0.150312609, Train-Class-Acc: {0: '95.07%', 1: '92.42%'}, Val Loss: 0.113921904, Val Accuracy: 96.11%, Val-Class-Acc: {0: '97.55%', 1: '93.90%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.84%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_76.pth\n",
      "Model saved after epoch 87 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_87.pth \n",
      "\n",
      "Epoch 88/2000, Train Loss: 0.144246975, Train-Class-Acc: {0: '95.26%', 1: '92.84%'}, Val Loss: 0.109122780, Val Accuracy: 96.28%, Val-Class-Acc: {0: '97.39%', 1: '94.58%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.91%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_78.pth\n",
      "Model saved after epoch 88 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_88.pth \n",
      "\n",
      "Epoch 89/2000, Train Loss: 0.126816295, Train-Class-Acc: {0: '95.99%', 1: '93.59%'}, Val Loss: 0.105997992, Val Accuracy: 96.31%, Val-Class-Acc: {0: '97.25%', 1: '94.87%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.95%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_82.pth\n",
      "Model saved after epoch 89 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_89.pth \n",
      "\n",
      "Epoch 90/2000, Train Loss: 0.123937161, Train-Class-Acc: {0: '95.95%', 1: '93.82%'}, Val Loss: 0.103911697, Val Accuracy: 96.35%, Val-Class-Acc: {0: '97.29%', 1: '94.89%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.97%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_79.pth\n",
      "Model saved after epoch 90 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_90.pth \n",
      "\n",
      "Epoch 91/2000, Train Loss: 0.152954501, Train-Class-Acc: {0: '95.01%', 1: '92.45%'}, Val Loss: 0.121286404, Val Accuracy: 95.68%, Val-Class-Acc: {0: '97.99%', 1: '92.12%'}, LR: 0.000100000\n",
      "Epoch 92/2000, Train Loss: 0.146488075, Train-Class-Acc: {0: '95.23%', 1: '92.71%'}, Val Loss: 0.104046205, Val Accuracy: 96.32%, Val-Class-Acc: {0: '97.27%', 1: '94.85%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.05%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_83.pth\n",
      "Model saved after epoch 92 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_92.pth \n",
      "\n",
      "Epoch 93/2000, Train Loss: 0.159179425, Train-Class-Acc: {0: '95.10%', 1: '92.18%'}, Val Loss: 0.283403634, Val Accuracy: 90.39%, Val-Class-Acc: {0: '98.62%', 1: '77.74%'}, LR: 0.000100000\n",
      "Epoch 94/2000, Train Loss: 0.149372776, Train-Class-Acc: {0: '95.31%', 1: '92.62%'}, Val Loss: 0.103143373, Val Accuracy: 96.16%, Val-Class-Acc: {0: '95.94%', 1: '96.50%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.11%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_87.pth\n",
      "Model saved after epoch 94 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_94.pth \n",
      "\n",
      "Epoch 95/2000, Train Loss: 0.122739561, Train-Class-Acc: {0: '96.11%', 1: '93.88%'}, Val Loss: 0.102191381, Val Accuracy: 96.28%, Val-Class-Acc: {0: '97.69%', 1: '94.11%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.16%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_94.pth\n",
      "Model saved after epoch 95 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_95.pth \n",
      "\n",
      "Epoch 96/2000, Train Loss: 0.156978270, Train-Class-Acc: {0: '95.19%', 1: '92.02%'}, Val Loss: 0.110926700, Val Accuracy: 96.21%, Val-Class-Acc: {0: '97.76%', 1: '93.83%'}, LR: 0.000100000\n",
      "Epoch 97/2000, Train Loss: 0.131073938, Train-Class-Acc: {0: '95.83%', 1: '93.39%'}, Val Loss: 0.098015525, Val Accuracy: 96.52%, Val-Class-Acc: {0: '97.35%', 1: '95.25%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.28%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_88.pth\n",
      "Model saved after epoch 97 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_97.pth \n",
      "\n",
      "Epoch 98/2000, Train Loss: 0.149925058, Train-Class-Acc: {0: '95.16%', 1: '92.24%'}, Val Loss: 0.118984561, Val Accuracy: 95.57%, Val-Class-Acc: {0: '98.15%', 1: '91.62%'}, LR: 0.000100000\n",
      "Epoch 99/2000, Train Loss: 0.144172386, Train-Class-Acc: {0: '95.34%', 1: '92.64%'}, Val Loss: 0.097035566, Val Accuracy: 96.36%, Val-Class-Acc: {0: '96.74%', 1: '95.78%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.28%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_95.pth\n",
      "Model saved after epoch 99 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_99.pth \n",
      "\n",
      "Epoch 100/2000, Train Loss: 0.121749277, Train-Class-Acc: {0: '96.24%', 1: '93.82%'}, Val Loss: 0.097131094, Val Accuracy: 96.08%, Val-Class-Acc: {0: '95.71%', 1: '96.63%'}, LR: 0.000100000\n",
      "Epoch 101/2000, Train Loss: 0.134576448, Train-Class-Acc: {0: '95.76%', 1: '93.07%'}, Val Loss: 0.134582030, Val Accuracy: 94.68%, Val-Class-Acc: {0: '98.42%', 1: '88.92%'}, LR: 0.000100000\n",
      "Epoch 102/2000, Train Loss: 0.124843962, Train-Class-Acc: {0: '95.98%', 1: '93.68%'}, Val Loss: 0.092496755, Val Accuracy: 96.43%, Val-Class-Acc: {0: '96.63%', 1: '96.12%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.31%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_89.pth\n",
      "Model saved after epoch 102 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_102.pth \n",
      "\n",
      "Epoch 103/2000, Train Loss: 0.123462454, Train-Class-Acc: {0: '96.13%', 1: '93.58%'}, Val Loss: 0.094427314, Val Accuracy: 96.54%, Val-Class-Acc: {0: '97.86%', 1: '94.50%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.32%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_92.pth\n",
      "Model saved after epoch 103 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_103.pth \n",
      "\n",
      "Epoch 104/2000, Train Loss: 0.123945792, Train-Class-Acc: {0: '96.21%', 1: '93.41%'}, Val Loss: 0.110973300, Val Accuracy: 95.26%, Val-Class-Acc: {0: '93.59%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 105/2000, Train Loss: 0.161886060, Train-Class-Acc: {0: '95.06%', 1: '91.70%'}, Val Loss: 0.193722893, Val Accuracy: 91.92%, Val-Class-Acc: {0: '87.70%', 1: '98.42%'}, LR: 0.000100000\n",
      "Epoch 106/2000, Train Loss: 0.158545844, Train-Class-Acc: {0: '95.01%', 1: '91.82%'}, Val Loss: 0.094559179, Val Accuracy: 96.42%, Val-Class-Acc: {0: '96.92%', 1: '95.66%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.35%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_90.pth\n",
      "Model saved after epoch 106 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_106.pth \n",
      "\n",
      "Epoch 107/2000, Train Loss: 0.122570972, Train-Class-Acc: {0: '96.27%', 1: '93.58%'}, Val Loss: 0.091741258, Val Accuracy: 96.45%, Val-Class-Acc: {0: '96.61%', 1: '96.21%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.36%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_99.pth\n",
      "Model saved after epoch 107 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_107.pth \n",
      "\n",
      "Epoch 108/2000, Train Loss: 0.113395356, Train-Class-Acc: {0: '96.55%', 1: '94.03%'}, Val Loss: 0.090406168, Val Accuracy: 96.65%, Val-Class-Acc: {0: '97.68%', 1: '95.06%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.42%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_106.pth\n",
      "Model saved after epoch 108 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_108.pth \n",
      "\n",
      "Epoch 109/2000, Train Loss: 0.109516177, Train-Class-Acc: {0: '96.59%', 1: '94.18%'}, Val Loss: 0.104533318, Val Accuracy: 96.19%, Val-Class-Acc: {0: '98.26%', 1: '92.99%'}, LR: 0.000100000\n",
      "Epoch 110/2000, Train Loss: 0.153492452, Train-Class-Acc: {0: '95.30%', 1: '92.14%'}, Val Loss: 0.095393957, Val Accuracy: 96.08%, Val-Class-Acc: {0: '95.77%', 1: '96.55%'}, LR: 0.000100000\n",
      "Epoch 111/2000, Train Loss: 0.134057596, Train-Class-Acc: {0: '95.98%', 1: '92.67%'}, Val Loss: 0.107392398, Val Accuracy: 95.43%, Val-Class-Acc: {0: '93.99%', 1: '97.63%'}, LR: 0.000100000\n",
      "Epoch 112/2000, Train Loss: 0.129674346, Train-Class-Acc: {0: '95.98%', 1: '93.15%'}, Val Loss: 0.097738005, Val Accuracy: 96.52%, Val-Class-Acc: {0: '98.14%', 1: '94.03%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.43%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_102.pth\n",
      "Model saved after epoch 112 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_112.pth \n",
      "\n",
      "Epoch 113/2000, Train Loss: 0.130827964, Train-Class-Acc: {0: '95.97%', 1: '92.91%'}, Val Loss: 0.114971380, Val Accuracy: 95.08%, Val-Class-Acc: {0: '93.05%', 1: '98.21%'}, LR: 0.000100000\n",
      "Epoch 114/2000, Train Loss: 0.144948766, Train-Class-Acc: {0: '95.58%', 1: '92.11%'}, Val Loss: 0.122780781, Val Accuracy: 95.31%, Val-Class-Acc: {0: '98.44%', 1: '90.50%'}, LR: 0.000100000\n",
      "Epoch 115/2000, Train Loss: 0.112787297, Train-Class-Acc: {0: '96.62%', 1: '94.01%'}, Val Loss: 0.093391408, Val Accuracy: 96.33%, Val-Class-Acc: {0: '96.04%', 1: '96.77%'}, LR: 0.000100000\n",
      "Epoch 116/2000, Train Loss: 0.118139402, Train-Class-Acc: {0: '96.44%', 1: '93.52%'}, Val Loss: 0.091634164, Val Accuracy: 96.44%, Val-Class-Acc: {0: '96.36%', 1: '96.55%'}, LR: 0.000100000\n",
      "Epoch 117/2000, Train Loss: 0.112407224, Train-Class-Acc: {0: '96.61%', 1: '93.92%'}, Val Loss: 0.129460866, Val Accuracy: 94.81%, Val-Class-Acc: {0: '98.70%', 1: '88.82%'}, LR: 0.000100000\n",
      "Epoch 118/2000, Train Loss: 0.141852518, Train-Class-Acc: {0: '95.67%', 1: '92.14%'}, Val Loss: 0.090822550, Val Accuracy: 96.54%, Val-Class-Acc: {0: '96.82%', 1: '96.10%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.45%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_107.pth\n",
      "Model saved after epoch 118 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_118.pth \n",
      "\n",
      "Epoch 119/2000, Train Loss: 0.112210670, Train-Class-Acc: {0: '96.54%', 1: '93.92%'}, Val Loss: 0.089933257, Val Accuracy: 96.81%, Val-Class-Acc: {0: '97.95%', 1: '95.07%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.52%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_112.pth\n",
      "Model saved after epoch 119 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_119.pth \n",
      "\n",
      "Epoch 120/2000, Train Loss: 0.122302354, Train-Class-Acc: {0: '96.38%', 1: '93.31%'}, Val Loss: 0.089868240, Val Accuracy: 96.85%, Val-Class-Acc: {0: '98.04%', 1: '95.02%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.52%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_97.pth\n",
      "Model saved after epoch 120 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_120.pth \n",
      "\n",
      "Epoch 121/2000, Train Loss: 0.121599930, Train-Class-Acc: {0: '96.42%', 1: '93.27%'}, Val Loss: 0.089847712, Val Accuracy: 96.70%, Val-Class-Acc: {0: '97.18%', 1: '95.95%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.54%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_103.pth\n",
      "Model saved after epoch 121 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_121.pth \n",
      "\n",
      "Epoch 122/2000, Train Loss: 0.109592803, Train-Class-Acc: {0: '96.80%', 1: '94.02%'}, Val Loss: 0.093202491, Val Accuracy: 96.27%, Val-Class-Acc: {0: '96.02%', 1: '96.64%'}, LR: 0.000100000\n",
      "Epoch 123/2000, Train Loss: 0.125448972, Train-Class-Acc: {0: '96.28%', 1: '93.17%'}, Val Loss: 0.094200093, Val Accuracy: 96.51%, Val-Class-Acc: {0: '98.25%', 1: '93.82%'}, LR: 0.000100000\n",
      "Epoch 124/2000, Train Loss: 0.117514473, Train-Class-Acc: {0: '96.49%', 1: '93.42%'}, Val Loss: 0.098392985, Val Accuracy: 96.34%, Val-Class-Acc: {0: '98.35%', 1: '93.25%'}, LR: 0.000100000\n",
      "Epoch 125/2000, Train Loss: 0.151548867, Train-Class-Acc: {0: '95.54%', 1: '91.12%'}, Val Loss: 0.101229561, Val Accuracy: 96.45%, Val-Class-Acc: {0: '98.40%', 1: '93.45%'}, LR: 0.000100000\n",
      "Epoch 126/2000, Train Loss: 0.126646659, Train-Class-Acc: {0: '96.27%', 1: '92.94%'}, Val Loss: 0.092370005, Val Accuracy: 96.74%, Val-Class-Acc: {0: '98.28%', 1: '94.39%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.54%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_118.pth\n",
      "Model saved after epoch 126 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_126.pth \n",
      "\n",
      "Epoch 127/2000, Train Loss: 0.124773025, Train-Class-Acc: {0: '96.47%', 1: '92.69%'}, Val Loss: 0.115559149, Val Accuracy: 94.85%, Val-Class-Acc: {0: '92.77%', 1: '98.04%'}, LR: 0.000100000\n",
      "Epoch 128/2000, Train Loss: 0.108037873, Train-Class-Acc: {0: '96.77%', 1: '94.14%'}, Val Loss: 0.087460101, Val Accuracy: 96.85%, Val-Class-Acc: {0: '97.16%', 1: '96.38%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.65%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_108.pth\n",
      "Model saved after epoch 128 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_128.pth \n",
      "\n",
      "Epoch 129/2000, Train Loss: 0.106034001, Train-Class-Acc: {0: '96.90%', 1: '94.02%'}, Val Loss: 0.086673585, Val Accuracy: 96.86%, Val-Class-Acc: {0: '97.64%', 1: '95.66%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.70%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_121.pth\n",
      "Model saved after epoch 129 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_129.pth \n",
      "\n",
      "Epoch 130/2000, Train Loss: 0.106937994, Train-Class-Acc: {0: '96.88%', 1: '93.99%'}, Val Loss: 0.087549005, Val Accuracy: 96.68%, Val-Class-Acc: {0: '97.04%', 1: '96.13%'}, LR: 0.000100000\n",
      "Epoch 131/2000, Train Loss: 0.108750802, Train-Class-Acc: {0: '96.75%', 1: '93.89%'}, Val Loss: 0.094776887, Val Accuracy: 96.63%, Val-Class-Acc: {0: '98.55%', 1: '93.68%'}, LR: 0.000100000\n",
      "Epoch 132/2000, Train Loss: 0.139291198, Train-Class-Acc: {0: '95.96%', 1: '91.99%'}, Val Loss: 0.127865281, Val Accuracy: 94.66%, Val-Class-Acc: {0: '98.76%', 1: '88.36%'}, LR: 0.000100000\n",
      "Epoch 133/2000, Train Loss: 0.108182085, Train-Class-Acc: {0: '96.97%', 1: '93.90%'}, Val Loss: 0.097407732, Val Accuracy: 96.42%, Val-Class-Acc: {0: '98.59%', 1: '93.07%'}, LR: 0.000100000\n",
      "Epoch 134/2000, Train Loss: 0.102687656, Train-Class-Acc: {0: '97.03%', 1: '94.11%'}, Val Loss: 0.104014526, Val Accuracy: 96.09%, Val-Class-Acc: {0: '98.62%', 1: '92.21%'}, LR: 0.000100000\n",
      "Epoch 135/2000, Train Loss: 0.110036769, Train-Class-Acc: {0: '96.87%', 1: '93.65%'}, Val Loss: 0.088841724, Val Accuracy: 96.67%, Val-Class-Acc: {0: '96.46%', 1: '96.98%'}, LR: 0.000100000\n",
      "Epoch 136/2000, Train Loss: 0.108808301, Train-Class-Acc: {0: '96.79%', 1: '93.76%'}, Val Loss: 0.087340284, Val Accuracy: 96.70%, Val-Class-Acc: {0: '96.95%', 1: '96.32%'}, LR: 0.000100000\n",
      "Epoch 137/2000, Train Loss: 0.124561398, Train-Class-Acc: {0: '96.38%', 1: '92.92%'}, Val Loss: 0.089033391, Val Accuracy: 97.01%, Val-Class-Acc: {0: '98.31%', 1: '95.02%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.74%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_126.pth\n",
      "Model saved after epoch 137 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_137.pth \n",
      "\n",
      "Epoch 138/2000, Train Loss: 0.099614192, Train-Class-Acc: {0: '97.24%', 1: '94.28%'}, Val Loss: 0.086550907, Val Accuracy: 96.89%, Val-Class-Acc: {0: '98.09%', 1: '95.03%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.81%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_119.pth\n",
      "Model saved after epoch 138 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_138.pth \n",
      "\n",
      "Epoch 139/2000, Train Loss: 0.108432097, Train-Class-Acc: {0: '96.91%', 1: '93.72%'}, Val Loss: 0.090478075, Val Accuracy: 96.75%, Val-Class-Acc: {0: '98.49%', 1: '94.08%'}, LR: 0.000100000\n",
      "Epoch 140/2000, Train Loss: 0.126733043, Train-Class-Acc: {0: '96.30%', 1: '92.60%'}, Val Loss: 0.167849928, Val Accuracy: 93.11%, Val-Class-Acc: {0: '98.61%', 1: '84.65%'}, LR: 0.000100000\n",
      "Epoch 141/2000, Train Loss: 0.141922133, Train-Class-Acc: {0: '96.08%', 1: '91.56%'}, Val Loss: 0.092098667, Val Accuracy: 96.82%, Val-Class-Acc: {0: '98.49%', 1: '94.26%'}, LR: 0.000100000\n",
      "Epoch 142/2000, Train Loss: 0.094908709, Train-Class-Acc: {0: '97.41%', 1: '94.61%'}, Val Loss: 0.093835721, Val Accuracy: 96.47%, Val-Class-Acc: {0: '95.76%', 1: '97.57%'}, LR: 0.000100000\n",
      "Epoch 143/2000, Train Loss: 0.115551275, Train-Class-Acc: {0: '96.73%', 1: '93.29%'}, Val Loss: 0.106799415, Val Accuracy: 95.30%, Val-Class-Acc: {0: '93.84%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 144/2000, Train Loss: 0.104675240, Train-Class-Acc: {0: '96.98%', 1: '93.98%'}, Val Loss: 0.085031635, Val Accuracy: 96.92%, Val-Class-Acc: {0: '97.47%', 1: '96.07%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.85%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_120.pth\n",
      "Model saved after epoch 144 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_144.pth \n",
      "\n",
      "Epoch 145/2000, Train Loss: 0.114495297, Train-Class-Acc: {0: '96.79%', 1: '93.35%'}, Val Loss: 0.087808840, Val Accuracy: 96.88%, Val-Class-Acc: {0: '97.19%', 1: '96.42%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.85%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_128.pth\n",
      "Model saved after epoch 145 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_145.pth \n",
      "\n",
      "Epoch 146/2000, Train Loss: 0.098260105, Train-Class-Acc: {0: '97.17%', 1: '94.43%'}, Val Loss: 0.095038771, Val Accuracy: 96.71%, Val-Class-Acc: {0: '98.68%', 1: '93.68%'}, LR: 0.000100000\n",
      "Epoch 147/2000, Train Loss: 0.104437272, Train-Class-Acc: {0: '97.15%', 1: '93.81%'}, Val Loss: 0.094354865, Val Accuracy: 96.47%, Val-Class-Acc: {0: '95.61%', 1: '97.80%'}, LR: 0.000100000\n",
      "Epoch 148/2000, Train Loss: 0.093030269, Train-Class-Acc: {0: '97.32%', 1: '94.74%'}, Val Loss: 0.085258844, Val Accuracy: 97.04%, Val-Class-Acc: {0: '98.13%', 1: '95.37%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.86%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_129.pth\n",
      "Model saved after epoch 148 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_148.pth \n",
      "\n",
      "Epoch 149/2000, Train Loss: 0.101811539, Train-Class-Acc: {0: '97.17%', 1: '94.18%'}, Val Loss: 0.119839254, Val Accuracy: 95.06%, Val-Class-Acc: {0: '93.14%', 1: '98.01%'}, LR: 0.000100000\n",
      "Epoch 150/2000, Train Loss: 0.122157627, Train-Class-Acc: {0: '96.64%', 1: '92.89%'}, Val Loss: 0.084842650, Val Accuracy: 97.14%, Val-Class-Acc: {0: '97.49%', 1: '96.59%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.88%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_145.pth\n",
      "Model saved after epoch 150 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_150.pth \n",
      "\n",
      "Epoch 151/2000, Train Loss: 0.107409737, Train-Class-Acc: {0: '97.01%', 1: '93.62%'}, Val Loss: 0.086332539, Val Accuracy: 96.93%, Val-Class-Acc: {0: '97.38%', 1: '96.23%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.89%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_138.pth\n",
      "Model saved after epoch 151 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_151.pth \n",
      "\n",
      "Epoch 152/2000, Train Loss: 0.114239054, Train-Class-Acc: {0: '96.84%', 1: '93.22%'}, Val Loss: 0.087074341, Val Accuracy: 96.85%, Val-Class-Acc: {0: '96.61%', 1: '97.23%'}, LR: 0.000100000\n",
      "Epoch 153/2000, Train Loss: 0.097665684, Train-Class-Acc: {0: '97.27%', 1: '94.34%'}, Val Loss: 0.085432332, Val Accuracy: 96.89%, Val-Class-Acc: {0: '98.44%', 1: '94.49%'}, LR: 0.000100000\n",
      "Epoch 154/2000, Train Loss: 0.092102950, Train-Class-Acc: {0: '97.38%', 1: '94.74%'}, Val Loss: 0.099898155, Val Accuracy: 96.35%, Val-Class-Acc: {0: '98.62%', 1: '92.84%'}, LR: 0.000100000\n",
      "Epoch 155/2000, Train Loss: 0.102491427, Train-Class-Acc: {0: '97.19%', 1: '93.86%'}, Val Loss: 0.096123309, Val Accuracy: 96.10%, Val-Class-Acc: {0: '95.11%', 1: '97.63%'}, LR: 0.000100000\n",
      "Epoch 156/2000, Train Loss: 0.105202364, Train-Class-Acc: {0: '97.08%', 1: '93.63%'}, Val Loss: 0.166844962, Val Accuracy: 93.84%, Val-Class-Acc: {0: '90.77%', 1: '98.57%'}, LR: 0.000100000\n",
      "Epoch 157/2000, Train Loss: 0.117546290, Train-Class-Acc: {0: '96.67%', 1: '93.08%'}, Val Loss: 0.087606724, Val Accuracy: 96.90%, Val-Class-Acc: {0: '98.46%', 1: '94.50%'}, LR: 0.000100000\n",
      "Epoch 158/2000, Train Loss: 0.095012860, Train-Class-Acc: {0: '97.37%', 1: '94.37%'}, Val Loss: 0.089073400, Val Accuracy: 96.84%, Val-Class-Acc: {0: '98.66%', 1: '94.03%'}, LR: 0.000100000\n",
      "Epoch 159/2000, Train Loss: 0.087383059, Train-Class-Acc: {0: '97.52%', 1: '95.01%'}, Val Loss: 0.089779560, Val Accuracy: 96.80%, Val-Class-Acc: {0: '98.55%', 1: '94.10%'}, LR: 0.000100000\n",
      "Epoch 160/2000, Train Loss: 0.094061473, Train-Class-Acc: {0: '97.39%', 1: '94.49%'}, Val Loss: 0.082696865, Val Accuracy: 97.16%, Val-Class-Acc: {0: '97.79%', 1: '96.19%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.92%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_144.pth\n",
      "Model saved after epoch 160 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_160.pth \n",
      "\n",
      "Epoch 161/2000, Train Loss: 0.101964582, Train-Class-Acc: {0: '97.15%', 1: '93.71%'}, Val Loss: 0.108210479, Val Accuracy: 95.56%, Val-Class-Acc: {0: '93.90%', 1: '98.13%'}, LR: 0.000100000\n",
      "Epoch 162/2000, Train Loss: 0.142179153, Train-Class-Acc: {0: '96.26%', 1: '91.20%'}, Val Loss: 0.085165604, Val Accuracy: 97.14%, Val-Class-Acc: {0: '98.22%', 1: '95.48%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.93%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_151.pth\n",
      "Model saved after epoch 162 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_162.pth \n",
      "\n",
      "Epoch 163/2000, Train Loss: 0.100370973, Train-Class-Acc: {0: '97.26%', 1: '94.13%'}, Val Loss: 0.125976960, Val Accuracy: 94.96%, Val-Class-Acc: {0: '98.80%', 1: '89.04%'}, LR: 0.000100000\n",
      "Epoch 164/2000, Train Loss: 0.092658685, Train-Class-Acc: {0: '97.54%', 1: '94.49%'}, Val Loss: 0.082408442, Val Accuracy: 97.14%, Val-Class-Acc: {0: '98.00%', 1: '95.82%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.01%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_137.pth\n",
      "Model saved after epoch 164 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_164.pth \n",
      "\n",
      "Epoch 165/2000, Train Loss: 0.110854892, Train-Class-Acc: {0: '96.93%', 1: '93.42%'}, Val Loss: 0.082203817, Val Accuracy: 97.19%, Val-Class-Acc: {0: '97.99%', 1: '95.96%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.04%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_148.pth\n",
      "Model saved after epoch 165 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_165.pth \n",
      "\n",
      "Epoch 166/2000, Train Loss: 0.083121534, Train-Class-Acc: {0: '97.75%', 1: '95.19%'}, Val Loss: 0.090811996, Val Accuracy: 96.75%, Val-Class-Acc: {0: '98.65%', 1: '93.82%'}, LR: 0.000100000\n",
      "Epoch 167/2000, Train Loss: 0.090136145, Train-Class-Acc: {0: '97.48%', 1: '94.75%'}, Val Loss: 0.084177278, Val Accuracy: 97.08%, Val-Class-Acc: {0: '97.45%', 1: '96.51%'}, LR: 0.000100000\n",
      "Epoch 168/2000, Train Loss: 0.117452104, Train-Class-Acc: {0: '96.95%', 1: '92.86%'}, Val Loss: 0.112835901, Val Accuracy: 95.25%, Val-Class-Acc: {0: '93.23%', 1: '98.36%'}, LR: 0.000100000\n",
      "Epoch 169/2000, Train Loss: 0.093083075, Train-Class-Acc: {0: '97.41%', 1: '94.66%'}, Val Loss: 0.081911053, Val Accuracy: 97.29%, Val-Class-Acc: {0: '97.70%', 1: '96.66%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.14%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_150.pth\n",
      "Model saved after epoch 169 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_169.pth \n",
      "\n",
      "Epoch 170/2000, Train Loss: 0.104229951, Train-Class-Acc: {0: '97.11%', 1: '93.65%'}, Val Loss: 0.085804059, Val Accuracy: 97.00%, Val-Class-Acc: {0: '96.83%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 171/2000, Train Loss: 0.102178934, Train-Class-Acc: {0: '97.21%', 1: '93.67%'}, Val Loss: 0.125849895, Val Accuracy: 94.88%, Val-Class-Acc: {0: '92.40%', 1: '98.69%'}, LR: 0.000100000\n",
      "Epoch 172/2000, Train Loss: 0.104569858, Train-Class-Acc: {0: '97.09%', 1: '93.61%'}, Val Loss: 0.081900163, Val Accuracy: 97.31%, Val-Class-Acc: {0: '97.82%', 1: '96.53%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.14%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_162.pth\n",
      "Model saved after epoch 172 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_172.pth \n",
      "\n",
      "Epoch 173/2000, Train Loss: 0.080653354, Train-Class-Acc: {0: '97.74%', 1: '95.38%'}, Val Loss: 0.083185287, Val Accuracy: 97.23%, Val-Class-Acc: {0: '97.58%', 1: '96.69%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.14%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_164.pth\n",
      "Model saved after epoch 173 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_173.pth \n",
      "\n",
      "Epoch 174/2000, Train Loss: 0.136024187, Train-Class-Acc: {0: '96.46%', 1: '91.23%'}, Val Loss: 0.095392403, Val Accuracy: 96.36%, Val-Class-Acc: {0: '95.67%', 1: '97.43%'}, LR: 0.000100000\n",
      "Epoch 175/2000, Train Loss: 0.092751609, Train-Class-Acc: {0: '97.46%', 1: '94.58%'}, Val Loss: 0.081845084, Val Accuracy: 97.22%, Val-Class-Acc: {0: '97.40%', 1: '96.93%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.16%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_160.pth\n",
      "Model saved after epoch 175 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_175.pth \n",
      "\n",
      "Epoch 176/2000, Train Loss: 0.092089443, Train-Class-Acc: {0: '97.37%', 1: '94.54%'}, Val Loss: 0.080083367, Val Accuracy: 97.28%, Val-Class-Acc: {0: '98.01%', 1: '96.15%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.19%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_165.pth\n",
      "Model saved after epoch 176 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_176.pth \n",
      "\n",
      "Epoch 177/2000, Train Loss: 0.081422398, Train-Class-Acc: {0: '97.73%', 1: '95.21%'}, Val Loss: 0.081362037, Val Accuracy: 97.16%, Val-Class-Acc: {0: '98.13%', 1: '95.68%'}, LR: 0.000100000\n",
      "Epoch 178/2000, Train Loss: 0.099474811, Train-Class-Acc: {0: '97.19%', 1: '94.12%'}, Val Loss: 0.080316202, Val Accuracy: 97.35%, Val-Class-Acc: {0: '98.30%', 1: '95.89%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.22%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_175.pth\n",
      "Model saved after epoch 178 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_178.pth \n",
      "\n",
      "Epoch 179/2000, Train Loss: 0.077021497, Train-Class-Acc: {0: '97.92%', 1: '95.55%'}, Val Loss: 0.081496193, Val Accuracy: 97.21%, Val-Class-Acc: {0: '98.05%', 1: '95.92%'}, LR: 0.000100000\n",
      "Epoch 180/2000, Train Loss: 0.093921238, Train-Class-Acc: {0: '97.28%', 1: '94.43%'}, Val Loss: 0.097119871, Val Accuracy: 96.45%, Val-Class-Acc: {0: '98.71%', 1: '92.97%'}, LR: 0.000100000\n",
      "Epoch 181/2000, Train Loss: 0.127795367, Train-Class-Acc: {0: '96.63%', 1: '92.31%'}, Val Loss: 0.090250184, Val Accuracy: 96.66%, Val-Class-Acc: {0: '98.55%', 1: '93.76%'}, LR: 0.000100000\n",
      "Epoch 182/2000, Train Loss: 0.084432631, Train-Class-Acc: {0: '97.70%', 1: '94.92%'}, Val Loss: 0.080062425, Val Accuracy: 97.36%, Val-Class-Acc: {0: '97.75%', 1: '96.75%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.23%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_173.pth\n",
      "Model saved after epoch 182 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_182.pth \n",
      "\n",
      "Epoch 183/2000, Train Loss: 0.085907237, Train-Class-Acc: {0: '97.59%', 1: '94.87%'}, Val Loss: 0.083268624, Val Accuracy: 97.14%, Val-Class-Acc: {0: '96.91%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 184/2000, Train Loss: 0.157216140, Train-Class-Acc: {0: '95.73%', 1: '89.90%'}, Val Loss: 0.147526565, Val Accuracy: 93.70%, Val-Class-Acc: {0: '98.86%', 1: '85.76%'}, LR: 0.000100000\n",
      "Epoch 185/2000, Train Loss: 0.093935836, Train-Class-Acc: {0: '97.58%', 1: '94.37%'}, Val Loss: 0.081356511, Val Accuracy: 97.18%, Val-Class-Acc: {0: '98.16%', 1: '95.68%'}, LR: 0.000100000\n",
      "Epoch 186/2000, Train Loss: 0.087570618, Train-Class-Acc: {0: '97.57%', 1: '94.82%'}, Val Loss: 0.093437521, Val Accuracy: 96.65%, Val-Class-Acc: {0: '98.67%', 1: '93.54%'}, LR: 0.000100000\n",
      "Epoch 187/2000, Train Loss: 0.082676252, Train-Class-Acc: {0: '97.71%', 1: '95.08%'}, Val Loss: 0.080325650, Val Accuracy: 97.38%, Val-Class-Acc: {0: '97.88%', 1: '96.60%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.28%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_176.pth\n",
      "Model saved after epoch 187 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_187.pth \n",
      "\n",
      "Epoch 188/2000, Train Loss: 0.083737695, Train-Class-Acc: {0: '97.59%', 1: '95.02%'}, Val Loss: 0.087190372, Val Accuracy: 96.59%, Val-Class-Acc: {0: '95.79%', 1: '97.83%'}, LR: 0.000100000\n",
      "Epoch 189/2000, Train Loss: 0.089174391, Train-Class-Acc: {0: '97.49%', 1: '94.74%'}, Val Loss: 0.082544262, Val Accuracy: 97.18%, Val-Class-Acc: {0: '98.66%', 1: '94.91%'}, LR: 0.000100000\n",
      "Epoch 190/2000, Train Loss: 0.084513877, Train-Class-Acc: {0: '97.63%', 1: '94.91%'}, Val Loss: 0.082520209, Val Accuracy: 97.11%, Val-Class-Acc: {0: '96.90%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 191/2000, Train Loss: 0.084140786, Train-Class-Acc: {0: '97.60%', 1: '95.00%'}, Val Loss: 0.089040316, Val Accuracy: 96.61%, Val-Class-Acc: {0: '95.66%', 1: '98.07%'}, LR: 0.000100000\n",
      "Epoch 192/2000, Train Loss: 0.082132827, Train-Class-Acc: {0: '97.65%', 1: '95.13%'}, Val Loss: 0.081613275, Val Accuracy: 97.05%, Val-Class-Acc: {0: '98.31%', 1: '95.12%'}, LR: 0.000100000\n",
      "Epoch 193/2000, Train Loss: 0.083990691, Train-Class-Acc: {0: '97.61%', 1: '94.95%'}, Val Loss: 0.079464239, Val Accuracy: 97.42%, Val-Class-Acc: {0: '97.68%', 1: '97.01%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.29%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_169.pth\n",
      "Model saved after epoch 193 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_193.pth \n",
      "\n",
      "Epoch 194/2000, Train Loss: 0.090480825, Train-Class-Acc: {0: '97.40%', 1: '94.60%'}, Val Loss: 0.081896980, Val Accuracy: 97.06%, Val-Class-Acc: {0: '97.37%', 1: '96.57%'}, LR: 0.000100000\n",
      "Epoch 195/2000, Train Loss: 0.089331540, Train-Class-Acc: {0: '97.51%', 1: '94.45%'}, Val Loss: 0.102562133, Val Accuracy: 95.92%, Val-Class-Acc: {0: '94.53%', 1: '98.07%'}, LR: 0.000100000\n",
      "Epoch 196/2000, Train Loss: 0.077746520, Train-Class-Acc: {0: '97.74%', 1: '95.54%'}, Val Loss: 0.089250331, Val Accuracy: 96.70%, Val-Class-Acc: {0: '98.64%', 1: '93.72%'}, LR: 0.000100000\n",
      "Epoch 197/2000, Train Loss: 0.092400298, Train-Class-Acc: {0: '97.40%', 1: '94.42%'}, Val Loss: 0.078045340, Val Accuracy: 97.39%, Val-Class-Acc: {0: '98.13%', 1: '96.27%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.31%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_172.pth\n",
      "Model saved after epoch 197 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_197.pth \n",
      "\n",
      "Epoch 198/2000, Train Loss: 0.071794097, Train-Class-Acc: {0: '97.99%', 1: '95.84%'}, Val Loss: 0.080107822, Val Accuracy: 97.36%, Val-Class-Acc: {0: '97.57%', 1: '97.05%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.35%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_178.pth\n",
      "Model saved after epoch 198 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_198.pth \n",
      "\n",
      "Epoch 199/2000, Train Loss: 0.082429925, Train-Class-Acc: {0: '97.64%', 1: '95.15%'}, Val Loss: 0.078630536, Val Accuracy: 97.33%, Val-Class-Acc: {0: '97.50%', 1: '97.07%'}, LR: 0.000100000\n",
      "Epoch 200/2000, Train Loss: 0.113774607, Train-Class-Acc: {0: '96.91%', 1: '93.23%'}, Val Loss: 0.079961629, Val Accuracy: 97.22%, Val-Class-Acc: {0: '97.32%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 201/2000, Train Loss: 0.074715667, Train-Class-Acc: {0: '97.94%', 1: '95.58%'}, Val Loss: 0.079203639, Val Accuracy: 97.17%, Val-Class-Acc: {0: '96.92%', 1: '97.57%'}, LR: 0.000100000\n",
      "Epoch 202/2000, Train Loss: 0.083289701, Train-Class-Acc: {0: '97.60%', 1: '95.18%'}, Val Loss: 0.082387165, Val Accuracy: 97.09%, Val-Class-Acc: {0: '98.26%', 1: '95.29%'}, LR: 0.000100000\n",
      "Epoch 203/2000, Train Loss: 0.097055374, Train-Class-Acc: {0: '97.40%', 1: '94.50%'}, Val Loss: 0.078941432, Val Accuracy: 97.15%, Val-Class-Acc: {0: '98.57%', 1: '94.97%'}, LR: 0.000100000\n",
      "Epoch 204/2000, Train Loss: 0.077254074, Train-Class-Acc: {0: '97.91%', 1: '95.43%'}, Val Loss: 0.077586538, Val Accuracy: 97.46%, Val-Class-Acc: {0: '97.71%', 1: '97.07%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.36%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_182.pth\n",
      "Model saved after epoch 204 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_204.pth \n",
      "\n",
      "Epoch 205/2000, Train Loss: 0.072597054, Train-Class-Acc: {0: '97.97%', 1: '95.83%'}, Val Loss: 0.077085921, Val Accuracy: 97.45%, Val-Class-Acc: {0: '97.80%', 1: '96.92%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.36%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_198.pth\n",
      "Model saved after epoch 205 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_205.pth \n",
      "\n",
      "Epoch 206/2000, Train Loss: 0.082692934, Train-Class-Acc: {0: '97.56%', 1: '95.08%'}, Val Loss: 0.085122356, Val Accuracy: 96.90%, Val-Class-Acc: {0: '98.68%', 1: '94.16%'}, LR: 0.000100000\n",
      "Epoch 207/2000, Train Loss: 0.074408270, Train-Class-Acc: {0: '97.92%', 1: '95.63%'}, Val Loss: 0.077191912, Val Accuracy: 97.32%, Val-Class-Acc: {0: '97.92%', 1: '96.39%'}, LR: 0.000100000\n",
      "Epoch 208/2000, Train Loss: 0.098986885, Train-Class-Acc: {0: '97.13%', 1: '93.99%'}, Val Loss: 0.087122288, Val Accuracy: 96.71%, Val-Class-Acc: {0: '95.79%', 1: '98.12%'}, LR: 0.000100000\n",
      "Epoch 209/2000, Train Loss: 0.070120761, Train-Class-Acc: {0: '98.03%', 1: '96.03%'}, Val Loss: 0.079805760, Val Accuracy: 97.13%, Val-Class-Acc: {0: '98.12%', 1: '95.59%'}, LR: 0.000100000\n",
      "Epoch 210/2000, Train Loss: 0.087941425, Train-Class-Acc: {0: '97.40%', 1: '94.61%'}, Val Loss: 0.074842048, Val Accuracy: 97.57%, Val-Class-Acc: {0: '97.88%', 1: '97.09%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.38%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_187.pth\n",
      "Model saved after epoch 210 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_210.pth \n",
      "\n",
      "Epoch 211/2000, Train Loss: 0.087864855, Train-Class-Acc: {0: '97.48%', 1: '94.77%'}, Val Loss: 0.075387435, Val Accuracy: 97.44%, Val-Class-Acc: {0: '97.66%', 1: '97.10%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.39%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_197.pth\n",
      "Model saved after epoch 211 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_211.pth \n",
      "\n",
      "Epoch 212/2000, Train Loss: 0.071847550, Train-Class-Acc: {0: '97.99%', 1: '95.87%'}, Val Loss: 0.089099510, Val Accuracy: 96.78%, Val-Class-Acc: {0: '98.70%', 1: '93.84%'}, LR: 0.000100000\n",
      "Epoch 213/2000, Train Loss: 0.078005626, Train-Class-Acc: {0: '97.81%', 1: '95.37%'}, Val Loss: 0.075413652, Val Accuracy: 97.46%, Val-Class-Acc: {0: '98.19%', 1: '96.32%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.42%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_193.pth\n",
      "Model saved after epoch 213 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_213.pth \n",
      "\n",
      "Epoch 214/2000, Train Loss: 0.071657588, Train-Class-Acc: {0: '97.92%', 1: '95.85%'}, Val Loss: 0.090301155, Val Accuracy: 96.68%, Val-Class-Acc: {0: '98.72%', 1: '93.55%'}, LR: 0.000100000\n",
      "Epoch 215/2000, Train Loss: 0.071248579, Train-Class-Acc: {0: '97.97%', 1: '95.76%'}, Val Loss: 0.082721788, Val Accuracy: 97.06%, Val-Class-Acc: {0: '98.46%', 1: '94.91%'}, LR: 0.000100000\n",
      "Epoch 216/2000, Train Loss: 0.082690804, Train-Class-Acc: {0: '97.53%', 1: '95.10%'}, Val Loss: 0.094966670, Val Accuracy: 96.57%, Val-Class-Acc: {0: '98.70%', 1: '93.28%'}, LR: 0.000100000\n",
      "Epoch 217/2000, Train Loss: 0.077569698, Train-Class-Acc: {0: '97.83%', 1: '95.47%'}, Val Loss: 0.093285014, Val Accuracy: 96.47%, Val-Class-Acc: {0: '95.06%', 1: '98.64%'}, LR: 0.000100000\n",
      "Epoch 218/2000, Train Loss: 0.076374412, Train-Class-Acc: {0: '97.74%', 1: '95.45%'}, Val Loss: 0.085687591, Val Accuracy: 97.00%, Val-Class-Acc: {0: '98.59%', 1: '94.57%'}, LR: 0.000100000\n",
      "Epoch 219/2000, Train Loss: 0.093070425, Train-Class-Acc: {0: '97.24%', 1: '94.40%'}, Val Loss: 0.093225070, Val Accuracy: 96.56%, Val-Class-Acc: {0: '98.78%', 1: '93.15%'}, LR: 0.000100000\n",
      "Epoch 220/2000, Train Loss: 0.069019208, Train-Class-Acc: {0: '98.05%', 1: '95.94%'}, Val Loss: 0.074495516, Val Accuracy: 97.45%, Val-Class-Acc: {0: '97.96%', 1: '96.66%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.44%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_211.pth\n",
      "Model saved after epoch 220 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_220.pth \n",
      "\n",
      "Epoch 221/2000, Train Loss: 0.082072333, Train-Class-Acc: {0: '97.61%', 1: '95.32%'}, Val Loss: 0.083007108, Val Accuracy: 96.97%, Val-Class-Acc: {0: '98.65%', 1: '94.39%'}, LR: 0.000100000\n",
      "Epoch 222/2000, Train Loss: 0.074225707, Train-Class-Acc: {0: '97.86%', 1: '95.56%'}, Val Loss: 0.073040476, Val Accuracy: 97.59%, Val-Class-Acc: {0: '97.76%', 1: '97.32%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.45%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_220.pth\n",
      "Model saved after epoch 222 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_222.pth \n",
      "\n",
      "Epoch 223/2000, Train Loss: 0.068471380, Train-Class-Acc: {0: '98.01%', 1: '96.21%'}, Val Loss: 0.115348747, Val Accuracy: 96.04%, Val-Class-Acc: {0: '98.91%', 1: '91.61%'}, LR: 0.000100000\n",
      "Epoch 224/2000, Train Loss: 0.076019726, Train-Class-Acc: {0: '97.78%', 1: '95.49%'}, Val Loss: 0.074573532, Val Accuracy: 97.34%, Val-Class-Acc: {0: '98.23%', 1: '95.98%'}, LR: 0.000100000\n",
      "Epoch 225/2000, Train Loss: 0.086409795, Train-Class-Acc: {0: '97.45%', 1: '94.72%'}, Val Loss: 0.083981307, Val Accuracy: 96.80%, Val-Class-Acc: {0: '95.78%', 1: '98.37%'}, LR: 0.000100000\n",
      "Epoch 226/2000, Train Loss: 0.073343804, Train-Class-Acc: {0: '97.89%', 1: '95.73%'}, Val Loss: 0.073847881, Val Accuracy: 97.39%, Val-Class-Acc: {0: '97.18%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 227/2000, Train Loss: 0.069860055, Train-Class-Acc: {0: '98.03%', 1: '95.90%'}, Val Loss: 0.087984527, Val Accuracy: 96.62%, Val-Class-Acc: {0: '95.68%', 1: '98.06%'}, LR: 0.000100000\n",
      "Epoch 228/2000, Train Loss: 0.078858896, Train-Class-Acc: {0: '97.63%', 1: '95.35%'}, Val Loss: 0.082125048, Val Accuracy: 96.82%, Val-Class-Acc: {0: '95.88%', 1: '98.25%'}, LR: 0.000100000\n",
      "Epoch 229/2000, Train Loss: 0.075887780, Train-Class-Acc: {0: '97.69%', 1: '95.61%'}, Val Loss: 0.073004714, Val Accuracy: 97.39%, Val-Class-Acc: {0: '98.08%', 1: '96.35%'}, LR: 0.000100000\n",
      "Epoch 230/2000, Train Loss: 0.065942251, Train-Class-Acc: {0: '98.13%', 1: '96.11%'}, Val Loss: 0.075630226, Val Accuracy: 97.49%, Val-Class-Acc: {0: '97.54%', 1: '97.40%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.45%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_205.pth\n",
      "Model saved after epoch 230 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_230.pth \n",
      "\n",
      "Epoch 231/2000, Train Loss: 0.075399504, Train-Class-Acc: {0: '97.88%', 1: '95.66%'}, Val Loss: 0.076721148, Val Accuracy: 97.23%, Val-Class-Acc: {0: '98.01%', 1: '96.02%'}, LR: 0.000100000\n",
      "Epoch 232/2000, Train Loss: 0.071472457, Train-Class-Acc: {0: '97.83%', 1: '95.87%'}, Val Loss: 0.089358162, Val Accuracy: 96.75%, Val-Class-Acc: {0: '98.85%', 1: '93.52%'}, LR: 0.000100000\n",
      "Epoch 233/2000, Train Loss: 0.081294635, Train-Class-Acc: {0: '97.58%', 1: '95.18%'}, Val Loss: 0.074990382, Val Accuracy: 97.30%, Val-Class-Acc: {0: '98.11%', 1: '96.06%'}, LR: 0.000100000\n",
      "Epoch 234/2000, Train Loss: 0.089326938, Train-Class-Acc: {0: '97.50%', 1: '94.98%'}, Val Loss: 0.107067238, Val Accuracy: 96.05%, Val-Class-Acc: {0: '99.00%', 1: '91.52%'}, LR: 0.000100000\n",
      "Epoch 235/2000, Train Loss: 0.081522746, Train-Class-Acc: {0: '97.64%', 1: '95.03%'}, Val Loss: 0.076462407, Val Accuracy: 97.24%, Val-Class-Acc: {0: '97.80%', 1: '96.39%'}, LR: 0.000100000\n",
      "Epoch 236/2000, Train Loss: 0.069460160, Train-Class-Acc: {0: '98.03%', 1: '95.86%'}, Val Loss: 0.095843455, Val Accuracy: 96.19%, Val-Class-Acc: {0: '95.05%', 1: '97.95%'}, LR: 0.000100000\n",
      "Epoch 237/2000, Train Loss: 0.074281732, Train-Class-Acc: {0: '97.75%', 1: '95.58%'}, Val Loss: 0.070597368, Val Accuracy: 97.59%, Val-Class-Acc: {0: '97.94%', 1: '97.07%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.46%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_213.pth\n",
      "Model saved after epoch 237 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_237.pth \n",
      "\n",
      "Epoch 238/2000, Train Loss: 0.065346968, Train-Class-Acc: {0: '98.08%', 1: '96.19%'}, Val Loss: 0.077108902, Val Accuracy: 97.00%, Val-Class-Acc: {0: '97.17%', 1: '96.74%'}, LR: 0.000100000\n",
      "Epoch 239/2000, Train Loss: 0.094749180, Train-Class-Acc: {0: '97.16%', 1: '94.41%'}, Val Loss: 0.078289848, Val Accuracy: 97.12%, Val-Class-Acc: {0: '98.39%', 1: '95.16%'}, LR: 0.000100000\n",
      "Epoch 240/2000, Train Loss: 0.062262057, Train-Class-Acc: {0: '98.34%', 1: '96.32%'}, Val Loss: 0.097363607, Val Accuracy: 96.33%, Val-Class-Acc: {0: '94.90%', 1: '98.53%'}, LR: 0.000100000\n",
      "Epoch 241/2000, Train Loss: 0.074321261, Train-Class-Acc: {0: '97.69%', 1: '95.61%'}, Val Loss: 0.081611482, Val Accuracy: 97.05%, Val-Class-Acc: {0: '98.62%', 1: '94.64%'}, LR: 0.000100000\n",
      "Epoch 242/2000, Train Loss: 0.074162975, Train-Class-Acc: {0: '97.83%', 1: '95.55%'}, Val Loss: 0.073153879, Val Accuracy: 97.61%, Val-Class-Acc: {0: '97.91%', 1: '97.13%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.46%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_204.pth\n",
      "Model saved after epoch 242 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_242.pth \n",
      "\n",
      "Epoch 243/2000, Train Loss: 0.062538401, Train-Class-Acc: {0: '98.16%', 1: '96.32%'}, Val Loss: 0.080147029, Val Accuracy: 97.12%, Val-Class-Acc: {0: '98.10%', 1: '95.61%'}, LR: 0.000100000\n",
      "Epoch 244/2000, Train Loss: 0.098302598, Train-Class-Acc: {0: '97.04%', 1: '93.98%'}, Val Loss: 0.086754295, Val Accuracy: 96.55%, Val-Class-Acc: {0: '95.97%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 245/2000, Train Loss: 0.063232705, Train-Class-Acc: {0: '98.17%', 1: '96.36%'}, Val Loss: 0.075979780, Val Accuracy: 97.03%, Val-Class-Acc: {0: '96.54%', 1: '97.78%'}, LR: 0.000100000\n",
      "Epoch 246/2000, Train Loss: 0.082871227, Train-Class-Acc: {0: '97.57%', 1: '95.37%'}, Val Loss: 0.149608604, Val Accuracy: 94.74%, Val-Class-Acc: {0: '99.10%', 1: '88.04%'}, LR: 0.000100000\n",
      "Epoch 247/2000, Train Loss: 0.071848780, Train-Class-Acc: {0: '97.95%', 1: '95.72%'}, Val Loss: 0.067901610, Val Accuracy: 97.70%, Val-Class-Acc: {0: '98.01%', 1: '97.23%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.49%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_230.pth\n",
      "Model saved after epoch 247 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_247.pth \n",
      "\n",
      "Epoch 248/2000, Train Loss: 0.066443518, Train-Class-Acc: {0: '98.00%', 1: '96.08%'}, Val Loss: 0.075073836, Val Accuracy: 97.54%, Val-Class-Acc: {0: '97.99%', 1: '96.85%'}, LR: 0.000100000\n",
      "Epoch 249/2000, Train Loss: 0.065617934, Train-Class-Acc: {0: '97.99%', 1: '96.05%'}, Val Loss: 0.074322195, Val Accuracy: 97.36%, Val-Class-Acc: {0: '98.20%', 1: '96.06%'}, LR: 0.000100000\n",
      "Epoch 250/2000, Train Loss: 0.074376167, Train-Class-Acc: {0: '97.71%', 1: '95.54%'}, Val Loss: 0.071599119, Val Accuracy: 97.48%, Val-Class-Acc: {0: '97.77%', 1: '97.04%'}, LR: 0.000100000\n",
      "Epoch 251/2000, Train Loss: 0.071932328, Train-Class-Acc: {0: '97.80%', 1: '95.70%'}, Val Loss: 0.072021871, Val Accuracy: 97.34%, Val-Class-Acc: {0: '98.23%', 1: '95.97%'}, LR: 0.000100000\n",
      "Epoch 252/2000, Train Loss: 0.073864739, Train-Class-Acc: {0: '97.80%', 1: '95.65%'}, Val Loss: 0.097188815, Val Accuracy: 96.24%, Val-Class-Acc: {0: '94.86%', 1: '98.35%'}, LR: 0.000100000\n",
      "Epoch 253/2000, Train Loss: 0.071016353, Train-Class-Acc: {0: '97.94%', 1: '95.81%'}, Val Loss: 0.074113274, Val Accuracy: 97.29%, Val-Class-Acc: {0: '98.24%', 1: '95.83%'}, LR: 0.000100000\n",
      "Epoch 254/2000, Train Loss: 0.056749774, Train-Class-Acc: {0: '98.38%', 1: '96.72%'}, Val Loss: 0.070823496, Val Accuracy: 97.59%, Val-Class-Acc: {0: '98.26%', 1: '96.57%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.57%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_210.pth\n",
      "Model saved after epoch 254 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_254.pth \n",
      "\n",
      "Epoch 255/2000, Train Loss: 0.074179849, Train-Class-Acc: {0: '97.83%', 1: '95.66%'}, Val Loss: 0.111832458, Val Accuracy: 95.58%, Val-Class-Acc: {0: '94.06%', 1: '97.91%'}, LR: 0.000100000\n",
      "Epoch 256/2000, Train Loss: 0.084642423, Train-Class-Acc: {0: '97.36%', 1: '94.81%'}, Val Loss: 0.069411185, Val Accuracy: 97.59%, Val-Class-Acc: {0: '98.21%', 1: '96.65%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.59%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_222.pth\n",
      "Model saved after epoch 256 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_256.pth \n",
      "\n",
      "Epoch 257/2000, Train Loss: 0.054992386, Train-Class-Acc: {0: '98.46%', 1: '96.85%'}, Val Loss: 0.071493418, Val Accuracy: 97.58%, Val-Class-Acc: {0: '98.13%', 1: '96.73%'}, LR: 0.000100000\n",
      "Epoch 258/2000, Train Loss: 0.059088585, Train-Class-Acc: {0: '98.21%', 1: '96.55%'}, Val Loss: 0.079684658, Val Accuracy: 97.26%, Val-Class-Acc: {0: '98.31%', 1: '95.66%'}, LR: 0.000100000\n",
      "Epoch 259/2000, Train Loss: 0.057283504, Train-Class-Acc: {0: '98.27%', 1: '96.68%'}, Val Loss: 0.078256367, Val Accuracy: 97.14%, Val-Class-Acc: {0: '98.53%', 1: '95.01%'}, LR: 0.000100000\n",
      "Epoch 260/2000, Train Loss: 0.067981003, Train-Class-Acc: {0: '97.88%', 1: '96.13%'}, Val Loss: 0.083334877, Val Accuracy: 97.12%, Val-Class-Acc: {0: '98.58%', 1: '94.86%'}, LR: 0.000100000\n",
      "Epoch 261/2000, Train Loss: 0.062811775, Train-Class-Acc: {0: '98.16%', 1: '96.35%'}, Val Loss: 0.088032048, Val Accuracy: 96.98%, Val-Class-Acc: {0: '98.80%', 1: '94.19%'}, LR: 0.000100000\n",
      "Epoch 262/2000, Train Loss: 0.057679957, Train-Class-Acc: {0: '98.29%', 1: '96.61%'}, Val Loss: 0.085733535, Val Accuracy: 97.04%, Val-Class-Acc: {0: '98.87%', 1: '94.22%'}, LR: 0.000100000\n",
      "Epoch 263/2000, Train Loss: 0.064891190, Train-Class-Acc: {0: '98.02%', 1: '96.38%'}, Val Loss: 0.090950462, Val Accuracy: 96.92%, Val-Class-Acc: {0: '98.69%', 1: '94.19%'}, LR: 0.000100000\n",
      "Epoch 264/2000, Train Loss: 0.063231321, Train-Class-Acc: {0: '98.08%', 1: '96.15%'}, Val Loss: 0.082106491, Val Accuracy: 97.02%, Val-Class-Acc: {0: '98.49%', 1: '94.77%'}, LR: 0.000100000\n",
      "Epoch 265/2000, Train Loss: 0.065469820, Train-Class-Acc: {0: '97.95%', 1: '96.04%'}, Val Loss: 0.076125715, Val Accuracy: 96.96%, Val-Class-Acc: {0: '96.54%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 266/2000, Train Loss: 0.061435123, Train-Class-Acc: {0: '98.12%', 1: '96.44%'}, Val Loss: 0.078331709, Val Accuracy: 97.14%, Val-Class-Acc: {0: '98.42%', 1: '95.17%'}, LR: 0.000100000\n",
      "Epoch 267/2000, Train Loss: 0.060460087, Train-Class-Acc: {0: '98.16%', 1: '96.45%'}, Val Loss: 0.097071394, Val Accuracy: 96.74%, Val-Class-Acc: {0: '98.56%', 1: '93.94%'}, LR: 0.000100000\n",
      "Epoch 268/2000, Train Loss: 0.069261314, Train-Class-Acc: {0: '97.84%', 1: '95.81%'}, Val Loss: 0.068732115, Val Accuracy: 97.59%, Val-Class-Acc: {0: '98.47%', 1: '96.25%'}, LR: 0.000100000\n",
      "Epoch 269/2000, Train Loss: 0.061728967, Train-Class-Acc: {0: '98.13%', 1: '96.27%'}, Val Loss: 0.079052230, Val Accuracy: 97.21%, Val-Class-Acc: {0: '98.44%', 1: '95.33%'}, LR: 0.000100000\n",
      "Epoch 270/2000, Train Loss: 0.051583060, Train-Class-Acc: {0: '98.50%', 1: '96.97%'}, Val Loss: 0.087219015, Val Accuracy: 97.11%, Val-Class-Acc: {0: '98.82%', 1: '94.48%'}, LR: 0.000100000\n",
      "Epoch 271/2000, Train Loss: 0.062709887, Train-Class-Acc: {0: '98.07%', 1: '96.19%'}, Val Loss: 0.074211188, Val Accuracy: 97.01%, Val-Class-Acc: {0: '96.67%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 272/2000, Train Loss: 0.059633317, Train-Class-Acc: {0: '98.13%', 1: '96.52%'}, Val Loss: 0.072828933, Val Accuracy: 97.36%, Val-Class-Acc: {0: '98.41%', 1: '95.74%'}, LR: 0.000100000\n",
      "Epoch 273/2000, Train Loss: 0.058680978, Train-Class-Acc: {0: '98.17%', 1: '96.48%'}, Val Loss: 0.073382226, Val Accuracy: 97.40%, Val-Class-Acc: {0: '98.31%', 1: '95.99%'}, LR: 0.000100000\n",
      "Epoch 274/2000, Train Loss: 0.078100999, Train-Class-Acc: {0: '97.52%', 1: '95.46%'}, Val Loss: 0.080764857, Val Accuracy: 97.22%, Val-Class-Acc: {0: '98.48%', 1: '95.29%'}, LR: 0.000100000\n",
      "Epoch 275/2000, Train Loss: 0.053848589, Train-Class-Acc: {0: '98.50%', 1: '96.73%'}, Val Loss: 0.075117589, Val Accuracy: 96.95%, Val-Class-Acc: {0: '96.37%', 1: '97.84%'}, LR: 0.000100000\n",
      "Epoch 276/2000, Train Loss: 0.062659903, Train-Class-Acc: {0: '98.07%', 1: '96.43%'}, Val Loss: 0.070909732, Val Accuracy: 97.64%, Val-Class-Acc: {0: '97.90%', 1: '97.24%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.59%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_254.pth\n",
      "Model saved after epoch 276 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_276.pth \n",
      "\n",
      "Epoch 277/2000, Train Loss: 0.054321574, Train-Class-Acc: {0: '98.46%', 1: '96.79%'}, Val Loss: 0.069403290, Val Accuracy: 97.54%, Val-Class-Acc: {0: '98.23%', 1: '96.49%'}, LR: 0.000100000\n",
      "Epoch 278/2000, Train Loss: 0.072126115, Train-Class-Acc: {0: '97.78%', 1: '95.80%'}, Val Loss: 0.073829020, Val Accuracy: 97.63%, Val-Class-Acc: {0: '98.17%', 1: '96.79%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.59%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_256.pth\n",
      "Model saved after epoch 278 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_278.pth \n",
      "\n",
      "Epoch 279/2000, Train Loss: 0.050326067, Train-Class-Acc: {0: '98.57%', 1: '97.10%'}, Val Loss: 0.072727310, Val Accuracy: 97.61%, Val-Class-Acc: {0: '98.17%', 1: '96.76%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.59%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_237.pth\n",
      "Model saved after epoch 279 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_279.pth \n",
      "\n",
      "Epoch 280/2000, Train Loss: 0.046347915, Train-Class-Acc: {0: '98.65%', 1: '97.37%'}, Val Loss: 0.076182604, Val Accuracy: 97.28%, Val-Class-Acc: {0: '98.44%', 1: '95.49%'}, LR: 0.000100000\n",
      "Epoch 281/2000, Train Loss: 0.064056738, Train-Class-Acc: {0: '98.10%', 1: '96.34%'}, Val Loss: 0.072326831, Val Accuracy: 97.42%, Val-Class-Acc: {0: '98.33%', 1: '96.03%'}, LR: 0.000100000\n",
      "Epoch 282/2000, Train Loss: 0.071043549, Train-Class-Acc: {0: '97.80%', 1: '95.97%'}, Val Loss: 0.076028522, Val Accuracy: 97.26%, Val-Class-Acc: {0: '98.47%', 1: '95.40%'}, LR: 0.000100000\n",
      "Epoch 283/2000, Train Loss: 0.054291177, Train-Class-Acc: {0: '98.39%', 1: '96.68%'}, Val Loss: 0.071651092, Val Accuracy: 97.74%, Val-Class-Acc: {0: '97.91%', 1: '97.48%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_242.pth\n",
      "Model saved after epoch 283 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_283.pth \n",
      "\n",
      "Epoch 284/2000, Train Loss: 0.050050016, Train-Class-Acc: {0: '98.49%', 1: '97.06%'}, Val Loss: 0.070478381, Val Accuracy: 97.41%, Val-Class-Acc: {0: '97.28%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 285/2000, Train Loss: 0.076787354, Train-Class-Acc: {0: '97.58%', 1: '95.68%'}, Val Loss: 0.109272137, Val Accuracy: 95.91%, Val-Class-Acc: {0: '94.48%', 1: '98.12%'}, LR: 0.000100000\n",
      "Epoch 286/2000, Train Loss: 0.066755770, Train-Class-Acc: {0: '98.00%', 1: '96.03%'}, Val Loss: 0.080594260, Val Accuracy: 97.37%, Val-Class-Acc: {0: '98.30%', 1: '95.94%'}, LR: 0.000100000\n",
      "Epoch 287/2000, Train Loss: 0.052323498, Train-Class-Acc: {0: '98.43%', 1: '96.84%'}, Val Loss: 0.123288670, Val Accuracy: 95.77%, Val-Class-Acc: {0: '93.59%', 1: '99.13%'}, LR: 0.000100000\n",
      "Epoch 288/2000, Train Loss: 0.076234617, Train-Class-Acc: {0: '97.54%', 1: '95.59%'}, Val Loss: 0.076665483, Val Accuracy: 97.49%, Val-Class-Acc: {0: '98.21%', 1: '96.37%'}, LR: 0.000100000\n",
      "Epoch 289/2000, Train Loss: 0.049040060, Train-Class-Acc: {0: '98.59%', 1: '97.14%'}, Val Loss: 0.071496485, Val Accuracy: 97.62%, Val-Class-Acc: {0: '97.69%', 1: '97.52%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_279.pth\n",
      "Model saved after epoch 289 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_289.pth \n",
      "\n",
      "Epoch 290/2000, Train Loss: 0.056414172, Train-Class-Acc: {0: '98.25%', 1: '96.61%'}, Val Loss: 0.071852388, Val Accuracy: 97.69%, Val-Class-Acc: {0: '97.91%', 1: '97.35%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.62%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_289.pth\n",
      "Model saved after epoch 290 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_290.pth \n",
      "\n",
      "Epoch 291/2000, Train Loss: 0.075062439, Train-Class-Acc: {0: '97.54%', 1: '95.66%'}, Val Loss: 0.113676961, Val Accuracy: 96.04%, Val-Class-Acc: {0: '99.06%', 1: '91.40%'}, LR: 0.000100000\n",
      "Epoch 292/2000, Train Loss: 0.053912143, Train-Class-Acc: {0: '98.53%', 1: '96.69%'}, Val Loss: 0.070838597, Val Accuracy: 97.54%, Val-Class-Acc: {0: '97.42%', 1: '97.72%'}, LR: 0.000100000\n",
      "Epoch 293/2000, Train Loss: 0.047273554, Train-Class-Acc: {0: '98.56%', 1: '97.28%'}, Val Loss: 0.068917226, Val Accuracy: 97.68%, Val-Class-Acc: {0: '97.85%', 1: '97.42%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.63%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_278.pth\n",
      "Model saved after epoch 293 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_293.pth \n",
      "\n",
      "Epoch 294/2000, Train Loss: 0.063343934, Train-Class-Acc: {0: '98.00%', 1: '96.20%'}, Val Loss: 0.080388888, Val Accuracy: 96.88%, Val-Class-Acc: {0: '95.90%', 1: '98.40%'}, LR: 0.000100000\n",
      "Epoch 295/2000, Train Loss: 0.058037614, Train-Class-Acc: {0: '98.08%', 1: '96.57%'}, Val Loss: 0.084803246, Val Accuracy: 97.09%, Val-Class-Acc: {0: '98.78%', 1: '94.49%'}, LR: 0.000100000\n",
      "Epoch 296/2000, Train Loss: 0.064255467, Train-Class-Acc: {0: '98.03%', 1: '96.10%'}, Val Loss: 0.083724734, Val Accuracy: 97.43%, Val-Class-Acc: {0: '97.64%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 297/2000, Train Loss: 0.045163444, Train-Class-Acc: {0: '98.73%', 1: '97.33%'}, Val Loss: 0.082872940, Val Accuracy: 96.94%, Val-Class-Acc: {0: '95.82%', 1: '98.66%'}, LR: 0.000100000\n",
      "Epoch 298/2000, Train Loss: 0.052169793, Train-Class-Acc: {0: '98.29%', 1: '97.05%'}, Val Loss: 0.071830636, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.23%', 1: '97.10%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.64%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_276.pth\n",
      "Model saved after epoch 298 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_298.pth \n",
      "\n",
      "Epoch 299/2000, Train Loss: 0.050481985, Train-Class-Acc: {0: '98.45%', 1: '96.97%'}, Val Loss: 0.070554967, Val Accuracy: 97.37%, Val-Class-Acc: {0: '96.85%', 1: '98.16%'}, LR: 0.000100000\n",
      "Epoch 300/2000, Train Loss: 0.055143493, Train-Class-Acc: {0: '98.27%', 1: '97.02%'}, Val Loss: 0.130136388, Val Accuracy: 95.95%, Val-Class-Acc: {0: '99.17%', 1: '90.99%'}, LR: 0.000100000\n",
      "Epoch 301/2000, Train Loss: 0.052462567, Train-Class-Acc: {0: '98.47%', 1: '96.83%'}, Val Loss: 0.078943854, Val Accuracy: 97.27%, Val-Class-Acc: {0: '98.40%', 1: '95.55%'}, LR: 0.000100000\n",
      "Epoch 302/2000, Train Loss: 0.056019946, Train-Class-Acc: {0: '98.25%', 1: '96.66%'}, Val Loss: 0.071318424, Val Accuracy: 97.25%, Val-Class-Acc: {0: '97.00%', 1: '97.63%'}, LR: 0.000100000\n",
      "Epoch 303/2000, Train Loss: 0.050837431, Train-Class-Acc: {0: '98.42%', 1: '97.02%'}, Val Loss: 0.080104333, Val Accuracy: 97.34%, Val-Class-Acc: {0: '98.63%', 1: '95.36%'}, LR: 0.000100000\n",
      "Epoch 304/2000, Train Loss: 0.051957942, Train-Class-Acc: {0: '98.52%', 1: '96.95%'}, Val Loss: 0.067593465, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.03%', 1: '97.76%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.68%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_293.pth\n",
      "Model saved after epoch 304 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_304.pth \n",
      "\n",
      "Epoch 305/2000, Train Loss: 0.046854766, Train-Class-Acc: {0: '98.59%', 1: '97.29%'}, Val Loss: 0.070838367, Val Accuracy: 97.85%, Val-Class-Acc: {0: '97.93%', 1: '97.74%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.69%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_290.pth\n",
      "Model saved after epoch 305 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_305.pth \n",
      "\n",
      "Epoch 306/2000, Train Loss: 0.058030982, Train-Class-Acc: {0: '98.17%', 1: '96.69%'}, Val Loss: 0.087712556, Val Accuracy: 97.07%, Val-Class-Acc: {0: '98.90%', 1: '94.25%'}, LR: 0.000100000\n",
      "Epoch 307/2000, Train Loss: 0.056215559, Train-Class-Acc: {0: '98.30%', 1: '96.68%'}, Val Loss: 0.073571213, Val Accuracy: 97.62%, Val-Class-Acc: {0: '98.34%', 1: '96.50%'}, LR: 0.000100000\n",
      "Epoch 308/2000, Train Loss: 0.042761255, Train-Class-Acc: {0: '98.75%', 1: '97.52%'}, Val Loss: 0.078123429, Val Accuracy: 97.23%, Val-Class-Acc: {0: '98.47%', 1: '95.32%'}, LR: 0.000100000\n",
      "Epoch 309/2000, Train Loss: 0.046951049, Train-Class-Acc: {0: '98.55%', 1: '97.19%'}, Val Loss: 0.071609428, Val Accuracy: 97.36%, Val-Class-Acc: {0: '96.92%', 1: '98.05%'}, LR: 0.000100000\n",
      "Epoch 310/2000, Train Loss: 0.070476988, Train-Class-Acc: {0: '97.65%', 1: '95.80%'}, Val Loss: 0.078104698, Val Accuracy: 97.40%, Val-Class-Acc: {0: '97.14%', 1: '97.81%'}, LR: 0.000100000\n",
      "Epoch 311/2000, Train Loss: 0.058109318, Train-Class-Acc: {0: '98.17%', 1: '96.45%'}, Val Loss: 0.073172748, Val Accuracy: 97.43%, Val-Class-Acc: {0: '97.15%', 1: '97.85%'}, LR: 0.000100000\n",
      "Epoch 312/2000, Train Loss: 0.045902606, Train-Class-Acc: {0: '98.61%', 1: '97.27%'}, Val Loss: 0.092646484, Val Accuracy: 96.70%, Val-Class-Acc: {0: '95.33%', 1: '98.81%'}, LR: 0.000100000\n",
      "Epoch 313/2000, Train Loss: 0.051482468, Train-Class-Acc: {0: '98.36%', 1: '97.04%'}, Val Loss: 0.071461305, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.10%', 1: '97.48%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.70%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_247.pth\n",
      "Model saved after epoch 313 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_313.pth \n",
      "\n",
      "Epoch 314/2000, Train Loss: 0.051931484, Train-Class-Acc: {0: '98.35%', 1: '96.91%'}, Val Loss: 0.075847607, Val Accuracy: 97.56%, Val-Class-Acc: {0: '98.37%', 1: '96.30%'}, LR: 0.000100000\n",
      "Epoch 315/2000, Train Loss: 0.061321641, Train-Class-Acc: {0: '98.01%', 1: '96.31%'}, Val Loss: 0.067531422, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.30%', 1: '97.28%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.74%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_283.pth\n",
      "Model saved after epoch 315 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_315.pth \n",
      "\n",
      "Epoch 316/2000, Train Loss: 0.041170189, Train-Class-Acc: {0: '98.84%', 1: '97.63%'}, Val Loss: 0.071285839, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.37%', 1: '96.76%'}, LR: 0.000100000\n",
      "Epoch 317/2000, Train Loss: 0.058762235, Train-Class-Acc: {0: '98.16%', 1: '96.53%'}, Val Loss: 0.074954141, Val Accuracy: 97.05%, Val-Class-Acc: {0: '96.27%', 1: '98.25%'}, LR: 0.000100000\n",
      "Epoch 318/2000, Train Loss: 0.042511957, Train-Class-Acc: {0: '98.76%', 1: '97.55%'}, Val Loss: 0.069045641, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.36%', 1: '97.17%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.79%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_298.pth\n",
      "Model saved after epoch 318 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_318.pth \n",
      "\n",
      "Epoch 319/2000, Train Loss: 0.061966895, Train-Class-Acc: {0: '98.11%', 1: '96.51%'}, Val Loss: 0.070341905, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.26%', 1: '97.32%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.85%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_305.pth\n",
      "Model saved after epoch 319 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_319.pth \n",
      "\n",
      "Epoch 320/2000, Train Loss: 0.047502576, Train-Class-Acc: {0: '98.53%', 1: '97.17%'}, Val Loss: 0.070652261, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.27%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 321/2000, Train Loss: 0.055884029, Train-Class-Acc: {0: '98.17%', 1: '96.69%'}, Val Loss: 0.081286371, Val Accuracy: 97.43%, Val-Class-Acc: {0: '98.36%', 1: '95.98%'}, LR: 0.000100000\n",
      "Epoch 322/2000, Train Loss: 0.039023377, Train-Class-Acc: {0: '98.93%', 1: '97.73%'}, Val Loss: 0.075571806, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.34%', 1: '96.83%'}, LR: 0.000100000\n",
      "Epoch 323/2000, Train Loss: 0.067637702, Train-Class-Acc: {0: '97.90%', 1: '96.16%'}, Val Loss: 0.090190519, Val Accuracy: 96.95%, Val-Class-Acc: {0: '95.61%', 1: '99.01%'}, LR: 0.000100000\n",
      "Epoch 324/2000, Train Loss: 0.050270636, Train-Class-Acc: {0: '98.46%', 1: '97.03%'}, Val Loss: 0.070434545, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.22%', 1: '97.40%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.85%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_313.pth\n",
      "Model saved after epoch 324 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_324.pth \n",
      "\n",
      "Epoch 325/2000, Train Loss: 0.052639097, Train-Class-Acc: {0: '98.32%', 1: '96.89%'}, Val Loss: 0.072400464, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.35%', 1: '96.91%'}, LR: 0.000100000\n",
      "Epoch 326/2000, Train Loss: 0.057929007, Train-Class-Acc: {0: '98.16%', 1: '96.67%'}, Val Loss: 0.071637930, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.05%', 1: '97.74%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.89%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_319.pth\n",
      "Model saved after epoch 326 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_326.pth \n",
      "\n",
      "Epoch 327/2000, Train Loss: 0.040151183, Train-Class-Acc: {0: '98.86%', 1: '97.68%'}, Val Loss: 0.083271550, Val Accuracy: 97.18%, Val-Class-Acc: {0: '98.57%', 1: '95.05%'}, LR: 0.000100000\n",
      "Epoch 328/2000, Train Loss: 0.046254825, Train-Class-Acc: {0: '98.55%', 1: '97.30%'}, Val Loss: 0.076729414, Val Accuracy: 97.43%, Val-Class-Acc: {0: '98.50%', 1: '95.79%'}, LR: 0.000100000\n",
      "Epoch 329/2000, Train Loss: 0.091143095, Train-Class-Acc: {0: '97.47%', 1: '95.27%'}, Val Loss: 0.077963054, Val Accuracy: 97.28%, Val-Class-Acc: {0: '96.94%', 1: '97.81%'}, LR: 0.000100000\n",
      "Epoch 330/2000, Train Loss: 0.044844652, Train-Class-Acc: {0: '98.80%', 1: '97.41%'}, Val Loss: 0.085108444, Val Accuracy: 97.25%, Val-Class-Acc: {0: '98.50%', 1: '95.33%'}, LR: 0.000100000\n",
      "Epoch 331/2000, Train Loss: 0.050585202, Train-Class-Acc: {0: '98.42%', 1: '96.93%'}, Val Loss: 0.074985784, Val Accuracy: 97.30%, Val-Class-Acc: {0: '96.79%', 1: '98.10%'}, LR: 0.000100000\n",
      "Epoch 332/2000, Train Loss: 0.040229141, Train-Class-Acc: {0: '98.83%', 1: '97.71%'}, Val Loss: 0.076565013, Val Accuracy: 97.64%, Val-Class-Acc: {0: '98.38%', 1: '96.51%'}, LR: 0.000100000\n",
      "Epoch 333/2000, Train Loss: 0.053411089, Train-Class-Acc: {0: '98.28%', 1: '96.94%'}, Val Loss: 0.087578537, Val Accuracy: 97.15%, Val-Class-Acc: {0: '98.84%', 1: '94.56%'}, LR: 0.000100000\n",
      "Epoch 334/2000, Train Loss: 0.045563811, Train-Class-Acc: {0: '98.63%', 1: '97.23%'}, Val Loss: 0.071787738, Val Accuracy: 98.00%, Val-Class-Acc: {0: '97.87%', 1: '98.20%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.89%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_318.pth\n",
      "Model saved after epoch 334 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_334.pth \n",
      "\n",
      "Epoch 335/2000, Train Loss: 0.049111122, Train-Class-Acc: {0: '98.41%', 1: '97.14%'}, Val Loss: 0.071369350, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.35%', 1: '96.99%'}, LR: 0.000100000\n",
      "Epoch 336/2000, Train Loss: 0.041521470, Train-Class-Acc: {0: '98.74%', 1: '97.57%'}, Val Loss: 0.070909738, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.36%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 337/2000, Train Loss: 0.041638739, Train-Class-Acc: {0: '98.75%', 1: '97.59%'}, Val Loss: 0.067824495, Val Accuracy: 98.05%, Val-Class-Acc: {0: '97.94%', 1: '98.22%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.90%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_315.pth\n",
      "Model saved after epoch 337 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_337.pth \n",
      "\n",
      "Epoch 338/2000, Train Loss: 0.073314601, Train-Class-Acc: {0: '97.62%', 1: '95.74%'}, Val Loss: 0.070369284, Val Accuracy: 97.91%, Val-Class-Acc: {0: '97.94%', 1: '97.86%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.90%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_324.pth\n",
      "Model saved after epoch 338 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_338.pth \n",
      "\n",
      "Epoch 339/2000, Train Loss: 0.040581964, Train-Class-Acc: {0: '98.91%', 1: '97.67%'}, Val Loss: 0.068887289, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.28%', 1: '97.58%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.91%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_338.pth\n",
      "Model saved after epoch 339 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_339.pth \n",
      "\n",
      "Epoch 340/2000, Train Loss: 0.047682608, Train-Class-Acc: {0: '98.47%', 1: '97.23%'}, Val Loss: 0.068044087, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.08%', 1: '97.98%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.93%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_304.pth\n",
      "Model saved after epoch 340 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_340.pth \n",
      "\n",
      "Epoch 341/2000, Train Loss: 0.040797953, Train-Class-Acc: {0: '98.72%', 1: '97.62%'}, Val Loss: 0.088134698, Val Accuracy: 97.18%, Val-Class-Acc: {0: '98.78%', 1: '94.73%'}, LR: 0.000100000\n",
      "Epoch 342/2000, Train Loss: 0.046352339, Train-Class-Acc: {0: '98.54%', 1: '97.21%'}, Val Loss: 0.070535696, Val Accuracy: 98.01%, Val-Class-Acc: {0: '97.70%', 1: '98.48%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.93%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_326.pth\n",
      "Model saved after epoch 342 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_342.pth \n",
      "\n",
      "Epoch 343/2000, Train Loss: 0.046044867, Train-Class-Acc: {0: '98.54%', 1: '97.27%'}, Val Loss: 0.076552966, Val Accuracy: 97.35%, Val-Class-Acc: {0: '96.36%', 1: '98.87%'}, LR: 0.000100000\n",
      "Epoch 344/2000, Train Loss: 0.044811546, Train-Class-Acc: {0: '98.62%', 1: '97.40%'}, Val Loss: 0.076477499, Val Accuracy: 97.35%, Val-Class-Acc: {0: '96.32%', 1: '98.92%'}, LR: 0.000100000\n",
      "Epoch 345/2000, Train Loss: 0.042153275, Train-Class-Acc: {0: '98.70%', 1: '97.56%'}, Val Loss: 0.075261175, Val Accuracy: 97.44%, Val-Class-Acc: {0: '96.55%', 1: '98.80%'}, LR: 0.000100000\n",
      "Epoch 346/2000, Train Loss: 0.063115374, Train-Class-Acc: {0: '98.06%', 1: '96.60%'}, Val Loss: 0.073424124, Val Accuracy: 97.85%, Val-Class-Acc: {0: '97.66%', 1: '98.14%'}, LR: 0.000100000\n",
      "Epoch 347/2000, Train Loss: 0.043777773, Train-Class-Acc: {0: '98.73%', 1: '97.36%'}, Val Loss: 0.071729094, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.32%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 348/2000, Train Loss: 0.034621692, Train-Class-Acc: {0: '99.04%', 1: '98.03%'}, Val Loss: 0.068551147, Val Accuracy: 98.05%, Val-Class-Acc: {0: '98.23%', 1: '97.77%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.00%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_334.pth\n",
      "Model saved after epoch 348 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_348.pth \n",
      "\n",
      "Epoch 349/2000, Train Loss: 0.059812165, Train-Class-Acc: {0: '98.00%', 1: '96.60%'}, Val Loss: 0.097747713, Val Accuracy: 96.96%, Val-Class-Acc: {0: '98.96%', 1: '93.90%'}, LR: 0.000100000\n",
      "Epoch 350/2000, Train Loss: 0.057847686, Train-Class-Acc: {0: '98.18%', 1: '96.36%'}, Val Loss: 0.072003780, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.23%', 1: '97.60%'}, LR: 0.000100000\n",
      "Epoch 351/2000, Train Loss: 0.048961836, Train-Class-Acc: {0: '98.43%', 1: '97.05%'}, Val Loss: 0.077702439, Val Accuracy: 97.53%, Val-Class-Acc: {0: '98.53%', 1: '96.00%'}, LR: 0.000100000\n",
      "Epoch 352/2000, Train Loss: 0.049093439, Train-Class-Acc: {0: '98.49%', 1: '97.02%'}, Val Loss: 0.070127224, Val Accuracy: 97.99%, Val-Class-Acc: {0: '97.78%', 1: '98.32%'}, LR: 0.000100000\n",
      "Epoch 353/2000, Train Loss: 0.052242578, Train-Class-Acc: {0: '98.35%', 1: '96.93%'}, Val Loss: 0.070111169, Val Accuracy: 97.96%, Val-Class-Acc: {0: '97.82%', 1: '98.19%'}, LR: 0.000100000\n",
      "Epoch 354/2000, Train Loss: 0.038228946, Train-Class-Acc: {0: '98.88%', 1: '97.87%'}, Val Loss: 0.074730238, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.27%', 1: '97.14%'}, LR: 0.000100000\n",
      "Epoch 355/2000, Train Loss: 0.041617098, Train-Class-Acc: {0: '98.68%', 1: '97.52%'}, Val Loss: 0.088140420, Val Accuracy: 97.29%, Val-Class-Acc: {0: '98.75%', 1: '95.04%'}, LR: 0.000100000\n",
      "Epoch 356/2000, Train Loss: 0.047550488, Train-Class-Acc: {0: '98.46%', 1: '97.08%'}, Val Loss: 0.094947787, Val Accuracy: 96.80%, Val-Class-Acc: {0: '95.34%', 1: '99.05%'}, LR: 0.000100000\n",
      "Epoch 357/2000, Train Loss: 0.044809690, Train-Class-Acc: {0: '98.62%', 1: '97.49%'}, Val Loss: 0.071795397, Val Accuracy: 98.06%, Val-Class-Acc: {0: '97.81%', 1: '98.44%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.00%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_339.pth\n",
      "Model saved after epoch 357 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_357.pth \n",
      "\n",
      "Epoch 358/2000, Train Loss: 0.040102815, Train-Class-Acc: {0: '98.78%', 1: '97.60%'}, Val Loss: 0.087240643, Val Accuracy: 97.33%, Val-Class-Acc: {0: '98.15%', 1: '96.06%'}, LR: 0.000100000\n",
      "Epoch 359/2000, Train Loss: 0.044244679, Train-Class-Acc: {0: '98.60%', 1: '97.36%'}, Val Loss: 0.072060371, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.32%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 360/2000, Train Loss: 0.034467037, Train-Class-Acc: {0: '98.99%', 1: '98.05%'}, Val Loss: 0.069347737, Val Accuracy: 98.08%, Val-Class-Acc: {0: '97.85%', 1: '98.44%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.01%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_342.pth\n",
      "Model saved after epoch 360 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_360.pth \n",
      "\n",
      "Epoch 361/2000, Train Loss: 0.036565764, Train-Class-Acc: {0: '98.90%', 1: '97.90%'}, Val Loss: 0.068558644, Val Accuracy: 98.13%, Val-Class-Acc: {0: '97.96%', 1: '98.39%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.04%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_340.pth\n",
      "Model saved after epoch 361 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_361.pth \n",
      "\n",
      "Epoch 362/2000, Train Loss: 0.055864717, Train-Class-Acc: {0: '98.32%', 1: '97.02%'}, Val Loss: 0.067880056, Val Accuracy: 98.14%, Val-Class-Acc: {0: '97.95%', 1: '98.44%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.05%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_348.pth\n",
      "Model saved after epoch 362 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_362.pth \n",
      "\n",
      "Epoch 363/2000, Train Loss: 0.048920596, Train-Class-Acc: {0: '98.44%', 1: '97.19%'}, Val Loss: 0.088968797, Val Accuracy: 97.48%, Val-Class-Acc: {0: '98.00%', 1: '96.67%'}, LR: 0.000100000\n",
      "Epoch 364/2000, Train Loss: 0.066057960, Train-Class-Acc: {0: '97.83%', 1: '96.09%'}, Val Loss: 0.075346291, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.36%', 1: '96.76%'}, LR: 0.000100000\n",
      "Epoch 365/2000, Train Loss: 0.034703806, Train-Class-Acc: {0: '99.09%', 1: '98.08%'}, Val Loss: 0.090185722, Val Accuracy: 97.24%, Val-Class-Acc: {0: '98.81%', 1: '94.84%'}, LR: 0.000100000\n",
      "Epoch 366/2000, Train Loss: 0.050156639, Train-Class-Acc: {0: '98.48%', 1: '97.11%'}, Val Loss: 0.076051360, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.49%', 1: '96.57%'}, LR: 0.000100000\n",
      "Epoch 367/2000, Train Loss: 0.048964951, Train-Class-Acc: {0: '98.48%', 1: '97.15%'}, Val Loss: 0.068003053, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.03%', 1: '98.25%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.05%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_337.pth\n",
      "Model saved after epoch 367 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_367.pth \n",
      "\n",
      "Epoch 368/2000, Train Loss: 0.039471138, Train-Class-Acc: {0: '98.75%', 1: '97.72%'}, Val Loss: 0.071197117, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.28%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 369/2000, Train Loss: 0.034785553, Train-Class-Acc: {0: '98.96%', 1: '97.99%'}, Val Loss: 0.069911342, Val Accuracy: 98.08%, Val-Class-Acc: {0: '98.17%', 1: '97.94%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.06%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_357.pth\n",
      "Model saved after epoch 369 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_369.pth \n",
      "\n",
      "Epoch 370/2000, Train Loss: 0.066721560, Train-Class-Acc: {0: '98.15%', 1: '96.68%'}, Val Loss: 0.114428870, Val Accuracy: 96.14%, Val-Class-Acc: {0: '94.61%', 1: '98.50%'}, LR: 0.000100000\n",
      "Epoch 371/2000, Train Loss: 0.047958652, Train-Class-Acc: {0: '98.46%', 1: '97.12%'}, Val Loss: 0.090534896, Val Accuracy: 97.06%, Val-Class-Acc: {0: '98.61%', 1: '94.68%'}, LR: 0.000100000\n",
      "Epoch 372/2000, Train Loss: 0.038222588, Train-Class-Acc: {0: '98.85%', 1: '97.77%'}, Val Loss: 0.110660278, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.08%', 1: '93.63%'}, LR: 0.000100000\n",
      "Epoch 373/2000, Train Loss: 0.047107611, Train-Class-Acc: {0: '98.54%', 1: '97.21%'}, Val Loss: 0.083201340, Val Accuracy: 97.44%, Val-Class-Acc: {0: '98.63%', 1: '95.60%'}, LR: 0.000100000\n",
      "Epoch 374/2000, Train Loss: 0.048564518, Train-Class-Acc: {0: '98.45%', 1: '97.07%'}, Val Loss: 0.079439170, Val Accuracy: 97.54%, Val-Class-Acc: {0: '98.72%', 1: '95.73%'}, LR: 0.000100000\n",
      "Epoch 375/2000, Train Loss: 0.036022102, Train-Class-Acc: {0: '98.94%', 1: '97.91%'}, Val Loss: 0.069697198, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.27%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 376/2000, Train Loss: 0.031904949, Train-Class-Acc: {0: '99.05%', 1: '98.24%'}, Val Loss: 0.072954860, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.29%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 377/2000, Train Loss: 0.038768279, Train-Class-Acc: {0: '98.78%', 1: '97.83%'}, Val Loss: 0.077363022, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.56%', 1: '96.72%'}, LR: 0.000100000\n",
      "Epoch 378/2000, Train Loss: 0.042341381, Train-Class-Acc: {0: '98.69%', 1: '97.51%'}, Val Loss: 0.073392520, Val Accuracy: 97.86%, Val-Class-Acc: {0: '97.39%', 1: '98.57%'}, LR: 0.000100000\n",
      "Epoch 379/2000, Train Loss: 0.035325294, Train-Class-Acc: {0: '98.93%', 1: '98.00%'}, Val Loss: 0.077699637, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.28%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 380/2000, Train Loss: 0.042322800, Train-Class-Acc: {0: '98.64%', 1: '97.52%'}, Val Loss: 0.082313389, Val Accuracy: 97.56%, Val-Class-Acc: {0: '98.60%', 1: '95.95%'}, LR: 0.000100000\n",
      "Epoch 381/2000, Train Loss: 0.034407583, Train-Class-Acc: {0: '98.97%', 1: '98.00%'}, Val Loss: 0.070674688, Val Accuracy: 98.09%, Val-Class-Acc: {0: '97.83%', 1: '98.50%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.08%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_369.pth\n",
      "Model saved after epoch 381 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_381.pth \n",
      "\n",
      "Epoch 382/2000, Train Loss: 0.041073254, Train-Class-Acc: {0: '98.77%', 1: '97.74%'}, Val Loss: 0.069398694, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.03%', 1: '98.37%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.08%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_360.pth\n",
      "Model saved after epoch 382 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_382.pth \n",
      "\n",
      "Epoch 383/2000, Train Loss: 0.041225491, Train-Class-Acc: {0: '98.71%', 1: '97.69%'}, Val Loss: 0.100851290, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.00%', 1: '94.40%'}, LR: 0.000100000\n",
      "Epoch 384/2000, Train Loss: 0.058078962, Train-Class-Acc: {0: '98.15%', 1: '96.67%'}, Val Loss: 0.091648060, Val Accuracy: 97.21%, Val-Class-Acc: {0: '98.90%', 1: '94.61%'}, LR: 0.000100000\n",
      "Epoch 385/2000, Train Loss: 0.043336858, Train-Class-Acc: {0: '98.62%', 1: '97.45%'}, Val Loss: 0.095739524, Val Accuracy: 97.16%, Val-Class-Acc: {0: '98.83%', 1: '94.59%'}, LR: 0.000100000\n",
      "Epoch 386/2000, Train Loss: 0.041027853, Train-Class-Acc: {0: '98.76%', 1: '97.53%'}, Val Loss: 0.083480302, Val Accuracy: 97.43%, Val-Class-Acc: {0: '96.25%', 1: '99.25%'}, LR: 0.000100000\n",
      "Epoch 387/2000, Train Loss: 0.055034837, Train-Class-Acc: {0: '98.17%', 1: '96.75%'}, Val Loss: 0.094907756, Val Accuracy: 97.21%, Val-Class-Acc: {0: '98.91%', 1: '94.59%'}, LR: 0.000100000\n",
      "Epoch 388/2000, Train Loss: 0.044263121, Train-Class-Acc: {0: '98.63%', 1: '97.36%'}, Val Loss: 0.072086838, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.51%', 1: '96.90%'}, LR: 0.000100000\n",
      "Epoch 389/2000, Train Loss: 0.033487805, Train-Class-Acc: {0: '99.02%', 1: '98.10%'}, Val Loss: 0.072392934, Val Accuracy: 98.07%, Val-Class-Acc: {0: '98.31%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 390/2000, Train Loss: 0.031257048, Train-Class-Acc: {0: '99.08%', 1: '98.25%'}, Val Loss: 0.071065508, Val Accuracy: 98.05%, Val-Class-Acc: {0: '98.35%', 1: '97.60%'}, LR: 0.000100000\n",
      "Epoch 391/2000, Train Loss: 0.033361734, Train-Class-Acc: {0: '98.99%', 1: '98.11%'}, Val Loss: 0.073183433, Val Accuracy: 98.07%, Val-Class-Acc: {0: '98.32%', 1: '97.68%'}, LR: 0.000100000\n",
      "Epoch 392/2000, Train Loss: 0.100385425, Train-Class-Acc: {0: '97.16%', 1: '95.10%'}, Val Loss: 0.107900656, Val Accuracy: 96.46%, Val-Class-Acc: {0: '94.98%', 1: '98.73%'}, LR: 0.000100000\n",
      "Epoch 393/2000, Train Loss: 0.043083492, Train-Class-Acc: {0: '98.86%', 1: '97.43%'}, Val Loss: 0.079223000, Val Accuracy: 97.62%, Val-Class-Acc: {0: '98.42%', 1: '96.39%'}, LR: 0.000100000\n",
      "Epoch 394/2000, Train Loss: 0.032333822, Train-Class-Acc: {0: '99.11%', 1: '98.22%'}, Val Loss: 0.075245299, Val Accuracy: 97.80%, Val-Class-Acc: {0: '97.02%', 1: '99.00%'}, LR: 0.000100000\n",
      "Epoch 395/2000, Train Loss: 0.047948205, Train-Class-Acc: {0: '98.44%', 1: '97.18%'}, Val Loss: 0.071807007, Val Accuracy: 98.05%, Val-Class-Acc: {0: '97.91%', 1: '98.27%'}, LR: 0.000100000\n",
      "Epoch 396/2000, Train Loss: 0.030192972, Train-Class-Acc: {0: '99.16%', 1: '98.39%'}, Val Loss: 0.069415593, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.21%', 1: '98.12%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.09%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_381.pth\n",
      "Model saved after epoch 396 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_396.pth \n",
      "\n",
      "Epoch 397/2000, Train Loss: 0.032873101, Train-Class-Acc: {0: '99.00%', 1: '98.16%'}, Val Loss: 0.072343405, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.00%', 1: '98.45%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.12%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_367.pth\n",
      "Model saved after epoch 397 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_397.pth \n",
      "\n",
      "Epoch 398/2000, Train Loss: 0.036568352, Train-Class-Acc: {0: '98.81%', 1: '97.91%'}, Val Loss: 0.072671294, Val Accuracy: 98.01%, Val-Class-Acc: {0: '97.62%', 1: '98.62%'}, LR: 0.000100000\n",
      "Epoch 399/2000, Train Loss: 0.032400556, Train-Class-Acc: {0: '98.99%', 1: '98.14%'}, Val Loss: 0.070445991, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.20%', 1: '98.13%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.13%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_361.pth\n",
      "Model saved after epoch 399 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_399.pth \n",
      "\n",
      "Epoch 400/2000, Train Loss: 0.039159886, Train-Class-Acc: {0: '98.71%', 1: '97.67%'}, Val Loss: 0.082437949, Val Accuracy: 97.56%, Val-Class-Acc: {0: '98.60%', 1: '95.98%'}, LR: 0.000100000\n",
      "Epoch 401/2000, Train Loss: 0.042363514, Train-Class-Acc: {0: '98.62%', 1: '97.45%'}, Val Loss: 0.068295786, Val Accuracy: 98.22%, Val-Class-Acc: {0: '98.26%', 1: '98.16%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.14%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_362.pth\n",
      "Model saved after epoch 401 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_401.pth \n",
      "\n",
      "Epoch 402/2000, Train Loss: 0.031163162, Train-Class-Acc: {0: '99.08%', 1: '98.22%'}, Val Loss: 0.079897964, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.51%', 1: '96.58%'}, LR: 0.000100000\n",
      "Epoch 403/2000, Train Loss: 0.053243314, Train-Class-Acc: {0: '98.48%', 1: '97.37%'}, Val Loss: 0.100839604, Val Accuracy: 96.89%, Val-Class-Acc: {0: '95.82%', 1: '98.53%'}, LR: 0.000100000\n",
      "Epoch 404/2000, Train Loss: 0.095103828, Train-Class-Acc: {0: '97.47%', 1: '94.90%'}, Val Loss: 0.082181052, Val Accuracy: 97.67%, Val-Class-Acc: {0: '98.21%', 1: '96.84%'}, LR: 0.000100000\n",
      "Epoch 405/2000, Train Loss: 0.037511156, Train-Class-Acc: {0: '98.96%', 1: '97.97%'}, Val Loss: 0.085835540, Val Accuracy: 97.53%, Val-Class-Acc: {0: '98.57%', 1: '95.92%'}, LR: 0.000100000\n",
      "Epoch 406/2000, Train Loss: 0.044391904, Train-Class-Acc: {0: '98.63%', 1: '97.40%'}, Val Loss: 0.081549093, Val Accuracy: 97.79%, Val-Class-Acc: {0: '97.45%', 1: '98.31%'}, LR: 0.000100000\n",
      "Epoch 407/2000, Train Loss: 0.033704940, Train-Class-Acc: {0: '99.01%', 1: '98.15%'}, Val Loss: 0.080205682, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.48%', 1: '96.62%'}, LR: 0.000100000\n",
      "Epoch 408/2000, Train Loss: 0.035913502, Train-Class-Acc: {0: '98.93%', 1: '98.06%'}, Val Loss: 0.092271278, Val Accuracy: 97.29%, Val-Class-Acc: {0: '98.84%', 1: '94.92%'}, LR: 0.000100000\n",
      "Epoch 409/2000, Train Loss: 0.066130385, Train-Class-Acc: {0: '97.95%', 1: '96.24%'}, Val Loss: 0.072541067, Val Accuracy: 97.93%, Val-Class-Acc: {0: '97.72%', 1: '98.25%'}, LR: 0.000100000\n",
      "Epoch 410/2000, Train Loss: 0.045749301, Train-Class-Acc: {0: '98.55%', 1: '97.16%'}, Val Loss: 0.078105800, Val Accuracy: 97.92%, Val-Class-Acc: {0: '97.91%', 1: '97.94%'}, LR: 0.000100000\n",
      "Epoch 411/2000, Train Loss: 0.032902511, Train-Class-Acc: {0: '99.05%', 1: '98.21%'}, Val Loss: 0.079207523, Val Accuracy: 97.88%, Val-Class-Acc: {0: '97.78%', 1: '98.03%'}, LR: 0.000100000\n",
      "Epoch 412/2000, Train Loss: 0.030207161, Train-Class-Acc: {0: '99.12%', 1: '98.36%'}, Val Loss: 0.076774269, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.31%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 413/2000, Train Loss: 0.029190059, Train-Class-Acc: {0: '99.14%', 1: '98.39%'}, Val Loss: 0.085807621, Val Accuracy: 97.51%, Val-Class-Acc: {0: '98.42%', 1: '96.11%'}, LR: 0.000100000\n",
      "Epoch 414/2000, Train Loss: 0.029081644, Train-Class-Acc: {0: '99.14%', 1: '98.41%'}, Val Loss: 0.075847875, Val Accuracy: 98.06%, Val-Class-Acc: {0: '98.25%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 415/2000, Train Loss: 0.075768663, Train-Class-Acc: {0: '97.60%', 1: '95.81%'}, Val Loss: 0.092787134, Val Accuracy: 97.08%, Val-Class-Acc: {0: '98.59%', 1: '94.75%'}, LR: 0.000100000\n",
      "Epoch 416/2000, Train Loss: 0.034820525, Train-Class-Acc: {0: '99.01%', 1: '98.00%'}, Val Loss: 0.074974440, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.14%', 1: '97.79%'}, LR: 0.000100000\n",
      "Epoch 417/2000, Train Loss: 0.027309362, Train-Class-Acc: {0: '99.28%', 1: '98.61%'}, Val Loss: 0.074630711, Val Accuracy: 98.06%, Val-Class-Acc: {0: '98.42%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 418/2000, Train Loss: 0.035905106, Train-Class-Acc: {0: '98.88%', 1: '97.94%'}, Val Loss: 0.072595290, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.35%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 419/2000, Train Loss: 0.028892734, Train-Class-Acc: {0: '99.16%', 1: '98.41%'}, Val Loss: 0.075700215, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.18%', 1: '97.78%'}, LR: 0.000100000\n",
      "Epoch 420/2000, Train Loss: 0.028010944, Train-Class-Acc: {0: '99.18%', 1: '98.50%'}, Val Loss: 0.078773245, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.43%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 421/2000, Train Loss: 0.044845183, Train-Class-Acc: {0: '98.63%', 1: '97.55%'}, Val Loss: 0.080115689, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.62%', 1: '96.37%'}, LR: 0.000100000\n",
      "Epoch 422/2000, Train Loss: 0.027413127, Train-Class-Acc: {0: '99.27%', 1: '98.54%'}, Val Loss: 0.080654133, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.51%', 1: '96.90%'}, LR: 0.000100000\n",
      "Epoch 423/2000, Train Loss: 0.040871223, Train-Class-Acc: {0: '98.71%', 1: '97.58%'}, Val Loss: 0.074163575, Val Accuracy: 97.86%, Val-Class-Acc: {0: '97.74%', 1: '98.03%'}, LR: 0.000100000\n",
      "Epoch 424/2000, Train Loss: 0.038299341, Train-Class-Acc: {0: '98.76%', 1: '97.79%'}, Val Loss: 0.087452960, Val Accuracy: 97.61%, Val-Class-Acc: {0: '98.55%', 1: '96.16%'}, LR: 0.000100000\n",
      "Epoch 425/2000, Train Loss: 0.037967218, Train-Class-Acc: {0: '98.82%', 1: '97.86%'}, Val Loss: 0.090653729, Val Accuracy: 97.50%, Val-Class-Acc: {0: '98.76%', 1: '95.56%'}, LR: 0.000100000\n",
      "Epoch 426/2000, Train Loss: 0.029560005, Train-Class-Acc: {0: '99.15%', 1: '98.37%'}, Val Loss: 0.080744842, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.20%', 1: '97.68%'}, LR: 0.000100000\n",
      "Epoch 427/2000, Train Loss: 0.040014380, Train-Class-Acc: {0: '98.81%', 1: '97.80%'}, Val Loss: 0.081474662, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.47%', 1: '96.96%'}, LR: 0.000100000\n",
      "Epoch 428/2000, Train Loss: 0.031110302, Train-Class-Acc: {0: '99.07%', 1: '98.26%'}, Val Loss: 0.080081398, Val Accuracy: 97.93%, Val-Class-Acc: {0: '97.61%', 1: '98.43%'}, LR: 0.000100000\n",
      "Epoch 429/2000, Train Loss: 0.028443368, Train-Class-Acc: {0: '99.14%', 1: '98.41%'}, Val Loss: 0.077715507, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.14%', 1: '97.81%'}, LR: 0.000100000\n",
      "Epoch 430/2000, Train Loss: 0.027546756, Train-Class-Acc: {0: '99.20%', 1: '98.54%'}, Val Loss: 0.086946210, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.40%', 1: '96.99%'}, LR: 0.000100000\n",
      "Epoch 431/2000, Train Loss: 0.027394014, Train-Class-Acc: {0: '99.19%', 1: '98.51%'}, Val Loss: 0.093859465, Val Accuracy: 97.48%, Val-Class-Acc: {0: '98.65%', 1: '95.67%'}, LR: 0.000100000\n",
      "Epoch 432/2000, Train Loss: 0.028816482, Train-Class-Acc: {0: '99.14%', 1: '98.33%'}, Val Loss: 0.084064169, Val Accuracy: 97.89%, Val-Class-Acc: {0: '97.50%', 1: '98.50%'}, LR: 0.000100000\n",
      "Epoch 433/2000, Train Loss: 0.072852640, Train-Class-Acc: {0: '97.83%', 1: '96.17%'}, Val Loss: 0.109493293, Val Accuracy: 96.85%, Val-Class-Acc: {0: '95.54%', 1: '98.86%'}, LR: 0.000100000\n",
      "Epoch 434/2000, Train Loss: 0.032281798, Train-Class-Acc: {0: '99.10%', 1: '98.28%'}, Val Loss: 0.081879404, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.14%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 435/2000, Train Loss: 0.037941105, Train-Class-Acc: {0: '98.76%', 1: '97.73%'}, Val Loss: 0.085372564, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.47%', 1: '96.92%'}, LR: 0.000100000\n",
      "Epoch 436/2000, Train Loss: 0.040254499, Train-Class-Acc: {0: '98.74%', 1: '97.57%'}, Val Loss: 0.081534839, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.13%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 437/2000, Train Loss: 0.045775802, Train-Class-Acc: {0: '98.74%', 1: '97.75%'}, Val Loss: 0.155147605, Val Accuracy: 95.59%, Val-Class-Acc: {0: '93.16%', 1: '99.34%'}, LR: 0.000100000\n",
      "Epoch 438/2000, Train Loss: 0.065430268, Train-Class-Acc: {0: '98.24%', 1: '96.48%'}, Val Loss: 0.082044144, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.41%', 1: '96.82%'}, LR: 0.000100000\n",
      "Epoch 439/2000, Train Loss: 0.026990477, Train-Class-Acc: {0: '99.30%', 1: '98.64%'}, Val Loss: 0.082763515, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.25%', 1: '97.23%'}, LR: 0.000100000\n",
      "Epoch 440/2000, Train Loss: 0.026829590, Train-Class-Acc: {0: '99.25%', 1: '98.60%'}, Val Loss: 0.079449585, Val Accuracy: 98.03%, Val-Class-Acc: {0: '98.25%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 441/2000, Train Loss: 0.029249808, Train-Class-Acc: {0: '99.10%', 1: '98.40%'}, Val Loss: 0.082667594, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.25%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 442/2000, Train Loss: 0.028934399, Train-Class-Acc: {0: '99.13%', 1: '98.37%'}, Val Loss: 0.083136835, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.34%', 1: '97.25%'}, LR: 0.000100000\n",
      "Epoch 443/2000, Train Loss: 0.034247780, Train-Class-Acc: {0: '98.93%', 1: '98.06%'}, Val Loss: 0.082398376, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.31%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 444/2000, Train Loss: 0.028002517, Train-Class-Acc: {0: '99.14%', 1: '98.45%'}, Val Loss: 0.080088092, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.24%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 445/2000, Train Loss: 0.024996895, Train-Class-Acc: {0: '99.28%', 1: '98.67%'}, Val Loss: 0.082328207, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.04%', 1: '97.90%'}, LR: 0.000100000\n",
      "Epoch 446/2000, Train Loss: 0.030356547, Train-Class-Acc: {0: '99.04%', 1: '98.32%'}, Val Loss: 0.081770339, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.14%', 1: '97.68%'}, LR: 0.000100000\n",
      "Epoch 447/2000, Train Loss: 0.047885550, Train-Class-Acc: {0: '98.79%', 1: '97.58%'}, Val Loss: 0.226438976, Val Accuracy: 94.50%, Val-Class-Acc: {0: '91.34%', 1: '99.36%'}, LR: 0.000100000\n",
      "Epoch 448/2000, Train Loss: 0.067488590, Train-Class-Acc: {0: '98.09%', 1: '96.59%'}, Val Loss: 0.080645279, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.24%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 449/2000, Train Loss: 0.028191060, Train-Class-Acc: {0: '99.20%', 1: '98.53%'}, Val Loss: 0.080808760, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.60%', 1: '98.13%'}, LR: 0.000100000\n",
      "Epoch 450/2000, Train Loss: 0.026202696, Train-Class-Acc: {0: '99.27%', 1: '98.61%'}, Val Loss: 0.086942003, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.58%', 1: '96.38%'}, LR: 0.000100000\n",
      "Epoch 451/2000, Train Loss: 0.030332314, Train-Class-Acc: {0: '99.08%', 1: '98.35%'}, Val Loss: 0.093799221, Val Accuracy: 97.54%, Val-Class-Acc: {0: '98.69%', 1: '95.77%'}, LR: 0.000100000\n",
      "Epoch 452/2000, Train Loss: 0.030418815, Train-Class-Acc: {0: '99.07%', 1: '98.31%'}, Val Loss: 0.089734407, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.50%', 1: '96.87%'}, LR: 0.000100000\n",
      "Epoch 453/2000, Train Loss: 0.039934888, Train-Class-Acc: {0: '98.80%', 1: '97.83%'}, Val Loss: 0.100195778, Val Accuracy: 97.47%, Val-Class-Acc: {0: '96.54%', 1: '98.90%'}, LR: 0.000100000\n",
      "Epoch 454/2000, Train Loss: 0.061073383, Train-Class-Acc: {0: '98.14%', 1: '96.60%'}, Val Loss: 0.085056505, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.61%', 1: '96.63%'}, LR: 0.000100000\n",
      "Epoch 455/2000, Train Loss: 0.026256049, Train-Class-Acc: {0: '99.32%', 1: '98.66%'}, Val Loss: 0.084364793, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.39%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 456/2000, Train Loss: 0.025609751, Train-Class-Acc: {0: '99.26%', 1: '98.67%'}, Val Loss: 0.081491219, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.44%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 457/2000, Train Loss: 0.023260664, Train-Class-Acc: {0: '99.37%', 1: '98.80%'}, Val Loss: 0.083073985, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.18%', 1: '97.66%'}, LR: 0.000100000\n",
      "Epoch 458/2000, Train Loss: 0.030827992, Train-Class-Acc: {0: '99.00%', 1: '98.19%'}, Val Loss: 0.098381308, Val Accuracy: 97.54%, Val-Class-Acc: {0: '96.60%', 1: '98.98%'}, LR: 0.000100000\n",
      "Epoch 459/2000, Train Loss: 0.028054120, Train-Class-Acc: {0: '99.14%', 1: '98.48%'}, Val Loss: 0.084380881, Val Accuracy: 97.92%, Val-Class-Acc: {0: '97.98%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 460/2000, Train Loss: 0.056532110, Train-Class-Acc: {0: '98.32%', 1: '97.01%'}, Val Loss: 0.092358665, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.26%', 1: '96.90%'}, LR: 0.000100000\n",
      "Epoch 461/2000, Train Loss: 0.025443772, Train-Class-Acc: {0: '99.33%', 1: '98.67%'}, Val Loss: 0.088647463, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.10%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 462/2000, Train Loss: 0.023152002, Train-Class-Acc: {0: '99.37%', 1: '98.82%'}, Val Loss: 0.087075902, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.45%', 1: '97.03%'}, LR: 0.000100000\n",
      "Epoch 463/2000, Train Loss: 0.033318346, Train-Class-Acc: {0: '99.00%', 1: '98.12%'}, Val Loss: 0.224240675, Val Accuracy: 94.79%, Val-Class-Acc: {0: '91.81%', 1: '99.39%'}, LR: 0.000100000\n",
      "Epoch 464/2000, Train Loss: 0.085752446, Train-Class-Acc: {0: '97.68%', 1: '95.74%'}, Val Loss: 0.082931862, Val Accuracy: 97.77%, Val-Class-Acc: {0: '98.24%', 1: '97.05%'}, LR: 0.000100000\n",
      "Epoch 465/2000, Train Loss: 0.025842525, Train-Class-Acc: {0: '99.37%', 1: '98.73%'}, Val Loss: 0.087579757, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.53%', 1: '96.72%'}, LR: 0.000100000\n",
      "Epoch 466/2000, Train Loss: 0.028172825, Train-Class-Acc: {0: '99.13%', 1: '98.45%'}, Val Loss: 0.088308896, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.56%', 1: '96.69%'}, LR: 0.000100000\n",
      "Epoch 467/2000, Train Loss: 0.023126310, Train-Class-Acc: {0: '99.39%', 1: '98.83%'}, Val Loss: 0.086228898, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.37%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 468/2000, Train Loss: 0.023428250, Train-Class-Acc: {0: '99.34%', 1: '98.78%'}, Val Loss: 0.089065779, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.58%', 1: '96.76%'}, LR: 0.000100000\n",
      "Epoch 469/2000, Train Loss: 0.041984916, Train-Class-Acc: {0: '98.68%', 1: '97.77%'}, Val Loss: 0.089246636, Val Accuracy: 97.77%, Val-Class-Acc: {0: '98.64%', 1: '96.42%'}, LR: 0.000100000\n",
      "Epoch 470/2000, Train Loss: 0.036631495, Train-Class-Acc: {0: '98.85%', 1: '97.78%'}, Val Loss: 0.084316905, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.01%', 1: '97.58%'}, LR: 0.000100000\n",
      "Epoch 471/2000, Train Loss: 0.024478694, Train-Class-Acc: {0: '99.31%', 1: '98.74%'}, Val Loss: 0.082736213, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.25%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 472/2000, Train Loss: 0.026266624, Train-Class-Acc: {0: '99.20%', 1: '98.60%'}, Val Loss: 0.096200915, Val Accuracy: 97.56%, Val-Class-Acc: {0: '98.41%', 1: '96.24%'}, LR: 0.000100000\n",
      "Epoch 473/2000, Train Loss: 0.031341550, Train-Class-Acc: {0: '99.11%', 1: '98.37%'}, Val Loss: 0.088381371, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.08%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 474/2000, Train Loss: 0.028112322, Train-Class-Acc: {0: '99.14%', 1: '98.38%'}, Val Loss: 0.098944651, Val Accuracy: 97.64%, Val-Class-Acc: {0: '96.70%', 1: '99.10%'}, LR: 0.000100000\n",
      "Epoch 475/2000, Train Loss: 0.031119587, Train-Class-Acc: {0: '99.01%', 1: '98.32%'}, Val Loss: 0.088022644, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.18%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 476/2000, Train Loss: 0.035013124, Train-Class-Acc: {0: '98.94%', 1: '98.03%'}, Val Loss: 0.088454882, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.12%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 477/2000, Train Loss: 0.024875187, Train-Class-Acc: {0: '99.28%', 1: '98.63%'}, Val Loss: 0.097382956, Val Accuracy: 97.71%, Val-Class-Acc: {0: '96.87%', 1: '99.01%'}, LR: 0.000100000\n",
      "Epoch 478/2000, Train Loss: 0.058889861, Train-Class-Acc: {0: '98.35%', 1: '97.03%'}, Val Loss: 0.092353636, Val Accuracy: 97.74%, Val-Class-Acc: {0: '97.12%', 1: '98.68%'}, LR: 0.000100000\n",
      "Epoch 479/2000, Train Loss: 0.024755509, Train-Class-Acc: {0: '99.31%', 1: '98.71%'}, Val Loss: 0.088472502, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.35%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 480/2000, Train Loss: 0.023124431, Train-Class-Acc: {0: '99.36%', 1: '98.79%'}, Val Loss: 0.089540553, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.26%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 481/2000, Train Loss: 0.021829767, Train-Class-Acc: {0: '99.39%', 1: '98.90%'}, Val Loss: 0.090910357, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.48%', 1: '96.99%'}, LR: 0.000100000\n",
      "Epoch 482/2000, Train Loss: 0.031909697, Train-Class-Acc: {0: '99.01%', 1: '98.25%'}, Val Loss: 0.086045177, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.66%', 1: '98.07%'}, LR: 0.000100000\n",
      "Epoch 483/2000, Train Loss: 0.084780245, Train-Class-Acc: {0: '97.62%', 1: '95.58%'}, Val Loss: 0.086308203, Val Accuracy: 97.87%, Val-Class-Acc: {0: '97.65%', 1: '98.20%'}, LR: 0.000100000\n",
      "Epoch 484/2000, Train Loss: 0.026038130, Train-Class-Acc: {0: '99.35%', 1: '98.73%'}, Val Loss: 0.094191969, Val Accuracy: 97.67%, Val-Class-Acc: {0: '98.54%', 1: '96.33%'}, LR: 0.000100000\n",
      "Epoch 485/2000, Train Loss: 0.022737584, Train-Class-Acc: {0: '99.40%', 1: '98.85%'}, Val Loss: 0.086126912, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.66%', 1: '98.04%'}, LR: 0.000100000\n",
      "Epoch 486/2000, Train Loss: 0.030051527, Train-Class-Acc: {0: '99.02%', 1: '98.27%'}, Val Loss: 0.087434402, Val Accuracy: 97.85%, Val-Class-Acc: {0: '97.55%', 1: '98.32%'}, LR: 0.000100000\n",
      "Epoch 487/2000, Train Loss: 0.022088939, Train-Class-Acc: {0: '99.38%', 1: '98.90%'}, Val Loss: 0.087781730, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.57%', 1: '98.22%'}, LR: 0.000100000\n",
      "Epoch 488/2000, Train Loss: 0.033703524, Train-Class-Acc: {0: '98.90%', 1: '98.08%'}, Val Loss: 0.086838378, Val Accuracy: 97.89%, Val-Class-Acc: {0: '97.94%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 489/2000, Train Loss: 0.022685741, Train-Class-Acc: {0: '99.35%', 1: '98.81%'}, Val Loss: 0.093593801, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.39%', 1: '96.87%'}, LR: 0.000100000\n",
      "Epoch 490/2000, Train Loss: 0.022184254, Train-Class-Acc: {0: '99.37%', 1: '98.83%'}, Val Loss: 0.089659776, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.28%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 491/2000, Train Loss: 0.021783337, Train-Class-Acc: {0: '99.36%', 1: '98.87%'}, Val Loss: 0.089443237, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.65%', 1: '98.08%'}, LR: 0.000100000\n",
      "Epoch 492/2000, Train Loss: 0.147566752, Train-Class-Acc: {0: '96.58%', 1: '93.68%'}, Val Loss: 0.112692784, Val Accuracy: 96.53%, Val-Class-Acc: {0: '98.52%', 1: '93.47%'}, LR: 0.000100000\n",
      "Epoch 493/2000, Train Loss: 0.037548085, Train-Class-Acc: {0: '99.08%', 1: '97.90%'}, Val Loss: 0.087631755, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.19%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 494/2000, Train Loss: 0.023131462, Train-Class-Acc: {0: '99.44%', 1: '98.92%'}, Val Loss: 0.090415163, Val Accuracy: 97.67%, Val-Class-Acc: {0: '98.47%', 1: '96.45%'}, LR: 0.000100000\n",
      "Epoch 495/2000, Train Loss: 0.022222546, Train-Class-Acc: {0: '99.41%', 1: '98.91%'}, Val Loss: 0.085840766, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.03%', 1: '97.60%'}, LR: 0.000100000\n",
      "Epoch 496/2000, Train Loss: 0.024842537, Train-Class-Acc: {0: '99.25%', 1: '98.70%'}, Val Loss: 0.088963907, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.28%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 497/2000, Train Loss: 0.026630423, Train-Class-Acc: {0: '99.22%', 1: '98.58%'}, Val Loss: 0.110581396, Val Accuracy: 97.30%, Val-Class-Acc: {0: '98.94%', 1: '94.77%'}, LR: 0.000100000\n",
      "Epoch 498/2000, Train Loss: 0.023947662, Train-Class-Acc: {0: '99.33%', 1: '98.73%'}, Val Loss: 0.087209533, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.02%', 1: '97.67%'}, LR: 0.000100000\n",
      "Epoch 499/2000, Train Loss: 0.020546469, Train-Class-Acc: {0: '99.44%', 1: '98.99%'}, Val Loss: 0.092694915, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.43%', 1: '97.04%'}, LR: 0.000100000\n",
      "Epoch 500/2000, Train Loss: 0.021992331, Train-Class-Acc: {0: '99.36%', 1: '98.85%'}, Val Loss: 0.096575871, Val Accuracy: 97.77%, Val-Class-Acc: {0: '98.57%', 1: '96.54%'}, LR: 0.000100000\n",
      "Epoch 501/2000, Train Loss: 0.020727138, Train-Class-Acc: {0: '99.43%', 1: '98.92%'}, Val Loss: 0.091532500, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.39%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 502/2000, Train Loss: 0.023810584, Train-Class-Acc: {0: '99.29%', 1: '98.67%'}, Val Loss: 0.092674735, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.12%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 503/2000, Train Loss: 0.028479493, Train-Class-Acc: {0: '99.15%', 1: '98.49%'}, Val Loss: 0.089540776, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.30%', 1: '97.27%'}, LR: 0.000100000\n",
      "Epoch 504/2000, Train Loss: 0.128138715, Train-Class-Acc: {0: '97.02%', 1: '94.35%'}, Val Loss: 0.124678968, Val Accuracy: 96.29%, Val-Class-Acc: {0: '94.77%', 1: '98.61%'}, LR: 0.000100000\n",
      "Epoch 505/2000, Train Loss: 0.038755471, Train-Class-Acc: {0: '98.98%', 1: '97.91%'}, Val Loss: 0.090070269, Val Accuracy: 97.77%, Val-Class-Acc: {0: '97.78%', 1: '97.75%'}, LR: 0.000100000\n",
      "Epoch 506/2000, Train Loss: 0.023451915, Train-Class-Acc: {0: '99.41%', 1: '98.88%'}, Val Loss: 0.091176261, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.52%', 1: '96.76%'}, LR: 0.000100000\n",
      "Epoch 507/2000, Train Loss: 0.022636002, Train-Class-Acc: {0: '99.40%', 1: '98.88%'}, Val Loss: 0.090109931, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.39%', 1: '97.04%'}, LR: 0.000100000\n",
      "Epoch 508/2000, Train Loss: 0.021651064, Train-Class-Acc: {0: '99.41%', 1: '98.90%'}, Val Loss: 0.087808761, Val Accuracy: 97.85%, Val-Class-Acc: {0: '97.99%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 509/2000, Train Loss: 0.021788411, Train-Class-Acc: {0: '99.38%', 1: '98.88%'}, Val Loss: 0.091754978, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.20%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 510/2000, Train Loss: 0.021428951, Train-Class-Acc: {0: '99.38%', 1: '98.91%'}, Val Loss: 0.095836077, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.44%', 1: '96.89%'}, LR: 0.000100000\n",
      "Epoch 511/2000, Train Loss: 0.069658662, Train-Class-Acc: {0: '98.15%', 1: '96.77%'}, Val Loss: 0.087479573, Val Accuracy: 97.86%, Val-Class-Acc: {0: '97.96%', 1: '97.72%'}, LR: 0.000100000\n",
      "Epoch 512/2000, Train Loss: 0.022847783, Train-Class-Acc: {0: '99.42%', 1: '98.89%'}, Val Loss: 0.086996041, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.85%', 1: '97.79%'}, LR: 0.000100000\n",
      "Epoch 513/2000, Train Loss: 0.020784364, Train-Class-Acc: {0: '99.46%', 1: '98.97%'}, Val Loss: 0.088638576, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.84%', 1: '97.80%'}, LR: 0.000100000\n",
      "Epoch 514/2000, Train Loss: 0.041880846, Train-Class-Acc: {0: '98.73%', 1: '97.76%'}, Val Loss: 0.098028166, Val Accuracy: 97.73%, Val-Class-Acc: {0: '97.41%', 1: '98.23%'}, LR: 0.000100000\n",
      "Epoch 515/2000, Train Loss: 0.023559986, Train-Class-Acc: {0: '99.36%', 1: '98.75%'}, Val Loss: 0.089410308, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.03%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 516/2000, Train Loss: 0.019920010, Train-Class-Acc: {0: '99.48%', 1: '99.04%'}, Val Loss: 0.088989554, Val Accuracy: 97.85%, Val-Class-Acc: {0: '97.90%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 517/2000, Train Loss: 0.020652797, Train-Class-Acc: {0: '99.44%', 1: '98.96%'}, Val Loss: 0.099732824, Val Accuracy: 97.77%, Val-Class-Acc: {0: '97.90%', 1: '97.57%'}, LR: 0.000100000\n",
      "Epoch 518/2000, Train Loss: 0.045470406, Train-Class-Acc: {0: '98.75%', 1: '97.79%'}, Val Loss: 0.091178436, Val Accuracy: 97.79%, Val-Class-Acc: {0: '97.64%', 1: '98.04%'}, LR: 0.000100000\n",
      "Epoch 519/2000, Train Loss: 0.020760198, Train-Class-Acc: {0: '99.48%', 1: '99.03%'}, Val Loss: 0.093520576, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.46%', 1: '96.98%'}, LR: 0.000100000\n",
      "Epoch 520/2000, Train Loss: 0.021112478, Train-Class-Acc: {0: '99.40%', 1: '98.91%'}, Val Loss: 0.088264342, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.06%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 521/2000, Train Loss: 0.019454990, Train-Class-Acc: {0: '99.46%', 1: '99.04%'}, Val Loss: 0.101088652, Val Accuracy: 97.66%, Val-Class-Acc: {0: '98.62%', 1: '96.18%'}, LR: 0.000100000\n",
      "Epoch 522/2000, Train Loss: 0.019408001, Train-Class-Acc: {0: '99.46%', 1: '98.99%'}, Val Loss: 0.094886877, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.09%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 523/2000, Train Loss: 0.020231972, Train-Class-Acc: {0: '99.43%', 1: '98.94%'}, Val Loss: 0.097365402, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.14%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 524/2000, Train Loss: 0.068873191, Train-Class-Acc: {0: '98.08%', 1: '96.56%'}, Val Loss: 0.088533040, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.54%', 1: '96.64%'}, LR: 0.000100000\n",
      "Epoch 525/2000, Train Loss: 0.021387677, Train-Class-Acc: {0: '99.47%', 1: '98.97%'}, Val Loss: 0.088456592, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.32%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 526/2000, Train Loss: 0.019556542, Train-Class-Acc: {0: '99.49%', 1: '99.05%'}, Val Loss: 0.091725634, Val Accuracy: 97.79%, Val-Class-Acc: {0: '97.78%', 1: '97.80%'}, LR: 0.000100000\n",
      "Epoch 527/2000, Train Loss: 0.023453022, Train-Class-Acc: {0: '99.30%', 1: '98.72%'}, Val Loss: 0.089921630, Val Accuracy: 97.75%, Val-Class-Acc: {0: '97.61%', 1: '97.96%'}, LR: 0.000100000\n",
      "Epoch 528/2000, Train Loss: 0.023509053, Train-Class-Acc: {0: '99.28%', 1: '98.71%'}, Val Loss: 0.091994094, Val Accuracy: 97.78%, Val-Class-Acc: {0: '97.42%', 1: '98.32%'}, LR: 0.000100000\n",
      "Epoch 529/2000, Train Loss: 0.020938690, Train-Class-Acc: {0: '99.39%', 1: '98.93%'}, Val Loss: 0.091866268, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.31%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 530/2000, Train Loss: 0.018785851, Train-Class-Acc: {0: '99.48%', 1: '99.06%'}, Val Loss: 0.099036179, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.44%', 1: '96.89%'}, LR: 0.000100000\n",
      "Epoch 531/2000, Train Loss: 0.081709605, Train-Class-Acc: {0: '98.09%', 1: '96.46%'}, Val Loss: 0.091243516, Val Accuracy: 97.86%, Val-Class-Acc: {0: '97.75%', 1: '98.02%'}, LR: 0.000100000\n",
      "Epoch 532/2000, Train Loss: 0.022645463, Train-Class-Acc: {0: '99.39%', 1: '98.90%'}, Val Loss: 0.089355065, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.51%', 1: '96.98%'}, LR: 0.000100000\n",
      "Epoch 533/2000, Train Loss: 0.021135127, Train-Class-Acc: {0: '99.42%', 1: '98.93%'}, Val Loss: 0.092250074, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.50%', 1: '96.84%'}, LR: 0.000100000\n",
      "Epoch 534/2000, Train Loss: 0.019478429, Train-Class-Acc: {0: '99.47%', 1: '99.03%'}, Val Loss: 0.095869857, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.61%', 1: '96.78%'}, LR: 0.000100000\n",
      "Epoch 535/2000, Train Loss: 0.023651568, Train-Class-Acc: {0: '99.26%', 1: '98.70%'}, Val Loss: 0.097356219, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.59%', 1: '96.77%'}, LR: 0.000100000\n",
      "Epoch 536/2000, Train Loss: 0.019955067, Train-Class-Acc: {0: '99.45%', 1: '98.95%'}, Val Loss: 0.097440154, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.30%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 537/2000, Train Loss: 0.033528171, Train-Class-Acc: {0: '99.03%', 1: '98.39%'}, Val Loss: 0.124458268, Val Accuracy: 97.13%, Val-Class-Acc: {0: '98.77%', 1: '94.62%'}, LR: 0.000100000\n",
      "Epoch 538/2000, Train Loss: 0.038650667, Train-Class-Acc: {0: '98.89%', 1: '98.00%'}, Val Loss: 0.095570300, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.68%', 1: '96.48%'}, LR: 0.000100000\n",
      "Epoch 539/2000, Train Loss: 0.023608263, Train-Class-Acc: {0: '99.28%', 1: '98.74%'}, Val Loss: 0.100527561, Val Accuracy: 97.62%, Val-Class-Acc: {0: '98.73%', 1: '95.92%'}, LR: 0.000100000\n",
      "Epoch 540/2000, Train Loss: 0.019962694, Train-Class-Acc: {0: '99.44%', 1: '98.98%'}, Val Loss: 0.092706695, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.90%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 541/2000, Train Loss: 0.019376671, Train-Class-Acc: {0: '99.45%', 1: '99.01%'}, Val Loss: 0.094211868, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.14%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 542/2000, Train Loss: 0.017600871, Train-Class-Acc: {0: '99.52%', 1: '99.14%'}, Val Loss: 0.095355820, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.10%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 543/2000, Train Loss: 0.050558334, Train-Class-Acc: {0: '98.62%', 1: '97.63%'}, Val Loss: 0.092618560, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.30%', 1: '97.24%'}, LR: 0.000100000\n",
      "Epoch 544/2000, Train Loss: 0.020716250, Train-Class-Acc: {0: '99.45%', 1: '98.93%'}, Val Loss: 0.089401357, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.57%', 1: '98.16%'}, LR: 0.000100000\n",
      "Epoch 545/2000, Train Loss: 0.041994377, Train-Class-Acc: {0: '98.70%', 1: '97.66%'}, Val Loss: 0.091523071, Val Accuracy: 97.75%, Val-Class-Acc: {0: '97.71%', 1: '97.81%'}, LR: 0.000100000\n",
      "Epoch 546/2000, Train Loss: 0.019337586, Train-Class-Acc: {0: '99.50%', 1: '99.07%'}, Val Loss: 0.092298243, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.49%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 547/2000, Train Loss: 0.019495548, Train-Class-Acc: {0: '99.46%', 1: '99.00%'}, Val Loss: 0.092767978, Val Accuracy: 97.87%, Val-Class-Acc: {0: '97.91%', 1: '97.81%'}, LR: 0.000100000\n",
      "Epoch 548/2000, Train Loss: 0.018950633, Train-Class-Acc: {0: '99.48%', 1: '99.02%'}, Val Loss: 0.093203810, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.12%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 549/2000, Train Loss: 0.018994900, Train-Class-Acc: {0: '99.46%', 1: '99.02%'}, Val Loss: 0.096354931, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.11%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 550/2000, Train Loss: 0.032074026, Train-Class-Acc: {0: '99.09%', 1: '98.38%'}, Val Loss: 0.091444764, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.03%', 1: '97.65%'}, LR: 0.000100000\n",
      "Epoch 551/2000, Train Loss: 0.019009250, Train-Class-Acc: {0: '99.47%', 1: '99.03%'}, Val Loss: 0.103544934, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.51%', 1: '96.51%'}, LR: 0.000100000\n",
      "Epoch 552/2000, Train Loss: 0.047558470, Train-Class-Acc: {0: '98.57%', 1: '97.50%'}, Val Loss: 0.096453361, Val Accuracy: 97.90%, Val-Class-Acc: {0: '97.51%', 1: '98.51%'}, LR: 0.000100000\n",
      "Epoch 553/2000, Train Loss: 0.044804656, Train-Class-Acc: {0: '98.60%', 1: '97.46%'}, Val Loss: 0.089674536, Val Accuracy: 97.78%, Val-Class-Acc: {0: '97.88%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 554/2000, Train Loss: 0.020464354, Train-Class-Acc: {0: '99.45%', 1: '99.01%'}, Val Loss: 0.091264401, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.13%', 1: '97.58%'}, LR: 0.000100000\n",
      "Epoch 555/2000, Train Loss: 0.018207344, Train-Class-Acc: {0: '99.52%', 1: '99.11%'}, Val Loss: 0.092966065, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.02%', 1: '97.67%'}, LR: 0.000100000\n",
      "Epoch 556/2000, Train Loss: 0.019779385, Train-Class-Acc: {0: '99.42%', 1: '98.97%'}, Val Loss: 0.097499512, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.10%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 557/2000, Train Loss: 0.017904236, Train-Class-Acc: {0: '99.51%', 1: '99.11%'}, Val Loss: 0.099307050, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.28%', 1: '97.17%'}, LR: 0.000100000\n",
      "Epoch 558/2000, Train Loss: 0.017944789, Train-Class-Acc: {0: '99.49%', 1: '99.10%'}, Val Loss: 0.096909395, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.09%', 1: '97.58%'}, LR: 0.000100000\n",
      "Epoch 559/2000, Train Loss: 0.018479108, Train-Class-Acc: {0: '99.46%', 1: '99.05%'}, Val Loss: 0.104421652, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.62%', 1: '96.31%'}, LR: 0.000100000\n",
      "Epoch 560/2000, Train Loss: 0.055562572, Train-Class-Acc: {0: '98.54%', 1: '97.38%'}, Val Loss: 0.138055178, Val Accuracy: 96.63%, Val-Class-Acc: {0: '95.22%', 1: '98.81%'}, LR: 0.000100000\n",
      "Epoch 561/2000, Train Loss: 0.032675894, Train-Class-Acc: {0: '99.00%', 1: '98.23%'}, Val Loss: 0.096883243, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.23%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 562/2000, Train Loss: 0.018973359, Train-Class-Acc: {0: '99.52%', 1: '99.04%'}, Val Loss: 0.096160359, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.50%', 1: '96.95%'}, LR: 0.000100000\n",
      "Epoch 563/2000, Train Loss: 0.019361450, Train-Class-Acc: {0: '99.48%', 1: '98.99%'}, Val Loss: 0.096251920, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.31%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 564/2000, Train Loss: 0.019054423, Train-Class-Acc: {0: '99.43%', 1: '99.06%'}, Val Loss: 0.111532432, Val Accuracy: 97.50%, Val-Class-Acc: {0: '98.53%', 1: '95.90%'}, LR: 0.000100000\n",
      "Epoch 565/2000, Train Loss: 0.026174939, Train-Class-Acc: {0: '99.22%', 1: '98.55%'}, Val Loss: 0.096703143, Val Accuracy: 97.80%, Val-Class-Acc: {0: '97.82%', 1: '97.78%'}, LR: 0.000100000\n",
      "Epoch 566/2000, Train Loss: 0.018272042, Train-Class-Acc: {0: '99.48%', 1: '99.08%'}, Val Loss: 0.101264599, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.45%', 1: '96.79%'}, LR: 0.000100000\n",
      "Epoch 567/2000, Train Loss: 0.022049232, Train-Class-Acc: {0: '99.32%', 1: '98.78%'}, Val Loss: 0.096818186, Val Accuracy: 97.84%, Val-Class-Acc: {0: '97.85%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 568/2000, Train Loss: 0.018755019, Train-Class-Acc: {0: '99.46%', 1: '99.02%'}, Val Loss: 0.098154576, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.02%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 569/2000, Train Loss: 0.017357850, Train-Class-Acc: {0: '99.51%', 1: '99.12%'}, Val Loss: 0.103884676, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.37%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 570/2000, Train Loss: 0.017793029, Train-Class-Acc: {0: '99.50%', 1: '99.07%'}, Val Loss: 0.097898311, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.13%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 571/2000, Train Loss: 0.301138797, Train-Class-Acc: {0: '93.88%', 1: '88.23%'}, Val Loss: 0.109820905, Val Accuracy: 96.86%, Val-Class-Acc: {0: '98.17%', 1: '94.84%'}, LR: 0.000100000\n",
      "Epoch 572/2000, Train Loss: 0.034506174, Train-Class-Acc: {0: '99.22%', 1: '98.10%'}, Val Loss: 0.087844707, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.12%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 573/2000, Train Loss: 0.020999170, Train-Class-Acc: {0: '99.50%', 1: '99.10%'}, Val Loss: 0.091499725, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.21%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 574/2000, Train Loss: 0.019859509, Train-Class-Acc: {0: '99.49%', 1: '99.10%'}, Val Loss: 0.106460921, Val Accuracy: 97.38%, Val-Class-Acc: {0: '98.58%', 1: '95.54%'}, LR: 0.000100000\n",
      "Epoch 575/2000, Train Loss: 0.019407172, Train-Class-Acc: {0: '99.50%', 1: '99.10%'}, Val Loss: 0.092971961, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.99%', 1: '97.54%'}, LR: 0.000100000\n",
      "Epoch 576/2000, Train Loss: 0.017664570, Train-Class-Acc: {0: '99.55%', 1: '99.18%'}, Val Loss: 0.103349151, Val Accuracy: 97.55%, Val-Class-Acc: {0: '98.51%', 1: '96.07%'}, LR: 0.000100000\n",
      "Epoch 577/2000, Train Loss: 0.017544711, Train-Class-Acc: {0: '99.54%', 1: '99.17%'}, Val Loss: 0.090845109, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.21%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 578/2000, Train Loss: 0.016747652, Train-Class-Acc: {0: '99.56%', 1: '99.21%'}, Val Loss: 0.098125318, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.53%', 1: '96.99%'}, LR: 0.000100000\n",
      "Epoch 579/2000, Train Loss: 0.017824597, Train-Class-Acc: {0: '99.52%', 1: '99.10%'}, Val Loss: 0.090203853, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.06%', 1: '97.72%'}, LR: 0.000100000\n",
      "Epoch 580/2000, Train Loss: 0.071336903, Train-Class-Acc: {0: '98.22%', 1: '97.03%'}, Val Loss: 0.101726305, Val Accuracy: 97.55%, Val-Class-Acc: {0: '98.39%', 1: '96.25%'}, LR: 0.000100000\n",
      "Epoch 581/2000, Train Loss: 0.027005094, Train-Class-Acc: {0: '99.22%', 1: '98.53%'}, Val Loss: 0.096729936, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.35%', 1: '97.07%'}, LR: 0.000100000\n",
      "Epoch 582/2000, Train Loss: 0.017434866, Train-Class-Acc: {0: '99.58%', 1: '99.21%'}, Val Loss: 0.090182799, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.24%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 583/2000, Train Loss: 0.017424545, Train-Class-Acc: {0: '99.55%', 1: '99.19%'}, Val Loss: 0.093213717, Val Accuracy: 97.85%, Val-Class-Acc: {0: '97.92%', 1: '97.74%'}, LR: 0.000100000\n",
      "Epoch 584/2000, Train Loss: 0.017129587, Train-Class-Acc: {0: '99.55%', 1: '99.17%'}, Val Loss: 0.095819923, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.04%', 1: '97.57%'}, LR: 0.000100000\n",
      "Epoch 585/2000, Train Loss: 0.016988301, Train-Class-Acc: {0: '99.54%', 1: '99.18%'}, Val Loss: 0.092528904, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.00%', 1: '97.74%'}, LR: 0.000100000\n",
      "Epoch 586/2000, Train Loss: 0.021239311, Train-Class-Acc: {0: '99.33%', 1: '98.85%'}, Val Loss: 0.094389459, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.03%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 587/2000, Train Loss: 0.018417407, Train-Class-Acc: {0: '99.47%', 1: '99.07%'}, Val Loss: 0.098670650, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.50%', 1: '98.30%'}, LR: 0.000100000\n",
      "Epoch 588/2000, Train Loss: 0.016853273, Train-Class-Acc: {0: '99.53%', 1: '99.19%'}, Val Loss: 0.100792226, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.05%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 589/2000, Train Loss: 0.065402158, Train-Class-Acc: {0: '98.34%', 1: '97.24%'}, Val Loss: 0.141915931, Val Accuracy: 96.42%, Val-Class-Acc: {0: '98.49%', 1: '93.24%'}, LR: 0.000100000\n",
      "Epoch 590/2000, Train Loss: 0.056038435, Train-Class-Acc: {0: '98.37%', 1: '96.99%'}, Val Loss: 0.092249293, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.17%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 591/2000, Train Loss: 0.018246050, Train-Class-Acc: {0: '99.60%', 1: '99.20%'}, Val Loss: 0.094325237, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.40%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 592/2000, Train Loss: 0.016611869, Train-Class-Acc: {0: '99.61%', 1: '99.27%'}, Val Loss: 0.093742497, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.23%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 593/2000, Train Loss: 0.016879352, Train-Class-Acc: {0: '99.57%', 1: '99.21%'}, Val Loss: 0.099100245, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.43%', 1: '97.13%'}, LR: 0.000100000\n",
      "Epoch 594/2000, Train Loss: 0.016245054, Train-Class-Acc: {0: '99.59%', 1: '99.22%'}, Val Loss: 0.095637467, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.08%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 595/2000, Train Loss: 0.016298456, Train-Class-Acc: {0: '99.56%', 1: '99.22%'}, Val Loss: 0.097603559, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.40%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 596/2000, Train Loss: 0.018902264, Train-Class-Acc: {0: '99.43%', 1: '99.01%'}, Val Loss: 0.121032668, Val Accuracy: 97.37%, Val-Class-Acc: {0: '98.54%', 1: '95.56%'}, LR: 0.000100000\n",
      "Epoch 597/2000, Train Loss: 0.031922607, Train-Class-Acc: {0: '98.99%', 1: '98.19%'}, Val Loss: 0.097314326, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.57%', 1: '97.08%'}, LR: 0.000100000\n",
      "Epoch 598/2000, Train Loss: 0.057669511, Train-Class-Acc: {0: '98.57%', 1: '97.29%'}, Val Loss: 0.103165786, Val Accuracy: 97.70%, Val-Class-Acc: {0: '97.99%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 599/2000, Train Loss: 0.022151855, Train-Class-Acc: {0: '99.42%', 1: '98.95%'}, Val Loss: 0.093925578, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.24%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 600/2000, Train Loss: 0.017137063, Train-Class-Acc: {0: '99.57%', 1: '99.21%'}, Val Loss: 0.090974032, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.05%', 1: '97.70%'}, LR: 0.000100000\n",
      "Epoch 601/2000, Train Loss: 0.016070062, Train-Class-Acc: {0: '99.60%', 1: '99.24%'}, Val Loss: 0.092757060, Val Accuracy: 97.87%, Val-Class-Acc: {0: '97.95%', 1: '97.75%'}, LR: 0.000100000\n",
      "Epoch 602/2000, Train Loss: 0.015373445, Train-Class-Acc: {0: '99.60%', 1: '99.29%'}, Val Loss: 0.097530943, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.18%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 603/2000, Train Loss: 0.015549476, Train-Class-Acc: {0: '99.59%', 1: '99.26%'}, Val Loss: 0.101933344, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.29%', 1: '97.27%'}, LR: 0.000100000\n",
      "Epoch 604/2000, Train Loss: 0.016243854, Train-Class-Acc: {0: '99.56%', 1: '99.18%'}, Val Loss: 0.096061886, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.09%', 1: '97.65%'}, LR: 0.000100000\n",
      "Epoch 605/2000, Train Loss: 0.015236745, Train-Class-Acc: {0: '99.59%', 1: '99.25%'}, Val Loss: 0.094274189, Val Accuracy: 97.90%, Val-Class-Acc: {0: '97.98%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 606/2000, Train Loss: 0.080656963, Train-Class-Acc: {0: '98.15%', 1: '96.56%'}, Val Loss: 0.095334719, Val Accuracy: 97.93%, Val-Class-Acc: {0: '97.79%', 1: '98.14%'}, LR: 0.000100000\n",
      "Epoch 607/2000, Train Loss: 0.018378092, Train-Class-Acc: {0: '99.56%', 1: '99.18%'}, Val Loss: 0.092420026, Val Accuracy: 97.88%, Val-Class-Acc: {0: '97.98%', 1: '97.74%'}, LR: 0.000100000\n",
      "Epoch 608/2000, Train Loss: 0.016080606, Train-Class-Acc: {0: '99.60%', 1: '99.28%'}, Val Loss: 0.099425581, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.44%', 1: '96.83%'}, LR: 0.000100000\n",
      "Epoch 609/2000, Train Loss: 0.015237398, Train-Class-Acc: {0: '99.62%', 1: '99.30%'}, Val Loss: 0.096394299, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.08%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 610/2000, Train Loss: 0.016484024, Train-Class-Acc: {0: '99.55%', 1: '99.19%'}, Val Loss: 0.106492495, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.60%', 1: '96.27%'}, LR: 0.000100000\n",
      "Epoch 611/2000, Train Loss: 0.018027215, Train-Class-Acc: {0: '99.48%', 1: '99.07%'}, Val Loss: 0.101916351, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.49%', 1: '96.96%'}, LR: 0.000100000\n",
      "Epoch 612/2000, Train Loss: 0.015818945, Train-Class-Acc: {0: '99.57%', 1: '99.21%'}, Val Loss: 0.103877835, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.86%', 1: '97.72%'}, LR: 0.000100000\n",
      "Epoch 613/2000, Train Loss: 0.038747680, Train-Class-Acc: {0: '98.93%', 1: '98.09%'}, Val Loss: 0.109217087, Val Accuracy: 97.87%, Val-Class-Acc: {0: '97.10%', 1: '99.05%'}, LR: 0.000100000\n",
      "Epoch 614/2000, Train Loss: 0.018681221, Train-Class-Acc: {0: '99.48%', 1: '99.10%'}, Val Loss: 0.096291567, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.19%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 615/2000, Train Loss: 0.015878442, Train-Class-Acc: {0: '99.58%', 1: '99.23%'}, Val Loss: 0.097223789, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.11%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 616/2000, Train Loss: 0.015566476, Train-Class-Acc: {0: '99.58%', 1: '99.24%'}, Val Loss: 0.100449840, Val Accuracy: 97.79%, Val-Class-Acc: {0: '97.73%', 1: '97.90%'}, LR: 0.000100000\n",
      "Epoch 617/2000, Train Loss: 0.065119356, Train-Class-Acc: {0: '98.22%', 1: '96.90%'}, Val Loss: 0.106859680, Val Accuracy: 97.56%, Val-Class-Acc: {0: '98.26%', 1: '96.49%'}, LR: 0.000100000\n",
      "Epoch 618/2000, Train Loss: 0.018743246, Train-Class-Acc: {0: '99.53%', 1: '99.12%'}, Val Loss: 0.098077561, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.19%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 619/2000, Train Loss: 0.019154447, Train-Class-Acc: {0: '99.46%', 1: '98.99%'}, Val Loss: 0.097484870, Val Accuracy: 97.79%, Val-Class-Acc: {0: '97.81%', 1: '97.76%'}, LR: 0.000100000\n",
      "Epoch 620/2000, Train Loss: 0.020999764, Train-Class-Acc: {0: '99.38%', 1: '98.85%'}, Val Loss: 0.096715716, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.20%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 621/2000, Train Loss: 0.015162793, Train-Class-Acc: {0: '99.61%', 1: '99.28%'}, Val Loss: 0.100661640, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.19%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 622/2000, Train Loss: 0.014334438, Train-Class-Acc: {0: '99.63%', 1: '99.34%'}, Val Loss: 0.100820011, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.35%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 623/2000, Train Loss: 0.014200189, Train-Class-Acc: {0: '99.62%', 1: '99.34%'}, Val Loss: 0.100420792, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.34%', 1: '97.25%'}, LR: 0.000100000\n",
      "Epoch 624/2000, Train Loss: 0.014981199, Train-Class-Acc: {0: '99.58%', 1: '99.27%'}, Val Loss: 0.102430159, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.26%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 625/2000, Train Loss: 0.015663834, Train-Class-Acc: {0: '99.56%', 1: '99.22%'}, Val Loss: 0.102480381, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.11%', 1: '97.49%'}, LR: 0.000100000\n",
      "Epoch 626/2000, Train Loss: 0.014346274, Train-Class-Acc: {0: '99.61%', 1: '99.30%'}, Val Loss: 0.101248128, Val Accuracy: 97.79%, Val-Class-Acc: {0: '97.74%', 1: '97.87%'}, LR: 0.000100000\n",
      "Epoch 627/2000, Train Loss: 0.099620424, Train-Class-Acc: {0: '97.83%', 1: '96.17%'}, Val Loss: 0.099678573, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.33%', 1: '96.77%'}, LR: 0.000100000\n",
      "Epoch 628/2000, Train Loss: 0.019002463, Train-Class-Acc: {0: '99.56%', 1: '99.16%'}, Val Loss: 0.094585683, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.00%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 629/2000, Train Loss: 0.028649483, Train-Class-Acc: {0: '99.09%', 1: '98.32%'}, Val Loss: 0.105383990, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.01%', 1: '99.09%'}, LR: 0.000100000\n",
      "Epoch 630/2000, Train Loss: 0.025015241, Train-Class-Acc: {0: '99.21%', 1: '98.61%'}, Val Loss: 0.099767070, Val Accuracy: 97.92%, Val-Class-Acc: {0: '97.29%', 1: '98.90%'}, LR: 0.000100000\n",
      "Epoch 631/2000, Train Loss: 0.020315790, Train-Class-Acc: {0: '99.40%', 1: '98.96%'}, Val Loss: 0.093763428, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.20%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 632/2000, Train Loss: 0.015523089, Train-Class-Acc: {0: '99.60%', 1: '99.28%'}, Val Loss: 0.101989297, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.50%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 633/2000, Train Loss: 0.014568966, Train-Class-Acc: {0: '99.63%', 1: '99.32%'}, Val Loss: 0.102172243, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.30%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 634/2000, Train Loss: 0.014951561, Train-Class-Acc: {0: '99.59%', 1: '99.27%'}, Val Loss: 0.100703523, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.03%', 1: '97.67%'}, LR: 0.000100000\n",
      "Epoch 635/2000, Train Loss: 0.014822274, Train-Class-Acc: {0: '99.59%', 1: '99.27%'}, Val Loss: 0.110697938, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.51%', 1: '96.40%'}, LR: 0.000100000\n",
      "Epoch 636/2000, Train Loss: 0.074004137, Train-Class-Acc: {0: '98.10%', 1: '96.68%'}, Val Loss: 0.108623633, Val Accuracy: 97.41%, Val-Class-Acc: {0: '98.55%', 1: '95.65%'}, LR: 0.000100000\n",
      "Epoch 637/2000, Train Loss: 0.017439847, Train-Class-Acc: {0: '99.58%', 1: '99.20%'}, Val Loss: 0.096087748, Val Accuracy: 97.85%, Val-Class-Acc: {0: '97.91%', 1: '97.75%'}, LR: 0.000100000\n",
      "Epoch 638/2000, Train Loss: 0.015454574, Train-Class-Acc: {0: '99.60%', 1: '99.31%'}, Val Loss: 0.110529981, Val Accuracy: 97.61%, Val-Class-Acc: {0: '98.55%', 1: '96.16%'}, LR: 0.000100000\n",
      "Epoch 639/2000, Train Loss: 0.014517650, Train-Class-Acc: {0: '99.64%', 1: '99.33%'}, Val Loss: 0.101319086, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.22%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 640/2000, Train Loss: 0.015875325, Train-Class-Acc: {0: '99.57%', 1: '99.21%'}, Val Loss: 0.106037079, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.08%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 641/2000, Train Loss: 0.013710869, Train-Class-Acc: {0: '99.64%', 1: '99.37%'}, Val Loss: 0.100765065, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.03%', 1: '97.68%'}, LR: 0.000100000\n",
      "Epoch 642/2000, Train Loss: 0.016129013, Train-Class-Acc: {0: '99.53%', 1: '99.20%'}, Val Loss: 0.104932433, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.96%', 1: '97.64%'}, LR: 0.000100000\n",
      "Epoch 643/2000, Train Loss: 0.013983243, Train-Class-Acc: {0: '99.62%', 1: '99.34%'}, Val Loss: 0.105790615, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.46%', 1: '97.03%'}, LR: 0.000100000\n",
      "Epoch 644/2000, Train Loss: 0.039611551, Train-Class-Acc: {0: '99.00%', 1: '98.25%'}, Val Loss: 0.117164218, Val Accuracy: 97.42%, Val-Class-Acc: {0: '98.86%', 1: '95.21%'}, LR: 0.000100000\n",
      "Epoch 645/2000, Train Loss: 0.016612773, Train-Class-Acc: {0: '99.57%', 1: '99.17%'}, Val Loss: 0.104620916, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.44%', 1: '97.00%'}, LR: 0.000100000\n",
      "Epoch 646/2000, Train Loss: 0.014720692, Train-Class-Acc: {0: '99.61%', 1: '99.30%'}, Val Loss: 0.111427478, Val Accuracy: 97.66%, Val-Class-Acc: {0: '98.51%', 1: '96.35%'}, LR: 0.000100000\n",
      "Epoch 647/2000, Train Loss: 0.015013279, Train-Class-Acc: {0: '99.58%', 1: '99.28%'}, Val Loss: 0.104871513, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.57%', 1: '96.74%'}, LR: 0.000100000\n",
      "Epoch 648/2000, Train Loss: 0.016372545, Train-Class-Acc: {0: '99.53%', 1: '99.15%'}, Val Loss: 0.103349847, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.01%', 1: '97.68%'}, LR: 0.000100000\n",
      "Epoch 649/2000, Train Loss: 0.013649983, Train-Class-Acc: {0: '99.65%', 1: '99.33%'}, Val Loss: 0.105916577, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.05%', 1: '97.54%'}, LR: 0.000100000\n",
      "Epoch 650/2000, Train Loss: 0.026514359, Train-Class-Acc: {0: '99.25%', 1: '98.65%'}, Val Loss: 0.099881514, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.00%', 1: '97.70%'}, LR: 0.000100000\n",
      "Epoch 651/2000, Train Loss: 0.014372799, Train-Class-Acc: {0: '99.62%', 1: '99.29%'}, Val Loss: 0.103709116, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.06%', 1: '97.68%'}, LR: 0.000100000\n",
      "Epoch 652/2000, Train Loss: 0.046352660, Train-Class-Acc: {0: '98.68%', 1: '97.79%'}, Val Loss: 0.102864490, Val Accuracy: 97.77%, Val-Class-Acc: {0: '98.66%', 1: '96.39%'}, LR: 0.000100000\n",
      "Epoch 653/2000, Train Loss: 0.016400336, Train-Class-Acc: {0: '99.57%', 1: '99.20%'}, Val Loss: 0.097055764, Val Accuracy: 97.88%, Val-Class-Acc: {0: '97.96%', 1: '97.75%'}, LR: 0.000100000\n",
      "Epoch 654/2000, Train Loss: 0.015257080, Train-Class-Acc: {0: '99.58%', 1: '99.27%'}, Val Loss: 0.103876930, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.32%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 655/2000, Train Loss: 0.013232460, Train-Class-Acc: {0: '99.66%', 1: '99.38%'}, Val Loss: 0.100533145, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.08%', 1: '97.68%'}, LR: 0.000100000\n",
      "Epoch 656/2000, Train Loss: 0.013093312, Train-Class-Acc: {0: '99.65%', 1: '99.39%'}, Val Loss: 0.105181735, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.32%', 1: '97.27%'}, LR: 0.000100000\n",
      "Epoch 657/2000, Train Loss: 0.013861560, Train-Class-Acc: {0: '99.61%', 1: '99.33%'}, Val Loss: 0.105492573, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.17%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 658/2000, Train Loss: 0.012953537, Train-Class-Acc: {0: '99.65%', 1: '99.38%'}, Val Loss: 0.106337439, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.24%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 659/2000, Train Loss: 0.013247845, Train-Class-Acc: {0: '99.64%', 1: '99.35%'}, Val Loss: 0.113704650, Val Accuracy: 97.70%, Val-Class-Acc: {0: '96.74%', 1: '99.18%'}, LR: 0.000100000\n",
      "Epoch 660/2000, Train Loss: 0.318352479, Train-Class-Acc: {0: '93.78%', 1: '87.80%'}, Val Loss: 0.112342068, Val Accuracy: 97.03%, Val-Class-Acc: {0: '98.31%', 1: '95.06%'}, LR: 0.000100000\n",
      "Epoch 661/2000, Train Loss: 0.036864824, Train-Class-Acc: {0: '99.14%', 1: '97.89%'}, Val Loss: 0.105693144, Val Accuracy: 97.50%, Val-Class-Acc: {0: '98.54%', 1: '95.89%'}, LR: 0.000100000\n",
      "Epoch 662/2000, Train Loss: 0.020694375, Train-Class-Acc: {0: '99.51%', 1: '99.13%'}, Val Loss: 0.099500192, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.36%', 1: '96.97%'}, LR: 0.000100000\n",
      "Epoch 663/2000, Train Loss: 0.016603128, Train-Class-Acc: {0: '99.62%', 1: '99.32%'}, Val Loss: 0.100386776, Val Accuracy: 97.76%, Val-Class-Acc: {0: '98.59%', 1: '96.49%'}, LR: 0.000100000\n",
      "Epoch 664/2000, Train Loss: 0.017031814, Train-Class-Acc: {0: '99.56%', 1: '99.23%'}, Val Loss: 0.096823926, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.87%', 1: '97.72%'}, LR: 0.000100000\n",
      "Epoch 665/2000, Train Loss: 0.014465270, Train-Class-Acc: {0: '99.65%', 1: '99.40%'}, Val Loss: 0.096734250, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.08%', 1: '97.61%'}, LR: 0.000100000\n",
      "Epoch 666/2000, Train Loss: 0.015103768, Train-Class-Acc: {0: '99.59%', 1: '99.32%'}, Val Loss: 0.108697256, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.66%', 1: '96.25%'}, LR: 0.000100000\n",
      "Epoch 667/2000, Train Loss: 0.021782062, Train-Class-Acc: {0: '99.35%', 1: '98.84%'}, Val Loss: 0.102803177, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.37%', 1: '97.05%'}, LR: 0.000100000\n",
      "Epoch 668/2000, Train Loss: 0.015930024, Train-Class-Acc: {0: '99.56%', 1: '99.21%'}, Val Loss: 0.095854913, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.08%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 669/2000, Train Loss: 0.032320733, Train-Class-Acc: {0: '99.13%', 1: '98.63%'}, Val Loss: 0.138037329, Val Accuracy: 96.74%, Val-Class-Acc: {0: '95.33%', 1: '98.92%'}, LR: 0.000100000\n",
      "Epoch 670/2000, Train Loss: 0.036261858, Train-Class-Acc: {0: '99.03%', 1: '98.27%'}, Val Loss: 0.099931565, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.18%', 1: '97.27%'}, LR: 0.000100000\n",
      "Epoch 671/2000, Train Loss: 0.014355724, Train-Class-Acc: {0: '99.66%', 1: '99.38%'}, Val Loss: 0.101683713, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.36%', 1: '97.03%'}, LR: 0.000100000\n",
      "Epoch 672/2000, Train Loss: 0.015293504, Train-Class-Acc: {0: '99.61%', 1: '99.28%'}, Val Loss: 0.098773780, Val Accuracy: 97.86%, Val-Class-Acc: {0: '97.95%', 1: '97.73%'}, LR: 0.000100000\n",
      "Epoch 673/2000, Train Loss: 0.014112554, Train-Class-Acc: {0: '99.63%', 1: '99.38%'}, Val Loss: 0.104647137, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.27%', 1: '97.07%'}, LR: 0.000100000\n",
      "Epoch 674/2000, Train Loss: 0.013236705, Train-Class-Acc: {0: '99.67%', 1: '99.40%'}, Val Loss: 0.101211810, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.25%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 675/2000, Train Loss: 0.014160146, Train-Class-Acc: {0: '99.62%', 1: '99.33%'}, Val Loss: 0.104773600, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.26%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 676/2000, Train Loss: 0.013700954, Train-Class-Acc: {0: '99.62%', 1: '99.36%'}, Val Loss: 0.116131511, Val Accuracy: 97.70%, Val-Class-Acc: {0: '98.67%', 1: '96.20%'}, LR: 0.000100000\n",
      "Epoch 677/2000, Train Loss: 0.097795742, Train-Class-Acc: {0: '97.76%', 1: '95.79%'}, Val Loss: 0.099542335, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.46%', 1: '96.47%'}, LR: 0.000100000\n",
      "Epoch 678/2000, Train Loss: 0.018479635, Train-Class-Acc: {0: '99.56%', 1: '99.18%'}, Val Loss: 0.094426227, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.87%', 1: '97.75%'}, LR: 0.000100000\n",
      "Epoch 679/2000, Train Loss: 0.014559471, Train-Class-Acc: {0: '99.66%', 1: '99.40%'}, Val Loss: 0.094623625, Val Accuracy: 97.84%, Val-Class-Acc: {0: '97.94%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 680/2000, Train Loss: 0.014137309, Train-Class-Acc: {0: '99.65%', 1: '99.37%'}, Val Loss: 0.105058277, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.49%', 1: '96.62%'}, LR: 0.000100000\n",
      "Epoch 681/2000, Train Loss: 0.014323674, Train-Class-Acc: {0: '99.63%', 1: '99.33%'}, Val Loss: 0.098356878, Val Accuracy: 97.85%, Val-Class-Acc: {0: '97.95%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 682/2000, Train Loss: 0.013242308, Train-Class-Acc: {0: '99.66%', 1: '99.40%'}, Val Loss: 0.103917587, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.50%', 1: '96.96%'}, LR: 0.000100000\n",
      "Epoch 683/2000, Train Loss: 0.014559285, Train-Class-Acc: {0: '99.61%', 1: '99.27%'}, Val Loss: 0.101523355, Val Accuracy: 97.75%, Val-Class-Acc: {0: '97.68%', 1: '97.86%'}, LR: 0.000100000\n",
      "Epoch 684/2000, Train Loss: 0.070953458, Train-Class-Acc: {0: '98.38%', 1: '97.26%'}, Val Loss: 0.112191445, Val Accuracy: 97.48%, Val-Class-Acc: {0: '97.67%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 685/2000, Train Loss: 0.021915125, Train-Class-Acc: {0: '99.44%', 1: '98.98%'}, Val Loss: 0.098464434, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.24%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 686/2000, Train Loss: 0.014680657, Train-Class-Acc: {0: '99.66%', 1: '99.35%'}, Val Loss: 0.098968362, Val Accuracy: 97.78%, Val-Class-Acc: {0: '97.73%', 1: '97.85%'}, LR: 0.000100000\n",
      "Epoch 687/2000, Train Loss: 0.014105615, Train-Class-Acc: {0: '99.65%', 1: '99.35%'}, Val Loss: 0.098456560, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.22%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 688/2000, Train Loss: 0.013495469, Train-Class-Acc: {0: '99.66%', 1: '99.40%'}, Val Loss: 0.104079499, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.44%', 1: '96.88%'}, LR: 0.000100000\n",
      "Epoch 689/2000, Train Loss: 0.013036889, Train-Class-Acc: {0: '99.67%', 1: '99.39%'}, Val Loss: 0.100821594, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.13%', 1: '97.57%'}, LR: 0.000100000\n",
      "Epoch 690/2000, Train Loss: 0.015018276, Train-Class-Acc: {0: '99.58%', 1: '99.25%'}, Val Loss: 0.102591309, Val Accuracy: 97.87%, Val-Class-Acc: {0: '97.93%', 1: '97.76%'}, LR: 0.000100000\n",
      "Epoch 691/2000, Train Loss: 0.013278953, Train-Class-Acc: {0: '99.64%', 1: '99.38%'}, Val Loss: 0.108191179, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.65%', 1: '96.52%'}, LR: 0.000100000\n",
      "Epoch 692/2000, Train Loss: 0.012895738, Train-Class-Acc: {0: '99.66%', 1: '99.39%'}, Val Loss: 0.107932572, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.26%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 693/2000, Train Loss: 0.078808506, Train-Class-Acc: {0: '98.37%', 1: '97.45%'}, Val Loss: 0.118838377, Val Accuracy: 97.22%, Val-Class-Acc: {0: '98.14%', 1: '95.81%'}, LR: 0.000100000\n",
      "Epoch 694/2000, Train Loss: 0.060670876, Train-Class-Acc: {0: '98.37%', 1: '96.67%'}, Val Loss: 0.095443785, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.07%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 695/2000, Train Loss: 0.016440831, Train-Class-Acc: {0: '99.64%', 1: '99.33%'}, Val Loss: 0.101490819, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.16%', 1: '97.04%'}, LR: 0.000100000\n",
      "Epoch 696/2000, Train Loss: 0.014600307, Train-Class-Acc: {0: '99.65%', 1: '99.37%'}, Val Loss: 0.099521237, Val Accuracy: 97.70%, Val-Class-Acc: {0: '97.93%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 697/2000, Train Loss: 0.013997700, Train-Class-Acc: {0: '99.66%', 1: '99.37%'}, Val Loss: 0.099400872, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.36%', 1: '97.23%'}, LR: 0.000100000\n",
      "Epoch 698/2000, Train Loss: 0.012964572, Train-Class-Acc: {0: '99.68%', 1: '99.43%'}, Val Loss: 0.103802855, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.23%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 699/2000, Train Loss: 0.012593033, Train-Class-Acc: {0: '99.68%', 1: '99.44%'}, Val Loss: 0.103321695, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.30%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 700/2000, Train Loss: 0.012997328, Train-Class-Acc: {0: '99.66%', 1: '99.39%'}, Val Loss: 0.103010152, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.06%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 701/2000, Train Loss: 0.013413039, Train-Class-Acc: {0: '99.64%', 1: '99.37%'}, Val Loss: 0.105973995, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.20%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 702/2000, Train Loss: 0.012429887, Train-Class-Acc: {0: '99.67%', 1: '99.42%'}, Val Loss: 0.106218168, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.27%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 703/2000, Train Loss: 0.013148300, Train-Class-Acc: {0: '99.63%', 1: '99.38%'}, Val Loss: 0.118819867, Val Accuracy: 97.66%, Val-Class-Acc: {0: '98.61%', 1: '96.21%'}, LR: 0.000100000\n",
      "Epoch 704/2000, Train Loss: 0.017888859, Train-Class-Acc: {0: '99.48%', 1: '99.09%'}, Val Loss: 0.103988195, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.09%', 1: '97.60%'}, LR: 0.000100000\n",
      "Epoch 705/2000, Train Loss: 0.065603742, Train-Class-Acc: {0: '98.57%', 1: '97.35%'}, Val Loss: 0.110577245, Val Accuracy: 97.76%, Val-Class-Acc: {0: '97.71%', 1: '97.84%'}, LR: 0.000100000\n",
      "Epoch 706/2000, Train Loss: 0.017128287, Train-Class-Acc: {0: '99.58%', 1: '99.20%'}, Val Loss: 0.102120782, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.24%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 707/2000, Train Loss: 0.013705946, Train-Class-Acc: {0: '99.66%', 1: '99.39%'}, Val Loss: 0.106414394, Val Accuracy: 97.77%, Val-Class-Acc: {0: '98.52%', 1: '96.61%'}, LR: 0.000100000\n",
      "Epoch 708/2000, Train Loss: 0.013346084, Train-Class-Acc: {0: '99.65%', 1: '99.40%'}, Val Loss: 0.103007821, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.14%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 709/2000, Train Loss: 0.012286072, Train-Class-Acc: {0: '99.68%', 1: '99.44%'}, Val Loss: 0.104593437, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.30%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 710/2000, Train Loss: 0.012243902, Train-Class-Acc: {0: '99.68%', 1: '99.43%'}, Val Loss: 0.105835847, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.29%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 711/2000, Train Loss: 0.012780376, Train-Class-Acc: {0: '99.65%', 1: '99.40%'}, Val Loss: 0.109258230, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.40%', 1: '96.94%'}, LR: 0.000100000\n",
      "Epoch 712/2000, Train Loss: 0.013589974, Train-Class-Acc: {0: '99.61%', 1: '99.35%'}, Val Loss: 0.117910534, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.74%', 1: '96.15%'}, LR: 0.000100000\n",
      "Epoch 713/2000, Train Loss: 0.039887656, Train-Class-Acc: {0: '99.13%', 1: '98.46%'}, Val Loss: 0.106836510, Val Accuracy: 97.72%, Val-Class-Acc: {0: '97.71%', 1: '97.74%'}, LR: 0.000100000\n",
      "Epoch 714/2000, Train Loss: 0.014025842, Train-Class-Acc: {0: '99.64%', 1: '99.35%'}, Val Loss: 0.102460887, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.12%', 1: '97.27%'}, LR: 0.000100000\n",
      "Epoch 715/2000, Train Loss: 0.013384741, Train-Class-Acc: {0: '99.64%', 1: '99.37%'}, Val Loss: 0.111180765, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.69%', 1: '96.40%'}, LR: 0.000100000\n",
      "Epoch 716/2000, Train Loss: 0.013876845, Train-Class-Acc: {0: '99.62%', 1: '99.29%'}, Val Loss: 0.106076552, Val Accuracy: 97.75%, Val-Class-Acc: {0: '97.67%', 1: '97.87%'}, LR: 0.000100000\n",
      "Epoch 717/2000, Train Loss: 0.155223498, Train-Class-Acc: {0: '96.56%', 1: '93.28%'}, Val Loss: 0.121064254, Val Accuracy: 97.02%, Val-Class-Acc: {0: '97.85%', 1: '95.73%'}, LR: 0.000100000\n",
      "Epoch 718/2000, Train Loss: 0.035897769, Train-Class-Acc: {0: '99.01%', 1: '98.17%'}, Val Loss: 0.101023333, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.20%', 1: '96.98%'}, LR: 0.000100000\n",
      "Epoch 719/2000, Train Loss: 0.015742260, Train-Class-Acc: {0: '99.67%', 1: '99.39%'}, Val Loss: 0.095267771, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.16%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 720/2000, Train Loss: 0.013932624, Train-Class-Acc: {0: '99.69%', 1: '99.43%'}, Val Loss: 0.095357857, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.25%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 721/2000, Train Loss: 0.014841661, Train-Class-Acc: {0: '99.62%', 1: '99.33%'}, Val Loss: 0.098183686, Val Accuracy: 97.80%, Val-Class-Acc: {0: '97.78%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 722/2000, Train Loss: 0.020533779, Train-Class-Acc: {0: '99.36%', 1: '98.90%'}, Val Loss: 0.104100684, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.31%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 723/2000, Train Loss: 0.015098023, Train-Class-Acc: {0: '99.61%', 1: '99.24%'}, Val Loss: 0.103620365, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.20%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 724/2000, Train Loss: 0.092456416, Train-Class-Acc: {0: '97.51%', 1: '95.62%'}, Val Loss: 0.104622139, Val Accuracy: 97.74%, Val-Class-Acc: {0: '97.72%', 1: '97.76%'}, LR: 0.000100000\n",
      "Epoch 725/2000, Train Loss: 0.017652082, Train-Class-Acc: {0: '99.65%', 1: '99.28%'}, Val Loss: 0.094404080, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.06%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 726/2000, Train Loss: 0.013935097, Train-Class-Acc: {0: '99.68%', 1: '99.44%'}, Val Loss: 0.101513345, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.51%', 1: '96.50%'}, LR: 0.000100000\n",
      "Epoch 727/2000, Train Loss: 0.013648997, Train-Class-Acc: {0: '99.67%', 1: '99.41%'}, Val Loss: 0.097737281, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.02%', 1: '97.58%'}, LR: 0.000100000\n",
      "Epoch 728/2000, Train Loss: 0.012944549, Train-Class-Acc: {0: '99.67%', 1: '99.43%'}, Val Loss: 0.098686450, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.18%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 729/2000, Train Loss: 0.012965556, Train-Class-Acc: {0: '99.67%', 1: '99.42%'}, Val Loss: 0.103663081, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.39%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 730/2000, Train Loss: 0.039077163, Train-Class-Acc: {0: '98.72%', 1: '97.79%'}, Val Loss: 0.119060163, Val Accuracy: 97.50%, Val-Class-Acc: {0: '98.77%', 1: '95.54%'}, LR: 0.000100000\n",
      "Epoch 731/2000, Train Loss: 0.020758636, Train-Class-Acc: {0: '99.42%', 1: '98.86%'}, Val Loss: 0.099791795, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.93%', 1: '97.67%'}, LR: 0.000100000\n",
      "Epoch 732/2000, Train Loss: 0.012636710, Train-Class-Acc: {0: '99.69%', 1: '99.46%'}, Val Loss: 0.105653613, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.38%', 1: '97.00%'}, LR: 0.000100000\n",
      "Epoch 733/2000, Train Loss: 0.012599606, Train-Class-Acc: {0: '99.68%', 1: '99.44%'}, Val Loss: 0.104074026, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.22%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 734/2000, Train Loss: 0.012393664, Train-Class-Acc: {0: '99.68%', 1: '99.43%'}, Val Loss: 0.105771346, Val Accuracy: 97.78%, Val-Class-Acc: {0: '97.90%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 735/2000, Train Loss: 0.012505235, Train-Class-Acc: {0: '99.66%', 1: '99.42%'}, Val Loss: 0.102384722, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.19%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 736/2000, Train Loss: 0.012212266, Train-Class-Acc: {0: '99.67%', 1: '99.43%'}, Val Loss: 0.105484047, Val Accuracy: 97.85%, Val-Class-Acc: {0: '97.99%', 1: '97.63%'}, LR: 0.000100000\n",
      "Epoch 737/2000, Train Loss: 0.011805481, Train-Class-Acc: {0: '99.68%', 1: '99.45%'}, Val Loss: 0.110233181, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.12%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 738/2000, Train Loss: 0.011730413, Train-Class-Acc: {0: '99.68%', 1: '99.45%'}, Val Loss: 0.109864933, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.28%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 739/2000, Train Loss: 0.012110994, Train-Class-Acc: {0: '99.67%', 1: '99.42%'}, Val Loss: 0.110247885, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.12%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 740/2000, Train Loss: 0.011595636, Train-Class-Acc: {0: '99.68%', 1: '99.45%'}, Val Loss: 0.107137311, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.03%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 741/2000, Train Loss: 0.011516354, Train-Class-Acc: {0: '99.68%', 1: '99.46%'}, Val Loss: 0.114099776, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.37%', 1: '97.08%'}, LR: 0.000100000\n",
      "Epoch 742/2000, Train Loss: 0.011757691, Train-Class-Acc: {0: '99.67%', 1: '99.44%'}, Val Loss: 0.115293162, Val Accuracy: 97.76%, Val-Class-Acc: {0: '98.35%', 1: '96.84%'}, LR: 0.000100000\n",
      "Epoch 743/2000, Train Loss: 0.048189750, Train-Class-Acc: {0: '98.98%', 1: '98.19%'}, Val Loss: 0.140986536, Val Accuracy: 97.07%, Val-Class-Acc: {0: '98.36%', 1: '95.10%'}, LR: 0.000100000\n",
      "Epoch 744/2000, Train Loss: 0.023015213, Train-Class-Acc: {0: '99.36%', 1: '98.73%'}, Val Loss: 0.115107589, Val Accuracy: 97.61%, Val-Class-Acc: {0: '97.87%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 745/2000, Train Loss: 0.012689525, Train-Class-Acc: {0: '99.67%', 1: '99.43%'}, Val Loss: 0.119591472, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.35%', 1: '96.65%'}, LR: 0.000100000\n",
      "Epoch 746/2000, Train Loss: 0.011651896, Train-Class-Acc: {0: '99.69%', 1: '99.47%'}, Val Loss: 0.116018613, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.18%', 1: '97.03%'}, LR: 0.000100000\n",
      "Epoch 747/2000, Train Loss: 0.011400027, Train-Class-Acc: {0: '99.69%', 1: '99.47%'}, Val Loss: 0.110833950, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.04%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 748/2000, Train Loss: 0.011643555, Train-Class-Acc: {0: '99.69%', 1: '99.45%'}, Val Loss: 0.107967707, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.09%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 749/2000, Train Loss: 0.011970121, Train-Class-Acc: {0: '99.68%', 1: '99.41%'}, Val Loss: 0.112883215, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.26%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 750/2000, Train Loss: 0.011220980, Train-Class-Acc: {0: '99.69%', 1: '99.47%'}, Val Loss: 0.110067431, Val Accuracy: 97.84%, Val-Class-Acc: {0: '97.93%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 751/2000, Train Loss: 0.012433809, Train-Class-Acc: {0: '99.66%', 1: '99.37%'}, Val Loss: 0.111952918, Val Accuracy: 97.66%, Val-Class-Acc: {0: '97.20%', 1: '98.36%'}, LR: 0.000100000\n",
      "Epoch 752/2000, Train Loss: 0.203014146, Train-Class-Acc: {0: '96.01%', 1: '92.59%'}, Val Loss: 0.106519172, Val Accuracy: 97.62%, Val-Class-Acc: {0: '97.62%', 1: '97.61%'}, LR: 0.000100000\n",
      "Epoch 753/2000, Train Loss: 0.022101350, Train-Class-Acc: {0: '99.49%', 1: '98.99%'}, Val Loss: 0.096023234, Val Accuracy: 97.77%, Val-Class-Acc: {0: '97.87%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 754/2000, Train Loss: 0.014043592, Train-Class-Acc: {0: '99.69%', 1: '99.45%'}, Val Loss: 0.101257597, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.04%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 755/2000, Train Loss: 0.013015955, Train-Class-Acc: {0: '99.70%', 1: '99.47%'}, Val Loss: 0.100390618, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.24%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 756/2000, Train Loss: 0.012334530, Train-Class-Acc: {0: '99.70%', 1: '99.48%'}, Val Loss: 0.097346925, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.32%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 757/2000, Train Loss: 0.012114319, Train-Class-Acc: {0: '99.69%', 1: '99.47%'}, Val Loss: 0.100379899, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.05%', 1: '97.51%'}, LR: 0.000100000\n",
      "Epoch 758/2000, Train Loss: 0.012165587, Train-Class-Acc: {0: '99.68%', 1: '99.47%'}, Val Loss: 0.101001635, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.25%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 759/2000, Train Loss: 0.012270865, Train-Class-Acc: {0: '99.68%', 1: '99.44%'}, Val Loss: 0.103202908, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.31%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 760/2000, Train Loss: 0.040272502, Train-Class-Acc: {0: '98.92%', 1: '98.13%'}, Val Loss: 0.120203371, Val Accuracy: 97.45%, Val-Class-Acc: {0: '98.77%', 1: '95.42%'}, LR: 0.000100000\n",
      "Epoch 761/2000, Train Loss: 0.022939126, Train-Class-Acc: {0: '99.35%', 1: '98.72%'}, Val Loss: 0.101804900, Val Accuracy: 97.78%, Val-Class-Acc: {0: '97.93%', 1: '97.54%'}, LR: 0.000100000\n",
      "Epoch 762/2000, Train Loss: 0.012713803, Train-Class-Acc: {0: '99.69%', 1: '99.44%'}, Val Loss: 0.102301561, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.28%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 763/2000, Train Loss: 0.012198524, Train-Class-Acc: {0: '99.68%', 1: '99.46%'}, Val Loss: 0.102233253, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.08%', 1: '97.63%'}, LR: 0.000100000\n",
      "Epoch 764/2000, Train Loss: 0.011734355, Train-Class-Acc: {0: '99.69%', 1: '99.47%'}, Val Loss: 0.104436852, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.31%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 765/2000, Train Loss: 0.011990675, Train-Class-Acc: {0: '99.67%', 1: '99.44%'}, Val Loss: 0.108454692, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.24%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 766/2000, Train Loss: 0.010997107, Train-Class-Acc: {0: '99.71%', 1: '99.49%'}, Val Loss: 0.105657243, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.20%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 767/2000, Train Loss: 0.010851178, Train-Class-Acc: {0: '99.70%', 1: '99.50%'}, Val Loss: 0.110947897, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.34%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 768/2000, Train Loss: 0.011037231, Train-Class-Acc: {0: '99.70%', 1: '99.48%'}, Val Loss: 0.112068649, Val Accuracy: 97.76%, Val-Class-Acc: {0: '98.04%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 769/2000, Train Loss: 0.011990879, Train-Class-Acc: {0: '99.67%', 1: '99.41%'}, Val Loss: 0.111882103, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.34%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 770/2000, Train Loss: 0.012263699, Train-Class-Acc: {0: '99.64%', 1: '99.41%'}, Val Loss: 0.145438644, Val Accuracy: 97.33%, Val-Class-Acc: {0: '98.84%', 1: '95.00%'}, LR: 0.000100000\n",
      "Epoch 771/2000, Train Loss: 0.190911561, Train-Class-Acc: {0: '96.03%', 1: '92.82%'}, Val Loss: 0.118535760, Val Accuracy: 97.47%, Val-Class-Acc: {0: '97.76%', 1: '97.02%'}, LR: 0.000100000\n",
      "Epoch 772/2000, Train Loss: 0.028328473, Train-Class-Acc: {0: '99.27%', 1: '98.49%'}, Val Loss: 0.093264322, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.19%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 773/2000, Train Loss: 0.014750556, Train-Class-Acc: {0: '99.69%', 1: '99.43%'}, Val Loss: 0.096047695, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.11%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 774/2000, Train Loss: 0.014257866, Train-Class-Acc: {0: '99.65%', 1: '99.40%'}, Val Loss: 0.098538317, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.41%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 775/2000, Train Loss: 0.012083002, Train-Class-Acc: {0: '99.72%', 1: '99.49%'}, Val Loss: 0.097651100, Val Accuracy: 97.84%, Val-Class-Acc: {0: '97.94%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 776/2000, Train Loss: 0.011901342, Train-Class-Acc: {0: '99.70%', 1: '99.49%'}, Val Loss: 0.098523426, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.06%', 1: '97.60%'}, LR: 0.000100000\n",
      "Epoch 777/2000, Train Loss: 0.011676539, Train-Class-Acc: {0: '99.70%', 1: '99.49%'}, Val Loss: 0.100322836, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.87%', 1: '97.74%'}, LR: 0.000100000\n",
      "Epoch 778/2000, Train Loss: 0.053178468, Train-Class-Acc: {0: '98.41%', 1: '97.39%'}, Val Loss: 0.112894751, Val Accuracy: 97.34%, Val-Class-Acc: {0: '98.78%', 1: '95.11%'}, LR: 0.000100000\n",
      "Epoch 779/2000, Train Loss: 0.029481894, Train-Class-Acc: {0: '99.18%', 1: '98.39%'}, Val Loss: 0.102448049, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.60%', 1: '96.43%'}, LR: 0.000100000\n",
      "Epoch 780/2000, Train Loss: 0.012665579, Train-Class-Acc: {0: '99.71%', 1: '99.48%'}, Val Loss: 0.099220047, Val Accuracy: 97.69%, Val-Class-Acc: {0: '97.93%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 781/2000, Train Loss: 0.011870054, Train-Class-Acc: {0: '99.71%', 1: '99.48%'}, Val Loss: 0.104457035, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.28%', 1: '96.87%'}, LR: 0.000100000\n",
      "Epoch 782/2000, Train Loss: 0.011348785, Train-Class-Acc: {0: '99.72%', 1: '99.50%'}, Val Loss: 0.103912789, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.02%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 783/2000, Train Loss: 0.011593478, Train-Class-Acc: {0: '99.69%', 1: '99.49%'}, Val Loss: 0.105725754, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.26%', 1: '96.95%'}, LR: 0.000100000\n",
      "Epoch 784/2000, Train Loss: 0.011053353, Train-Class-Acc: {0: '99.71%', 1: '99.50%'}, Val Loss: 0.107591652, Val Accuracy: 97.65%, Val-Class-Acc: {0: '97.82%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 785/2000, Train Loss: 0.011318310, Train-Class-Acc: {0: '99.70%', 1: '99.49%'}, Val Loss: 0.107188447, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.13%', 1: '97.13%'}, LR: 0.000100000\n",
      "Epoch 786/2000, Train Loss: 0.011050901, Train-Class-Acc: {0: '99.70%', 1: '99.49%'}, Val Loss: 0.107306580, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.28%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 787/2000, Train Loss: 0.010722329, Train-Class-Acc: {0: '99.71%', 1: '99.50%'}, Val Loss: 0.111528657, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.09%', 1: '97.13%'}, LR: 0.000100000\n",
      "Epoch 788/2000, Train Loss: 0.078880245, Train-Class-Acc: {0: '98.13%', 1: '96.88%'}, Val Loss: 0.135261854, Val Accuracy: 96.65%, Val-Class-Acc: {0: '98.55%', 1: '93.74%'}, LR: 0.000100000\n",
      "Epoch 789/2000, Train Loss: 0.018667070, Train-Class-Acc: {0: '99.55%', 1: '99.06%'}, Val Loss: 0.109211430, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.18%', 1: '96.92%'}, LR: 0.000100000\n",
      "Epoch 790/2000, Train Loss: 0.011931649, Train-Class-Acc: {0: '99.72%', 1: '99.49%'}, Val Loss: 0.110703484, Val Accuracy: 97.70%, Val-Class-Acc: {0: '98.30%', 1: '96.78%'}, LR: 0.000100000\n",
      "Epoch 791/2000, Train Loss: 0.011604082, Train-Class-Acc: {0: '99.71%', 1: '99.49%'}, Val Loss: 0.112298271, Val Accuracy: 97.66%, Val-Class-Acc: {0: '98.25%', 1: '96.75%'}, LR: 0.000100000\n",
      "Epoch 792/2000, Train Loss: 0.011812115, Train-Class-Acc: {0: '99.68%', 1: '99.47%'}, Val Loss: 0.111068135, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.49%', 1: '96.57%'}, LR: 0.000100000\n",
      "Epoch 793/2000, Train Loss: 0.011228961, Train-Class-Acc: {0: '99.71%', 1: '99.49%'}, Val Loss: 0.109649385, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.12%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 794/2000, Train Loss: 0.011710840, Train-Class-Acc: {0: '99.68%', 1: '99.46%'}, Val Loss: 0.112815377, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.32%', 1: '96.83%'}, LR: 0.000100000\n",
      "Epoch 795/2000, Train Loss: 0.010973782, Train-Class-Acc: {0: '99.70%', 1: '99.50%'}, Val Loss: 0.112086383, Val Accuracy: 97.64%, Val-Class-Acc: {0: '97.87%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 796/2000, Train Loss: 0.011207995, Train-Class-Acc: {0: '99.68%', 1: '99.49%'}, Val Loss: 0.115230107, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.35%', 1: '96.72%'}, LR: 0.000100000\n",
      "Epoch 797/2000, Train Loss: 0.010626228, Train-Class-Acc: {0: '99.71%', 1: '99.51%'}, Val Loss: 0.118243423, Val Accuracy: 97.56%, Val-Class-Acc: {0: '98.49%', 1: '96.14%'}, LR: 0.000100000\n",
      "Epoch 798/2000, Train Loss: 0.010961543, Train-Class-Acc: {0: '99.69%', 1: '99.49%'}, Val Loss: 0.117912637, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.24%', 1: '96.93%'}, LR: 0.000100000\n",
      "Epoch 799/2000, Train Loss: 0.011192809, Train-Class-Acc: {0: '99.69%', 1: '99.47%'}, Val Loss: 0.118414231, Val Accuracy: 97.63%, Val-Class-Acc: {0: '97.83%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 800/2000, Train Loss: 0.098628929, Train-Class-Acc: {0: '97.88%', 1: '96.39%'}, Val Loss: 0.102772836, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.31%', 1: '96.83%'}, LR: 0.000100000\n",
      "Epoch 801/2000, Train Loss: 0.013907843, Train-Class-Acc: {0: '99.70%', 1: '99.41%'}, Val Loss: 0.098439996, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.62%', 1: '96.92%'}, LR: 0.000100000\n",
      "Epoch 802/2000, Train Loss: 0.011615779, Train-Class-Acc: {0: '99.72%', 1: '99.50%'}, Val Loss: 0.101338059, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.39%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 803/2000, Train Loss: 0.011289507, Train-Class-Acc: {0: '99.71%', 1: '99.51%'}, Val Loss: 0.106056965, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.76%', 1: '96.47%'}, LR: 0.000100000\n",
      "Epoch 804/2000, Train Loss: 0.012407406, Train-Class-Acc: {0: '99.66%', 1: '99.42%'}, Val Loss: 0.104498080, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.39%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 805/2000, Train Loss: 0.020652072, Train-Class-Acc: {0: '99.38%', 1: '98.86%'}, Val Loss: 0.102634702, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.40%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 806/2000, Train Loss: 0.013428940, Train-Class-Acc: {0: '99.61%', 1: '99.34%'}, Val Loss: 0.104734030, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.42%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 807/2000, Train Loss: 0.010955875, Train-Class-Acc: {0: '99.71%', 1: '99.50%'}, Val Loss: 0.111982762, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.49%', 1: '96.52%'}, LR: 0.000100000\n",
      "Epoch 808/2000, Train Loss: 0.011097835, Train-Class-Acc: {0: '99.70%', 1: '99.49%'}, Val Loss: 0.104431456, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.31%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 809/2000, Train Loss: 0.011301207, Train-Class-Acc: {0: '99.69%', 1: '99.47%'}, Val Loss: 0.108327186, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.09%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 810/2000, Train Loss: 0.010424626, Train-Class-Acc: {0: '99.70%', 1: '99.52%'}, Val Loss: 0.108154461, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.03%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 811/2000, Train Loss: 0.010312039, Train-Class-Acc: {0: '99.71%', 1: '99.51%'}, Val Loss: 0.111309883, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.13%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 812/2000, Train Loss: 0.011437083, Train-Class-Acc: {0: '99.68%', 1: '99.44%'}, Val Loss: 0.108451289, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.29%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 813/2000, Train Loss: 0.010165613, Train-Class-Acc: {0: '99.72%', 1: '99.52%'}, Val Loss: 0.111372290, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.26%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 814/2000, Train Loss: 0.025104054, Train-Class-Acc: {0: '99.39%', 1: '99.10%'}, Val Loss: 0.194673769, Val Accuracy: 96.78%, Val-Class-Acc: {0: '98.74%', 1: '93.76%'}, LR: 0.000100000\n",
      "Epoch 815/2000, Train Loss: 0.039221948, Train-Class-Acc: {0: '98.97%', 1: '97.91%'}, Val Loss: 0.104935365, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.13%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 816/2000, Train Loss: 0.011165709, Train-Class-Acc: {0: '99.71%', 1: '99.50%'}, Val Loss: 0.117454112, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.57%', 1: '96.46%'}, LR: 0.000100000\n",
      "Epoch 817/2000, Train Loss: 0.011079441, Train-Class-Acc: {0: '99.70%', 1: '99.48%'}, Val Loss: 0.115190758, Val Accuracy: 97.66%, Val-Class-Acc: {0: '97.91%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 818/2000, Train Loss: 0.010987531, Train-Class-Acc: {0: '99.70%', 1: '99.49%'}, Val Loss: 0.116572182, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.23%', 1: '96.96%'}, LR: 0.000100000\n",
      "Epoch 819/2000, Train Loss: 0.010206694, Train-Class-Acc: {0: '99.72%', 1: '99.53%'}, Val Loss: 0.111789992, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.26%', 1: '97.13%'}, LR: 0.000100000\n",
      "Epoch 820/2000, Train Loss: 0.009971144, Train-Class-Acc: {0: '99.72%', 1: '99.53%'}, Val Loss: 0.112945141, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.44%', 1: '96.91%'}, LR: 0.000100000\n",
      "Epoch 821/2000, Train Loss: 0.010080323, Train-Class-Acc: {0: '99.71%', 1: '99.52%'}, Val Loss: 0.109675517, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.12%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 822/2000, Train Loss: 0.010301034, Train-Class-Acc: {0: '99.70%', 1: '99.51%'}, Val Loss: 0.128485964, Val Accuracy: 97.62%, Val-Class-Acc: {0: '98.70%', 1: '95.96%'}, LR: 0.000100000\n",
      "Epoch 823/2000, Train Loss: 0.010672100, Train-Class-Acc: {0: '99.70%', 1: '99.47%'}, Val Loss: 0.120656570, Val Accuracy: 97.64%, Val-Class-Acc: {0: '98.19%', 1: '96.81%'}, LR: 0.000100000\n",
      "Epoch 824/2000, Train Loss: 0.009747210, Train-Class-Acc: {0: '99.72%', 1: '99.53%'}, Val Loss: 0.118534985, Val Accuracy: 97.60%, Val-Class-Acc: {0: '97.90%', 1: '97.13%'}, LR: 0.000100000\n",
      "Epoch 825/2000, Train Loss: 0.011454339, Train-Class-Acc: {0: '99.67%', 1: '99.41%'}, Val Loss: 0.115648852, Val Accuracy: 97.64%, Val-Class-Acc: {0: '97.21%', 1: '98.31%'}, LR: 0.000100000\n",
      "Epoch 826/2000, Train Loss: 0.165044064, Train-Class-Acc: {0: '96.73%', 1: '93.88%'}, Val Loss: 0.095709136, Val Accuracy: 97.55%, Val-Class-Acc: {0: '98.60%', 1: '95.95%'}, LR: 0.000100000\n",
      "Epoch 827/2000, Train Loss: 0.016679964, Train-Class-Acc: {0: '99.66%', 1: '99.28%'}, Val Loss: 0.100516263, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.16%', 1: '97.04%'}, LR: 0.000100000\n",
      "Epoch 828/2000, Train Loss: 0.012688947, Train-Class-Acc: {0: '99.69%', 1: '99.48%'}, Val Loss: 0.099542622, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.27%', 1: '96.92%'}, LR: 0.000100000\n",
      "Epoch 829/2000, Train Loss: 0.011153742, Train-Class-Acc: {0: '99.73%', 1: '99.52%'}, Val Loss: 0.099415888, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.25%', 1: '97.15%'}, LR: 0.000100000\n",
      "Epoch 830/2000, Train Loss: 0.010637807, Train-Class-Acc: {0: '99.73%', 1: '99.54%'}, Val Loss: 0.100093293, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.13%', 1: '97.54%'}, LR: 0.000100000\n",
      "Epoch 831/2000, Train Loss: 0.010266349, Train-Class-Acc: {0: '99.73%', 1: '99.55%'}, Val Loss: 0.099932355, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.00%', 1: '97.63%'}, LR: 0.000100000\n",
      "Epoch 832/2000, Train Loss: 0.010433647, Train-Class-Acc: {0: '99.72%', 1: '99.54%'}, Val Loss: 0.105759337, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.33%', 1: '97.17%'}, LR: 0.000100000\n",
      "Epoch 833/2000, Train Loss: 0.010183206, Train-Class-Acc: {0: '99.72%', 1: '99.53%'}, Val Loss: 0.105631912, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.91%', 1: '97.68%'}, LR: 0.000100000\n",
      "Epoch 834/2000, Train Loss: 0.010916936, Train-Class-Acc: {0: '99.70%', 1: '99.50%'}, Val Loss: 0.106975196, Val Accuracy: 97.76%, Val-Class-Acc: {0: '98.30%', 1: '96.94%'}, LR: 0.000100000\n",
      "Epoch 835/2000, Train Loss: 0.010213128, Train-Class-Acc: {0: '99.72%', 1: '99.53%'}, Val Loss: 0.104970174, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.13%', 1: '97.57%'}, LR: 0.000100000\n",
      "Epoch 836/2000, Train Loss: 0.016137455, Train-Class-Acc: {0: '99.50%', 1: '99.15%'}, Val Loss: 0.108618521, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.39%', 1: '97.13%'}, LR: 0.000100000\n",
      "Epoch 837/2000, Train Loss: 0.010878015, Train-Class-Acc: {0: '99.70%', 1: '99.49%'}, Val Loss: 0.107702405, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.33%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 838/2000, Train Loss: 0.042533439, Train-Class-Acc: {0: '99.12%', 1: '98.47%'}, Val Loss: 0.108682143, Val Accuracy: 97.76%, Val-Class-Acc: {0: '97.63%', 1: '97.97%'}, LR: 0.000100000\n",
      "Epoch 839/2000, Train Loss: 0.011536041, Train-Class-Acc: {0: '99.71%', 1: '99.47%'}, Val Loss: 0.110684453, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.28%', 1: '96.90%'}, LR: 0.000100000\n",
      "Epoch 840/2000, Train Loss: 0.010052438, Train-Class-Acc: {0: '99.74%', 1: '99.54%'}, Val Loss: 0.111242989, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.07%', 1: '97.12%'}, LR: 0.000100000\n",
      "Epoch 841/2000, Train Loss: 0.009993817, Train-Class-Acc: {0: '99.72%', 1: '99.55%'}, Val Loss: 0.108306002, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.27%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 842/2000, Train Loss: 0.009622684, Train-Class-Acc: {0: '99.74%', 1: '99.55%'}, Val Loss: 0.108443128, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.11%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 843/2000, Train Loss: 0.010614959, Train-Class-Acc: {0: '99.70%', 1: '99.50%'}, Val Loss: 0.108656766, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.20%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 844/2000, Train Loss: 0.035591008, Train-Class-Acc: {0: '99.03%', 1: '98.43%'}, Val Loss: 0.128772938, Val Accuracy: 97.39%, Val-Class-Acc: {0: '98.91%', 1: '95.05%'}, LR: 0.000100000\n",
      "Epoch 845/2000, Train Loss: 0.011777035, Train-Class-Acc: {0: '99.70%', 1: '99.42%'}, Val Loss: 0.114565981, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.00%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 846/2000, Train Loss: 0.009757103, Train-Class-Acc: {0: '99.74%', 1: '99.55%'}, Val Loss: 0.107229660, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.99%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 847/2000, Train Loss: 0.009796559, Train-Class-Acc: {0: '99.73%', 1: '99.55%'}, Val Loss: 0.112700580, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.21%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 848/2000, Train Loss: 0.011691518, Train-Class-Acc: {0: '99.66%', 1: '99.42%'}, Val Loss: 0.116098023, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.58%', 1: '96.73%'}, LR: 0.000100000\n",
      "Epoch 849/2000, Train Loss: 0.076227972, Train-Class-Acc: {0: '98.19%', 1: '96.67%'}, Val Loss: 0.159054329, Val Accuracy: 96.62%, Val-Class-Acc: {0: '98.94%', 1: '93.06%'}, LR: 0.000100000\n",
      "Epoch 850/2000, Train Loss: 0.049694291, Train-Class-Acc: {0: '98.66%', 1: '97.43%'}, Val Loss: 0.108158642, Val Accuracy: 97.54%, Val-Class-Acc: {0: '98.66%', 1: '95.82%'}, LR: 0.000100000\n",
      "Epoch 851/2000, Train Loss: 0.012766733, Train-Class-Acc: {0: '99.71%', 1: '99.46%'}, Val Loss: 0.103658996, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.18%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 852/2000, Train Loss: 0.011003603, Train-Class-Acc: {0: '99.73%', 1: '99.52%'}, Val Loss: 0.106288424, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.36%', 1: '96.98%'}, LR: 0.000100000\n",
      "Epoch 853/2000, Train Loss: 0.010248554, Train-Class-Acc: {0: '99.74%', 1: '99.56%'}, Val Loss: 0.101108634, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.18%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 854/2000, Train Loss: 0.035223355, Train-Class-Acc: {0: '99.00%', 1: '98.27%'}, Val Loss: 0.129678714, Val Accuracy: 97.23%, Val-Class-Acc: {0: '98.58%', 1: '95.16%'}, LR: 0.000100000\n",
      "Epoch 855/2000, Train Loss: 0.057583034, Train-Class-Acc: {0: '98.60%', 1: '97.17%'}, Val Loss: 0.103705022, Val Accuracy: 97.79%, Val-Class-Acc: {0: '97.76%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 856/2000, Train Loss: 0.012329891, Train-Class-Acc: {0: '99.73%', 1: '99.50%'}, Val Loss: 0.105714572, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.18%', 1: '96.93%'}, LR: 0.000100000\n",
      "Epoch 857/2000, Train Loss: 0.010787369, Train-Class-Acc: {0: '99.74%', 1: '99.54%'}, Val Loss: 0.105160045, Val Accuracy: 97.70%, Val-Class-Acc: {0: '98.17%', 1: '97.00%'}, LR: 0.000100000\n",
      "Epoch 858/2000, Train Loss: 0.010355902, Train-Class-Acc: {0: '99.74%', 1: '99.55%'}, Val Loss: 0.102601215, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.03%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 859/2000, Train Loss: 0.010962473, Train-Class-Acc: {0: '99.71%', 1: '99.51%'}, Val Loss: 0.104882132, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.26%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 860/2000, Train Loss: 0.010031834, Train-Class-Acc: {0: '99.73%', 1: '99.55%'}, Val Loss: 0.108615921, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.14%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 861/2000, Train Loss: 0.009798650, Train-Class-Acc: {0: '99.74%', 1: '99.56%'}, Val Loss: 0.107288391, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.02%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 862/2000, Train Loss: 0.009896047, Train-Class-Acc: {0: '99.72%', 1: '99.55%'}, Val Loss: 0.107507016, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.23%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 863/2000, Train Loss: 0.009590622, Train-Class-Acc: {0: '99.73%', 1: '99.56%'}, Val Loss: 0.108251699, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.30%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 864/2000, Train Loss: 0.009331885, Train-Class-Acc: {0: '99.74%', 1: '99.57%'}, Val Loss: 0.112770059, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.38%', 1: '96.91%'}, LR: 0.000100000\n",
      "Epoch 865/2000, Train Loss: 0.009510790, Train-Class-Acc: {0: '99.73%', 1: '99.56%'}, Val Loss: 0.110081129, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.16%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 866/2000, Train Loss: 0.009512283, Train-Class-Acc: {0: '99.73%', 1: '99.56%'}, Val Loss: 0.113516874, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.78%', 1: '96.58%'}, LR: 0.000100000\n",
      "Epoch 867/2000, Train Loss: 0.009655932, Train-Class-Acc: {0: '99.73%', 1: '99.53%'}, Val Loss: 0.115038233, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.55%', 1: '96.87%'}, LR: 0.000100000\n",
      "Epoch 868/2000, Train Loss: 0.009254326, Train-Class-Acc: {0: '99.73%', 1: '99.56%'}, Val Loss: 0.111790172, Val Accuracy: 97.80%, Val-Class-Acc: {0: '97.83%', 1: '97.76%'}, LR: 0.000100000\n",
      "Epoch 869/2000, Train Loss: 0.009849758, Train-Class-Acc: {0: '99.72%', 1: '99.53%'}, Val Loss: 0.120445587, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.30%', 1: '96.87%'}, LR: 0.000100000\n",
      "Epoch 870/2000, Train Loss: 0.009266628, Train-Class-Acc: {0: '99.73%', 1: '99.57%'}, Val Loss: 0.115768513, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.63%', 1: '96.81%'}, LR: 0.000100000\n",
      "Epoch 871/2000, Train Loss: 0.009169759, Train-Class-Acc: {0: '99.74%', 1: '99.56%'}, Val Loss: 0.117976626, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.24%', 1: '96.85%'}, LR: 0.000100000\n",
      "Epoch 872/2000, Train Loss: 0.169796460, Train-Class-Acc: {0: '97.08%', 1: '94.29%'}, Val Loss: 0.117809342, Val Accuracy: 97.39%, Val-Class-Acc: {0: '97.52%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 873/2000, Train Loss: 0.019642230, Train-Class-Acc: {0: '99.58%', 1: '99.10%'}, Val Loss: 0.099020243, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.22%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 874/2000, Train Loss: 0.011862854, Train-Class-Acc: {0: '99.73%', 1: '99.52%'}, Val Loss: 0.099031749, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.32%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 875/2000, Train Loss: 0.010587889, Train-Class-Acc: {0: '99.74%', 1: '99.55%'}, Val Loss: 0.095513242, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.40%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 876/2000, Train Loss: 0.010128442, Train-Class-Acc: {0: '99.74%', 1: '99.56%'}, Val Loss: 0.097761079, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.17%', 1: '97.57%'}, LR: 0.000100000\n",
      "Epoch 877/2000, Train Loss: 0.009800280, Train-Class-Acc: {0: '99.74%', 1: '99.57%'}, Val Loss: 0.106561078, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.40%', 1: '97.00%'}, LR: 0.000100000\n",
      "Epoch 878/2000, Train Loss: 0.009701636, Train-Class-Acc: {0: '99.74%', 1: '99.57%'}, Val Loss: 0.103032050, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.11%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 879/2000, Train Loss: 0.009983147, Train-Class-Acc: {0: '99.72%', 1: '99.56%'}, Val Loss: 0.105512493, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.94%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 880/2000, Train Loss: 0.009576176, Train-Class-Acc: {0: '99.74%', 1: '99.56%'}, Val Loss: 0.109384333, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.38%', 1: '97.04%'}, LR: 0.000100000\n",
      "Epoch 881/2000, Train Loss: 0.009307288, Train-Class-Acc: {0: '99.74%', 1: '99.57%'}, Val Loss: 0.107141234, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.14%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 882/2000, Train Loss: 0.009435818, Train-Class-Acc: {0: '99.73%', 1: '99.58%'}, Val Loss: 0.115455101, Val Accuracy: 97.77%, Val-Class-Acc: {0: '98.54%', 1: '96.58%'}, LR: 0.000100000\n",
      "Epoch 883/2000, Train Loss: 0.057501537, Train-Class-Acc: {0: '98.61%', 1: '97.56%'}, Val Loss: 0.105484989, Val Accuracy: 97.58%, Val-Class-Acc: {0: '98.32%', 1: '96.45%'}, LR: 0.000100000\n",
      "Epoch 884/2000, Train Loss: 0.014057819, Train-Class-Acc: {0: '99.64%', 1: '99.29%'}, Val Loss: 0.114837545, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.19%', 1: '97.00%'}, LR: 0.000100000\n",
      "Epoch 885/2000, Train Loss: 0.010610439, Train-Class-Acc: {0: '99.73%', 1: '99.52%'}, Val Loss: 0.114110087, Val Accuracy: 97.66%, Val-Class-Acc: {0: '97.94%', 1: '97.24%'}, LR: 0.000100000\n",
      "Epoch 886/2000, Train Loss: 0.009609186, Train-Class-Acc: {0: '99.74%', 1: '99.57%'}, Val Loss: 0.110465471, Val Accuracy: 97.67%, Val-Class-Acc: {0: '98.00%', 1: '97.17%'}, LR: 0.000100000\n",
      "Epoch 887/2000, Train Loss: 0.009537056, Train-Class-Acc: {0: '99.74%', 1: '99.58%'}, Val Loss: 0.124120088, Val Accuracy: 97.62%, Val-Class-Acc: {0: '98.74%', 1: '95.89%'}, LR: 0.000100000\n",
      "Epoch 888/2000, Train Loss: 0.009899694, Train-Class-Acc: {0: '99.73%', 1: '99.54%'}, Val Loss: 0.117046187, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.25%', 1: '96.90%'}, LR: 0.000100000\n",
      "Epoch 889/2000, Train Loss: 0.009074572, Train-Class-Acc: {0: '99.74%', 1: '99.59%'}, Val Loss: 0.110492024, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.11%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 890/2000, Train Loss: 0.091102363, Train-Class-Acc: {0: '98.20%', 1: '97.19%'}, Val Loss: 0.254329837, Val Accuracy: 94.31%, Val-Class-Acc: {0: '98.81%', 1: '87.38%'}, LR: 0.000100000\n",
      "Epoch 891/2000, Train Loss: 0.081881984, Train-Class-Acc: {0: '98.12%', 1: '95.54%'}, Val Loss: 0.120608135, Val Accuracy: 97.52%, Val-Class-Acc: {0: '98.69%', 1: '95.71%'}, LR: 0.000100000\n",
      "Epoch 892/2000, Train Loss: 0.014265312, Train-Class-Acc: {0: '99.73%', 1: '99.44%'}, Val Loss: 0.104515225, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.33%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 893/2000, Train Loss: 0.011276448, Train-Class-Acc: {0: '99.74%', 1: '99.56%'}, Val Loss: 0.098331211, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.16%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 894/2000, Train Loss: 0.010746689, Train-Class-Acc: {0: '99.74%', 1: '99.56%'}, Val Loss: 0.103061851, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.41%', 1: '96.99%'}, LR: 0.000100000\n",
      "Epoch 895/2000, Train Loss: 0.010747428, Train-Class-Acc: {0: '99.72%', 1: '99.55%'}, Val Loss: 0.109001822, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.16%', 1: '96.97%'}, LR: 0.000100000\n",
      "Epoch 896/2000, Train Loss: 0.009618236, Train-Class-Acc: {0: '99.75%', 1: '99.58%'}, Val Loss: 0.109489223, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.11%', 1: '97.04%'}, LR: 0.000100000\n",
      "Epoch 897/2000, Train Loss: 0.009787768, Train-Class-Acc: {0: '99.74%', 1: '99.58%'}, Val Loss: 0.112133339, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.26%', 1: '96.94%'}, LR: 0.000100000\n",
      "Epoch 898/2000, Train Loss: 0.009952922, Train-Class-Acc: {0: '99.73%', 1: '99.56%'}, Val Loss: 0.121302253, Val Accuracy: 97.59%, Val-Class-Acc: {0: '98.53%', 1: '96.15%'}, LR: 0.000100000\n",
      "Epoch 899/2000, Train Loss: 0.009417029, Train-Class-Acc: {0: '99.74%', 1: '99.58%'}, Val Loss: 0.116913487, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.26%', 1: '96.79%'}, LR: 0.000100000\n",
      "Epoch 900/2000, Train Loss: 0.010230592, Train-Class-Acc: {0: '99.72%', 1: '99.54%'}, Val Loss: 0.118269896, Val Accuracy: 97.63%, Val-Class-Acc: {0: '97.88%', 1: '97.24%'}, LR: 0.000100000\n",
      "Epoch 901/2000, Train Loss: 0.057939236, Train-Class-Acc: {0: '98.66%', 1: '97.63%'}, Val Loss: 0.120560580, Val Accuracy: 97.42%, Val-Class-Acc: {0: '98.36%', 1: '95.99%'}, LR: 0.000100000\n",
      "Epoch 902/2000, Train Loss: 0.011873947, Train-Class-Acc: {0: '99.72%', 1: '99.48%'}, Val Loss: 0.116148478, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.47%', 1: '96.63%'}, LR: 0.000100000\n",
      "Epoch 903/2000, Train Loss: 0.009915211, Train-Class-Acc: {0: '99.75%', 1: '99.57%'}, Val Loss: 0.116748137, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.44%', 1: '96.68%'}, LR: 0.000100000\n",
      "Epoch 904/2000, Train Loss: 0.009628942, Train-Class-Acc: {0: '99.74%', 1: '99.58%'}, Val Loss: 0.114891962, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.29%', 1: '96.90%'}, LR: 0.000100000\n",
      "Epoch 905/2000, Train Loss: 0.009345835, Train-Class-Acc: {0: '99.74%', 1: '99.59%'}, Val Loss: 0.122116843, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.67%', 1: '96.19%'}, LR: 0.000100000\n",
      "Epoch 906/2000, Train Loss: 0.009455534, Train-Class-Acc: {0: '99.74%', 1: '99.56%'}, Val Loss: 0.117972284, Val Accuracy: 97.67%, Val-Class-Acc: {0: '98.13%', 1: '96.97%'}, LR: 0.000100000\n",
      "Epoch 907/2000, Train Loss: 0.010174680, Train-Class-Acc: {0: '99.72%', 1: '99.53%'}, Val Loss: 0.120906837, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.55%', 1: '96.60%'}, LR: 0.000100000\n",
      "Epoch 908/2000, Train Loss: 0.009002222, Train-Class-Acc: {0: '99.75%', 1: '99.59%'}, Val Loss: 0.121328215, Val Accuracy: 97.57%, Val-Class-Acc: {0: '97.91%', 1: '97.04%'}, LR: 0.000100000\n",
      "Epoch 909/2000, Train Loss: 0.009362964, Train-Class-Acc: {0: '99.73%', 1: '99.57%'}, Val Loss: 0.137893422, Val Accuracy: 97.48%, Val-Class-Acc: {0: '98.79%', 1: '95.46%'}, LR: 0.000100000\n",
      "Epoch 910/2000, Train Loss: 0.010041454, Train-Class-Acc: {0: '99.71%', 1: '99.51%'}, Val Loss: 0.119778185, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.27%', 1: '96.93%'}, LR: 0.000100000\n",
      "Epoch 911/2000, Train Loss: 0.008870976, Train-Class-Acc: {0: '99.75%', 1: '99.59%'}, Val Loss: 0.122607426, Val Accuracy: 97.60%, Val-Class-Acc: {0: '98.08%', 1: '96.86%'}, LR: 0.000100000\n",
      "Epoch 912/2000, Train Loss: 0.010415950, Train-Class-Acc: {0: '99.70%', 1: '99.50%'}, Val Loss: 0.122070302, Val Accuracy: 97.67%, Val-Class-Acc: {0: '98.27%', 1: '96.75%'}, LR: 0.000100000\n",
      "Epoch 913/2000, Train Loss: 0.204592634, Train-Class-Acc: {0: '96.35%', 1: '93.22%'}, Val Loss: 0.206449998, Val Accuracy: 93.12%, Val-Class-Acc: {0: '91.04%', 1: '96.33%'}, LR: 0.000100000\n",
      "Epoch 914/2000, Train Loss: 0.067365319, Train-Class-Acc: {0: '98.14%', 1: '96.25%'}, Val Loss: 0.099938979, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.33%', 1: '97.04%'}, LR: 0.000100000\n",
      "Epoch 915/2000, Train Loss: 0.015625238, Train-Class-Acc: {0: '99.71%', 1: '99.41%'}, Val Loss: 0.092368657, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.22%', 1: '97.68%'}, LR: 0.000100000\n",
      "Epoch 916/2000, Train Loss: 0.012030617, Train-Class-Acc: {0: '99.74%', 1: '99.55%'}, Val Loss: 0.094850430, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.12%', 1: '97.75%'}, LR: 0.000100000\n",
      "Epoch 917/2000, Train Loss: 0.010861727, Train-Class-Acc: {0: '99.75%', 1: '99.58%'}, Val Loss: 0.095983295, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.89%', 1: '97.72%'}, LR: 0.000100000\n",
      "Epoch 918/2000, Train Loss: 0.010243305, Train-Class-Acc: {0: '99.75%', 1: '99.59%'}, Val Loss: 0.095323138, Val Accuracy: 97.87%, Val-Class-Acc: {0: '97.97%', 1: '97.72%'}, LR: 0.000100000\n",
      "Epoch 919/2000, Train Loss: 0.010152252, Train-Class-Acc: {0: '99.74%', 1: '99.58%'}, Val Loss: 0.096591313, Val Accuracy: 97.85%, Val-Class-Acc: {0: '97.86%', 1: '97.84%'}, LR: 0.000100000\n",
      "Epoch 920/2000, Train Loss: 0.010226258, Train-Class-Acc: {0: '99.72%', 1: '99.57%'}, Val Loss: 0.096878944, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.34%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 921/2000, Train Loss: 0.009821193, Train-Class-Acc: {0: '99.74%', 1: '99.58%'}, Val Loss: 0.098645501, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.20%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 922/2000, Train Loss: 0.010672172, Train-Class-Acc: {0: '99.70%', 1: '99.51%'}, Val Loss: 0.096561898, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.25%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 923/2000, Train Loss: 0.009788365, Train-Class-Acc: {0: '99.73%', 1: '99.57%'}, Val Loss: 0.104132621, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.62%', 1: '96.95%'}, LR: 0.000100000\n",
      "Epoch 924/2000, Train Loss: 0.069529329, Train-Class-Acc: {0: '98.54%', 1: '97.47%'}, Val Loss: 0.196403538, Val Accuracy: 95.38%, Val-Class-Acc: {0: '93.23%', 1: '98.68%'}, LR: 0.000100000\n",
      "Epoch 925/2000, Train Loss: 0.038203523, Train-Class-Acc: {0: '98.97%', 1: '98.03%'}, Val Loss: 0.113218375, Val Accuracy: 97.67%, Val-Class-Acc: {0: '98.30%', 1: '96.69%'}, LR: 0.000100000\n",
      "Epoch 926/2000, Train Loss: 0.011284811, Train-Class-Acc: {0: '99.76%', 1: '99.56%'}, Val Loss: 0.100045860, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.38%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 927/2000, Train Loss: 0.010235919, Train-Class-Acc: {0: '99.75%', 1: '99.58%'}, Val Loss: 0.109309638, Val Accuracy: 97.76%, Val-Class-Acc: {0: '98.34%', 1: '96.87%'}, LR: 0.000100000\n",
      "Epoch 928/2000, Train Loss: 0.010157617, Train-Class-Acc: {0: '99.74%', 1: '99.58%'}, Val Loss: 0.099291607, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.39%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 929/2000, Train Loss: 0.009344775, Train-Class-Acc: {0: '99.76%', 1: '99.60%'}, Val Loss: 0.099301330, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.46%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 930/2000, Train Loss: 0.009322748, Train-Class-Acc: {0: '99.75%', 1: '99.60%'}, Val Loss: 0.098459203, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.26%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 931/2000, Train Loss: 0.009028861, Train-Class-Acc: {0: '99.75%', 1: '99.61%'}, Val Loss: 0.103679935, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.28%', 1: '97.23%'}, LR: 0.000100000\n",
      "Epoch 932/2000, Train Loss: 0.009209215, Train-Class-Acc: {0: '99.75%', 1: '99.59%'}, Val Loss: 0.101403532, Val Accuracy: 97.77%, Val-Class-Acc: {0: '97.74%', 1: '97.83%'}, LR: 0.000100000\n",
      "Epoch 933/2000, Train Loss: 0.166236096, Train-Class-Acc: {0: '96.70%', 1: '93.57%'}, Val Loss: 0.102302734, Val Accuracy: 97.67%, Val-Class-Acc: {0: '97.61%', 1: '97.76%'}, LR: 0.000100000\n",
      "Epoch 934/2000, Train Loss: 0.020290469, Train-Class-Acc: {0: '99.57%', 1: '99.15%'}, Val Loss: 0.101756848, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.26%', 1: '97.15%'}, LR: 0.000100000\n",
      "Epoch 935/2000, Train Loss: 0.012317537, Train-Class-Acc: {0: '99.75%', 1: '99.54%'}, Val Loss: 0.096219845, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.43%', 1: '97.25%'}, LR: 0.000100000\n",
      "Epoch 936/2000, Train Loss: 0.011116553, Train-Class-Acc: {0: '99.75%', 1: '99.56%'}, Val Loss: 0.097075187, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.34%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 937/2000, Train Loss: 0.010101744, Train-Class-Acc: {0: '99.76%', 1: '99.59%'}, Val Loss: 0.096224459, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.10%', 1: '97.70%'}, LR: 0.000100000\n",
      "Epoch 938/2000, Train Loss: 0.009797287, Train-Class-Acc: {0: '99.75%', 1: '99.60%'}, Val Loss: 0.097680939, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.48%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 939/2000, Train Loss: 0.009620308, Train-Class-Acc: {0: '99.75%', 1: '99.60%'}, Val Loss: 0.101359675, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.03%', 1: '97.43%'}, LR: 0.000100000\n",
      "Epoch 940/2000, Train Loss: 0.013527608, Train-Class-Acc: {0: '99.59%', 1: '99.35%'}, Val Loss: 0.107429248, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.72%', 1: '96.44%'}, LR: 0.000100000\n",
      "Epoch 941/2000, Train Loss: 0.010038014, Train-Class-Acc: {0: '99.74%', 1: '99.56%'}, Val Loss: 0.098361429, Val Accuracy: 97.84%, Val-Class-Acc: {0: '97.86%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 942/2000, Train Loss: 0.009580271, Train-Class-Acc: {0: '99.74%', 1: '99.58%'}, Val Loss: 0.101320734, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.00%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 943/2000, Train Loss: 0.009097623, Train-Class-Acc: {0: '99.75%', 1: '99.60%'}, Val Loss: 0.110649426, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.55%', 1: '96.48%'}, LR: 0.000100000\n",
      "Epoch 944/2000, Train Loss: 0.024708353, Train-Class-Acc: {0: '99.33%', 1: '99.08%'}, Val Loss: 0.109807751, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.87%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 945/2000, Train Loss: 0.009389000, Train-Class-Acc: {0: '99.76%', 1: '99.58%'}, Val Loss: 0.108883959, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.10%', 1: '97.17%'}, LR: 0.000100000\n",
      "Epoch 946/2000, Train Loss: 0.009163430, Train-Class-Acc: {0: '99.75%', 1: '99.59%'}, Val Loss: 0.106367794, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.21%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 947/2000, Train Loss: 0.008900990, Train-Class-Acc: {0: '99.76%', 1: '99.61%'}, Val Loss: 0.106189565, Val Accuracy: 97.77%, Val-Class-Acc: {0: '97.99%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 948/2000, Train Loss: 0.009035310, Train-Class-Acc: {0: '99.75%', 1: '99.59%'}, Val Loss: 0.103256336, Val Accuracy: 97.87%, Val-Class-Acc: {0: '97.95%', 1: '97.73%'}, LR: 0.000100000\n",
      "Epoch 949/2000, Train Loss: 0.009156064, Train-Class-Acc: {0: '99.74%', 1: '99.59%'}, Val Loss: 0.106844861, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.33%', 1: '96.86%'}, LR: 0.000100000\n",
      "Epoch 950/2000, Train Loss: 0.049381846, Train-Class-Acc: {0: '98.65%', 1: '97.94%'}, Val Loss: 0.126980383, Val Accuracy: 97.12%, Val-Class-Acc: {0: '98.76%', 1: '94.60%'}, LR: 0.000100000\n",
      "Epoch 951/2000, Train Loss: 0.017426592, Train-Class-Acc: {0: '99.48%', 1: '99.08%'}, Val Loss: 0.113819825, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.28%', 1: '96.90%'}, LR: 0.000100000\n",
      "Epoch 952/2000, Train Loss: 0.009451978, Train-Class-Acc: {0: '99.76%', 1: '99.59%'}, Val Loss: 0.113670279, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.24%', 1: '96.85%'}, LR: 0.000100000\n",
      "Epoch 953/2000, Train Loss: 0.008958267, Train-Class-Acc: {0: '99.76%', 1: '99.61%'}, Val Loss: 0.115450804, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.48%', 1: '96.77%'}, LR: 0.000100000\n",
      "Epoch 954/2000, Train Loss: 0.009032950, Train-Class-Acc: {0: '99.76%', 1: '99.60%'}, Val Loss: 0.110802888, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.14%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 955/2000, Train Loss: 0.008939843, Train-Class-Acc: {0: '99.75%', 1: '99.60%'}, Val Loss: 0.119392943, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.42%', 1: '96.62%'}, LR: 0.000100000\n",
      "Epoch 956/2000, Train Loss: 0.008877272, Train-Class-Acc: {0: '99.74%', 1: '99.61%'}, Val Loss: 0.116996917, Val Accuracy: 97.59%, Val-Class-Acc: {0: '97.86%', 1: '97.17%'}, LR: 0.000100000\n",
      "Epoch 957/2000, Train Loss: 0.008377579, Train-Class-Acc: {0: '99.76%', 1: '99.62%'}, Val Loss: 0.113784421, Val Accuracy: 97.67%, Val-Class-Acc: {0: '97.91%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 958/2000, Train Loss: 0.008987958, Train-Class-Acc: {0: '99.74%', 1: '99.59%'}, Val Loss: 0.109732176, Val Accuracy: 97.71%, Val-Class-Acc: {0: '97.96%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 959/2000, Train Loss: 0.008844967, Train-Class-Acc: {0: '99.74%', 1: '99.59%'}, Val Loss: 0.116137030, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.33%', 1: '96.76%'}, LR: 0.000100000\n",
      "Epoch 960/2000, Train Loss: 0.008857070, Train-Class-Acc: {0: '99.74%', 1: '99.58%'}, Val Loss: 0.112133780, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.38%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 961/2000, Train Loss: 0.008283094, Train-Class-Acc: {0: '99.76%', 1: '99.62%'}, Val Loss: 0.118777948, Val Accuracy: 97.63%, Val-Class-Acc: {0: '98.04%', 1: '96.99%'}, LR: 0.000100000\n",
      "Epoch 962/2000, Train Loss: 0.008674907, Train-Class-Acc: {0: '99.74%', 1: '99.60%'}, Val Loss: 0.125615021, Val Accuracy: 97.66%, Val-Class-Acc: {0: '98.75%', 1: '95.97%'}, LR: 0.000100000\n",
      "Epoch 963/2000, Train Loss: 0.058460714, Train-Class-Acc: {0: '98.78%', 1: '97.91%'}, Val Loss: 0.101075091, Val Accuracy: 97.91%, Val-Class-Acc: {0: '97.80%', 1: '98.08%'}, LR: 0.000100000\n",
      "Epoch 964/2000, Train Loss: 0.010466351, Train-Class-Acc: {0: '99.75%', 1: '99.54%'}, Val Loss: 0.118273022, Val Accuracy: 97.70%, Val-Class-Acc: {0: '98.50%', 1: '96.46%'}, LR: 0.000100000\n",
      "Epoch 965/2000, Train Loss: 0.009168610, Train-Class-Acc: {0: '99.75%', 1: '99.59%'}, Val Loss: 0.116206430, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.31%', 1: '96.89%'}, LR: 0.000100000\n",
      "Epoch 966/2000, Train Loss: 0.008658818, Train-Class-Acc: {0: '99.76%', 1: '99.62%'}, Val Loss: 0.115028462, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.26%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 967/2000, Train Loss: 0.008462348, Train-Class-Acc: {0: '99.76%', 1: '99.62%'}, Val Loss: 0.118128169, Val Accuracy: 97.67%, Val-Class-Acc: {0: '98.44%', 1: '96.48%'}, LR: 0.000100000\n",
      "Epoch 968/2000, Train Loss: 0.008426370, Train-Class-Acc: {0: '99.76%', 1: '99.62%'}, Val Loss: 0.114412222, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.07%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 969/2000, Train Loss: 0.008329391, Train-Class-Acc: {0: '99.76%', 1: '99.62%'}, Val Loss: 0.116524946, Val Accuracy: 97.70%, Val-Class-Acc: {0: '97.97%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 970/2000, Train Loss: 0.008294036, Train-Class-Acc: {0: '99.75%', 1: '99.62%'}, Val Loss: 0.108448372, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.11%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 971/2000, Train Loss: 0.080710442, Train-Class-Acc: {0: '98.27%', 1: '97.35%'}, Val Loss: 0.111142295, Val Accuracy: 97.42%, Val-Class-Acc: {0: '97.88%', 1: '96.70%'}, LR: 0.000100000\n",
      "Epoch 972/2000, Train Loss: 0.015547735, Train-Class-Acc: {0: '99.61%', 1: '99.27%'}, Val Loss: 0.097748631, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.01%', 1: '97.72%'}, LR: 0.000100000\n",
      "Epoch 973/2000, Train Loss: 0.010037334, Train-Class-Acc: {0: '99.75%', 1: '99.58%'}, Val Loss: 0.111674688, Val Accuracy: 97.61%, Val-Class-Acc: {0: '98.47%', 1: '96.29%'}, LR: 0.000100000\n",
      "Epoch 974/2000, Train Loss: 0.008907703, Train-Class-Acc: {0: '99.77%', 1: '99.61%'}, Val Loss: 0.114076604, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.42%', 1: '96.65%'}, LR: 0.000100000\n",
      "Epoch 975/2000, Train Loss: 0.008666892, Train-Class-Acc: {0: '99.76%', 1: '99.63%'}, Val Loss: 0.111710662, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.58%', 1: '96.40%'}, LR: 0.000100000\n",
      "Epoch 976/2000, Train Loss: 0.009690397, Train-Class-Acc: {0: '99.72%', 1: '99.55%'}, Val Loss: 0.105430955, Val Accuracy: 97.72%, Val-Class-Acc: {0: '97.79%', 1: '97.60%'}, LR: 0.000100000\n",
      "Epoch 977/2000, Train Loss: 0.008461560, Train-Class-Acc: {0: '99.76%', 1: '99.63%'}, Val Loss: 0.117695816, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.41%', 1: '96.70%'}, LR: 0.000100000\n",
      "Epoch 978/2000, Train Loss: 0.008985290, Train-Class-Acc: {0: '99.75%', 1: '99.59%'}, Val Loss: 0.116254615, Val Accuracy: 97.56%, Val-Class-Acc: {0: '97.64%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 979/2000, Train Loss: 0.009879933, Train-Class-Acc: {0: '99.70%', 1: '99.54%'}, Val Loss: 0.115333109, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.41%', 1: '96.83%'}, LR: 0.000100000\n",
      "Epoch 980/2000, Train Loss: 0.009053858, Train-Class-Acc: {0: '99.74%', 1: '99.58%'}, Val Loss: 0.110245911, Val Accuracy: 97.62%, Val-Class-Acc: {0: '97.80%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 981/2000, Train Loss: 0.009150599, Train-Class-Acc: {0: '99.73%', 1: '99.58%'}, Val Loss: 0.116093556, Val Accuracy: 97.59%, Val-Class-Acc: {0: '97.81%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 982/2000, Train Loss: 0.078981898, Train-Class-Acc: {0: '98.15%', 1: '96.89%'}, Val Loss: 0.123546984, Val Accuracy: 97.69%, Val-Class-Acc: {0: '97.63%', 1: '97.78%'}, LR: 0.000100000\n",
      "Epoch 983/2000, Train Loss: 0.021737973, Train-Class-Acc: {0: '99.35%', 1: '98.84%'}, Val Loss: 0.107662426, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.33%', 1: '96.75%'}, LR: 0.000100000\n",
      "Epoch 984/2000, Train Loss: 0.009349182, Train-Class-Acc: {0: '99.77%', 1: '99.61%'}, Val Loss: 0.112973157, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.12%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 985/2000, Train Loss: 0.008927113, Train-Class-Acc: {0: '99.76%', 1: '99.63%'}, Val Loss: 0.113186125, Val Accuracy: 97.70%, Val-Class-Acc: {0: '98.24%', 1: '96.88%'}, LR: 0.000100000\n",
      "Epoch 986/2000, Train Loss: 0.008582811, Train-Class-Acc: {0: '99.77%', 1: '99.62%'}, Val Loss: 0.120560342, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.23%', 1: '96.83%'}, LR: 0.000100000\n",
      "Epoch 987/2000, Train Loss: 0.008437213, Train-Class-Acc: {0: '99.77%', 1: '99.63%'}, Val Loss: 0.118993307, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.30%', 1: '96.73%'}, LR: 0.000100000\n",
      "Epoch 988/2000, Train Loss: 0.008190419, Train-Class-Acc: {0: '99.77%', 1: '99.64%'}, Val Loss: 0.112736993, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.17%', 1: '96.99%'}, LR: 0.000100000\n",
      "Epoch 989/2000, Train Loss: 0.008094020, Train-Class-Acc: {0: '99.77%', 1: '99.64%'}, Val Loss: 0.113163420, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.19%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 990/2000, Train Loss: 0.008012188, Train-Class-Acc: {0: '99.77%', 1: '99.63%'}, Val Loss: 0.123431031, Val Accuracy: 97.70%, Val-Class-Acc: {0: '98.41%', 1: '96.61%'}, LR: 0.000100000\n",
      "Epoch 991/2000, Train Loss: 0.007988908, Train-Class-Acc: {0: '99.76%', 1: '99.64%'}, Val Loss: 0.122791852, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.40%', 1: '96.67%'}, LR: 0.000100000\n",
      "Epoch 992/2000, Train Loss: 0.007918915, Train-Class-Acc: {0: '99.77%', 1: '99.64%'}, Val Loss: 0.115270748, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.30%', 1: '97.16%'}, LR: 0.000100000\n",
      "Epoch 993/2000, Train Loss: 0.007929631, Train-Class-Acc: {0: '99.77%', 1: '99.63%'}, Val Loss: 0.120468496, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.53%', 1: '96.80%'}, LR: 0.000100000\n",
      "Epoch 994/2000, Train Loss: 0.008433804, Train-Class-Acc: {0: '99.76%', 1: '99.60%'}, Val Loss: 0.123847453, Val Accuracy: 97.48%, Val-Class-Acc: {0: '97.13%', 1: '98.02%'}, LR: 0.000100000\n",
      "Epoch 995/2000, Train Loss: 0.084223818, Train-Class-Acc: {0: '98.06%', 1: '96.81%'}, Val Loss: 0.124079760, Val Accuracy: 97.58%, Val-Class-Acc: {0: '98.26%', 1: '96.52%'}, LR: 0.000100000\n",
      "Epoch 996/2000, Train Loss: 0.010617418, Train-Class-Acc: {0: '99.75%', 1: '99.56%'}, Val Loss: 0.118894975, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.22%', 1: '97.00%'}, LR: 0.000100000\n",
      "Epoch 997/2000, Train Loss: 0.009084822, Train-Class-Acc: {0: '99.76%', 1: '99.61%'}, Val Loss: 0.120173067, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.21%', 1: '96.97%'}, LR: 0.000100000\n",
      "Epoch 998/2000, Train Loss: 0.025478056, Train-Class-Acc: {0: '99.31%', 1: '98.95%'}, Val Loss: 0.221086720, Val Accuracy: 95.74%, Val-Class-Acc: {0: '99.10%', 1: '90.56%'}, LR: 0.000100000\n",
      "Epoch 999/2000, Train Loss: 0.058074478, Train-Class-Acc: {0: '98.53%', 1: '97.21%'}, Val Loss: 0.133300938, Val Accuracy: 97.40%, Val-Class-Acc: {0: '98.32%', 1: '95.97%'}, LR: 0.000100000\n",
      "Epoch 1000/2000, Train Loss: 0.013096474, Train-Class-Acc: {0: '99.69%', 1: '99.39%'}, Val Loss: 0.097501363, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.12%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 1001/2000, Train Loss: 0.009188594, Train-Class-Acc: {0: '99.77%', 1: '99.62%'}, Val Loss: 0.101876508, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.44%', 1: '96.98%'}, LR: 0.000100000\n",
      "Epoch 1002/2000, Train Loss: 0.008805160, Train-Class-Acc: {0: '99.77%', 1: '99.63%'}, Val Loss: 0.098520200, Val Accuracy: 97.86%, Val-Class-Acc: {0: '97.90%', 1: '97.80%'}, LR: 0.000100000\n",
      "Epoch 1003/2000, Train Loss: 0.009072960, Train-Class-Acc: {0: '99.75%', 1: '99.61%'}, Val Loss: 0.101193077, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.06%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 1004/2000, Train Loss: 0.008382242, Train-Class-Acc: {0: '99.76%', 1: '99.64%'}, Val Loss: 0.106694014, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.36%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 1005/2000, Train Loss: 0.008318475, Train-Class-Acc: {0: '99.77%', 1: '99.63%'}, Val Loss: 0.111917832, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.47%', 1: '96.77%'}, LR: 0.000100000\n",
      "Epoch 1006/2000, Train Loss: 0.008182861, Train-Class-Acc: {0: '99.77%', 1: '99.64%'}, Val Loss: 0.105312270, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.22%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1007/2000, Train Loss: 0.007938522, Train-Class-Acc: {0: '99.77%', 1: '99.64%'}, Val Loss: 0.105353922, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.38%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 1008/2000, Train Loss: 0.076849068, Train-Class-Acc: {0: '98.32%', 1: '97.02%'}, Val Loss: 0.104612083, Val Accuracy: 97.76%, Val-Class-Acc: {0: '97.89%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 1009/2000, Train Loss: 0.012824871, Train-Class-Acc: {0: '99.72%', 1: '99.44%'}, Val Loss: 0.099113211, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.33%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 1010/2000, Train Loss: 0.009133623, Train-Class-Acc: {0: '99.78%', 1: '99.62%'}, Val Loss: 0.099093105, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.31%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 1011/2000, Train Loss: 0.008637883, Train-Class-Acc: {0: '99.77%', 1: '99.63%'}, Val Loss: 0.103116257, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.18%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1012/2000, Train Loss: 0.008363608, Train-Class-Acc: {0: '99.78%', 1: '99.64%'}, Val Loss: 0.103535213, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.20%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1013/2000, Train Loss: 0.008093516, Train-Class-Acc: {0: '99.77%', 1: '99.65%'}, Val Loss: 0.103792320, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.32%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1014/2000, Train Loss: 0.008001133, Train-Class-Acc: {0: '99.78%', 1: '99.64%'}, Val Loss: 0.102489285, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.34%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1015/2000, Train Loss: 0.007943767, Train-Class-Acc: {0: '99.77%', 1: '99.64%'}, Val Loss: 0.108046101, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.42%', 1: '97.13%'}, LR: 0.000100000\n",
      "Epoch 1016/2000, Train Loss: 0.007818915, Train-Class-Acc: {0: '99.78%', 1: '99.64%'}, Val Loss: 0.108700103, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.18%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 1017/2000, Train Loss: 0.010480391, Train-Class-Acc: {0: '99.68%', 1: '99.49%'}, Val Loss: 0.116024763, Val Accuracy: 97.77%, Val-Class-Acc: {0: '98.40%', 1: '96.79%'}, LR: 0.000100000\n",
      "Epoch 1018/2000, Train Loss: 0.050548370, Train-Class-Acc: {0: '98.51%', 1: '97.51%'}, Val Loss: 0.142708406, Val Accuracy: 97.26%, Val-Class-Acc: {0: '98.91%', 1: '94.73%'}, LR: 0.000100000\n",
      "Epoch 1019/2000, Train Loss: 0.013497195, Train-Class-Acc: {0: '99.67%', 1: '99.28%'}, Val Loss: 0.111903266, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.51%', 1: '96.73%'}, LR: 0.000100000\n",
      "Epoch 1020/2000, Train Loss: 0.008763699, Train-Class-Acc: {0: '99.77%', 1: '99.62%'}, Val Loss: 0.108511129, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.46%', 1: '96.90%'}, LR: 0.000100000\n",
      "Epoch 1021/2000, Train Loss: 0.008249554, Train-Class-Acc: {0: '99.78%', 1: '99.63%'}, Val Loss: 0.112777246, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.36%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 1022/2000, Train Loss: 0.008065103, Train-Class-Acc: {0: '99.78%', 1: '99.65%'}, Val Loss: 0.113068552, Val Accuracy: 97.70%, Val-Class-Acc: {0: '98.09%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 1023/2000, Train Loss: 0.007918908, Train-Class-Acc: {0: '99.78%', 1: '99.64%'}, Val Loss: 0.114412350, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.41%', 1: '96.75%'}, LR: 0.000100000\n",
      "Epoch 1024/2000, Train Loss: 0.007817008, Train-Class-Acc: {0: '99.78%', 1: '99.64%'}, Val Loss: 0.117015272, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.32%', 1: '96.97%'}, LR: 0.000100000\n",
      "Epoch 1025/2000, Train Loss: 0.031321049, Train-Class-Acc: {0: '99.13%', 1: '98.61%'}, Val Loss: 0.122012246, Val Accuracy: 97.57%, Val-Class-Acc: {0: '98.36%', 1: '96.35%'}, LR: 0.000100000\n",
      "Epoch 1026/2000, Train Loss: 0.009735270, Train-Class-Acc: {0: '99.75%', 1: '99.54%'}, Val Loss: 0.120587378, Val Accuracy: 97.63%, Val-Class-Acc: {0: '98.63%', 1: '96.08%'}, LR: 0.000100000\n",
      "Epoch 1027/2000, Train Loss: 0.008330150, Train-Class-Acc: {0: '99.77%', 1: '99.63%'}, Val Loss: 0.112175751, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.22%', 1: '96.97%'}, LR: 0.000100000\n",
      "Epoch 1028/2000, Train Loss: 0.007812197, Train-Class-Acc: {0: '99.78%', 1: '99.65%'}, Val Loss: 0.114953033, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.19%', 1: '97.00%'}, LR: 0.000100000\n",
      "Epoch 1029/2000, Train Loss: 0.008142944, Train-Class-Acc: {0: '99.76%', 1: '99.63%'}, Val Loss: 0.119739969, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.07%', 1: '97.08%'}, LR: 0.000100000\n",
      "Epoch 1030/2000, Train Loss: 0.007734250, Train-Class-Acc: {0: '99.78%', 1: '99.65%'}, Val Loss: 0.119320730, Val Accuracy: 97.76%, Val-Class-Acc: {0: '98.32%', 1: '96.89%'}, LR: 0.000100000\n",
      "Epoch 1031/2000, Train Loss: 0.007509844, Train-Class-Acc: {0: '99.78%', 1: '99.65%'}, Val Loss: 0.120099971, Val Accuracy: 97.62%, Val-Class-Acc: {0: '97.87%', 1: '97.24%'}, LR: 0.000100000\n",
      "Epoch 1032/2000, Train Loss: 0.007658178, Train-Class-Acc: {0: '99.77%', 1: '99.64%'}, Val Loss: 0.123998247, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.13%', 1: '97.02%'}, LR: 0.000100000\n",
      "Epoch 1033/2000, Train Loss: 0.008257250, Train-Class-Acc: {0: '99.76%', 1: '99.60%'}, Val Loss: 0.122021567, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.22%', 1: '96.84%'}, LR: 0.000100000\n",
      "Epoch 1034/2000, Train Loss: 0.007621608, Train-Class-Acc: {0: '99.77%', 1: '99.64%'}, Val Loss: 0.122871171, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.11%', 1: '97.03%'}, LR: 0.000100000\n",
      "Epoch 1035/2000, Train Loss: 0.007369043, Train-Class-Acc: {0: '99.78%', 1: '99.65%'}, Val Loss: 0.123482324, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.42%', 1: '96.64%'}, LR: 0.000100000\n",
      "Epoch 1036/2000, Train Loss: 0.007394283, Train-Class-Acc: {0: '99.78%', 1: '99.65%'}, Val Loss: 0.125641232, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.13%', 1: '97.02%'}, LR: 0.000100000\n",
      "Epoch 1037/2000, Train Loss: 0.007953970, Train-Class-Acc: {0: '99.76%', 1: '99.63%'}, Val Loss: 0.123027466, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.25%', 1: '97.08%'}, LR: 0.000100000\n",
      "Epoch 1038/2000, Train Loss: 0.007236004, Train-Class-Acc: {0: '99.79%', 1: '99.65%'}, Val Loss: 0.124855094, Val Accuracy: 97.56%, Val-Class-Acc: {0: '97.68%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 1039/2000, Train Loss: 0.007611680, Train-Class-Acc: {0: '99.77%', 1: '99.64%'}, Val Loss: 0.129181570, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.33%', 1: '96.71%'}, LR: 0.000100000\n",
      "Epoch 1040/2000, Train Loss: 0.007473861, Train-Class-Acc: {0: '99.77%', 1: '99.64%'}, Val Loss: 0.144632755, Val Accuracy: 97.50%, Val-Class-Acc: {0: '98.76%', 1: '95.56%'}, LR: 0.000100000\n",
      "Epoch 1041/2000, Train Loss: 0.008447015, Train-Class-Acc: {0: '99.74%', 1: '99.59%'}, Val Loss: 0.128840497, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.47%', 1: '96.72%'}, LR: 0.000100000\n",
      "Epoch 1042/2000, Train Loss: 0.155799152, Train-Class-Acc: {0: '97.41%', 1: '95.56%'}, Val Loss: 0.167044625, Val Accuracy: 95.61%, Val-Class-Acc: {0: '94.15%', 1: '97.86%'}, LR: 0.000100000\n",
      "Epoch 1043/2000, Train Loss: 0.046447204, Train-Class-Acc: {0: '98.72%', 1: '97.36%'}, Val Loss: 0.104649172, Val Accuracy: 97.63%, Val-Class-Acc: {0: '97.31%', 1: '98.12%'}, LR: 0.000100000\n",
      "Epoch 1044/2000, Train Loss: 0.011885470, Train-Class-Acc: {0: '99.73%', 1: '99.51%'}, Val Loss: 0.102964281, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.34%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 1045/2000, Train Loss: 0.009019231, Train-Class-Acc: {0: '99.79%', 1: '99.64%'}, Val Loss: 0.103348851, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.37%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 1046/2000, Train Loss: 0.008440839, Train-Class-Acc: {0: '99.79%', 1: '99.65%'}, Val Loss: 0.109914419, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.24%', 1: '96.96%'}, LR: 0.000100000\n",
      "Epoch 1047/2000, Train Loss: 0.008360626, Train-Class-Acc: {0: '99.78%', 1: '99.65%'}, Val Loss: 0.113799760, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.34%', 1: '96.84%'}, LR: 0.000100000\n",
      "Epoch 1048/2000, Train Loss: 0.007913615, Train-Class-Acc: {0: '99.78%', 1: '99.66%'}, Val Loss: 0.118106821, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.32%', 1: '96.80%'}, LR: 0.000100000\n",
      "Epoch 1049/2000, Train Loss: 0.007901758, Train-Class-Acc: {0: '99.78%', 1: '99.65%'}, Val Loss: 0.118814534, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.30%', 1: '96.80%'}, LR: 0.000100000\n",
      "Epoch 1050/2000, Train Loss: 0.007582945, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.117951967, Val Accuracy: 97.70%, Val-Class-Acc: {0: '98.17%', 1: '96.96%'}, LR: 0.000100000\n",
      "Epoch 1051/2000, Train Loss: 0.007621011, Train-Class-Acc: {0: '99.78%', 1: '99.66%'}, Val Loss: 0.122745443, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.18%', 1: '96.91%'}, LR: 0.000100000\n",
      "Epoch 1052/2000, Train Loss: 0.007770000, Train-Class-Acc: {0: '99.78%', 1: '99.65%'}, Val Loss: 0.119793664, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.07%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 1053/2000, Train Loss: 0.007401910, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.119022286, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.22%', 1: '96.93%'}, LR: 0.000100000\n",
      "Epoch 1054/2000, Train Loss: 0.007526261, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.126628176, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.32%', 1: '96.73%'}, LR: 0.000100000\n",
      "Epoch 1055/2000, Train Loss: 0.007591487, Train-Class-Acc: {0: '99.78%', 1: '99.64%'}, Val Loss: 0.123855648, Val Accuracy: 97.62%, Val-Class-Acc: {0: '97.85%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 1056/2000, Train Loss: 0.007584982, Train-Class-Acc: {0: '99.77%', 1: '99.66%'}, Val Loss: 0.136765696, Val Accuracy: 97.50%, Val-Class-Acc: {0: '98.61%', 1: '95.80%'}, LR: 0.000100000\n",
      "Epoch 1057/2000, Train Loss: 0.008356194, Train-Class-Acc: {0: '99.75%', 1: '99.59%'}, Val Loss: 0.116562181, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.12%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 1058/2000, Train Loss: 0.007368351, Train-Class-Acc: {0: '99.78%', 1: '99.66%'}, Val Loss: 0.119933880, Val Accuracy: 97.64%, Val-Class-Acc: {0: '97.85%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 1059/2000, Train Loss: 0.010966948, Train-Class-Acc: {0: '99.73%', 1: '99.42%'}, Val Loss: 1.158700468, Val Accuracy: 85.87%, Val-Class-Acc: {0: '77.48%', 1: '98.78%'}, LR: 0.000100000\n",
      "Epoch 1060/2000, Train Loss: 0.531041512, Train-Class-Acc: {0: '90.54%', 1: '80.44%'}, Val Loss: 0.127497183, Val Accuracy: 96.48%, Val-Class-Acc: {0: '96.37%', 1: '96.65%'}, LR: 0.000100000\n",
      "Epoch 1061/2000, Train Loss: 0.073523002, Train-Class-Acc: {0: '97.99%', 1: '95.80%'}, Val Loss: 0.081213747, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.50%', 1: '98.34%'}, LR: 0.000100000\n",
      "Epoch 1062/2000, Train Loss: 0.029955604, Train-Class-Acc: {0: '99.32%', 1: '98.48%'}, Val Loss: 0.083506502, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.06%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 1063/2000, Train Loss: 0.019044190, Train-Class-Acc: {0: '99.60%', 1: '99.16%'}, Val Loss: 0.084661268, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.23%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 1064/2000, Train Loss: 0.016422831, Train-Class-Acc: {0: '99.61%', 1: '99.25%'}, Val Loss: 0.089456587, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.21%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1065/2000, Train Loss: 0.013363917, Train-Class-Acc: {0: '99.69%', 1: '99.42%'}, Val Loss: 0.086360945, Val Accuracy: 97.76%, Val-Class-Acc: {0: '97.63%', 1: '97.94%'}, LR: 0.000100000\n",
      "Epoch 1066/2000, Train Loss: 0.013085141, Train-Class-Acc: {0: '99.68%', 1: '99.39%'}, Val Loss: 0.089464695, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.16%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 1067/2000, Train Loss: 0.010376401, Train-Class-Acc: {0: '99.75%', 1: '99.57%'}, Val Loss: 0.090363949, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.23%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 1068/2000, Train Loss: 0.009579857, Train-Class-Acc: {0: '99.76%', 1: '99.60%'}, Val Loss: 0.093419755, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.98%', 1: '97.57%'}, LR: 0.000100000\n",
      "Epoch 1069/2000, Train Loss: 0.009242361, Train-Class-Acc: {0: '99.77%', 1: '99.60%'}, Val Loss: 0.092110614, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.97%', 1: '97.57%'}, LR: 0.000100000\n",
      "Epoch 1070/2000, Train Loss: 0.009117673, Train-Class-Acc: {0: '99.76%', 1: '99.61%'}, Val Loss: 0.096586078, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.29%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 1071/2000, Train Loss: 0.008871988, Train-Class-Acc: {0: '99.77%', 1: '99.61%'}, Val Loss: 0.096574487, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.08%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 1072/2000, Train Loss: 0.008428271, Train-Class-Acc: {0: '99.78%', 1: '99.63%'}, Val Loss: 0.095496290, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.04%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 1073/2000, Train Loss: 0.008396238, Train-Class-Acc: {0: '99.77%', 1: '99.63%'}, Val Loss: 0.106215639, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.63%', 1: '96.87%'}, LR: 0.000100000\n",
      "Epoch 1074/2000, Train Loss: 0.008439572, Train-Class-Acc: {0: '99.77%', 1: '99.62%'}, Val Loss: 0.100675161, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.40%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 1075/2000, Train Loss: 0.008088990, Train-Class-Acc: {0: '99.78%', 1: '99.64%'}, Val Loss: 0.099996156, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.13%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1076/2000, Train Loss: 0.264090301, Train-Class-Acc: {0: '96.36%', 1: '92.08%'}, Val Loss: 0.258554394, Val Accuracy: 91.54%, Val-Class-Acc: {0: '95.39%', 1: '85.62%'}, LR: 0.000100000\n",
      "Epoch 1077/2000, Train Loss: 0.137549522, Train-Class-Acc: {0: '96.39%', 1: '91.29%'}, Val Loss: 0.081877713, Val Accuracy: 97.75%, Val-Class-Acc: {0: '97.62%', 1: '97.95%'}, LR: 0.000100000\n",
      "Epoch 1078/2000, Train Loss: 0.024655247, Train-Class-Acc: {0: '99.46%', 1: '99.02%'}, Val Loss: 0.081003936, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.15%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1079/2000, Train Loss: 0.014373896, Train-Class-Acc: {0: '99.75%', 1: '99.51%'}, Val Loss: 0.079935777, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.18%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 1080/2000, Train Loss: 0.012256965, Train-Class-Acc: {0: '99.76%', 1: '99.56%'}, Val Loss: 0.083919143, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.35%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1081/2000, Train Loss: 0.010898363, Train-Class-Acc: {0: '99.78%', 1: '99.59%'}, Val Loss: 0.078953836, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.35%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 1082/2000, Train Loss: 0.010788983, Train-Class-Acc: {0: '99.75%', 1: '99.58%'}, Val Loss: 0.086551776, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.57%', 1: '97.02%'}, LR: 0.000100000\n",
      "Epoch 1083/2000, Train Loss: 0.009572565, Train-Class-Acc: {0: '99.78%', 1: '99.61%'}, Val Loss: 0.082006292, Val Accuracy: 97.84%, Val-Class-Acc: {0: '97.97%', 1: '97.64%'}, LR: 0.000100000\n",
      "Epoch 1084/2000, Train Loss: 0.009401724, Train-Class-Acc: {0: '99.77%', 1: '99.62%'}, Val Loss: 0.091833651, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.60%', 1: '96.91%'}, LR: 0.000100000\n",
      "Epoch 1085/2000, Train Loss: 0.008991149, Train-Class-Acc: {0: '99.78%', 1: '99.62%'}, Val Loss: 0.086098719, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.25%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1086/2000, Train Loss: 0.008790846, Train-Class-Acc: {0: '99.78%', 1: '99.63%'}, Val Loss: 0.089090516, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.37%', 1: '97.23%'}, LR: 0.000100000\n",
      "Epoch 1087/2000, Train Loss: 0.008440810, Train-Class-Acc: {0: '99.79%', 1: '99.64%'}, Val Loss: 0.093872239, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.35%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 1088/2000, Train Loss: 0.012590877, Train-Class-Acc: {0: '99.67%', 1: '99.35%'}, Val Loss: 0.124814099, Val Accuracy: 96.91%, Val-Class-Acc: {0: '95.27%', 1: '99.43%'}, LR: 0.000100000\n",
      "Epoch 1089/2000, Train Loss: 0.234185798, Train-Class-Acc: {0: '95.76%', 1: '90.08%'}, Val Loss: 0.117136414, Val Accuracy: 97.01%, Val-Class-Acc: {0: '95.97%', 1: '98.61%'}, LR: 0.000100000\n",
      "Epoch 1090/2000, Train Loss: 0.027104673, Train-Class-Acc: {0: '99.40%', 1: '98.91%'}, Val Loss: 0.088713592, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.24%', 1: '97.24%'}, LR: 0.000100000\n",
      "Epoch 1091/2000, Train Loss: 0.013461187, Train-Class-Acc: {0: '99.77%', 1: '99.55%'}, Val Loss: 0.082470729, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.15%', 1: '97.49%'}, LR: 0.000100000\n",
      "Epoch 1092/2000, Train Loss: 0.011347216, Train-Class-Acc: {0: '99.78%', 1: '99.60%'}, Val Loss: 0.085410435, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.36%', 1: '97.02%'}, LR: 0.000100000\n",
      "Epoch 1093/2000, Train Loss: 0.010015023, Train-Class-Acc: {0: '99.79%', 1: '99.62%'}, Val Loss: 0.082492413, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.87%', 1: '97.76%'}, LR: 0.000100000\n",
      "Epoch 1094/2000, Train Loss: 0.009490243, Train-Class-Acc: {0: '99.79%', 1: '99.63%'}, Val Loss: 0.091564529, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.54%', 1: '96.70%'}, LR: 0.000100000\n",
      "Epoch 1095/2000, Train Loss: 0.009780782, Train-Class-Acc: {0: '99.77%', 1: '99.60%'}, Val Loss: 0.086401483, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.01%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 1096/2000, Train Loss: 0.009124299, Train-Class-Acc: {0: '99.78%', 1: '99.63%'}, Val Loss: 0.088701550, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.21%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 1097/2000, Train Loss: 0.008673093, Train-Class-Acc: {0: '99.79%', 1: '99.64%'}, Val Loss: 0.089769039, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.19%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 1098/2000, Train Loss: 0.008402379, Train-Class-Acc: {0: '99.79%', 1: '99.65%'}, Val Loss: 0.092657702, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.20%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1099/2000, Train Loss: 0.008363680, Train-Class-Acc: {0: '99.78%', 1: '99.64%'}, Val Loss: 0.094803725, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.52%', 1: '96.86%'}, LR: 0.000100000\n",
      "Epoch 1100/2000, Train Loss: 0.008351570, Train-Class-Acc: {0: '99.78%', 1: '99.64%'}, Val Loss: 0.100288633, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.67%', 1: '96.50%'}, LR: 0.000100000\n",
      "Epoch 1101/2000, Train Loss: 0.027943831, Train-Class-Acc: {0: '99.19%', 1: '98.50%'}, Val Loss: 0.096520733, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.25%', 1: '96.92%'}, LR: 0.000100000\n",
      "Epoch 1102/2000, Train Loss: 0.036889333, Train-Class-Acc: {0: '98.96%', 1: '97.97%'}, Val Loss: 0.095778223, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.86%', 1: '97.76%'}, LR: 0.000100000\n",
      "Epoch 1103/2000, Train Loss: 0.009488137, Train-Class-Acc: {0: '99.78%', 1: '99.61%'}, Val Loss: 0.092544447, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.08%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 1104/2000, Train Loss: 0.008468901, Train-Class-Acc: {0: '99.80%', 1: '99.64%'}, Val Loss: 0.093110475, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.11%', 1: '97.51%'}, LR: 0.000100000\n",
      "Epoch 1105/2000, Train Loss: 0.008377457, Train-Class-Acc: {0: '99.79%', 1: '99.65%'}, Val Loss: 0.091689030, Val Accuracy: 97.80%, Val-Class-Acc: {0: '97.98%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 1106/2000, Train Loss: 0.008025979, Train-Class-Acc: {0: '99.80%', 1: '99.65%'}, Val Loss: 0.093956971, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.03%', 1: '97.51%'}, LR: 0.000100000\n",
      "Epoch 1107/2000, Train Loss: 0.008141718, Train-Class-Acc: {0: '99.79%', 1: '99.65%'}, Val Loss: 0.094654614, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.14%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 1108/2000, Train Loss: 0.007860869, Train-Class-Acc: {0: '99.79%', 1: '99.65%'}, Val Loss: 0.096226777, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.01%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 1109/2000, Train Loss: 0.007755981, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.095242864, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.10%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 1110/2000, Train Loss: 0.008506320, Train-Class-Acc: {0: '99.77%', 1: '99.62%'}, Val Loss: 0.102604458, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.26%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 1111/2000, Train Loss: 0.007627594, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.098573919, Val Accuracy: 97.76%, Val-Class-Acc: {0: '97.99%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1112/2000, Train Loss: 0.007544455, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.097154833, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.17%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 1113/2000, Train Loss: 0.007524196, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.108208802, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.39%', 1: '97.07%'}, LR: 0.000100000\n",
      "Epoch 1114/2000, Train Loss: 0.007929308, Train-Class-Acc: {0: '99.78%', 1: '99.63%'}, Val Loss: 0.099161362, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.09%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1115/2000, Train Loss: 0.007417798, Train-Class-Acc: {0: '99.79%', 1: '99.65%'}, Val Loss: 0.099119714, Val Accuracy: 97.80%, Val-Class-Acc: {0: '97.85%', 1: '97.73%'}, LR: 0.000100000\n",
      "Epoch 1116/2000, Train Loss: 0.007772105, Train-Class-Acc: {0: '99.78%', 1: '99.64%'}, Val Loss: 0.096475681, Val Accuracy: 97.77%, Val-Class-Acc: {0: '97.68%', 1: '97.90%'}, LR: 0.000100000\n",
      "Epoch 1117/2000, Train Loss: 0.084972382, Train-Class-Acc: {0: '98.41%', 1: '96.95%'}, Val Loss: 0.126152561, Val Accuracy: 97.08%, Val-Class-Acc: {0: '98.94%', 1: '94.21%'}, LR: 0.000100000\n",
      "Epoch 1118/2000, Train Loss: 0.038738296, Train-Class-Acc: {0: '98.98%', 1: '97.93%'}, Val Loss: 0.090881410, Val Accuracy: 97.87%, Val-Class-Acc: {0: '97.88%', 1: '97.85%'}, LR: 0.000100000\n",
      "Epoch 1119/2000, Train Loss: 0.010477158, Train-Class-Acc: {0: '99.77%', 1: '99.57%'}, Val Loss: 0.091311016, Val Accuracy: 97.85%, Val-Class-Acc: {0: '97.85%', 1: '97.85%'}, LR: 0.000100000\n",
      "Epoch 1120/2000, Train Loss: 0.008743753, Train-Class-Acc: {0: '99.79%', 1: '99.64%'}, Val Loss: 0.094660121, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.22%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 1121/2000, Train Loss: 0.008140896, Train-Class-Acc: {0: '99.80%', 1: '99.66%'}, Val Loss: 0.096262912, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.35%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 1122/2000, Train Loss: 0.007999525, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.099577895, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.37%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 1123/2000, Train Loss: 0.007685055, Train-Class-Acc: {0: '99.80%', 1: '99.67%'}, Val Loss: 0.099054049, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.22%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1124/2000, Train Loss: 0.007823156, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.101719262, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.45%', 1: '96.89%'}, LR: 0.000100000\n",
      "Epoch 1125/2000, Train Loss: 0.007682404, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.100364257, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.17%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1126/2000, Train Loss: 0.007410997, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.103003359, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.13%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1127/2000, Train Loss: 0.007565550, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.100240197, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.38%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 1128/2000, Train Loss: 0.007262484, Train-Class-Acc: {0: '99.80%', 1: '99.67%'}, Val Loss: 0.104317878, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.34%', 1: '97.15%'}, LR: 0.000100000\n",
      "Epoch 1129/2000, Train Loss: 0.007801434, Train-Class-Acc: {0: '99.78%', 1: '99.63%'}, Val Loss: 0.103892377, Val Accuracy: 97.60%, Val-Class-Acc: {0: '97.04%', 1: '98.47%'}, LR: 0.000100000\n",
      "Epoch 1130/2000, Train Loss: 0.177773656, Train-Class-Acc: {0: '96.56%', 1: '93.19%'}, Val Loss: 0.113737062, Val Accuracy: 97.34%, Val-Class-Acc: {0: '96.62%', 1: '98.45%'}, LR: 0.000100000\n",
      "Epoch 1131/2000, Train Loss: 0.022402807, Train-Class-Acc: {0: '99.51%', 1: '98.97%'}, Val Loss: 0.080264463, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.04%', 1: '97.93%'}, LR: 0.000100000\n",
      "Epoch 1132/2000, Train Loss: 0.010934656, Train-Class-Acc: {0: '99.79%', 1: '99.60%'}, Val Loss: 0.081793448, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.19%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1133/2000, Train Loss: 0.009102180, Train-Class-Acc: {0: '99.80%', 1: '99.65%'}, Val Loss: 0.087582110, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.08%', 1: '97.70%'}, LR: 0.000100000\n",
      "Epoch 1134/2000, Train Loss: 0.008508829, Train-Class-Acc: {0: '99.80%', 1: '99.66%'}, Val Loss: 0.091008238, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.24%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 1135/2000, Train Loss: 0.008266357, Train-Class-Acc: {0: '99.80%', 1: '99.66%'}, Val Loss: 0.092217904, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.00%', 1: '97.67%'}, LR: 0.000100000\n",
      "Epoch 1136/2000, Train Loss: 0.008014897, Train-Class-Acc: {0: '99.80%', 1: '99.66%'}, Val Loss: 0.092096976, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.11%', 1: '97.49%'}, LR: 0.000100000\n",
      "Epoch 1137/2000, Train Loss: 0.008056872, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.095654255, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.22%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1138/2000, Train Loss: 0.007574952, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.096189250, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.03%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1139/2000, Train Loss: 0.007438366, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.097712352, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.15%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 1140/2000, Train Loss: 0.007344601, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.098850947, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.07%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1141/2000, Train Loss: 0.007377569, Train-Class-Acc: {0: '99.79%', 1: '99.68%'}, Val Loss: 0.099403778, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.24%', 1: '97.24%'}, LR: 0.000100000\n",
      "Epoch 1142/2000, Train Loss: 0.007293787, Train-Class-Acc: {0: '99.80%', 1: '99.67%'}, Val Loss: 0.104169229, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.28%', 1: '97.25%'}, LR: 0.000100000\n",
      "Epoch 1143/2000, Train Loss: 0.007147816, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.105724023, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.39%', 1: '96.99%'}, LR: 0.000100000\n",
      "Epoch 1144/2000, Train Loss: 0.015010055, Train-Class-Acc: {0: '99.60%', 1: '99.33%'}, Val Loss: 0.133010727, Val Accuracy: 97.47%, Val-Class-Acc: {0: '98.78%', 1: '95.45%'}, LR: 0.000100000\n",
      "Epoch 1145/2000, Train Loss: 0.071536304, Train-Class-Acc: {0: '98.40%', 1: '97.08%'}, Val Loss: 0.101037573, Val Accuracy: 97.87%, Val-Class-Acc: {0: '97.92%', 1: '97.80%'}, LR: 0.000100000\n",
      "Epoch 1146/2000, Train Loss: 0.010866553, Train-Class-Acc: {0: '99.74%', 1: '99.53%'}, Val Loss: 0.098823039, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.21%', 1: '97.27%'}, LR: 0.000100000\n",
      "Epoch 1147/2000, Train Loss: 0.008151792, Train-Class-Acc: {0: '99.80%', 1: '99.66%'}, Val Loss: 0.099839358, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.41%', 1: '97.01%'}, LR: 0.000100000\n",
      "Epoch 1148/2000, Train Loss: 0.007890761, Train-Class-Acc: {0: '99.80%', 1: '99.67%'}, Val Loss: 0.102127015, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.27%', 1: '97.25%'}, LR: 0.000100000\n",
      "Epoch 1149/2000, Train Loss: 0.007814088, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.099297742, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.07%', 1: '97.58%'}, LR: 0.000100000\n",
      "Epoch 1150/2000, Train Loss: 0.007381815, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.102778846, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.41%', 1: '97.03%'}, LR: 0.000100000\n",
      "Epoch 1151/2000, Train Loss: 0.007284228, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.100756293, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.31%', 1: '97.23%'}, LR: 0.000100000\n",
      "Epoch 1152/2000, Train Loss: 0.007394111, Train-Class-Acc: {0: '99.80%', 1: '99.66%'}, Val Loss: 0.104449777, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.15%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1153/2000, Train Loss: 0.042008121, Train-Class-Acc: {0: '98.93%', 1: '98.31%'}, Val Loss: 0.114525219, Val Accuracy: 97.18%, Val-Class-Acc: {0: '98.60%', 1: '94.99%'}, LR: 0.000100000\n",
      "Epoch 1154/2000, Train Loss: 0.010751212, Train-Class-Acc: {0: '99.73%', 1: '99.49%'}, Val Loss: 0.095640651, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.13%', 1: '97.65%'}, LR: 0.000100000\n",
      "Epoch 1155/2000, Train Loss: 0.007814001, Train-Class-Acc: {0: '99.80%', 1: '99.66%'}, Val Loss: 0.099780556, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.22%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1156/2000, Train Loss: 0.007671244, Train-Class-Acc: {0: '99.80%', 1: '99.66%'}, Val Loss: 0.103169132, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.28%', 1: '97.23%'}, LR: 0.000100000\n",
      "Epoch 1157/2000, Train Loss: 0.007303654, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.101570580, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.24%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 1158/2000, Train Loss: 0.007093952, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.103827643, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.27%', 1: '97.27%'}, LR: 0.000100000\n",
      "Epoch 1159/2000, Train Loss: 0.006995155, Train-Class-Acc: {0: '99.80%', 1: '99.69%'}, Val Loss: 0.104462940, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.16%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1160/2000, Train Loss: 0.006939880, Train-Class-Acc: {0: '99.80%', 1: '99.69%'}, Val Loss: 0.104511012, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.20%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 1161/2000, Train Loss: 0.007037761, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.105261131, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.20%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1162/2000, Train Loss: 0.006815989, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.103521678, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.02%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 1163/2000, Train Loss: 0.006829440, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.110762531, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.49%', 1: '96.90%'}, LR: 0.000100000\n",
      "Epoch 1164/2000, Train Loss: 0.007247764, Train-Class-Acc: {0: '99.78%', 1: '99.66%'}, Val Loss: 0.106503232, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.23%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 1165/2000, Train Loss: 0.006704121, Train-Class-Acc: {0: '99.80%', 1: '99.69%'}, Val Loss: 0.108307961, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.40%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 1166/2000, Train Loss: 0.006803050, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.107560758, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.31%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 1167/2000, Train Loss: 0.007572652, Train-Class-Acc: {0: '99.78%', 1: '99.62%'}, Val Loss: 0.112124810, Val Accuracy: 97.59%, Val-Class-Acc: {0: '97.30%', 1: '98.04%'}, LR: 0.000100000\n",
      "Epoch 1168/2000, Train Loss: 0.080157335, Train-Class-Acc: {0: '98.15%', 1: '96.98%'}, Val Loss: 0.095548462, Val Accuracy: 97.80%, Val-Class-Acc: {0: '97.60%', 1: '98.11%'}, LR: 0.000100000\n",
      "Epoch 1169/2000, Train Loss: 0.009845959, Train-Class-Acc: {0: '99.76%', 1: '99.58%'}, Val Loss: 0.097766042, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.36%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1170/2000, Train Loss: 0.008594392, Train-Class-Acc: {0: '99.78%', 1: '99.62%'}, Val Loss: 0.101658212, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.72%', 1: '97.95%'}, LR: 0.000100000\n",
      "Epoch 1171/2000, Train Loss: 0.007485857, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.102275408, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.08%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 1172/2000, Train Loss: 0.007101078, Train-Class-Acc: {0: '99.81%', 1: '99.69%'}, Val Loss: 0.105088465, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.33%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 1173/2000, Train Loss: 0.007119366, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.107341458, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.29%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 1174/2000, Train Loss: 0.007214501, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.107800551, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.34%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 1175/2000, Train Loss: 0.037176734, Train-Class-Acc: {0: '99.16%', 1: '98.85%'}, Val Loss: 0.279156512, Val Accuracy: 95.00%, Val-Class-Acc: {0: '99.00%', 1: '88.84%'}, LR: 0.000100000\n",
      "Epoch 1176/2000, Train Loss: 0.031920218, Train-Class-Acc: {0: '99.22%', 1: '98.42%'}, Val Loss: 0.104579001, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.12%', 1: '97.60%'}, LR: 0.000100000\n",
      "Epoch 1177/2000, Train Loss: 0.008302314, Train-Class-Acc: {0: '99.80%', 1: '99.66%'}, Val Loss: 0.104754180, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.20%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1178/2000, Train Loss: 0.007520241, Train-Class-Acc: {0: '99.81%', 1: '99.68%'}, Val Loss: 0.105368255, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.31%', 1: '97.15%'}, LR: 0.000100000\n",
      "Epoch 1179/2000, Train Loss: 0.007309656, Train-Class-Acc: {0: '99.81%', 1: '99.68%'}, Val Loss: 0.106002778, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.13%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1180/2000, Train Loss: 0.006937969, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.109102734, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.23%', 1: '97.23%'}, LR: 0.000100000\n",
      "Epoch 1181/2000, Train Loss: 0.006925561, Train-Class-Acc: {0: '99.80%', 1: '99.70%'}, Val Loss: 0.108066318, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.33%', 1: '97.14%'}, LR: 0.000100000\n",
      "Epoch 1182/2000, Train Loss: 0.006729813, Train-Class-Acc: {0: '99.81%', 1: '99.69%'}, Val Loss: 0.105640953, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.17%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 1183/2000, Train Loss: 0.006748916, Train-Class-Acc: {0: '99.80%', 1: '99.69%'}, Val Loss: 0.108766599, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.17%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 1184/2000, Train Loss: 0.006590349, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.108829392, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.10%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 1185/2000, Train Loss: 0.006577265, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.114145026, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.29%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 1186/2000, Train Loss: 0.006778777, Train-Class-Acc: {0: '99.81%', 1: '99.68%'}, Val Loss: 0.111791755, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.42%', 1: '97.12%'}, LR: 0.000100000\n",
      "Epoch 1187/2000, Train Loss: 0.007291742, Train-Class-Acc: {0: '99.78%', 1: '99.65%'}, Val Loss: 0.112760253, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.28%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 1188/2000, Train Loss: 0.006743901, Train-Class-Acc: {0: '99.80%', 1: '99.69%'}, Val Loss: 0.108247351, Val Accuracy: 97.84%, Val-Class-Acc: {0: '97.88%', 1: '97.79%'}, LR: 0.000100000\n",
      "Epoch 1189/2000, Train Loss: 0.006830965, Train-Class-Acc: {0: '99.79%', 1: '99.68%'}, Val Loss: 0.112905955, Val Accuracy: 97.75%, Val-Class-Acc: {0: '97.66%', 1: '97.89%'}, LR: 0.000100000\n",
      "Epoch 1190/2000, Train Loss: 0.007100747, Train-Class-Acc: {0: '99.79%', 1: '99.66%'}, Val Loss: 0.114142539, Val Accuracy: 97.69%, Val-Class-Acc: {0: '97.51%', 1: '97.99%'}, LR: 0.000100000\n",
      "Epoch 1191/2000, Train Loss: 0.120548082, Train-Class-Acc: {0: '97.41%', 1: '95.70%'}, Val Loss: 0.102806685, Val Accuracy: 97.62%, Val-Class-Acc: {0: '98.29%', 1: '96.58%'}, LR: 0.000100000\n",
      "Epoch 1192/2000, Train Loss: 0.013172709, Train-Class-Acc: {0: '99.71%', 1: '99.44%'}, Val Loss: 0.097758299, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.21%', 1: '97.65%'}, LR: 0.000100000\n",
      "Epoch 1193/2000, Train Loss: 0.008598807, Train-Class-Acc: {0: '99.80%', 1: '99.66%'}, Val Loss: 0.096789879, Val Accuracy: 97.89%, Val-Class-Acc: {0: '97.93%', 1: '97.85%'}, LR: 0.000100000\n",
      "Epoch 1194/2000, Train Loss: 0.007932804, Train-Class-Acc: {0: '99.80%', 1: '99.67%'}, Val Loss: 0.098147648, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.11%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 1195/2000, Train Loss: 0.007469944, Train-Class-Acc: {0: '99.81%', 1: '99.69%'}, Val Loss: 0.100625714, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.04%', 1: '97.67%'}, LR: 0.000100000\n",
      "Epoch 1196/2000, Train Loss: 0.007051683, Train-Class-Acc: {0: '99.81%', 1: '99.69%'}, Val Loss: 0.101280934, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.17%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1197/2000, Train Loss: 0.006832513, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.100934225, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.06%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1198/2000, Train Loss: 0.007097370, Train-Class-Acc: {0: '99.80%', 1: '99.69%'}, Val Loss: 0.115097368, Val Accuracy: 97.77%, Val-Class-Acc: {0: '98.65%', 1: '96.42%'}, LR: 0.000100000\n",
      "Epoch 1199/2000, Train Loss: 0.007003490, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.101722479, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.20%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1200/2000, Train Loss: 0.006761367, Train-Class-Acc: {0: '99.81%', 1: '99.69%'}, Val Loss: 0.106502099, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.25%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1201/2000, Train Loss: 0.006669945, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.109192694, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.07%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1202/2000, Train Loss: 0.006848954, Train-Class-Acc: {0: '99.81%', 1: '99.68%'}, Val Loss: 0.108521941, Val Accuracy: 97.73%, Val-Class-Acc: {0: '97.62%', 1: '97.91%'}, LR: 0.000100000\n",
      "Epoch 1203/2000, Train Loss: 0.006566585, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.108964288, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.16%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1204/2000, Train Loss: 0.006901280, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.111225889, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.12%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 1205/2000, Train Loss: 0.006328308, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.110400518, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.13%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1206/2000, Train Loss: 0.006629343, Train-Class-Acc: {0: '99.80%', 1: '99.69%'}, Val Loss: 0.115232710, Val Accuracy: 97.74%, Val-Class-Acc: {0: '97.64%', 1: '97.90%'}, LR: 0.000100000\n",
      "Epoch 1207/2000, Train Loss: 0.006419151, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.113313931, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.40%', 1: '97.12%'}, LR: 0.000100000\n",
      "Epoch 1208/2000, Train Loss: 0.006408051, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.108441822, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.32%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 1209/2000, Train Loss: 0.006598471, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.171936933, Val Accuracy: 97.04%, Val-Class-Acc: {0: '98.92%', 1: '94.14%'}, LR: 0.000100000\n",
      "Epoch 1210/2000, Train Loss: 0.076055208, Train-Class-Acc: {0: '98.41%', 1: '97.34%'}, Val Loss: 0.104797647, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.11%', 1: '97.64%'}, LR: 0.000100000\n",
      "Epoch 1211/2000, Train Loss: 0.008614333, Train-Class-Acc: {0: '99.79%', 1: '99.63%'}, Val Loss: 0.106363927, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.24%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 1212/2000, Train Loss: 0.007030088, Train-Class-Acc: {0: '99.82%', 1: '99.70%'}, Val Loss: 0.109673727, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.37%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 1213/2000, Train Loss: 0.006805122, Train-Class-Acc: {0: '99.82%', 1: '99.70%'}, Val Loss: 0.113960457, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.35%', 1: '96.79%'}, LR: 0.000100000\n",
      "Epoch 1214/2000, Train Loss: 0.006881887, Train-Class-Acc: {0: '99.81%', 1: '99.69%'}, Val Loss: 0.110739258, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.39%', 1: '97.08%'}, LR: 0.000100000\n",
      "Epoch 1215/2000, Train Loss: 0.006444310, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.109428700, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.37%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 1216/2000, Train Loss: 0.006445310, Train-Class-Acc: {0: '99.81%', 1: '99.71%'}, Val Loss: 0.111072972, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.19%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 1217/2000, Train Loss: 0.006295552, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.111161024, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.17%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1218/2000, Train Loss: 0.006259348, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.111421137, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.06%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 1219/2000, Train Loss: 0.006441746, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.115364777, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.23%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 1220/2000, Train Loss: 0.006595739, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.113712109, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.00%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 1221/2000, Train Loss: 0.006183656, Train-Class-Acc: {0: '99.81%', 1: '99.71%'}, Val Loss: 0.120921354, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.58%', 1: '96.45%'}, LR: 0.000100000\n",
      "Epoch 1222/2000, Train Loss: 0.006452432, Train-Class-Acc: {0: '99.81%', 1: '99.69%'}, Val Loss: 0.117970091, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.36%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 1223/2000, Train Loss: 0.021708597, Train-Class-Acc: {0: '99.55%', 1: '99.36%'}, Val Loss: 0.150509055, Val Accuracy: 97.15%, Val-Class-Acc: {0: '96.25%', 1: '98.55%'}, LR: 0.000100000\n",
      "Epoch 1224/2000, Train Loss: 0.273540914, Train-Class-Acc: {0: '94.76%', 1: '90.70%'}, Val Loss: 0.108675892, Val Accuracy: 97.00%, Val-Class-Acc: {0: '98.15%', 1: '95.24%'}, LR: 0.000100000\n",
      "Epoch 1225/2000, Train Loss: 0.019693938, Train-Class-Acc: {0: '99.63%', 1: '99.20%'}, Val Loss: 0.092457229, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.15%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 1226/2000, Train Loss: 0.010331950, Train-Class-Acc: {0: '99.81%', 1: '99.66%'}, Val Loss: 0.097854664, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.45%', 1: '96.95%'}, LR: 0.000100000\n",
      "Epoch 1227/2000, Train Loss: 0.009078873, Train-Class-Acc: {0: '99.81%', 1: '99.65%'}, Val Loss: 0.094045685, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.20%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1228/2000, Train Loss: 0.008241381, Train-Class-Acc: {0: '99.80%', 1: '99.68%'}, Val Loss: 0.095924632, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.39%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 1229/2000, Train Loss: 0.007689688, Train-Class-Acc: {0: '99.81%', 1: '99.69%'}, Val Loss: 0.097466888, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.31%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1230/2000, Train Loss: 0.007456405, Train-Class-Acc: {0: '99.81%', 1: '99.69%'}, Val Loss: 0.098659759, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.20%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 1231/2000, Train Loss: 0.007318424, Train-Class-Acc: {0: '99.81%', 1: '99.69%'}, Val Loss: 0.098169410, Val Accuracy: 97.86%, Val-Class-Acc: {0: '97.94%', 1: '97.74%'}, LR: 0.000100000\n",
      "Epoch 1232/2000, Train Loss: 0.007079043, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.102478075, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.39%', 1: '97.17%'}, LR: 0.000100000\n",
      "Epoch 1233/2000, Train Loss: 0.006783546, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.103978376, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.35%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 1234/2000, Train Loss: 0.006771205, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.102438637, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.30%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 1235/2000, Train Loss: 0.006763755, Train-Class-Acc: {0: '99.82%', 1: '99.70%'}, Val Loss: 0.103485391, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.35%', 1: '97.24%'}, LR: 0.000100000\n",
      "Epoch 1236/2000, Train Loss: 0.006526196, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.106953056, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.31%', 1: '97.27%'}, LR: 0.000100000\n",
      "Epoch 1237/2000, Train Loss: 0.006788482, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.104542160, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.39%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 1238/2000, Train Loss: 0.007672115, Train-Class-Acc: {0: '99.78%', 1: '99.64%'}, Val Loss: 0.106028135, Val Accuracy: 97.79%, Val-Class-Acc: {0: '97.98%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 1239/2000, Train Loss: 0.006462772, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.106361602, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.18%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1240/2000, Train Loss: 0.006537718, Train-Class-Acc: {0: '99.82%', 1: '99.70%'}, Val Loss: 0.106170147, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.02%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1241/2000, Train Loss: 0.006235424, Train-Class-Acc: {0: '99.82%', 1: '99.72%'}, Val Loss: 0.105583982, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.21%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1242/2000, Train Loss: 0.042060572, Train-Class-Acc: {0: '99.58%', 1: '98.63%'}, Val Loss: 0.596091869, Val Accuracy: 90.63%, Val-Class-Acc: {0: '85.07%', 1: '99.20%'}, LR: 0.000100000\n",
      "Epoch 1243/2000, Train Loss: 0.177982378, Train-Class-Acc: {0: '96.16%', 1: '93.48%'}, Val Loss: 0.098630541, Val Accuracy: 97.55%, Val-Class-Acc: {0: '97.13%', 1: '98.19%'}, LR: 0.000100000\n",
      "Epoch 1244/2000, Train Loss: 0.016375359, Train-Class-Acc: {0: '99.68%', 1: '99.34%'}, Val Loss: 0.095772692, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.33%', 1: '97.16%'}, LR: 0.000100000\n",
      "Epoch 1245/2000, Train Loss: 0.009422361, Train-Class-Acc: {0: '99.82%', 1: '99.67%'}, Val Loss: 0.092719134, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.22%', 1: '97.54%'}, LR: 0.000100000\n",
      "Epoch 1246/2000, Train Loss: 0.008280791, Train-Class-Acc: {0: '99.82%', 1: '99.69%'}, Val Loss: 0.093826344, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.22%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 1247/2000, Train Loss: 0.007819785, Train-Class-Acc: {0: '99.82%', 1: '99.69%'}, Val Loss: 0.094834630, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.08%', 1: '97.67%'}, LR: 0.000100000\n",
      "Epoch 1248/2000, Train Loss: 0.007595953, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.097162189, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.13%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 1249/2000, Train Loss: 0.007176273, Train-Class-Acc: {0: '99.82%', 1: '99.70%'}, Val Loss: 0.100657701, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.24%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 1250/2000, Train Loss: 0.006939311, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.099449786, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.18%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1251/2000, Train Loss: 0.006814269, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.099658097, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.04%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 1252/2000, Train Loss: 0.006769201, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.112314755, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.78%', 1: '96.30%'}, LR: 0.000100000\n",
      "Epoch 1253/2000, Train Loss: 0.007023943, Train-Class-Acc: {0: '99.81%', 1: '99.69%'}, Val Loss: 0.105112093, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.39%', 1: '97.16%'}, LR: 0.000100000\n",
      "Epoch 1254/2000, Train Loss: 0.006446431, Train-Class-Acc: {0: '99.83%', 1: '99.72%'}, Val Loss: 0.101051445, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.14%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1255/2000, Train Loss: 0.006396300, Train-Class-Acc: {0: '99.83%', 1: '99.72%'}, Val Loss: 0.103429853, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.27%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1256/2000, Train Loss: 0.006487636, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.105548561, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.19%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1257/2000, Train Loss: 0.006615127, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.103054609, Val Accuracy: 97.80%, Val-Class-Acc: {0: '97.86%', 1: '97.70%'}, LR: 0.000100000\n",
      "Epoch 1258/2000, Train Loss: 0.007529261, Train-Class-Acc: {0: '99.77%', 1: '99.65%'}, Val Loss: 0.106172547, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.23%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 1259/2000, Train Loss: 0.109023526, Train-Class-Acc: {0: '98.04%', 1: '96.86%'}, Val Loss: 0.159888769, Val Accuracy: 95.95%, Val-Class-Acc: {0: '97.18%', 1: '94.06%'}, LR: 0.000100000\n",
      "Epoch 1260/2000, Train Loss: 0.036692136, Train-Class-Acc: {0: '99.17%', 1: '97.99%'}, Val Loss: 0.107837184, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.28%', 1: '96.89%'}, LR: 0.000100000\n",
      "Epoch 1261/2000, Train Loss: 0.009330993, Train-Class-Acc: {0: '99.82%', 1: '99.66%'}, Val Loss: 0.101396646, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.25%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 1262/2000, Train Loss: 0.007943114, Train-Class-Acc: {0: '99.83%', 1: '99.69%'}, Val Loss: 0.099272437, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.18%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 1263/2000, Train Loss: 0.007341514, Train-Class-Acc: {0: '99.83%', 1: '99.71%'}, Val Loss: 0.097685594, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.21%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 1264/2000, Train Loss: 0.007025372, Train-Class-Acc: {0: '99.83%', 1: '99.71%'}, Val Loss: 0.098064156, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.27%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 1265/2000, Train Loss: 0.006926947, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.100269042, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.16%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 1266/2000, Train Loss: 0.006892483, Train-Class-Acc: {0: '99.82%', 1: '99.70%'}, Val Loss: 0.102207088, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.17%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 1267/2000, Train Loss: 0.006587310, Train-Class-Acc: {0: '99.83%', 1: '99.72%'}, Val Loss: 0.100757068, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.34%', 1: '97.23%'}, LR: 0.000100000\n",
      "Epoch 1268/2000, Train Loss: 0.006463592, Train-Class-Acc: {0: '99.83%', 1: '99.72%'}, Val Loss: 0.103114729, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.46%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 1269/2000, Train Loss: 0.006518243, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.105779658, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.45%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 1270/2000, Train Loss: 0.006354934, Train-Class-Acc: {0: '99.82%', 1: '99.72%'}, Val Loss: 0.106840679, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.35%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 1271/2000, Train Loss: 0.006618955, Train-Class-Acc: {0: '99.81%', 1: '99.71%'}, Val Loss: 0.105379878, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.30%', 1: '97.27%'}, LR: 0.000100000\n",
      "Epoch 1272/2000, Train Loss: 0.006148608, Train-Class-Acc: {0: '99.83%', 1: '99.72%'}, Val Loss: 0.107497817, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.32%', 1: '97.25%'}, LR: 0.000100000\n",
      "Epoch 1273/2000, Train Loss: 0.006339648, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.105601348, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.03%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 1274/2000, Train Loss: 0.006345344, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.106106580, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.21%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1275/2000, Train Loss: 0.006556901, Train-Class-Acc: {0: '99.81%', 1: '99.69%'}, Val Loss: 0.103644476, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.80%', 1: '97.85%'}, LR: 0.000100000\n",
      "Epoch 1276/2000, Train Loss: 0.006174870, Train-Class-Acc: {0: '99.82%', 1: '99.72%'}, Val Loss: 0.111656338, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.37%', 1: '97.12%'}, LR: 0.000100000\n",
      "Epoch 1277/2000, Train Loss: 0.066243981, Train-Class-Acc: {0: '98.59%', 1: '98.08%'}, Val Loss: 0.194906737, Val Accuracy: 96.26%, Val-Class-Acc: {0: '98.60%', 1: '92.65%'}, LR: 0.000100000\n",
      "Epoch 1278/2000, Train Loss: 0.031508989, Train-Class-Acc: {0: '99.18%', 1: '98.28%'}, Val Loss: 0.121781521, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.12%', 1: '96.99%'}, LR: 0.000100000\n",
      "Epoch 1279/2000, Train Loss: 0.007882581, Train-Class-Acc: {0: '99.82%', 1: '99.68%'}, Val Loss: 0.108971420, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.32%', 1: '96.81%'}, LR: 0.000100000\n",
      "Epoch 1280/2000, Train Loss: 0.007029287, Train-Class-Acc: {0: '99.83%', 1: '99.71%'}, Val Loss: 0.101341649, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.10%', 1: '97.61%'}, LR: 0.000100000\n",
      "Epoch 1281/2000, Train Loss: 0.006737109, Train-Class-Acc: {0: '99.83%', 1: '99.72%'}, Val Loss: 0.103888545, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.13%', 1: '97.25%'}, LR: 0.000100000\n",
      "Epoch 1282/2000, Train Loss: 0.006434187, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.104379461, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.10%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1283/2000, Train Loss: 0.006359802, Train-Class-Acc: {0: '99.83%', 1: '99.72%'}, Val Loss: 0.104756581, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.04%', 1: '97.60%'}, LR: 0.000100000\n",
      "Epoch 1284/2000, Train Loss: 0.006362905, Train-Class-Acc: {0: '99.82%', 1: '99.72%'}, Val Loss: 0.110502313, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.41%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 1285/2000, Train Loss: 0.006491529, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.104676868, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.87%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 1286/2000, Train Loss: 0.006294235, Train-Class-Acc: {0: '99.82%', 1: '99.72%'}, Val Loss: 0.106981722, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.32%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 1287/2000, Train Loss: 0.006576784, Train-Class-Acc: {0: '99.81%', 1: '99.70%'}, Val Loss: 0.112023144, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.31%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 1288/2000, Train Loss: 0.006265884, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.119433727, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.53%', 1: '96.74%'}, LR: 0.000100000\n",
      "Epoch 1289/2000, Train Loss: 0.065950630, Train-Class-Acc: {0: '98.50%', 1: '97.53%'}, Val Loss: 0.213611828, Val Accuracy: 95.48%, Val-Class-Acc: {0: '99.01%', 1: '90.06%'}, LR: 0.000100000\n",
      "Epoch 1290/2000, Train Loss: 0.030290619, Train-Class-Acc: {0: '99.22%', 1: '98.40%'}, Val Loss: 0.117075109, Val Accuracy: 97.61%, Val-Class-Acc: {0: '98.36%', 1: '96.44%'}, LR: 0.000100000\n",
      "Epoch 1291/2000, Train Loss: 0.008045543, Train-Class-Acc: {0: '99.83%', 1: '99.67%'}, Val Loss: 0.117044499, Val Accuracy: 97.76%, Val-Class-Acc: {0: '98.23%', 1: '97.03%'}, LR: 0.000100000\n",
      "Epoch 1292/2000, Train Loss: 0.007195276, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.116796209, Val Accuracy: 97.73%, Val-Class-Acc: {0: '98.29%', 1: '96.87%'}, LR: 0.000100000\n",
      "Epoch 1293/2000, Train Loss: 0.006691663, Train-Class-Acc: {0: '99.83%', 1: '99.72%'}, Val Loss: 0.118333308, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.39%', 1: '96.65%'}, LR: 0.000100000\n",
      "Epoch 1294/2000, Train Loss: 0.006464549, Train-Class-Acc: {0: '99.83%', 1: '99.72%'}, Val Loss: 0.115169789, Val Accuracy: 97.66%, Val-Class-Acc: {0: '97.87%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1295/2000, Train Loss: 0.006340849, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.107564940, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.15%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1296/2000, Train Loss: 0.006162211, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.108942550, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.19%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 1297/2000, Train Loss: 0.006147457, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.109120005, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.11%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 1298/2000, Train Loss: 0.006245897, Train-Class-Acc: {0: '99.82%', 1: '99.72%'}, Val Loss: 0.111063176, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.01%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 1299/2000, Train Loss: 0.006034226, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.112355210, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.20%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1300/2000, Train Loss: 0.005974128, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.108208098, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.23%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 1301/2000, Train Loss: 0.006260664, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.113081330, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.42%', 1: '97.08%'}, LR: 0.000100000\n",
      "Epoch 1302/2000, Train Loss: 0.006038487, Train-Class-Acc: {0: '99.82%', 1: '99.72%'}, Val Loss: 0.113082619, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.19%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1303/2000, Train Loss: 0.007544212, Train-Class-Acc: {0: '99.78%', 1: '99.63%'}, Val Loss: 0.127075294, Val Accuracy: 97.36%, Val-Class-Acc: {0: '96.46%', 1: '98.75%'}, LR: 0.000100000\n",
      "Epoch 1304/2000, Train Loss: 0.018013902, Train-Class-Acc: {0: '99.52%', 1: '99.29%'}, Val Loss: 0.116183956, Val Accuracy: 97.70%, Val-Class-Acc: {0: '98.23%', 1: '96.88%'}, LR: 0.000100000\n",
      "Epoch 1305/2000, Train Loss: 0.006004483, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.114515920, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.13%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 1306/2000, Train Loss: 0.005858434, Train-Class-Acc: {0: '99.84%', 1: '99.73%'}, Val Loss: 0.116438733, Val Accuracy: 97.66%, Val-Class-Acc: {0: '98.00%', 1: '97.14%'}, LR: 0.000100000\n",
      "Epoch 1307/2000, Train Loss: 0.005819436, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.114743930, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.41%', 1: '97.01%'}, LR: 0.000100000\n",
      "Epoch 1308/2000, Train Loss: 0.005712265, Train-Class-Acc: {0: '99.83%', 1: '99.74%'}, Val Loss: 0.121941093, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.64%', 1: '96.49%'}, LR: 0.000100000\n",
      "Epoch 1309/2000, Train Loss: 0.148971424, Train-Class-Acc: {0: '97.39%', 1: '96.68%'}, Val Loss: 0.237074702, Val Accuracy: 94.43%, Val-Class-Acc: {0: '93.66%', 1: '95.61%'}, LR: 0.000100000\n",
      "Epoch 1310/2000, Train Loss: 0.060610480, Train-Class-Acc: {0: '98.40%', 1: '96.84%'}, Val Loss: 0.100968991, Val Accuracy: 97.65%, Val-Class-Acc: {0: '98.37%', 1: '96.55%'}, LR: 0.000100000\n",
      "Epoch 1311/2000, Train Loss: 0.010398722, Train-Class-Acc: {0: '99.81%', 1: '99.62%'}, Val Loss: 0.099347457, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.23%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 1312/2000, Train Loss: 0.007852203, Train-Class-Acc: {0: '99.84%', 1: '99.71%'}, Val Loss: 0.100869334, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.25%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1313/2000, Train Loss: 0.007194827, Train-Class-Acc: {0: '99.83%', 1: '99.72%'}, Val Loss: 0.104533008, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.30%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 1314/2000, Train Loss: 0.006871311, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.095537476, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.34%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 1315/2000, Train Loss: 0.006594266, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.098805125, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.17%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 1316/2000, Train Loss: 0.006717648, Train-Class-Acc: {0: '99.83%', 1: '99.71%'}, Val Loss: 0.099352746, Val Accuracy: 97.74%, Val-Class-Acc: {0: '97.61%', 1: '97.94%'}, LR: 0.000100000\n",
      "Epoch 1317/2000, Train Loss: 0.006699224, Train-Class-Acc: {0: '99.82%', 1: '99.72%'}, Val Loss: 0.103601624, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.33%', 1: '97.25%'}, LR: 0.000100000\n",
      "Epoch 1318/2000, Train Loss: 0.006168432, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.104435129, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.19%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1319/2000, Train Loss: 0.006167383, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.103376453, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.03%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 1320/2000, Train Loss: 0.006394531, Train-Class-Acc: {0: '99.82%', 1: '99.72%'}, Val Loss: 0.106322061, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.44%', 1: '97.15%'}, LR: 0.000100000\n",
      "Epoch 1321/2000, Train Loss: 0.006138175, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.108445119, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.28%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 1322/2000, Train Loss: 0.005983717, Train-Class-Acc: {0: '99.83%', 1: '99.74%'}, Val Loss: 0.110940149, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.41%', 1: '97.08%'}, LR: 0.000100000\n",
      "Epoch 1323/2000, Train Loss: 0.006021557, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.124937218, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.81%', 1: '95.95%'}, LR: 0.000100000\n",
      "Epoch 1324/2000, Train Loss: 0.067777919, Train-Class-Acc: {0: '98.39%', 1: '97.43%'}, Val Loss: 0.109887756, Val Accuracy: 97.74%, Val-Class-Acc: {0: '97.67%', 1: '97.83%'}, LR: 0.000100000\n",
      "Epoch 1325/2000, Train Loss: 0.009550749, Train-Class-Acc: {0: '99.79%', 1: '99.58%'}, Val Loss: 0.105698212, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.17%', 1: '97.17%'}, LR: 0.000100000\n",
      "Epoch 1326/2000, Train Loss: 0.007097767, Train-Class-Acc: {0: '99.83%', 1: '99.72%'}, Val Loss: 0.108035906, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.30%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 1327/2000, Train Loss: 0.006439075, Train-Class-Acc: {0: '99.84%', 1: '99.73%'}, Val Loss: 0.106392549, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.11%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 1328/2000, Train Loss: 0.006310337, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.106638392, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.33%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 1329/2000, Train Loss: 0.006149407, Train-Class-Acc: {0: '99.84%', 1: '99.73%'}, Val Loss: 0.103078778, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.20%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 1330/2000, Train Loss: 0.005996832, Train-Class-Acc: {0: '99.83%', 1: '99.74%'}, Val Loss: 0.105595898, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.26%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 1331/2000, Train Loss: 0.006192575, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.106416941, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.04%', 1: '97.60%'}, LR: 0.000100000\n",
      "Epoch 1332/2000, Train Loss: 0.006060276, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.107276684, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.31%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 1333/2000, Train Loss: 0.005751633, Train-Class-Acc: {0: '99.84%', 1: '99.74%'}, Val Loss: 0.109902697, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.22%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1334/2000, Train Loss: 0.005945005, Train-Class-Acc: {0: '99.83%', 1: '99.72%'}, Val Loss: 0.107715644, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.08%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 1335/2000, Train Loss: 0.005997724, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.109019738, Val Accuracy: 97.80%, Val-Class-Acc: {0: '97.92%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1336/2000, Train Loss: 0.005791750, Train-Class-Acc: {0: '99.83%', 1: '99.74%'}, Val Loss: 0.111827104, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.26%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1337/2000, Train Loss: 0.005707385, Train-Class-Acc: {0: '99.83%', 1: '99.74%'}, Val Loss: 0.112724182, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.34%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 1338/2000, Train Loss: 0.005664936, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.110049677, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.27%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 1339/2000, Train Loss: 0.005695931, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.118512138, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.44%', 1: '96.85%'}, LR: 0.000100000\n",
      "Epoch 1340/2000, Train Loss: 0.005869713, Train-Class-Acc: {0: '99.82%', 1: '99.73%'}, Val Loss: 0.112600005, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.15%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 1341/2000, Train Loss: 0.005961255, Train-Class-Acc: {0: '99.82%', 1: '99.72%'}, Val Loss: 0.116600075, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.33%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 1342/2000, Train Loss: 0.070255039, Train-Class-Acc: {0: '98.68%', 1: '97.60%'}, Val Loss: 0.122163634, Val Accuracy: 97.29%, Val-Class-Acc: {0: '96.55%', 1: '98.42%'}, LR: 0.000100000\n",
      "Epoch 1343/2000, Train Loss: 0.022076177, Train-Class-Acc: {0: '99.39%', 1: '99.00%'}, Val Loss: 0.107545368, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.25%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 1344/2000, Train Loss: 0.006979114, Train-Class-Acc: {0: '99.84%', 1: '99.72%'}, Val Loss: 0.110177749, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.13%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 1345/2000, Train Loss: 0.006661585, Train-Class-Acc: {0: '99.83%', 1: '99.71%'}, Val Loss: 0.107927499, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.11%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 1346/2000, Train Loss: 0.006074949, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.112203337, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.44%', 1: '96.83%'}, LR: 0.000100000\n",
      "Epoch 1347/2000, Train Loss: 0.005860417, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.109111080, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.22%', 1: '97.00%'}, LR: 0.000100000\n",
      "Epoch 1348/2000, Train Loss: 0.005992378, Train-Class-Acc: {0: '99.83%', 1: '99.74%'}, Val Loss: 0.108288466, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.04%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 1349/2000, Train Loss: 0.005779243, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.110908279, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.12%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 1350/2000, Train Loss: 0.005614233, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.116037420, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.49%', 1: '96.78%'}, LR: 0.000100000\n",
      "Epoch 1351/2000, Train Loss: 0.005815809, Train-Class-Acc: {0: '99.84%', 1: '99.74%'}, Val Loss: 0.109134209, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.25%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 1352/2000, Train Loss: 0.005526715, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.111762975, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.04%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 1353/2000, Train Loss: 0.005727180, Train-Class-Acc: {0: '99.83%', 1: '99.73%'}, Val Loss: 0.111377238, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.09%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 1354/2000, Train Loss: 0.005523520, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.113730130, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.14%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 1355/2000, Train Loss: 0.005495558, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.117740599, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.35%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 1356/2000, Train Loss: 0.005546000, Train-Class-Acc: {0: '99.84%', 1: '99.74%'}, Val Loss: 0.112694786, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.03%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 1357/2000, Train Loss: 0.005405124, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.120754973, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.51%', 1: '96.78%'}, LR: 0.000100000\n",
      "Epoch 1358/2000, Train Loss: 0.005500011, Train-Class-Acc: {0: '99.84%', 1: '99.74%'}, Val Loss: 0.114509050, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.16%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 1359/2000, Train Loss: 0.005323057, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.119391927, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.22%', 1: '97.25%'}, LR: 0.000100000\n",
      "Epoch 1360/2000, Train Loss: 0.005263831, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.113233466, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.16%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 1361/2000, Train Loss: 0.180682373, Train-Class-Acc: {0: '96.60%', 1: '95.31%'}, Val Loss: 0.256062824, Val Accuracy: 93.24%, Val-Class-Acc: {0: '98.44%', 1: '85.23%'}, LR: 0.000100000\n",
      "Epoch 1362/2000, Train Loss: 0.074649883, Train-Class-Acc: {0: '98.16%', 1: '95.67%'}, Val Loss: 0.098411936, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.82%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 1363/2000, Train Loss: 0.011758999, Train-Class-Acc: {0: '99.82%', 1: '99.59%'}, Val Loss: 0.097119750, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.32%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1364/2000, Train Loss: 0.008119442, Train-Class-Acc: {0: '99.84%', 1: '99.71%'}, Val Loss: 0.101193328, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.21%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1365/2000, Train Loss: 0.007054662, Train-Class-Acc: {0: '99.85%', 1: '99.74%'}, Val Loss: 0.103801823, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.31%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1366/2000, Train Loss: 0.006633846, Train-Class-Acc: {0: '99.85%', 1: '99.74%'}, Val Loss: 0.102817684, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.24%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 1367/2000, Train Loss: 0.006551685, Train-Class-Acc: {0: '99.84%', 1: '99.74%'}, Val Loss: 0.104188865, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.31%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1368/2000, Train Loss: 0.006366998, Train-Class-Acc: {0: '99.84%', 1: '99.73%'}, Val Loss: 0.106041679, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.27%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1369/2000, Train Loss: 0.006206669, Train-Class-Acc: {0: '99.84%', 1: '99.74%'}, Val Loss: 0.107587898, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.41%', 1: '97.25%'}, LR: 0.000100000\n",
      "Epoch 1370/2000, Train Loss: 0.005870568, Train-Class-Acc: {0: '99.85%', 1: '99.75%'}, Val Loss: 0.106355240, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.28%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 1371/2000, Train Loss: 0.005886587, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.110520852, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.47%', 1: '97.08%'}, LR: 0.000100000\n",
      "Epoch 1372/2000, Train Loss: 0.005847010, Train-Class-Acc: {0: '99.84%', 1: '99.74%'}, Val Loss: 0.108110255, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.23%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1373/2000, Train Loss: 0.005643975, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.107231135, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.29%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1374/2000, Train Loss: 0.023833999, Train-Class-Acc: {0: '99.37%', 1: '99.09%'}, Val Loss: 0.123512270, Val Accuracy: 97.63%, Val-Class-Acc: {0: '97.73%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 1375/2000, Train Loss: 0.008015013, Train-Class-Acc: {0: '99.79%', 1: '99.62%'}, Val Loss: 0.116445044, Val Accuracy: 97.70%, Val-Class-Acc: {0: '98.10%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 1376/2000, Train Loss: 0.006149669, Train-Class-Acc: {0: '99.84%', 1: '99.73%'}, Val Loss: 0.113327423, Val Accuracy: 97.75%, Val-Class-Acc: {0: '98.23%', 1: '97.01%'}, LR: 0.000100000\n",
      "Epoch 1377/2000, Train Loss: 0.005723578, Train-Class-Acc: {0: '99.85%', 1: '99.75%'}, Val Loss: 0.112100069, Val Accuracy: 97.76%, Val-Class-Acc: {0: '98.21%', 1: '97.07%'}, LR: 0.000100000\n",
      "Epoch 1378/2000, Train Loss: 0.005627564, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.111197520, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.21%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 1379/2000, Train Loss: 0.005531192, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.110479406, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.18%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1380/2000, Train Loss: 0.005603263, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.110998793, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.14%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 1381/2000, Train Loss: 0.005609697, Train-Class-Acc: {0: '99.84%', 1: '99.74%'}, Val Loss: 0.110524417, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.29%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 1382/2000, Train Loss: 0.005382566, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.109745747, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.03%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 1383/2000, Train Loss: 0.007135660, Train-Class-Acc: {0: '99.79%', 1: '99.65%'}, Val Loss: 0.117973379, Val Accuracy: 97.67%, Val-Class-Acc: {0: '97.45%', 1: '98.02%'}, LR: 0.000100000\n",
      "Epoch 1384/2000, Train Loss: 0.051033133, Train-Class-Acc: {0: '98.85%', 1: '97.95%'}, Val Loss: 0.115526418, Val Accuracy: 97.71%, Val-Class-Acc: {0: '98.09%', 1: '97.12%'}, LR: 0.000100000\n",
      "Epoch 1385/2000, Train Loss: 0.006908476, Train-Class-Acc: {0: '99.84%', 1: '99.71%'}, Val Loss: 0.117677674, Val Accuracy: 97.65%, Val-Class-Acc: {0: '98.68%', 1: '96.07%'}, LR: 0.000100000\n",
      "Epoch 1386/2000, Train Loss: 0.006299806, Train-Class-Acc: {0: '99.84%', 1: '99.73%'}, Val Loss: 0.108499720, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.28%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 1387/2000, Train Loss: 0.005873651, Train-Class-Acc: {0: '99.84%', 1: '99.74%'}, Val Loss: 0.110894913, Val Accuracy: 97.77%, Val-Class-Acc: {0: '98.29%', 1: '96.97%'}, LR: 0.000100000\n",
      "Epoch 1388/2000, Train Loss: 0.005547287, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.112678941, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.22%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 1389/2000, Train Loss: 0.005422842, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.111421407, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.14%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 1390/2000, Train Loss: 0.005482117, Train-Class-Acc: {0: '99.84%', 1: '99.76%'}, Val Loss: 0.113122821, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.25%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 1391/2000, Train Loss: 0.005493335, Train-Class-Acc: {0: '99.84%', 1: '99.76%'}, Val Loss: 0.116664328, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.43%', 1: '97.03%'}, LR: 0.000100000\n",
      "Epoch 1392/2000, Train Loss: 0.005560259, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.112750666, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.36%', 1: '96.98%'}, LR: 0.000100000\n",
      "Epoch 1393/2000, Train Loss: 0.005385181, Train-Class-Acc: {0: '99.85%', 1: '99.75%'}, Val Loss: 0.113316841, Val Accuracy: 97.72%, Val-Class-Acc: {0: '97.98%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 1394/2000, Train Loss: 0.005292331, Train-Class-Acc: {0: '99.84%', 1: '99.76%'}, Val Loss: 0.114954676, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.42%', 1: '97.07%'}, LR: 0.000100000\n",
      "Epoch 1395/2000, Train Loss: 0.005408516, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.111708795, Val Accuracy: 97.79%, Val-Class-Acc: {0: '97.79%', 1: '97.79%'}, LR: 0.000100000\n",
      "Epoch 1396/2000, Train Loss: 0.036830359, Train-Class-Acc: {0: '99.17%', 1: '98.66%'}, Val Loss: 0.129143582, Val Accuracy: 97.59%, Val-Class-Acc: {0: '98.29%', 1: '96.51%'}, LR: 0.000100000\n",
      "Epoch 1397/2000, Train Loss: 0.006301833, Train-Class-Acc: {0: '99.84%', 1: '99.72%'}, Val Loss: 0.114121399, Val Accuracy: 97.76%, Val-Class-Acc: {0: '98.23%', 1: '97.04%'}, LR: 0.000100000\n",
      "Epoch 1398/2000, Train Loss: 0.005671505, Train-Class-Acc: {0: '99.85%', 1: '99.75%'}, Val Loss: 0.113967156, Val Accuracy: 97.80%, Val-Class-Acc: {0: '97.87%', 1: '97.70%'}, LR: 0.000100000\n",
      "Epoch 1399/2000, Train Loss: 0.005617693, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.116679731, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.03%', 1: '97.15%'}, LR: 0.000100000\n",
      "Epoch 1400/2000, Train Loss: 0.005264695, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.116293988, Val Accuracy: 97.76%, Val-Class-Acc: {0: '98.15%', 1: '97.17%'}, LR: 0.000100000\n",
      "Epoch 1401/2000, Train Loss: 0.005171932, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.116256177, Val Accuracy: 97.74%, Val-Class-Acc: {0: '98.10%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 1402/2000, Train Loss: 0.005231113, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.114396200, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.07%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1403/2000, Train Loss: 0.005072649, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.116777385, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.32%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 1404/2000, Train Loss: 0.005181165, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.117146427, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.02%', 1: '97.49%'}, LR: 0.000100000\n",
      "Epoch 1405/2000, Train Loss: 0.005022364, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.116700186, Val Accuracy: 97.80%, Val-Class-Acc: {0: '97.87%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 1406/2000, Train Loss: 0.005034742, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.117224453, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.49%', 1: '97.04%'}, LR: 0.000100000\n",
      "Epoch 1407/2000, Train Loss: 0.005324040, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.116354415, Val Accuracy: 97.72%, Val-Class-Acc: {0: '97.58%', 1: '97.93%'}, LR: 0.000100000\n",
      "Epoch 1408/2000, Train Loss: 0.130009542, Train-Class-Acc: {0: '97.31%', 1: '95.65%'}, Val Loss: 0.096786158, Val Accuracy: 97.31%, Val-Class-Acc: {0: '98.40%', 1: '95.62%'}, LR: 0.000100000\n",
      "Epoch 1409/2000, Train Loss: 0.015686972, Train-Class-Acc: {0: '99.62%', 1: '99.29%'}, Val Loss: 0.102360636, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.32%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1410/2000, Train Loss: 0.007339148, Train-Class-Acc: {0: '99.85%', 1: '99.72%'}, Val Loss: 0.104320958, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.13%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 1411/2000, Train Loss: 0.006380767, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.105451840, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.36%', 1: '97.12%'}, LR: 0.000100000\n",
      "Epoch 1412/2000, Train Loss: 0.006150298, Train-Class-Acc: {0: '99.85%', 1: '99.75%'}, Val Loss: 0.108974006, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.12%', 1: '97.51%'}, LR: 0.000100000\n",
      "Epoch 1413/2000, Train Loss: 0.005766326, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.107231393, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.19%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1414/2000, Train Loss: 0.005540835, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.115542911, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.39%', 1: '97.07%'}, LR: 0.000100000\n",
      "Epoch 1415/2000, Train Loss: 0.005514736, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.111671822, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.45%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 1416/2000, Train Loss: 0.005411480, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.113513772, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.10%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 1417/2000, Train Loss: 0.005340553, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.112745753, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.05%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 1418/2000, Train Loss: 0.005317565, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.113791672, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.17%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 1419/2000, Train Loss: 0.005159377, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.113402342, Val Accuracy: 97.79%, Val-Class-Acc: {0: '97.83%', 1: '97.73%'}, LR: 0.000100000\n",
      "Epoch 1420/2000, Train Loss: 0.005169829, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.116193761, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.20%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 1421/2000, Train Loss: 0.005087453, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.114172413, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.16%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1422/2000, Train Loss: 0.005471668, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.112474086, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.09%', 1: '97.49%'}, LR: 0.000100000\n",
      "Epoch 1423/2000, Train Loss: 0.005082523, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.110761186, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.00%', 1: '97.61%'}, LR: 0.000100000\n",
      "Epoch 1424/2000, Train Loss: 0.005306939, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.115555798, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.01%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1425/2000, Train Loss: 0.005070235, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.112136928, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.96%', 1: '97.63%'}, LR: 0.000100000\n",
      "Epoch 1426/2000, Train Loss: 0.005268558, Train-Class-Acc: {0: '99.85%', 1: '99.75%'}, Val Loss: 0.116065731, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.23%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 1427/2000, Train Loss: 0.004914694, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.115772063, Val Accuracy: 97.81%, Val-Class-Acc: {0: '98.01%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 1428/2000, Train Loss: 0.006206118, Train-Class-Acc: {0: '99.81%', 1: '99.71%'}, Val Loss: 0.115968303, Val Accuracy: 97.76%, Val-Class-Acc: {0: '97.69%', 1: '97.88%'}, LR: 0.000100000\n",
      "Epoch 1429/2000, Train Loss: 0.005189054, Train-Class-Acc: {0: '99.84%', 1: '99.76%'}, Val Loss: 0.113483136, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.86%', 1: '97.79%'}, LR: 0.000100000\n",
      "Epoch 1430/2000, Train Loss: 0.004859369, Train-Class-Acc: {0: '99.85%', 1: '99.78%'}, Val Loss: 0.116857668, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.12%', 1: '97.49%'}, LR: 0.000100000\n",
      "Epoch 1431/2000, Train Loss: 0.004986486, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.116132966, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.94%', 1: '97.61%'}, LR: 0.000100000\n",
      "Epoch 1432/2000, Train Loss: 0.027042883, Train-Class-Acc: {0: '99.69%', 1: '99.23%'}, Val Loss: 0.356033750, Val Accuracy: 94.57%, Val-Class-Acc: {0: '98.88%', 1: '87.94%'}, LR: 0.000100000\n",
      "Epoch 1433/2000, Train Loss: 0.393630728, Train-Class-Acc: {0: '92.12%', 1: '88.35%'}, Val Loss: 0.088264698, Val Accuracy: 97.10%, Val-Class-Acc: {0: '98.45%', 1: '95.01%'}, LR: 0.000100000\n",
      "Epoch 1434/2000, Train Loss: 0.024657016, Train-Class-Acc: {0: '99.50%', 1: '98.80%'}, Val Loss: 0.086475611, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.05%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1435/2000, Train Loss: 0.010770380, Train-Class-Acc: {0: '99.81%', 1: '99.63%'}, Val Loss: 0.086348879, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.05%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 1436/2000, Train Loss: 0.008222445, Train-Class-Acc: {0: '99.84%', 1: '99.72%'}, Val Loss: 0.089933192, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.10%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 1437/2000, Train Loss: 0.007240799, Train-Class-Acc: {0: '99.85%', 1: '99.73%'}, Val Loss: 0.090292989, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.32%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1438/2000, Train Loss: 0.007511486, Train-Class-Acc: {0: '99.82%', 1: '99.70%'}, Val Loss: 0.092755430, Val Accuracy: 97.85%, Val-Class-Acc: {0: '97.86%', 1: '97.84%'}, LR: 0.000100000\n",
      "Epoch 1439/2000, Train Loss: 0.006360513, Train-Class-Acc: {0: '99.85%', 1: '99.75%'}, Val Loss: 0.098245888, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.39%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 1440/2000, Train Loss: 0.006158983, Train-Class-Acc: {0: '99.85%', 1: '99.75%'}, Val Loss: 0.096985364, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.25%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 1441/2000, Train Loss: 0.005913706, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.107321895, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.71%', 1: '96.69%'}, LR: 0.000100000\n",
      "Epoch 1442/2000, Train Loss: 0.007838341, Train-Class-Acc: {0: '99.78%', 1: '99.65%'}, Val Loss: 0.099020311, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.16%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 1443/2000, Train Loss: 0.005893887, Train-Class-Acc: {0: '99.85%', 1: '99.75%'}, Val Loss: 0.103235565, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.41%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 1444/2000, Train Loss: 0.005562850, Train-Class-Acc: {0: '99.86%', 1: '99.76%'}, Val Loss: 0.103479509, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.22%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1445/2000, Train Loss: 0.005711563, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.105318614, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.40%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 1446/2000, Train Loss: 0.005421701, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.101501902, Val Accuracy: 97.84%, Val-Class-Acc: {0: '97.92%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 1447/2000, Train Loss: 0.005381139, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.103538402, Val Accuracy: 97.84%, Val-Class-Acc: {0: '97.91%', 1: '97.73%'}, LR: 0.000100000\n",
      "Epoch 1448/2000, Train Loss: 0.005712097, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.107546879, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.72%', 1: '97.00%'}, LR: 0.000100000\n",
      "Epoch 1449/2000, Train Loss: 0.005405919, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.105905835, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.36%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 1450/2000, Train Loss: 0.028666240, Train-Class-Acc: {0: '99.47%', 1: '99.14%'}, Val Loss: 0.187608080, Val Accuracy: 96.52%, Val-Class-Acc: {0: '98.95%', 1: '92.79%'}, LR: 0.000100000\n",
      "Epoch 1451/2000, Train Loss: 0.018681776, Train-Class-Acc: {0: '99.52%', 1: '99.22%'}, Val Loss: 0.101449264, Val Accuracy: 97.86%, Val-Class-Acc: {0: '97.96%', 1: '97.70%'}, LR: 0.000100000\n",
      "Epoch 1452/2000, Train Loss: 0.021864600, Train-Class-Acc: {0: '99.39%', 1: '98.94%'}, Val Loss: 0.525800363, Val Accuracy: 90.70%, Val-Class-Acc: {0: '84.99%', 1: '99.48%'}, LR: 0.000100000\n",
      "Epoch 1453/2000, Train Loss: 0.095985651, Train-Class-Acc: {0: '97.62%', 1: '96.92%'}, Val Loss: 0.081549743, Val Accuracy: 98.01%, Val-Class-Acc: {0: '97.92%', 1: '98.14%'}, LR: 0.000100000\n",
      "Epoch 1454/2000, Train Loss: 0.009022198, Train-Class-Acc: {0: '99.83%', 1: '99.67%'}, Val Loss: 0.084940384, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.05%', 1: '97.90%'}, LR: 0.000100000\n",
      "Epoch 1455/2000, Train Loss: 0.007010098, Train-Class-Acc: {0: '99.85%', 1: '99.75%'}, Val Loss: 0.088030933, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.25%', 1: '97.61%'}, LR: 0.000100000\n",
      "Epoch 1456/2000, Train Loss: 0.006300354, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.090675115, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.25%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 1457/2000, Train Loss: 0.006046048, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.092577291, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.24%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 1458/2000, Train Loss: 0.005860054, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.095085002, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.45%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 1459/2000, Train Loss: 0.005727779, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.098334916, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.48%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 1460/2000, Train Loss: 0.005633912, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.095930536, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.14%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 1461/2000, Train Loss: 0.005473131, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.101790870, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.45%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 1462/2000, Train Loss: 0.005409939, Train-Class-Acc: {0: '99.85%', 1: '99.78%'}, Val Loss: 0.101683767, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.43%', 1: '97.17%'}, LR: 0.000100000\n",
      "Epoch 1463/2000, Train Loss: 0.005238046, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.104117936, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.47%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 1464/2000, Train Loss: 0.005307285, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.100982870, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.14%', 1: '97.43%'}, LR: 0.000100000\n",
      "Epoch 1465/2000, Train Loss: 0.005307623, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.101936576, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.03%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 1466/2000, Train Loss: 0.005134588, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.101803297, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.23%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1467/2000, Train Loss: 0.005042514, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.103601258, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.16%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 1468/2000, Train Loss: 0.005378010, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.102057479, Val Accuracy: 97.84%, Val-Class-Acc: {0: '97.96%', 1: '97.65%'}, LR: 0.000100000\n",
      "Epoch 1469/2000, Train Loss: 0.005186755, Train-Class-Acc: {0: '99.85%', 1: '99.78%'}, Val Loss: 0.104059597, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.37%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1470/2000, Train Loss: 0.005106511, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.108027470, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.38%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 1471/2000, Train Loss: 0.004949016, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.107300945, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.39%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 1472/2000, Train Loss: 0.006176988, Train-Class-Acc: {0: '99.81%', 1: '99.72%'}, Val Loss: 0.106237451, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.47%', 1: '97.24%'}, LR: 0.000100000\n",
      "Epoch 1473/2000, Train Loss: 0.006265884, Train-Class-Acc: {0: '99.82%', 1: '99.69%'}, Val Loss: 0.112635820, Val Accuracy: 97.57%, Val-Class-Acc: {0: '97.14%', 1: '98.24%'}, LR: 0.000100000\n",
      "Epoch 1474/2000, Train Loss: 0.104501266, Train-Class-Acc: {0: '97.81%', 1: '96.38%'}, Val Loss: 0.094188134, Val Accuracy: 97.67%, Val-Class-Acc: {0: '98.44%', 1: '96.48%'}, LR: 0.000100000\n",
      "Epoch 1475/2000, Train Loss: 0.008893104, Train-Class-Acc: {0: '99.82%', 1: '99.66%'}, Val Loss: 0.091225204, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.19%', 1: '97.70%'}, LR: 0.000100000\n",
      "Epoch 1476/2000, Train Loss: 0.006452624, Train-Class-Acc: {0: '99.86%', 1: '99.76%'}, Val Loss: 0.096818429, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.32%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1477/2000, Train Loss: 0.006015793, Train-Class-Acc: {0: '99.86%', 1: '99.76%'}, Val Loss: 0.099438443, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.21%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 1478/2000, Train Loss: 0.005546734, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.101967142, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.40%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 1479/2000, Train Loss: 0.005545905, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.104485461, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.39%', 1: '97.20%'}, LR: 0.000100000\n",
      "Epoch 1480/2000, Train Loss: 0.005273433, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.102916824, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.24%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1481/2000, Train Loss: 0.005221164, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.102764698, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.31%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1482/2000, Train Loss: 0.005028932, Train-Class-Acc: {0: '99.86%', 1: '99.79%'}, Val Loss: 0.101827055, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.15%', 1: '97.49%'}, LR: 0.000100000\n",
      "Epoch 1483/2000, Train Loss: 0.005218777, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.107389176, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.15%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 1484/2000, Train Loss: 0.005060936, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.105474474, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.08%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 1485/2000, Train Loss: 0.004881269, Train-Class-Acc: {0: '99.86%', 1: '99.79%'}, Val Loss: 0.108578771, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.44%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 1486/2000, Train Loss: 0.005345481, Train-Class-Acc: {0: '99.84%', 1: '99.76%'}, Val Loss: 0.107590953, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.18%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1487/2000, Train Loss: 0.076674651, Train-Class-Acc: {0: '98.36%', 1: '97.20%'}, Val Loss: 0.126018344, Val Accuracy: 96.82%, Val-Class-Acc: {0: '98.63%', 1: '94.04%'}, LR: 0.000100000\n",
      "Epoch 1488/2000, Train Loss: 0.013106328, Train-Class-Acc: {0: '99.69%', 1: '99.35%'}, Val Loss: 0.097953419, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.28%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 1489/2000, Train Loss: 0.006341889, Train-Class-Acc: {0: '99.87%', 1: '99.75%'}, Val Loss: 0.100033736, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.13%', 1: '97.66%'}, LR: 0.000100000\n",
      "Epoch 1490/2000, Train Loss: 0.005754586, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.102614640, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.19%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 1491/2000, Train Loss: 0.005603986, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.108104585, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.41%', 1: '97.07%'}, LR: 0.000100000\n",
      "Epoch 1492/2000, Train Loss: 0.005497207, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.105531041, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.12%', 1: '97.54%'}, LR: 0.000100000\n",
      "Epoch 1493/2000, Train Loss: 0.005348762, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.108833029, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.08%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 1494/2000, Train Loss: 0.005026833, Train-Class-Acc: {0: '99.86%', 1: '99.80%'}, Val Loss: 0.107271159, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.26%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 1495/2000, Train Loss: 0.004992837, Train-Class-Acc: {0: '99.86%', 1: '99.79%'}, Val Loss: 0.107620883, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.31%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 1496/2000, Train Loss: 0.004872791, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.114057331, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.46%', 1: '96.93%'}, LR: 0.000100000\n",
      "Epoch 1497/2000, Train Loss: 0.004980068, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.117370404, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.49%', 1: '96.80%'}, LR: 0.000100000\n",
      "Epoch 1498/2000, Train Loss: 0.005191222, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.110036545, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.10%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 1499/2000, Train Loss: 0.004960570, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.109978811, Val Accuracy: 97.74%, Val-Class-Acc: {0: '97.60%', 1: '97.96%'}, LR: 0.000100000\n",
      "Epoch 1500/2000, Train Loss: 0.005739486, Train-Class-Acc: {0: '99.83%', 1: '99.74%'}, Val Loss: 0.121222767, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.79%', 1: '96.45%'}, LR: 0.000100000\n",
      "Epoch 1501/2000, Train Loss: 0.005021451, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.111276555, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.21%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1502/2000, Train Loss: 0.004684049, Train-Class-Acc: {0: '99.86%', 1: '99.80%'}, Val Loss: 0.112812609, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.15%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 1503/2000, Train Loss: 0.004644319, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.112947561, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.97%', 1: '97.60%'}, LR: 0.000100000\n",
      "Epoch 1504/2000, Train Loss: 0.004758474, Train-Class-Acc: {0: '99.86%', 1: '99.79%'}, Val Loss: 0.114076689, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.29%', 1: '97.24%'}, LR: 0.000100000\n",
      "Epoch 1505/2000, Train Loss: 0.004730228, Train-Class-Acc: {0: '99.86%', 1: '99.79%'}, Val Loss: 0.113442003, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.20%', 1: '97.36%'}, LR: 0.000100000\n",
      "Epoch 1506/2000, Train Loss: 0.004979241, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.115419295, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.17%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 1507/2000, Train Loss: 0.222347091, Train-Class-Acc: {0: '97.42%', 1: '95.45%'}, Val Loss: 1.027479747, Val Accuracy: 81.67%, Val-Class-Acc: {0: '97.57%', 1: '57.22%'}, LR: 0.000100000\n",
      "Epoch 1508/2000, Train Loss: 0.239876879, Train-Class-Acc: {0: '93.88%', 1: '88.13%'}, Val Loss: 0.080993226, Val Accuracy: 97.32%, Val-Class-Acc: {0: '98.54%', 1: '95.44%'}, LR: 0.000100000\n",
      "Epoch 1509/2000, Train Loss: 0.026182293, Train-Class-Acc: {0: '99.48%', 1: '98.74%'}, Val Loss: 0.075355867, Val Accuracy: 97.91%, Val-Class-Acc: {0: '97.92%', 1: '97.88%'}, LR: 0.000100000\n",
      "Epoch 1510/2000, Train Loss: 0.011379588, Train-Class-Acc: {0: '99.81%', 1: '99.60%'}, Val Loss: 0.073900695, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.15%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 1511/2000, Train Loss: 0.008955095, Train-Class-Acc: {0: '99.83%', 1: '99.67%'}, Val Loss: 0.085270842, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.33%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1512/2000, Train Loss: 0.007309427, Train-Class-Acc: {0: '99.85%', 1: '99.73%'}, Val Loss: 0.088115847, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.34%', 1: '97.29%'}, LR: 0.000100000\n",
      "Epoch 1513/2000, Train Loss: 0.006699503, Train-Class-Acc: {0: '99.85%', 1: '99.74%'}, Val Loss: 0.088945184, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.37%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1514/2000, Train Loss: 0.006302016, Train-Class-Acc: {0: '99.86%', 1: '99.75%'}, Val Loss: 0.090343843, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.19%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 1515/2000, Train Loss: 0.005953370, Train-Class-Acc: {0: '99.86%', 1: '99.76%'}, Val Loss: 0.093840820, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.37%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1516/2000, Train Loss: 0.005775172, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.094374013, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.26%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 1517/2000, Train Loss: 0.005580285, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.095419578, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.22%', 1: '97.43%'}, LR: 0.000100000\n",
      "Epoch 1518/2000, Train Loss: 0.005543424, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.095594663, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.20%', 1: '97.43%'}, LR: 0.000100000\n",
      "Epoch 1519/2000, Train Loss: 0.005464010, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.097787736, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.27%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 1520/2000, Train Loss: 0.008341339, Train-Class-Acc: {0: '99.76%', 1: '99.59%'}, Val Loss: 0.101586526, Val Accuracy: 97.78%, Val-Class-Acc: {0: '97.93%', 1: '97.54%'}, LR: 0.000100000\n",
      "Epoch 1521/2000, Train Loss: 0.006475040, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.096031199, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.01%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1522/2000, Train Loss: 0.005218272, Train-Class-Acc: {0: '99.87%', 1: '99.77%'}, Val Loss: 0.098263996, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.14%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 1523/2000, Train Loss: 0.005396593, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.099507554, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.19%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1524/2000, Train Loss: 0.005197930, Train-Class-Acc: {0: '99.86%', 1: '99.77%'}, Val Loss: 0.100747245, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.38%', 1: '97.25%'}, LR: 0.000100000\n",
      "Epoch 1525/2000, Train Loss: 0.005156299, Train-Class-Acc: {0: '99.87%', 1: '99.77%'}, Val Loss: 0.101255368, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.10%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1526/2000, Train Loss: 0.005360247, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.100553964, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.19%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1527/2000, Train Loss: 0.004980185, Train-Class-Acc: {0: '99.87%', 1: '99.78%'}, Val Loss: 0.101739232, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.27%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 1528/2000, Train Loss: 0.004869630, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.098023327, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.08%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 1529/2000, Train Loss: 0.155068334, Train-Class-Acc: {0: '97.16%', 1: '95.57%'}, Val Loss: 0.102012117, Val Accuracy: 97.34%, Val-Class-Acc: {0: '97.26%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 1530/2000, Train Loss: 0.027210355, Train-Class-Acc: {0: '99.27%', 1: '98.76%'}, Val Loss: 0.073737488, Val Accuracy: 98.06%, Val-Class-Acc: {0: '98.27%', 1: '97.73%'}, LR: 0.000100000\n",
      "Epoch 1531/2000, Train Loss: 0.008387820, Train-Class-Acc: {0: '99.86%', 1: '99.72%'}, Val Loss: 0.077349686, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.40%', 1: '97.63%'}, LR: 0.000100000\n",
      "Epoch 1532/2000, Train Loss: 0.006783648, Train-Class-Acc: {0: '99.87%', 1: '99.77%'}, Val Loss: 0.080693380, Val Accuracy: 98.03%, Val-Class-Acc: {0: '98.33%', 1: '97.58%'}, LR: 0.000100000\n",
      "Epoch 1533/2000, Train Loss: 0.006149011, Train-Class-Acc: {0: '99.87%', 1: '99.78%'}, Val Loss: 0.081730826, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.29%', 1: '97.51%'}, LR: 0.000100000\n",
      "Epoch 1534/2000, Train Loss: 0.005762158, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.085663650, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.15%', 1: '97.63%'}, LR: 0.000100000\n",
      "Epoch 1535/2000, Train Loss: 0.005586313, Train-Class-Acc: {0: '99.87%', 1: '99.78%'}, Val Loss: 0.086090601, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.07%', 1: '97.64%'}, LR: 0.000100000\n",
      "Epoch 1536/2000, Train Loss: 0.005508639, Train-Class-Acc: {0: '99.87%', 1: '99.78%'}, Val Loss: 0.089142010, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.23%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 1537/2000, Train Loss: 0.005365628, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.095105027, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.46%', 1: '97.09%'}, LR: 0.000100000\n",
      "Epoch 1538/2000, Train Loss: 0.005195277, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.093789933, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.30%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1539/2000, Train Loss: 0.005097899, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.094364535, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.25%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1540/2000, Train Loss: 0.005036082, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.092937587, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.19%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1541/2000, Train Loss: 0.004933729, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.099927121, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.30%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 1542/2000, Train Loss: 0.005061597, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.099157935, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.34%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 1543/2000, Train Loss: 0.004842008, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.099549712, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.24%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1544/2000, Train Loss: 0.005377345, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.096374657, Val Accuracy: 97.78%, Val-Class-Acc: {0: '97.67%', 1: '97.94%'}, LR: 0.000100000\n",
      "Epoch 1545/2000, Train Loss: 0.006860562, Train-Class-Acc: {0: '99.79%', 1: '99.68%'}, Val Loss: 0.096821695, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.11%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 1546/2000, Train Loss: 0.004761279, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.103473178, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.24%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 1547/2000, Train Loss: 0.004837736, Train-Class-Acc: {0: '99.86%', 1: '99.79%'}, Val Loss: 0.101401443, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.17%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 1548/2000, Train Loss: 0.191363665, Train-Class-Acc: {0: '96.11%', 1: '94.06%'}, Val Loss: 0.120295160, Val Accuracy: 96.77%, Val-Class-Acc: {0: '98.43%', 1: '94.21%'}, LR: 0.000100000\n",
      "Epoch 1549/2000, Train Loss: 0.022276446, Train-Class-Acc: {0: '99.57%', 1: '98.94%'}, Val Loss: 0.101841297, Val Accuracy: 97.68%, Val-Class-Acc: {0: '98.21%', 1: '96.87%'}, LR: 0.000100000\n",
      "Epoch 1550/2000, Train Loss: 0.008332113, Train-Class-Acc: {0: '99.87%', 1: '99.73%'}, Val Loss: 0.064474121, Val Accuracy: 98.33%, Val-Class-Acc: {0: '98.50%', 1: '98.08%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.16%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_382.pth\n",
      "Model saved after epoch 1550 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1550.pth \n",
      "\n",
      "Epoch 1551/2000, Train Loss: 0.006852379, Train-Class-Acc: {0: '99.87%', 1: '99.78%'}, Val Loss: 0.073781721, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.41%', 1: '97.81%'}, LR: 0.000100000\n",
      "Epoch 1552/2000, Train Loss: 0.006179282, Train-Class-Acc: {0: '99.88%', 1: '99.78%'}, Val Loss: 0.076965277, Val Accuracy: 98.11%, Val-Class-Acc: {0: '98.14%', 1: '98.06%'}, LR: 0.000100000\n",
      "Epoch 1553/2000, Train Loss: 0.005842024, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.076071498, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.32%', 1: '97.87%'}, LR: 0.000100000\n",
      "Epoch 1554/2000, Train Loss: 0.005554189, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.079879570, Val Accuracy: 98.03%, Val-Class-Acc: {0: '98.12%', 1: '97.88%'}, LR: 0.000100000\n",
      "Epoch 1555/2000, Train Loss: 0.005431171, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.081435260, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.19%', 1: '97.73%'}, LR: 0.000100000\n",
      "Epoch 1556/2000, Train Loss: 0.005275278, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.083305478, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.34%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 1557/2000, Train Loss: 0.005272534, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.083362143, Val Accuracy: 97.84%, Val-Class-Acc: {0: '97.88%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 1558/2000, Train Loss: 0.005084052, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.085870490, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.19%', 1: '97.49%'}, LR: 0.000100000\n",
      "Epoch 1559/2000, Train Loss: 0.004927595, Train-Class-Acc: {0: '99.87%', 1: '99.81%'}, Val Loss: 0.090332254, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.30%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1560/2000, Train Loss: 0.004949236, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.095607623, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.27%', 1: '97.27%'}, LR: 0.000100000\n",
      "Epoch 1561/2000, Train Loss: 0.004896038, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.092473433, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.13%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 1562/2000, Train Loss: 0.004861514, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.092462897, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.10%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 1563/2000, Train Loss: 0.006277741, Train-Class-Acc: {0: '99.82%', 1: '99.71%'}, Val Loss: 0.096087963, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.41%', 1: '97.16%'}, LR: 0.000100000\n",
      "Epoch 1564/2000, Train Loss: 0.178900825, Train-Class-Acc: {0: '96.37%', 1: '94.25%'}, Val Loss: 0.094756334, Val Accuracy: 97.74%, Val-Class-Acc: {0: '97.53%', 1: '98.05%'}, LR: 0.000100000\n",
      "Epoch 1565/2000, Train Loss: 0.020271458, Train-Class-Acc: {0: '99.60%', 1: '99.11%'}, Val Loss: 0.079757462, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.31%', 1: '97.26%'}, LR: 0.000100000\n",
      "Epoch 1566/2000, Train Loss: 0.008127618, Train-Class-Acc: {0: '99.87%', 1: '99.74%'}, Val Loss: 0.083001688, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.35%', 1: '97.24%'}, LR: 0.000100000\n",
      "Epoch 1567/2000, Train Loss: 0.006764189, Train-Class-Acc: {0: '99.87%', 1: '99.77%'}, Val Loss: 0.082222116, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.24%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1568/2000, Train Loss: 0.006051433, Train-Class-Acc: {0: '99.88%', 1: '99.79%'}, Val Loss: 0.088807827, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.18%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 1569/2000, Train Loss: 0.005729807, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.089492057, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.93%', 1: '97.63%'}, LR: 0.000100000\n",
      "Epoch 1570/2000, Train Loss: 0.005555908, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.089969426, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.16%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 1571/2000, Train Loss: 0.005365503, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.091687575, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.17%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 1572/2000, Train Loss: 0.005315499, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.093393853, Val Accuracy: 97.78%, Val-Class-Acc: {0: '97.86%', 1: '97.65%'}, LR: 0.000100000\n",
      "Epoch 1573/2000, Train Loss: 0.005325100, Train-Class-Acc: {0: '99.87%', 1: '99.78%'}, Val Loss: 0.092311111, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.01%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 1574/2000, Train Loss: 0.005043937, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.100402597, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.36%', 1: '97.08%'}, LR: 0.000100000\n",
      "Epoch 1575/2000, Train Loss: 0.005022362, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.098643118, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.17%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1576/2000, Train Loss: 0.004905606, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.098639119, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.29%', 1: '97.19%'}, LR: 0.000100000\n",
      "Epoch 1577/2000, Train Loss: 0.004854956, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.098723984, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.35%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 1578/2000, Train Loss: 0.004855485, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.100017753, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.30%', 1: '97.24%'}, LR: 0.000100000\n",
      "Epoch 1579/2000, Train Loss: 0.004688331, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.100515099, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.12%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1580/2000, Train Loss: 0.004731813, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.101553002, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.18%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1581/2000, Train Loss: 0.004674223, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.101028721, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.19%', 1: '97.43%'}, LR: 0.000100000\n",
      "Epoch 1582/2000, Train Loss: 0.004660098, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.101190459, Val Accuracy: 97.78%, Val-Class-Acc: {0: '97.95%', 1: '97.51%'}, LR: 0.000100000\n",
      "Epoch 1583/2000, Train Loss: 0.004597109, Train-Class-Acc: {0: '99.87%', 1: '99.81%'}, Val Loss: 0.102931185, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.34%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 1584/2000, Train Loss: 0.004903409, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.114704317, Val Accuracy: 97.80%, Val-Class-Acc: {0: '98.66%', 1: '96.48%'}, LR: 0.000100000\n",
      "Epoch 1585/2000, Train Loss: 0.005007676, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.103925343, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.14%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 1586/2000, Train Loss: 0.183542813, Train-Class-Acc: {0: '97.69%', 1: '95.97%'}, Val Loss: 0.446898870, Val Accuracy: 89.49%, Val-Class-Acc: {0: '84.76%', 1: '96.77%'}, LR: 0.000100000\n",
      "Epoch 1587/2000, Train Loss: 0.223035995, Train-Class-Acc: {0: '93.06%', 1: '88.27%'}, Val Loss: 0.079818252, Val Accuracy: 97.43%, Val-Class-Acc: {0: '98.39%', 1: '95.95%'}, LR: 0.000100000\n",
      "Epoch 1588/2000, Train Loss: 0.027552064, Train-Class-Acc: {0: '99.37%', 1: '98.69%'}, Val Loss: 0.076159697, Val Accuracy: 97.96%, Val-Class-Acc: {0: '97.80%', 1: '98.22%'}, LR: 0.000100000\n",
      "Epoch 1589/2000, Train Loss: 0.011169414, Train-Class-Acc: {0: '99.81%', 1: '99.63%'}, Val Loss: 0.073893400, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.06%', 1: '97.90%'}, LR: 0.000100000\n",
      "Epoch 1590/2000, Train Loss: 0.008301616, Train-Class-Acc: {0: '99.84%', 1: '99.71%'}, Val Loss: 0.080264750, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.25%', 1: '97.49%'}, LR: 0.000100000\n",
      "Epoch 1591/2000, Train Loss: 0.007105542, Train-Class-Acc: {0: '99.86%', 1: '99.74%'}, Val Loss: 0.077240483, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.43%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1592/2000, Train Loss: 0.006626242, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.080735412, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.31%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1593/2000, Train Loss: 0.006165284, Train-Class-Acc: {0: '99.86%', 1: '99.76%'}, Val Loss: 0.081131444, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.39%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 1594/2000, Train Loss: 0.005813448, Train-Class-Acc: {0: '99.87%', 1: '99.78%'}, Val Loss: 0.084186383, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.17%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 1595/2000, Train Loss: 0.005698536, Train-Class-Acc: {0: '99.87%', 1: '99.78%'}, Val Loss: 0.084486050, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.26%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 1596/2000, Train Loss: 0.005608211, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.088355091, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.26%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1597/2000, Train Loss: 0.005486678, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.093044497, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.47%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 1598/2000, Train Loss: 0.005427773, Train-Class-Acc: {0: '99.86%', 1: '99.78%'}, Val Loss: 0.089143684, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.05%', 1: '97.51%'}, LR: 0.000100000\n",
      "Epoch 1599/2000, Train Loss: 0.005124064, Train-Class-Acc: {0: '99.87%', 1: '99.78%'}, Val Loss: 0.089135592, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.21%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 1600/2000, Train Loss: 0.100724937, Train-Class-Acc: {0: '98.25%', 1: '96.35%'}, Val Loss: 0.103081202, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.46%', 1: '98.36%'}, LR: 0.000100000\n",
      "Epoch 1601/2000, Train Loss: 0.011323147, Train-Class-Acc: {0: '99.78%', 1: '99.55%'}, Val Loss: 0.087722127, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.22%', 1: '97.47%'}, LR: 0.000100000\n",
      "Epoch 1602/2000, Train Loss: 0.006933207, Train-Class-Acc: {0: '99.87%', 1: '99.76%'}, Val Loss: 0.084614410, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.19%', 1: '97.67%'}, LR: 0.000100000\n",
      "Epoch 1603/2000, Train Loss: 0.006103897, Train-Class-Acc: {0: '99.88%', 1: '99.78%'}, Val Loss: 0.087671498, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.24%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 1604/2000, Train Loss: 0.005742810, Train-Class-Acc: {0: '99.88%', 1: '99.78%'}, Val Loss: 0.091712103, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.40%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 1605/2000, Train Loss: 0.005444386, Train-Class-Acc: {0: '99.88%', 1: '99.79%'}, Val Loss: 0.088549089, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.20%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 1606/2000, Train Loss: 0.005250377, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.088451625, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.08%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 1607/2000, Train Loss: 0.005173485, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.091331154, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.28%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 1608/2000, Train Loss: 0.005601996, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.093612005, Val Accuracy: 97.80%, Val-Class-Acc: {0: '97.93%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 1609/2000, Train Loss: 0.005017946, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.091233116, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.06%', 1: '97.49%'}, LR: 0.000100000\n",
      "Epoch 1610/2000, Train Loss: 0.005003283, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.095550560, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.36%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 1611/2000, Train Loss: 0.004790776, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.093460922, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.17%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 1612/2000, Train Loss: 0.004763338, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.096434205, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.50%', 1: '96.97%'}, LR: 0.000100000\n",
      "Epoch 1613/2000, Train Loss: 0.083501936, Train-Class-Acc: {0: '98.79%', 1: '96.97%'}, Val Loss: 0.372284253, Val Accuracy: 92.21%, Val-Class-Acc: {0: '87.88%', 1: '98.88%'}, LR: 0.000100000\n",
      "Epoch 1614/2000, Train Loss: 0.137653134, Train-Class-Acc: {0: '96.58%', 1: '94.28%'}, Val Loss: 0.090584857, Val Accuracy: 97.26%, Val-Class-Acc: {0: '98.69%', 1: '95.06%'}, LR: 0.000100000\n",
      "Epoch 1615/2000, Train Loss: 0.013027997, Train-Class-Acc: {0: '99.82%', 1: '99.55%'}, Val Loss: 0.072008336, Val Accuracy: 98.21%, Val-Class-Acc: {0: '98.47%', 1: '97.81%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.17%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_397.pth\n",
      "Model saved after epoch 1615 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1615.pth \n",
      "\n",
      "Epoch 1616/2000, Train Loss: 0.008002041, Train-Class-Acc: {0: '99.88%', 1: '99.75%'}, Val Loss: 0.074835508, Val Accuracy: 98.15%, Val-Class-Acc: {0: '98.45%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 1617/2000, Train Loss: 0.006733024, Train-Class-Acc: {0: '99.88%', 1: '99.78%'}, Val Loss: 0.075617449, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.26%', 1: '97.89%'}, LR: 0.000100000\n",
      "Epoch 1618/2000, Train Loss: 0.006135245, Train-Class-Acc: {0: '99.88%', 1: '99.79%'}, Val Loss: 0.076455718, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.06%', 1: '97.90%'}, LR: 0.000100000\n",
      "Epoch 1619/2000, Train Loss: 0.005923696, Train-Class-Acc: {0: '99.88%', 1: '99.79%'}, Val Loss: 0.079815272, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.11%', 1: '97.67%'}, LR: 0.000100000\n",
      "Epoch 1620/2000, Train Loss: 0.005652580, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.082274344, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.01%', 1: '97.67%'}, LR: 0.000100000\n",
      "Epoch 1621/2000, Train Loss: 0.005560325, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.087368050, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.37%', 1: '97.21%'}, LR: 0.000100000\n",
      "Epoch 1622/2000, Train Loss: 0.005291110, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.088145008, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.17%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1623/2000, Train Loss: 0.005103415, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.089779239, Val Accuracy: 97.78%, Val-Class-Acc: {0: '97.86%', 1: '97.66%'}, LR: 0.000100000\n",
      "Epoch 1624/2000, Train Loss: 0.005134596, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.088204002, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.12%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 1625/2000, Train Loss: 0.005007208, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.093847006, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.15%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1626/2000, Train Loss: 0.005529535, Train-Class-Acc: {0: '99.85%', 1: '99.76%'}, Val Loss: 0.093363192, Val Accuracy: 97.78%, Val-Class-Acc: {0: '97.96%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 1627/2000, Train Loss: 0.004806442, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.090510816, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.07%', 1: '97.49%'}, LR: 0.000100000\n",
      "Epoch 1628/2000, Train Loss: 0.071108973, Train-Class-Acc: {0: '98.50%', 1: '97.53%'}, Val Loss: 0.110879962, Val Accuracy: 97.33%, Val-Class-Acc: {0: '97.00%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 1629/2000, Train Loss: 0.016326484, Train-Class-Acc: {0: '99.56%', 1: '99.21%'}, Val Loss: 0.090123642, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.32%', 1: '97.13%'}, LR: 0.000100000\n",
      "Epoch 1630/2000, Train Loss: 0.006449668, Train-Class-Acc: {0: '99.88%', 1: '99.77%'}, Val Loss: 0.090448944, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.20%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 1631/2000, Train Loss: 0.005685935, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.087865370, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.08%', 1: '97.65%'}, LR: 0.000100000\n",
      "Epoch 1632/2000, Train Loss: 0.005464464, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.091553511, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.18%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 1633/2000, Train Loss: 0.005181721, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.089579178, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.13%', 1: '97.51%'}, LR: 0.000100000\n",
      "Epoch 1634/2000, Train Loss: 0.005043651, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.088973019, Val Accuracy: 97.84%, Val-Class-Acc: {0: '97.99%', 1: '97.61%'}, LR: 0.000100000\n",
      "Epoch 1635/2000, Train Loss: 0.004918186, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.092776332, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.15%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1636/2000, Train Loss: 0.004838694, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.093177850, Val Accuracy: 97.79%, Val-Class-Acc: {0: '97.98%', 1: '97.50%'}, LR: 0.000100000\n",
      "Epoch 1637/2000, Train Loss: 0.004745570, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.097944398, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.31%', 1: '97.17%'}, LR: 0.000100000\n",
      "Epoch 1638/2000, Train Loss: 0.004757980, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.091412422, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.92%', 1: '97.70%'}, LR: 0.000100000\n",
      "Epoch 1639/2000, Train Loss: 0.004700305, Train-Class-Acc: {0: '99.87%', 1: '99.81%'}, Val Loss: 0.096572008, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.16%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1640/2000, Train Loss: 0.004592379, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.093772095, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.98%', 1: '97.60%'}, LR: 0.000100000\n",
      "Epoch 1641/2000, Train Loss: 0.004609303, Train-Class-Acc: {0: '99.87%', 1: '99.81%'}, Val Loss: 0.097041593, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.18%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1642/2000, Train Loss: 0.004554762, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.097304575, Val Accuracy: 97.77%, Val-Class-Acc: {0: '97.86%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1643/2000, Train Loss: 0.004678171, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.101085614, Val Accuracy: 97.77%, Val-Class-Acc: {0: '97.92%', 1: '97.54%'}, LR: 0.000100000\n",
      "Epoch 1644/2000, Train Loss: 0.004581441, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.100207738, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.12%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 1645/2000, Train Loss: 0.004945688, Train-Class-Acc: {0: '99.85%', 1: '99.78%'}, Val Loss: 0.101768060, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.13%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1646/2000, Train Loss: 0.004482260, Train-Class-Acc: {0: '99.87%', 1: '99.81%'}, Val Loss: 0.101090549, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.32%', 1: '97.23%'}, LR: 0.000100000\n",
      "Epoch 1647/2000, Train Loss: 0.004400356, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.108285839, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.76%', 1: '96.45%'}, LR: 0.000100000\n",
      "Epoch 1648/2000, Train Loss: 0.161426340, Train-Class-Acc: {0: '96.43%', 1: '94.93%'}, Val Loss: 0.098727949, Val Accuracy: 97.19%, Val-Class-Acc: {0: '98.12%', 1: '95.75%'}, LR: 0.000100000\n",
      "Epoch 1649/2000, Train Loss: 0.011962788, Train-Class-Acc: {0: '99.80%', 1: '99.56%'}, Val Loss: 0.070510848, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.34%', 1: '97.95%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.17%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_396.pth\n",
      "Model saved after epoch 1649 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1649.pth \n",
      "\n",
      "Epoch 1650/2000, Train Loss: 0.006975349, Train-Class-Acc: {0: '99.88%', 1: '99.77%'}, Val Loss: 0.077936626, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.49%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1651/2000, Train Loss: 0.005910768, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.085078128, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.29%', 1: '97.54%'}, LR: 0.000100000\n",
      "Epoch 1652/2000, Train Loss: 0.005496668, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.083557272, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.20%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1653/2000, Train Loss: 0.005247241, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.088140821, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.32%', 1: '97.32%'}, LR: 0.000100000\n",
      "Epoch 1654/2000, Train Loss: 0.005098808, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.090417164, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.14%', 1: '97.43%'}, LR: 0.000100000\n",
      "Epoch 1655/2000, Train Loss: 0.004928844, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.088642631, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.13%', 1: '97.43%'}, LR: 0.000100000\n",
      "Epoch 1656/2000, Train Loss: 0.004960860, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.094182015, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.45%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 1657/2000, Train Loss: 0.005141254, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.092795892, Val Accuracy: 97.82%, Val-Class-Acc: {0: '97.95%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1658/2000, Train Loss: 0.004719346, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.094706935, Val Accuracy: 97.84%, Val-Class-Acc: {0: '98.15%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1659/2000, Train Loss: 0.004525512, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.096370919, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.04%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 1660/2000, Train Loss: 0.004789260, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.095593063, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.07%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1661/2000, Train Loss: 0.004450982, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.096279622, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.23%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 1662/2000, Train Loss: 0.004629623, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.101230006, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.37%', 1: '97.16%'}, LR: 0.000100000\n",
      "Epoch 1663/2000, Train Loss: 0.004703834, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.100789948, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.25%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1664/2000, Train Loss: 0.004391820, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.100798372, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.08%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 1665/2000, Train Loss: 0.004269085, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.096958680, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.10%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 1666/2000, Train Loss: 0.032151352, Train-Class-Acc: {0: '99.40%', 1: '99.02%'}, Val Loss: 0.197066800, Val Accuracy: 95.76%, Val-Class-Acc: {0: '93.60%', 1: '99.07%'}, LR: 0.000100000\n",
      "Epoch 1667/2000, Train Loss: 0.148588734, Train-Class-Acc: {0: '96.87%', 1: '94.19%'}, Val Loss: 0.071245300, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.14%', 1: '97.90%'}, LR: 0.000100000\n",
      "Epoch 1668/2000, Train Loss: 0.011220729, Train-Class-Acc: {0: '99.82%', 1: '99.66%'}, Val Loss: 0.083863047, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.36%', 1: '97.41%'}, LR: 0.000100000\n",
      "Epoch 1669/2000, Train Loss: 0.007088506, Train-Class-Acc: {0: '99.88%', 1: '99.77%'}, Val Loss: 0.071501621, Val Accuracy: 98.20%, Val-Class-Acc: {0: '98.46%', 1: '97.78%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.17%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_399.pth\n",
      "Model saved after epoch 1669 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1669.pth \n",
      "\n",
      "Epoch 1670/2000, Train Loss: 0.006102573, Train-Class-Acc: {0: '99.88%', 1: '99.79%'}, Val Loss: 0.082593916, Val Accuracy: 98.07%, Val-Class-Acc: {0: '98.19%', 1: '97.89%'}, LR: 0.000100000\n",
      "Epoch 1671/2000, Train Loss: 0.005569546, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.078696795, Val Accuracy: 98.07%, Val-Class-Acc: {0: '98.18%', 1: '97.90%'}, LR: 0.000100000\n",
      "Epoch 1672/2000, Train Loss: 0.005195551, Train-Class-Acc: {0: '99.89%', 1: '99.81%'}, Val Loss: 0.081096125, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.22%', 1: '97.68%'}, LR: 0.000100000\n",
      "Epoch 1673/2000, Train Loss: 0.005090726, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.084733167, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.11%', 1: '97.72%'}, LR: 0.000100000\n",
      "Epoch 1674/2000, Train Loss: 0.004896834, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.080951492, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.10%', 1: '97.75%'}, LR: 0.000100000\n",
      "Epoch 1675/2000, Train Loss: 0.004829532, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.083994688, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.11%', 1: '97.58%'}, LR: 0.000100000\n",
      "Epoch 1676/2000, Train Loss: 0.004676855, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.090366311, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.47%', 1: '97.11%'}, LR: 0.000100000\n",
      "Epoch 1677/2000, Train Loss: 0.004651802, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.093587120, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.41%', 1: '97.01%'}, LR: 0.000100000\n",
      "Epoch 1678/2000, Train Loss: 0.004593510, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.096837573, Val Accuracy: 97.83%, Val-Class-Acc: {0: '98.46%', 1: '96.87%'}, LR: 0.000100000\n",
      "Epoch 1679/2000, Train Loss: 0.004589928, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.095718065, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.31%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 1680/2000, Train Loss: 0.004478674, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.095407213, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.38%', 1: '97.07%'}, LR: 0.000100000\n",
      "Epoch 1681/2000, Train Loss: 0.004401931, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.094487407, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.10%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1682/2000, Train Loss: 0.004325442, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.099419404, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.15%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1683/2000, Train Loss: 0.004317425, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.095521589, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.19%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 1684/2000, Train Loss: 0.004325500, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.092963086, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.28%', 1: '97.30%'}, LR: 0.000100000\n",
      "Epoch 1685/2000, Train Loss: 0.004243434, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.096227715, Val Accuracy: 97.83%, Val-Class-Acc: {0: '97.97%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1686/2000, Train Loss: 0.004850913, Train-Class-Acc: {0: '99.86%', 1: '99.79%'}, Val Loss: 0.106590743, Val Accuracy: 97.82%, Val-Class-Acc: {0: '98.50%', 1: '96.76%'}, LR: 0.000100000\n",
      "Epoch 1687/2000, Train Loss: 0.229401484, Train-Class-Acc: {0: '95.79%', 1: '93.44%'}, Val Loss: 0.179372678, Val Accuracy: 94.42%, Val-Class-Acc: {0: '93.65%', 1: '95.60%'}, LR: 0.000100000\n",
      "Epoch 1688/2000, Train Loss: 0.058719629, Train-Class-Acc: {0: '98.40%', 1: '97.10%'}, Val Loss: 0.080959079, Val Accuracy: 98.00%, Val-Class-Acc: {0: '97.92%', 1: '98.12%'}, LR: 0.000100000\n",
      "Epoch 1689/2000, Train Loss: 0.010930802, Train-Class-Acc: {0: '99.83%', 1: '99.67%'}, Val Loss: 0.076722620, Val Accuracy: 98.03%, Val-Class-Acc: {0: '98.20%', 1: '97.76%'}, LR: 0.000100000\n",
      "Epoch 1690/2000, Train Loss: 0.007576340, Train-Class-Acc: {0: '99.87%', 1: '99.76%'}, Val Loss: 0.081634131, Val Accuracy: 98.05%, Val-Class-Acc: {0: '98.01%', 1: '98.12%'}, LR: 0.000100000\n",
      "Epoch 1691/2000, Train Loss: 0.006413031, Train-Class-Acc: {0: '99.88%', 1: '99.79%'}, Val Loss: 0.089023900, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.11%', 1: '97.86%'}, LR: 0.000100000\n",
      "Epoch 1692/2000, Train Loss: 0.005837675, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.081124828, Val Accuracy: 98.03%, Val-Class-Acc: {0: '97.96%', 1: '98.13%'}, LR: 0.000100000\n",
      "Epoch 1693/2000, Train Loss: 0.005481036, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.081860662, Val Accuracy: 97.97%, Val-Class-Acc: {0: '97.92%', 1: '98.04%'}, LR: 0.000100000\n",
      "Epoch 1694/2000, Train Loss: 0.005338179, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.089380500, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.35%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 1695/2000, Train Loss: 0.005043078, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.083078706, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.08%', 1: '97.89%'}, LR: 0.000100000\n",
      "Epoch 1696/2000, Train Loss: 0.004921650, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.085961414, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.10%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 1697/2000, Train Loss: 0.004790181, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.084703398, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.00%', 1: '97.94%'}, LR: 0.000100000\n",
      "Epoch 1698/2000, Train Loss: 0.004906405, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.085252287, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.08%', 1: '97.81%'}, LR: 0.000100000\n",
      "Epoch 1699/2000, Train Loss: 0.004594307, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.088127313, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.13%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 1700/2000, Train Loss: 0.004556681, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.088398279, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.19%', 1: '97.70%'}, LR: 0.000100000\n",
      "Epoch 1701/2000, Train Loss: 0.004581362, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.093398928, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.15%', 1: '97.73%'}, LR: 0.000100000\n",
      "Epoch 1702/2000, Train Loss: 0.004726364, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.090751767, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.22%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 1703/2000, Train Loss: 0.004428579, Train-Class-Acc: {0: '99.89%', 1: '99.81%'}, Val Loss: 0.088573479, Val Accuracy: 97.95%, Val-Class-Acc: {0: '97.94%', 1: '97.98%'}, LR: 0.000100000\n",
      "Epoch 1704/2000, Train Loss: 0.004373013, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.090843631, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.02%', 1: '97.93%'}, LR: 0.000100000\n",
      "Epoch 1705/2000, Train Loss: 0.095337814, Train-Class-Acc: {0: '98.40%', 1: '98.45%'}, Val Loss: 0.872689869, Val Accuracy: 86.77%, Val-Class-Acc: {0: '98.53%', 1: '68.68%'}, LR: 0.000100000\n",
      "Epoch 1706/2000, Train Loss: 0.169235107, Train-Class-Acc: {0: '95.68%', 1: '93.51%'}, Val Loss: 0.071769509, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.21%', 1: '98.02%'}, LR: 0.000100000\n",
      "Epoch 1707/2000, Train Loss: 0.013875393, Train-Class-Acc: {0: '99.78%', 1: '99.54%'}, Val Loss: 0.067405027, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.40%', 1: '97.88%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.18%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1649.pth\n",
      "Model saved after epoch 1707 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1707.pth \n",
      "\n",
      "Epoch 1708/2000, Train Loss: 0.007942701, Train-Class-Acc: {0: '99.87%', 1: '99.76%'}, Val Loss: 0.075325133, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.61%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 1709/2000, Train Loss: 0.006692698, Train-Class-Acc: {0: '99.88%', 1: '99.78%'}, Val Loss: 0.074801243, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.18%', 1: '98.09%'}, LR: 0.000100000\n",
      "Epoch 1710/2000, Train Loss: 0.006072199, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.077636726, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.50%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 1711/2000, Train Loss: 0.005686539, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.075744347, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.20%', 1: '98.13%'}, LR: 0.000100000\n",
      "Epoch 1712/2000, Train Loss: 0.005423776, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.080313782, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.54%', 1: '97.58%'}, LR: 0.000100000\n",
      "Epoch 1713/2000, Train Loss: 0.005435540, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.081975079, Val Accuracy: 98.15%, Val-Class-Acc: {0: '98.49%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1714/2000, Train Loss: 0.004956383, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.079563711, Val Accuracy: 98.15%, Val-Class-Acc: {0: '98.32%', 1: '97.89%'}, LR: 0.000100000\n",
      "Epoch 1715/2000, Train Loss: 0.004919141, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.082042589, Val Accuracy: 98.08%, Val-Class-Acc: {0: '98.24%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 1716/2000, Train Loss: 0.004760428, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.083469208, Val Accuracy: 98.07%, Val-Class-Acc: {0: '98.23%', 1: '97.81%'}, LR: 0.000100000\n",
      "Epoch 1717/2000, Train Loss: 0.004842307, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.082617286, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.32%', 1: '97.76%'}, LR: 0.000100000\n",
      "Epoch 1718/2000, Train Loss: 0.004582260, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.082030513, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.23%', 1: '97.89%'}, LR: 0.000100000\n",
      "Epoch 1719/2000, Train Loss: 0.004770846, Train-Class-Acc: {0: '99.87%', 1: '99.81%'}, Val Loss: 0.083010304, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.26%', 1: '97.86%'}, LR: 0.000100000\n",
      "Epoch 1720/2000, Train Loss: 0.004534699, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.089196927, Val Accuracy: 98.08%, Val-Class-Acc: {0: '98.69%', 1: '97.15%'}, LR: 0.000100000\n",
      "Epoch 1721/2000, Train Loss: 0.004687919, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.085387983, Val Accuracy: 98.08%, Val-Class-Acc: {0: '98.18%', 1: '97.93%'}, LR: 0.000100000\n",
      "Epoch 1722/2000, Train Loss: 0.004860412, Train-Class-Acc: {0: '99.87%', 1: '99.79%'}, Val Loss: 0.085846378, Val Accuracy: 98.05%, Val-Class-Acc: {0: '98.21%', 1: '97.81%'}, LR: 0.000100000\n",
      "Epoch 1723/2000, Train Loss: 0.004386558, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.094695760, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.56%', 1: '97.18%'}, LR: 0.000100000\n",
      "Epoch 1724/2000, Train Loss: 0.004576043, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.083761461, Val Accuracy: 98.08%, Val-Class-Acc: {0: '98.18%', 1: '97.92%'}, LR: 0.000100000\n",
      "Epoch 1725/2000, Train Loss: 0.004888986, Train-Class-Acc: {0: '99.87%', 1: '99.78%'}, Val Loss: 0.087221604, Val Accuracy: 98.00%, Val-Class-Acc: {0: '97.98%', 1: '98.03%'}, LR: 0.000100000\n",
      "Epoch 1726/2000, Train Loss: 0.004656202, Train-Class-Acc: {0: '99.87%', 1: '99.80%'}, Val Loss: 0.088455719, Val Accuracy: 98.05%, Val-Class-Acc: {0: '98.14%', 1: '97.92%'}, LR: 0.000100000\n",
      "Epoch 1727/2000, Train Loss: 0.004257736, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.085841030, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.14%', 1: '98.05%'}, LR: 0.000100000\n",
      "Epoch 1728/2000, Train Loss: 0.004500139, Train-Class-Acc: {0: '99.87%', 1: '99.81%'}, Val Loss: 0.089741287, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.31%', 1: '97.57%'}, LR: 0.000100000\n",
      "Epoch 1729/2000, Train Loss: 0.147576646, Train-Class-Acc: {0: '97.04%', 1: '95.83%'}, Val Loss: 0.207437359, Val Accuracy: 93.96%, Val-Class-Acc: {0: '92.20%', 1: '96.66%'}, LR: 0.000100000\n",
      "Epoch 1730/2000, Train Loss: 0.057334930, Train-Class-Acc: {0: '98.29%', 1: '97.36%'}, Val Loss: 0.080167872, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.26%', 1: '97.34%'}, LR: 0.000100000\n",
      "Epoch 1731/2000, Train Loss: 0.009025248, Train-Class-Acc: {0: '99.87%', 1: '99.74%'}, Val Loss: 0.079958290, Val Accuracy: 98.08%, Val-Class-Acc: {0: '98.17%', 1: '97.94%'}, LR: 0.000100000\n",
      "Epoch 1732/2000, Train Loss: 0.006608018, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.080339142, Val Accuracy: 98.09%, Val-Class-Acc: {0: '98.33%', 1: '97.73%'}, LR: 0.000100000\n",
      "Epoch 1733/2000, Train Loss: 0.005783575, Train-Class-Acc: {0: '99.89%', 1: '99.80%'}, Val Loss: 0.079937892, Val Accuracy: 98.06%, Val-Class-Acc: {0: '98.04%', 1: '98.09%'}, LR: 0.000100000\n",
      "Epoch 1734/2000, Train Loss: 0.005330430, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.082093542, Val Accuracy: 98.07%, Val-Class-Acc: {0: '98.16%', 1: '97.95%'}, LR: 0.000100000\n",
      "Epoch 1735/2000, Train Loss: 0.005188501, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.088732489, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.26%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 1736/2000, Train Loss: 0.004998719, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.085463712, Val Accuracy: 98.09%, Val-Class-Acc: {0: '98.37%', 1: '97.66%'}, LR: 0.000100000\n",
      "Epoch 1737/2000, Train Loss: 0.004965187, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.088220126, Val Accuracy: 98.05%, Val-Class-Acc: {0: '98.23%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 1738/2000, Train Loss: 0.004839593, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.087894759, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.20%', 1: '97.80%'}, LR: 0.000100000\n",
      "Epoch 1739/2000, Train Loss: 0.004578213, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.090842864, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.17%', 1: '97.85%'}, LR: 0.000100000\n",
      "Epoch 1740/2000, Train Loss: 0.004493227, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.088069406, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.21%', 1: '97.80%'}, LR: 0.000100000\n",
      "Epoch 1741/2000, Train Loss: 0.005428225, Train-Class-Acc: {0: '99.85%', 1: '99.77%'}, Val Loss: 0.092892391, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.19%', 1: '97.81%'}, LR: 0.000100000\n",
      "Epoch 1742/2000, Train Loss: 0.004377721, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.090253814, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.18%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 1743/2000, Train Loss: 0.004398196, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.090803684, Val Accuracy: 98.00%, Val-Class-Acc: {0: '97.93%', 1: '98.12%'}, LR: 0.000100000\n",
      "Epoch 1744/2000, Train Loss: 0.004280830, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.092316831, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.18%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 1745/2000, Train Loss: 0.004181813, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.091047170, Val Accuracy: 98.06%, Val-Class-Acc: {0: '98.15%', 1: '97.92%'}, LR: 0.000100000\n",
      "Epoch 1746/2000, Train Loss: 0.004191045, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.092468689, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.11%', 1: '97.93%'}, LR: 0.000100000\n",
      "Epoch 1747/2000, Train Loss: 0.029935190, Train-Class-Acc: {0: '99.42%', 1: '98.84%'}, Val Loss: 0.093939446, Val Accuracy: 97.95%, Val-Class-Acc: {0: '97.71%', 1: '98.33%'}, LR: 0.000100000\n",
      "Epoch 1748/2000, Train Loss: 0.026306272, Train-Class-Acc: {0: '99.23%', 1: '98.64%'}, Val Loss: 0.085901542, Val Accuracy: 98.03%, Val-Class-Acc: {0: '97.80%', 1: '98.38%'}, LR: 0.000100000\n",
      "Epoch 1749/2000, Train Loss: 0.005618116, Train-Class-Acc: {0: '99.87%', 1: '99.77%'}, Val Loss: 0.081025074, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.23%', 1: '98.01%'}, LR: 0.000100000\n",
      "Epoch 1750/2000, Train Loss: 0.004807244, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.085212770, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.32%', 1: '97.54%'}, LR: 0.000100000\n",
      "Epoch 1751/2000, Train Loss: 0.004850462, Train-Class-Acc: {0: '99.88%', 1: '99.80%'}, Val Loss: 0.082713254, Val Accuracy: 98.11%, Val-Class-Acc: {0: '98.28%', 1: '97.84%'}, LR: 0.000100000\n",
      "Epoch 1752/2000, Train Loss: 0.004444091, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.087435806, Val Accuracy: 98.03%, Val-Class-Acc: {0: '98.41%', 1: '97.46%'}, LR: 0.000100000\n",
      "Epoch 1753/2000, Train Loss: 0.004288912, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.089811647, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.34%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 1754/2000, Train Loss: 0.004244732, Train-Class-Acc: {0: '99.90%', 1: '99.82%'}, Val Loss: 0.088641168, Val Accuracy: 98.05%, Val-Class-Acc: {0: '98.08%', 1: '98.01%'}, LR: 0.000100000\n",
      "Epoch 1755/2000, Train Loss: 0.004098001, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.092892118, Val Accuracy: 98.03%, Val-Class-Acc: {0: '98.24%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 1756/2000, Train Loss: 0.004334319, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.089877554, Val Accuracy: 98.03%, Val-Class-Acc: {0: '98.09%', 1: '97.92%'}, LR: 0.000100000\n",
      "Epoch 1757/2000, Train Loss: 0.004052553, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.091396304, Val Accuracy: 98.03%, Val-Class-Acc: {0: '98.27%', 1: '97.65%'}, LR: 0.000100000\n",
      "Epoch 1758/2000, Train Loss: 0.003990699, Train-Class-Acc: {0: '99.89%', 1: '99.84%'}, Val Loss: 0.091975178, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.24%', 1: '97.75%'}, LR: 0.000100000\n",
      "Epoch 1759/2000, Train Loss: 0.004076215, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.090735886, Val Accuracy: 98.02%, Val-Class-Acc: {0: '97.99%', 1: '98.05%'}, LR: 0.000100000\n",
      "Epoch 1760/2000, Train Loss: 0.004046535, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.089083671, Val Accuracy: 98.07%, Val-Class-Acc: {0: '98.20%', 1: '97.88%'}, LR: 0.000100000\n",
      "Epoch 1761/2000, Train Loss: 0.003987526, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.093695801, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.13%', 1: '97.85%'}, LR: 0.000100000\n",
      "Epoch 1762/2000, Train Loss: 0.003967353, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.101004407, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.26%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1763/2000, Train Loss: 0.003875176, Train-Class-Acc: {0: '99.90%', 1: '99.83%'}, Val Loss: 0.104443036, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.19%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 1764/2000, Train Loss: 0.004163372, Train-Class-Acc: {0: '99.88%', 1: '99.82%'}, Val Loss: 0.102974994, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.42%', 1: '97.22%'}, LR: 0.000100000\n",
      "Epoch 1765/2000, Train Loss: 0.051299781, Train-Class-Acc: {0: '98.80%', 1: '98.41%'}, Val Loss: 0.109335619, Val Accuracy: 97.20%, Val-Class-Acc: {0: '98.96%', 1: '94.49%'}, LR: 0.000100000\n",
      "Epoch 1766/2000, Train Loss: 0.009695715, Train-Class-Acc: {0: '99.74%', 1: '99.54%'}, Val Loss: 0.081108982, Val Accuracy: 98.13%, Val-Class-Acc: {0: '98.18%', 1: '98.06%'}, LR: 0.000100000\n",
      "Epoch 1767/2000, Train Loss: 0.004743822, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.088513036, Val Accuracy: 98.03%, Val-Class-Acc: {0: '98.12%', 1: '97.90%'}, LR: 0.000100000\n",
      "Epoch 1768/2000, Train Loss: 0.004383405, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.088572676, Val Accuracy: 98.03%, Val-Class-Acc: {0: '98.45%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1769/2000, Train Loss: 0.004198619, Train-Class-Acc: {0: '99.90%', 1: '99.83%'}, Val Loss: 0.087347467, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.19%', 1: '97.81%'}, LR: 0.000100000\n",
      "Epoch 1770/2000, Train Loss: 0.004110736, Train-Class-Acc: {0: '99.90%', 1: '99.83%'}, Val Loss: 0.092498227, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.17%', 1: '97.64%'}, LR: 0.000100000\n",
      "Epoch 1771/2000, Train Loss: 0.004009518, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.096339391, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.22%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 1772/2000, Train Loss: 0.003932569, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.096209550, Val Accuracy: 97.90%, Val-Class-Acc: {0: '97.96%', 1: '97.80%'}, LR: 0.000100000\n",
      "Epoch 1773/2000, Train Loss: 0.003983026, Train-Class-Acc: {0: '99.89%', 1: '99.84%'}, Val Loss: 0.103169330, Val Accuracy: 97.93%, Val-Class-Acc: {0: '97.95%', 1: '97.91%'}, LR: 0.000100000\n",
      "Epoch 1774/2000, Train Loss: 0.003863295, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.094547755, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.26%', 1: '97.43%'}, LR: 0.000100000\n",
      "Epoch 1775/2000, Train Loss: 0.003784078, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.099302108, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.10%', 1: '97.80%'}, LR: 0.000100000\n",
      "Epoch 1776/2000, Train Loss: 0.005372641, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.095965557, Val Accuracy: 97.94%, Val-Class-Acc: {0: '97.84%', 1: '98.11%'}, LR: 0.000100000\n",
      "Epoch 1777/2000, Train Loss: 0.003934048, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.096174061, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.26%', 1: '97.66%'}, LR: 0.000100000\n",
      "Epoch 1778/2000, Train Loss: 0.003746952, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.099293430, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.26%', 1: '97.53%'}, LR: 0.000100000\n",
      "Epoch 1779/2000, Train Loss: 0.003845808, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.098698035, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.26%', 1: '97.58%'}, LR: 0.000100000\n",
      "Epoch 1780/2000, Train Loss: 0.003667107, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.099066843, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.15%', 1: '97.78%'}, LR: 0.000100000\n",
      "Epoch 1781/2000, Train Loss: 0.003637825, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.097515333, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.26%', 1: '97.55%'}, LR: 0.000100000\n",
      "Epoch 1782/2000, Train Loss: 0.097158805, Train-Class-Acc: {0: '98.49%', 1: '97.05%'}, Val Loss: 0.219956127, Val Accuracy: 94.85%, Val-Class-Acc: {0: '94.48%', 1: '95.41%'}, LR: 0.000100000\n",
      "Epoch 1783/2000, Train Loss: 0.056980648, Train-Class-Acc: {0: '98.39%', 1: '97.60%'}, Val Loss: 0.080415860, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.11%', 1: '97.68%'}, LR: 0.000100000\n",
      "Epoch 1784/2000, Train Loss: 0.007438491, Train-Class-Acc: {0: '99.87%', 1: '99.76%'}, Val Loss: 0.084403063, Val Accuracy: 98.03%, Val-Class-Acc: {0: '98.17%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 1785/2000, Train Loss: 0.005532322, Train-Class-Acc: {0: '99.90%', 1: '99.81%'}, Val Loss: 0.080844767, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.16%', 1: '97.64%'}, LR: 0.000100000\n",
      "Epoch 1786/2000, Train Loss: 0.004901482, Train-Class-Acc: {0: '99.90%', 1: '99.83%'}, Val Loss: 0.084362119, Val Accuracy: 97.96%, Val-Class-Acc: {0: '98.19%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 1787/2000, Train Loss: 0.004569300, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.087676125, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.22%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1788/2000, Train Loss: 0.004430077, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.092174080, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.18%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1789/2000, Train Loss: 0.004246772, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.092340235, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.08%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 1790/2000, Train Loss: 0.004116919, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.095362614, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.34%', 1: '97.16%'}, LR: 0.000100000\n",
      "Epoch 1791/2000, Train Loss: 0.004087630, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.097009783, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.17%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 1792/2000, Train Loss: 0.003994506, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.098969937, Val Accuracy: 97.85%, Val-Class-Acc: {0: '98.37%', 1: '97.06%'}, LR: 0.000100000\n",
      "Epoch 1793/2000, Train Loss: 0.004012665, Train-Class-Acc: {0: '99.89%', 1: '99.84%'}, Val Loss: 0.096659393, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.22%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 1794/2000, Train Loss: 0.004060524, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.097430028, Val Accuracy: 97.89%, Val-Class-Acc: {0: '97.94%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 1795/2000, Train Loss: 0.003994535, Train-Class-Acc: {0: '99.89%', 1: '99.84%'}, Val Loss: 0.095920593, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.17%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1796/2000, Train Loss: 0.003820050, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.099160163, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.21%', 1: '97.43%'}, LR: 0.000100000\n",
      "Epoch 1797/2000, Train Loss: 0.003792773, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.096198727, Val Accuracy: 97.91%, Val-Class-Acc: {0: '98.12%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 1798/2000, Train Loss: 0.003714660, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.099303314, Val Accuracy: 97.88%, Val-Class-Acc: {0: '98.25%', 1: '97.33%'}, LR: 0.000100000\n",
      "Epoch 1799/2000, Train Loss: 0.003695414, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.098928518, Val Accuracy: 97.89%, Val-Class-Acc: {0: '98.02%', 1: '97.70%'}, LR: 0.000100000\n",
      "Epoch 1800/2000, Train Loss: 0.003772416, Train-Class-Acc: {0: '99.89%', 1: '99.84%'}, Val Loss: 0.104031756, Val Accuracy: 97.78%, Val-Class-Acc: {0: '98.44%', 1: '96.75%'}, LR: 0.000100000\n",
      "Epoch 1801/2000, Train Loss: 0.003758332, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.095654328, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.10%', 1: '97.65%'}, LR: 0.000100000\n",
      "Epoch 1802/2000, Train Loss: 0.003631332, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.099275137, Val Accuracy: 97.90%, Val-Class-Acc: {0: '98.26%', 1: '97.35%'}, LR: 0.000100000\n",
      "Epoch 1803/2000, Train Loss: 0.003771661, Train-Class-Acc: {0: '99.89%', 1: '99.84%'}, Val Loss: 0.098928113, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.02%', 1: '97.85%'}, LR: 0.000100000\n",
      "Epoch 1804/2000, Train Loss: 0.003654911, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.101583386, Val Accuracy: 97.92%, Val-Class-Acc: {0: '98.33%', 1: '97.28%'}, LR: 0.000100000\n",
      "Epoch 1805/2000, Train Loss: 0.003772784, Train-Class-Acc: {0: '99.89%', 1: '99.84%'}, Val Loss: 0.102512039, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.24%', 1: '97.57%'}, LR: 0.000100000\n",
      "Epoch 1806/2000, Train Loss: 0.003524794, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.100451531, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.19%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 1807/2000, Train Loss: 0.003649237, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.096448915, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.21%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 1808/2000, Train Loss: 0.003584906, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.101557479, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.18%', 1: '97.67%'}, LR: 0.000100000\n",
      "Epoch 1809/2000, Train Loss: 0.003572791, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.100654564, Val Accuracy: 98.00%, Val-Class-Acc: {0: '98.16%', 1: '97.75%'}, LR: 0.000100000\n",
      "Epoch 1810/2000, Train Loss: 0.168057241, Train-Class-Acc: {0: '97.43%', 1: '94.46%'}, Val Loss: 0.134235757, Val Accuracy: 96.04%, Val-Class-Acc: {0: '94.38%', 1: '98.59%'}, LR: 0.000100000\n",
      "Epoch 1811/2000, Train Loss: 0.029785072, Train-Class-Acc: {0: '99.23%', 1: '98.59%'}, Val Loss: 0.080751768, Val Accuracy: 98.01%, Val-Class-Acc: {0: '97.98%', 1: '98.05%'}, LR: 0.000100000\n",
      "Epoch 1812/2000, Train Loss: 0.007348364, Train-Class-Acc: {0: '99.87%', 1: '99.75%'}, Val Loss: 0.080797449, Val Accuracy: 98.13%, Val-Class-Acc: {0: '98.29%', 1: '97.88%'}, LR: 0.000100000\n",
      "Epoch 1813/2000, Train Loss: 0.005466824, Train-Class-Acc: {0: '99.90%', 1: '99.81%'}, Val Loss: 0.087029345, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.26%', 1: '97.89%'}, LR: 0.000100000\n",
      "Epoch 1814/2000, Train Loss: 0.005082839, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.090524364, Val Accuracy: 98.11%, Val-Class-Acc: {0: '98.37%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 1815/2000, Train Loss: 0.004648279, Train-Class-Acc: {0: '99.90%', 1: '99.83%'}, Val Loss: 0.090021873, Val Accuracy: 98.00%, Val-Class-Acc: {0: '97.88%', 1: '98.18%'}, LR: 0.000100000\n",
      "Epoch 1816/2000, Train Loss: 0.004411017, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.092545688, Val Accuracy: 98.07%, Val-Class-Acc: {0: '98.20%', 1: '97.86%'}, LR: 0.000100000\n",
      "Epoch 1817/2000, Train Loss: 0.004169680, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.091339814, Val Accuracy: 98.05%, Val-Class-Acc: {0: '98.20%', 1: '97.81%'}, LR: 0.000100000\n",
      "Epoch 1818/2000, Train Loss: 0.004008587, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.093819565, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.16%', 1: '97.86%'}, LR: 0.000100000\n",
      "Epoch 1819/2000, Train Loss: 0.003921014, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.093124068, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.27%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1820/2000, Train Loss: 0.004000522, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.098003580, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.36%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 1821/2000, Train Loss: 0.003858880, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.096936772, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.00%', 1: '98.04%'}, LR: 0.000100000\n",
      "Epoch 1822/2000, Train Loss: 0.003779391, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.092826116, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.14%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 1823/2000, Train Loss: 0.003842039, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.091685660, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.16%', 1: '97.72%'}, LR: 0.000100000\n",
      "Epoch 1824/2000, Train Loss: 0.003717101, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.096223778, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.25%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 1825/2000, Train Loss: 0.003578852, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.094704830, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.22%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 1826/2000, Train Loss: 0.003603338, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.099565675, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.13%', 1: '97.89%'}, LR: 0.000100000\n",
      "Epoch 1827/2000, Train Loss: 0.003683010, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.099655379, Val Accuracy: 97.99%, Val-Class-Acc: {0: '98.02%', 1: '97.94%'}, LR: 0.000100000\n",
      "Epoch 1828/2000, Train Loss: 0.003975067, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.097089233, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.13%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 1829/2000, Train Loss: 0.003585091, Train-Class-Acc: {0: '99.91%', 1: '99.84%'}, Val Loss: 0.100460387, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.08%', 1: '97.98%'}, LR: 0.000100000\n",
      "Epoch 1830/2000, Train Loss: 0.003895587, Train-Class-Acc: {0: '99.88%', 1: '99.83%'}, Val Loss: 0.100814600, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.25%', 1: '97.54%'}, LR: 0.000100000\n",
      "Epoch 1831/2000, Train Loss: 0.003507628, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.100009278, Val Accuracy: 97.93%, Val-Class-Acc: {0: '98.25%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 1832/2000, Train Loss: 0.003649174, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.101787523, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.27%', 1: '97.51%'}, LR: 0.000100000\n",
      "Epoch 1833/2000, Train Loss: 0.003906743, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.105703940, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.53%', 1: '97.10%'}, LR: 0.000100000\n",
      "Epoch 1834/2000, Train Loss: 0.003598868, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.099916120, Val Accuracy: 98.01%, Val-Class-Acc: {0: '98.13%', 1: '97.83%'}, LR: 0.000100000\n",
      "Epoch 1835/2000, Train Loss: 0.210972829, Train-Class-Acc: {0: '95.96%', 1: '93.39%'}, Val Loss: 0.101790722, Val Accuracy: 96.59%, Val-Class-Acc: {0: '98.64%', 1: '93.45%'}, LR: 0.000100000\n",
      "Epoch 1836/2000, Train Loss: 0.021643859, Train-Class-Acc: {0: '99.56%', 1: '99.03%'}, Val Loss: 0.077418187, Val Accuracy: 98.01%, Val-Class-Acc: {0: '97.96%', 1: '98.09%'}, LR: 0.000100000\n",
      "Epoch 1837/2000, Train Loss: 0.007062967, Train-Class-Acc: {0: '99.88%', 1: '99.78%'}, Val Loss: 0.079249535, Val Accuracy: 98.07%, Val-Class-Acc: {0: '98.15%', 1: '97.94%'}, LR: 0.000100000\n",
      "Epoch 1838/2000, Train Loss: 0.005555429, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.079600538, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.11%', 1: '98.13%'}, LR: 0.000100000\n",
      "Epoch 1839/2000, Train Loss: 0.004987920, Train-Class-Acc: {0: '99.90%', 1: '99.83%'}, Val Loss: 0.079394622, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.45%', 1: '97.67%'}, LR: 0.000100000\n",
      "Epoch 1840/2000, Train Loss: 0.004585120, Train-Class-Acc: {0: '99.91%', 1: '99.84%'}, Val Loss: 0.081018124, Val Accuracy: 98.15%, Val-Class-Acc: {0: '98.34%', 1: '97.87%'}, LR: 0.000100000\n",
      "Epoch 1841/2000, Train Loss: 0.004408461, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.082910895, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.35%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 1842/2000, Train Loss: 0.004204516, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.083033562, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.29%', 1: '97.95%'}, LR: 0.000100000\n",
      "Epoch 1843/2000, Train Loss: 0.004145465, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.083486549, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.42%', 1: '97.79%'}, LR: 0.000100000\n",
      "Epoch 1844/2000, Train Loss: 0.004023745, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.083873993, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.36%', 1: '97.92%'}, LR: 0.000100000\n",
      "Epoch 1845/2000, Train Loss: 0.003869312, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.085546839, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.45%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 1846/2000, Train Loss: 0.003785585, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.085989859, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.34%', 1: '97.93%'}, LR: 0.000100000\n",
      "Epoch 1847/2000, Train Loss: 0.003714325, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.087728697, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.36%', 1: '97.79%'}, LR: 0.000100000\n",
      "Epoch 1848/2000, Train Loss: 0.003688071, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.085872131, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.20%', 1: '98.05%'}, LR: 0.000100000\n",
      "Epoch 1849/2000, Train Loss: 0.003716616, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.086215400, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.31%', 1: '98.00%'}, LR: 0.000100000\n",
      "Epoch 1850/2000, Train Loss: 0.003643236, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.086210448, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.36%', 1: '97.91%'}, LR: 0.000100000\n",
      "Epoch 1851/2000, Train Loss: 0.003620590, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.088024818, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.15%', 1: '98.08%'}, LR: 0.000100000\n",
      "Epoch 1852/2000, Train Loss: 0.003550818, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.090464443, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.47%', 1: '97.58%'}, LR: 0.000100000\n",
      "Epoch 1853/2000, Train Loss: 0.003972280, Train-Class-Acc: {0: '99.89%', 1: '99.83%'}, Val Loss: 0.090870959, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.53%', 1: '97.45%'}, LR: 0.000100000\n",
      "Epoch 1854/2000, Train Loss: 0.003518694, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.092367894, Val Accuracy: 98.07%, Val-Class-Acc: {0: '98.52%', 1: '97.37%'}, LR: 0.000100000\n",
      "Epoch 1855/2000, Train Loss: 0.003633760, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.093567984, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.38%', 1: '97.68%'}, LR: 0.000100000\n",
      "Epoch 1856/2000, Train Loss: 0.003629517, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.091240343, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.39%', 1: '97.76%'}, LR: 0.000100000\n",
      "Epoch 1857/2000, Train Loss: 0.003424443, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.090593292, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.32%', 1: '97.93%'}, LR: 0.000100000\n",
      "Epoch 1858/2000, Train Loss: 0.003609105, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.092733854, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.44%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1859/2000, Train Loss: 0.003392052, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.093653729, Val Accuracy: 98.09%, Val-Class-Acc: {0: '98.27%', 1: '97.83%'}, LR: 0.000100000\n",
      "Epoch 1860/2000, Train Loss: 0.003463805, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.095910045, Val Accuracy: 98.09%, Val-Class-Acc: {0: '98.41%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 1861/2000, Train Loss: 0.003381052, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.091105318, Val Accuracy: 98.15%, Val-Class-Acc: {0: '98.28%', 1: '97.96%'}, LR: 0.000100000\n",
      "Epoch 1862/2000, Train Loss: 0.003315128, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.093324539, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.36%', 1: '97.85%'}, LR: 0.000100000\n",
      "Epoch 1863/2000, Train Loss: 0.169247742, Train-Class-Acc: {0: '96.96%', 1: '95.39%'}, Val Loss: 0.086730163, Val Accuracy: 97.42%, Val-Class-Acc: {0: '97.45%', 1: '97.38%'}, LR: 0.000100000\n",
      "Epoch 1864/2000, Train Loss: 0.020163771, Train-Class-Acc: {0: '99.50%', 1: '99.08%'}, Val Loss: 0.073854725, Val Accuracy: 98.08%, Val-Class-Acc: {0: '98.44%', 1: '97.52%'}, LR: 0.000100000\n",
      "Epoch 1865/2000, Train Loss: 0.006435416, Train-Class-Acc: {0: '99.87%', 1: '99.78%'}, Val Loss: 0.079242212, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.38%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 1866/2000, Train Loss: 0.005097078, Train-Class-Acc: {0: '99.90%', 1: '99.82%'}, Val Loss: 0.081030281, Val Accuracy: 98.13%, Val-Class-Acc: {0: '98.19%', 1: '98.04%'}, LR: 0.000100000\n",
      "Epoch 1867/2000, Train Loss: 0.004530709, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.081320278, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.27%', 1: '98.04%'}, LR: 0.000100000\n",
      "Epoch 1868/2000, Train Loss: 0.004268739, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.084552503, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.53%', 1: '97.44%'}, LR: 0.000100000\n",
      "Epoch 1869/2000, Train Loss: 0.004209243, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.083511416, Val Accuracy: 98.20%, Val-Class-Acc: {0: '98.28%', 1: '98.08%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.19%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1707.pth\n",
      "Model saved after epoch 1869 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1869.pth \n",
      "\n",
      "Epoch 1870/2000, Train Loss: 0.003996720, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.085055765, Val Accuracy: 98.15%, Val-Class-Acc: {0: '98.22%', 1: '98.05%'}, LR: 0.000100000\n",
      "Epoch 1871/2000, Train Loss: 0.003877141, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.085510956, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.30%', 1: '97.96%'}, LR: 0.000100000\n",
      "Epoch 1872/2000, Train Loss: 0.003783964, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.086053878, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.37%', 1: '97.92%'}, LR: 0.000100000\n",
      "Epoch 1873/2000, Train Loss: 0.003642041, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.089814215, Val Accuracy: 98.11%, Val-Class-Acc: {0: '98.47%', 1: '97.56%'}, LR: 0.000100000\n",
      "Epoch 1874/2000, Train Loss: 0.003636336, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.089710835, Val Accuracy: 98.13%, Val-Class-Acc: {0: '98.32%', 1: '97.84%'}, LR: 0.000100000\n",
      "Epoch 1875/2000, Train Loss: 0.003621777, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.087960331, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.39%', 1: '97.89%'}, LR: 0.000100000\n",
      "Epoch 1876/2000, Train Loss: 0.003655635, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.092109699, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.34%', 1: '97.74%'}, LR: 0.000100000\n",
      "Epoch 1877/2000, Train Loss: 0.003618990, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.090785784, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.37%', 1: '97.80%'}, LR: 0.000100000\n",
      "Epoch 1878/2000, Train Loss: 0.003480704, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.088802398, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.34%', 1: '97.96%'}, LR: 0.000100000\n",
      "Epoch 1879/2000, Train Loss: 0.003424031, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.090366212, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.24%', 1: '98.04%'}, LR: 0.000100000\n",
      "Epoch 1880/2000, Train Loss: 0.003537244, Train-Class-Acc: {0: '99.90%', 1: '99.86%'}, Val Loss: 0.090686707, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.34%', 1: '97.93%'}, LR: 0.000100000\n",
      "Epoch 1881/2000, Train Loss: 0.003556780, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.092582453, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.40%', 1: '97.75%'}, LR: 0.000100000\n",
      "Epoch 1882/2000, Train Loss: 0.003376052, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.091819024, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.42%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 1883/2000, Train Loss: 0.003301667, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.093137740, Val Accuracy: 98.15%, Val-Class-Acc: {0: '98.36%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 1884/2000, Train Loss: 0.020636549, Train-Class-Acc: {0: '99.58%', 1: '99.57%'}, Val Loss: 0.148470066, Val Accuracy: 97.24%, Val-Class-Acc: {0: '98.06%', 1: '95.99%'}, LR: 0.000100000\n",
      "Epoch 1885/2000, Train Loss: 0.221239984, Train-Class-Acc: {0: '95.68%', 1: '91.97%'}, Val Loss: 0.082187292, Val Accuracy: 97.45%, Val-Class-Acc: {0: '98.45%', 1: '95.90%'}, LR: 0.000100000\n",
      "Epoch 1886/2000, Train Loss: 0.017664098, Train-Class-Acc: {0: '99.63%', 1: '99.27%'}, Val Loss: 0.079563678, Val Accuracy: 97.79%, Val-Class-Acc: {0: '98.77%', 1: '96.29%'}, LR: 0.000100000\n",
      "Epoch 1887/2000, Train Loss: 0.007894454, Train-Class-Acc: {0: '99.86%', 1: '99.71%'}, Val Loss: 0.076934013, Val Accuracy: 98.06%, Val-Class-Acc: {0: '98.50%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 1888/2000, Train Loss: 0.005739115, Train-Class-Acc: {0: '99.89%', 1: '99.81%'}, Val Loss: 0.076233056, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.31%', 1: '98.00%'}, LR: 0.000100000\n",
      "Epoch 1889/2000, Train Loss: 0.004781222, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.078196967, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.39%', 1: '97.88%'}, LR: 0.000100000\n",
      "Epoch 1890/2000, Train Loss: 0.004595178, Train-Class-Acc: {0: '99.91%', 1: '99.84%'}, Val Loss: 0.079766735, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.52%', 1: '97.65%'}, LR: 0.000100000\n",
      "Epoch 1891/2000, Train Loss: 0.004284060, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.080971758, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.32%', 1: '98.00%'}, LR: 0.000100000\n",
      "Epoch 1892/2000, Train Loss: 0.004208438, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.081965349, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.39%', 1: '97.87%'}, LR: 0.000100000\n",
      "Epoch 1893/2000, Train Loss: 0.004067564, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.082964587, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.33%', 1: '97.97%'}, LR: 0.000100000\n",
      "Epoch 1894/2000, Train Loss: 0.003861606, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.086603327, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.50%', 1: '97.54%'}, LR: 0.000100000\n",
      "Epoch 1895/2000, Train Loss: 0.003779826, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.083317735, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.34%', 1: '97.93%'}, LR: 0.000100000\n",
      "Epoch 1896/2000, Train Loss: 0.003716169, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.086922801, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.47%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 1897/2000, Train Loss: 0.003734915, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.087815934, Val Accuracy: 98.15%, Val-Class-Acc: {0: '98.59%', 1: '97.48%'}, LR: 0.000100000\n",
      "Epoch 1898/2000, Train Loss: 0.003621038, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.086339282, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.55%', 1: '97.60%'}, LR: 0.000100000\n",
      "Epoch 1899/2000, Train Loss: 0.003767721, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.086930115, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.37%', 1: '97.92%'}, LR: 0.000100000\n",
      "Epoch 1900/2000, Train Loss: 0.003763282, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.087911988, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.26%', 1: '98.01%'}, LR: 0.000100000\n",
      "Epoch 1901/2000, Train Loss: 0.003498271, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.088358029, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.45%', 1: '97.73%'}, LR: 0.000100000\n",
      "Epoch 1902/2000, Train Loss: 0.003426229, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.089408024, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.37%', 1: '97.92%'}, LR: 0.000100000\n",
      "Epoch 1903/2000, Train Loss: 0.003433852, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.090371540, Val Accuracy: 98.15%, Val-Class-Acc: {0: '98.50%', 1: '97.62%'}, LR: 0.000100000\n",
      "Epoch 1904/2000, Train Loss: 0.003395037, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.090888155, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.45%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 1905/2000, Train Loss: 0.003466070, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.090754263, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.60%', 1: '97.42%'}, LR: 0.000100000\n",
      "Epoch 1906/2000, Train Loss: 0.003487164, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.092196708, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.44%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 1907/2000, Train Loss: 0.003321917, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.092119837, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.50%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 1908/2000, Train Loss: 0.003347098, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.091227332, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.41%', 1: '97.86%'}, LR: 0.000100000\n",
      "Epoch 1909/2000, Train Loss: 0.012908190, Train-Class-Acc: {0: '99.87%', 1: '99.49%'}, Val Loss: 0.334835326, Val Accuracy: 94.30%, Val-Class-Acc: {0: '90.71%', 1: '99.84%'}, LR: 0.000100000\n",
      "Epoch 1910/2000, Train Loss: 0.034358798, Train-Class-Acc: {0: '99.08%', 1: '98.73%'}, Val Loss: 0.086135508, Val Accuracy: 98.05%, Val-Class-Acc: {0: '97.59%', 1: '98.76%'}, LR: 0.000100000\n",
      "Epoch 1911/2000, Train Loss: 0.024781618, Train-Class-Acc: {0: '99.28%', 1: '98.74%'}, Val Loss: 0.085542272, Val Accuracy: 97.87%, Val-Class-Acc: {0: '98.44%', 1: '97.01%'}, LR: 0.000100000\n",
      "Epoch 1912/2000, Train Loss: 0.004884132, Train-Class-Acc: {0: '99.90%', 1: '99.82%'}, Val Loss: 0.083090747, Val Accuracy: 98.04%, Val-Class-Acc: {0: '98.46%', 1: '97.39%'}, LR: 0.000100000\n",
      "Epoch 1913/2000, Train Loss: 0.004105386, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.085047164, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.43%', 1: '97.40%'}, LR: 0.000100000\n",
      "Epoch 1914/2000, Train Loss: 0.003793081, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.087052666, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.34%', 1: '97.72%'}, LR: 0.000100000\n",
      "Epoch 1915/2000, Train Loss: 0.003617640, Train-Class-Acc: {0: '99.92%', 1: '99.86%'}, Val Loss: 0.088396095, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.36%', 1: '97.69%'}, LR: 0.000100000\n",
      "Epoch 1916/2000, Train Loss: 0.003522554, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.088839642, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.35%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 1917/2000, Train Loss: 0.003689363, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.091270763, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.38%', 1: '97.79%'}, LR: 0.000100000\n",
      "Epoch 1918/2000, Train Loss: 0.003449081, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.090423395, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.24%', 1: '97.88%'}, LR: 0.000100000\n",
      "Epoch 1919/2000, Train Loss: 0.003414752, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.092033505, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.35%', 1: '97.76%'}, LR: 0.000100000\n",
      "Epoch 1920/2000, Train Loss: 0.003411156, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.092005541, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.46%', 1: '97.64%'}, LR: 0.000100000\n",
      "Epoch 1921/2000, Train Loss: 0.003372946, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.089468147, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.26%', 1: '98.00%'}, LR: 0.000100000\n",
      "Epoch 1922/2000, Train Loss: 0.003300656, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.094074154, Val Accuracy: 98.13%, Val-Class-Acc: {0: '98.48%', 1: '97.59%'}, LR: 0.000100000\n",
      "Epoch 1923/2000, Train Loss: 0.003318503, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.091540726, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.17%', 1: '98.05%'}, LR: 0.000100000\n",
      "Epoch 1924/2000, Train Loss: 0.003309232, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.092998388, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.46%', 1: '97.72%'}, LR: 0.000100000\n",
      "Epoch 1925/2000, Train Loss: 0.003218420, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.093863430, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.41%', 1: '97.80%'}, LR: 0.000100000\n",
      "Epoch 1926/2000, Train Loss: 0.003201667, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.096748029, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.47%', 1: '97.63%'}, LR: 0.000100000\n",
      "Epoch 1927/2000, Train Loss: 0.003221202, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.092190949, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.33%', 1: '97.89%'}, LR: 0.000100000\n",
      "Epoch 1928/2000, Train Loss: 0.003320096, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.096884104, Val Accuracy: 98.07%, Val-Class-Acc: {0: '98.30%', 1: '97.74%'}, LR: 0.000100000\n",
      "Epoch 1929/2000, Train Loss: 0.003320713, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.095039025, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.24%', 1: '97.95%'}, LR: 0.000100000\n",
      "Epoch 1930/2000, Train Loss: 0.003064885, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.094593584, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.33%', 1: '97.93%'}, LR: 0.000100000\n",
      "Epoch 1931/2000, Train Loss: 0.003025141, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.092834875, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.46%', 1: '97.74%'}, LR: 0.000100000\n",
      "Epoch 1932/2000, Train Loss: 0.003005164, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.099656196, Val Accuracy: 98.09%, Val-Class-Acc: {0: '98.51%', 1: '97.43%'}, LR: 0.000100000\n",
      "Epoch 1933/2000, Train Loss: 0.003299647, Train-Class-Acc: {0: '99.90%', 1: '99.85%'}, Val Loss: 0.095430436, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.42%', 1: '97.82%'}, LR: 0.000100000\n",
      "Epoch 1934/2000, Train Loss: 0.003252251, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.098593240, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.48%', 1: '97.61%'}, LR: 0.000100000\n",
      "Epoch 1935/2000, Train Loss: 0.003186640, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.095486726, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.12%', 1: '98.13%'}, LR: 0.000100000\n",
      "Epoch 1936/2000, Train Loss: 0.003031823, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.107190340, Val Accuracy: 97.95%, Val-Class-Acc: {0: '98.55%', 1: '97.02%'}, LR: 0.000100000\n",
      "Epoch 1937/2000, Train Loss: 0.351481241, Train-Class-Acc: {0: '94.87%', 1: '88.78%'}, Val Loss: 0.120769083, Val Accuracy: 95.70%, Val-Class-Acc: {0: '98.56%', 1: '91.30%'}, LR: 0.000100000\n",
      "Epoch 1938/2000, Train Loss: 0.045001261, Train-Class-Acc: {0: '98.91%', 1: '97.54%'}, Val Loss: 0.076927419, Val Accuracy: 97.93%, Val-Class-Acc: {0: '97.66%', 1: '98.34%'}, LR: 0.000100000\n",
      "Epoch 1939/2000, Train Loss: 0.019197838, Train-Class-Acc: {0: '99.48%', 1: '99.17%'}, Val Loss: 0.078066338, Val Accuracy: 98.01%, Val-Class-Acc: {0: '97.96%', 1: '98.08%'}, LR: 0.000100000\n",
      "Epoch 1940/2000, Train Loss: 0.007012706, Train-Class-Acc: {0: '99.89%', 1: '99.79%'}, Val Loss: 0.078079905, Val Accuracy: 98.08%, Val-Class-Acc: {0: '98.02%', 1: '98.18%'}, LR: 0.000100000\n",
      "Epoch 1941/2000, Train Loss: 0.005828322, Train-Class-Acc: {0: '99.89%', 1: '99.82%'}, Val Loss: 0.083497558, Val Accuracy: 98.07%, Val-Class-Acc: {0: '98.27%', 1: '97.78%'}, LR: 0.000100000\n",
      "Epoch 1942/2000, Train Loss: 0.004901956, Train-Class-Acc: {0: '99.91%', 1: '99.84%'}, Val Loss: 0.081897138, Val Accuracy: 98.11%, Val-Class-Acc: {0: '98.09%', 1: '98.15%'}, LR: 0.000100000\n",
      "Epoch 1943/2000, Train Loss: 0.004497673, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.081902423, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.16%', 1: '98.17%'}, LR: 0.000100000\n",
      "Epoch 1944/2000, Train Loss: 0.004237418, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.085735188, Val Accuracy: 98.11%, Val-Class-Acc: {0: '98.40%', 1: '97.66%'}, LR: 0.000100000\n",
      "Epoch 1945/2000, Train Loss: 0.004044543, Train-Class-Acc: {0: '99.92%', 1: '99.86%'}, Val Loss: 0.084142890, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.23%', 1: '98.11%'}, LR: 0.000100000\n",
      "Epoch 1946/2000, Train Loss: 0.003860220, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.084940565, Val Accuracy: 98.20%, Val-Class-Acc: {0: '98.38%', 1: '97.93%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.20%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1669.pth\n",
      "Model saved after epoch 1946 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1946.pth \n",
      "\n",
      "Epoch 1947/2000, Train Loss: 0.003803349, Train-Class-Acc: {0: '99.92%', 1: '99.86%'}, Val Loss: 0.087563237, Val Accuracy: 98.15%, Val-Class-Acc: {0: '98.49%', 1: '97.61%'}, LR: 0.000100000\n",
      "Epoch 1948/2000, Train Loss: 0.003647923, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.085634924, Val Accuracy: 98.20%, Val-Class-Acc: {0: '98.35%', 1: '97.98%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.20%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1869.pth\n",
      "Model saved after epoch 1948 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1948.pth \n",
      "\n",
      "Epoch 1949/2000, Train Loss: 0.003579473, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.085762928, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.13%', 1: '98.20%'}, LR: 0.000100000\n",
      "Epoch 1950/2000, Train Loss: 0.003522341, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.089313009, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.44%', 1: '97.77%'}, LR: 0.000100000\n",
      "Epoch 1951/2000, Train Loss: 0.003421246, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.088236614, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.38%', 1: '97.90%'}, LR: 0.000100000\n",
      "Epoch 1952/2000, Train Loss: 0.039496821, Train-Class-Acc: {0: '99.16%', 1: '98.68%'}, Val Loss: 0.085044271, Val Accuracy: 97.81%, Val-Class-Acc: {0: '97.95%', 1: '97.58%'}, LR: 0.000100000\n",
      "Epoch 1953/2000, Train Loss: 0.018693213, Train-Class-Acc: {0: '99.47%', 1: '99.02%'}, Val Loss: 0.081994369, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.19%', 1: '98.02%'}, LR: 0.000100000\n",
      "Epoch 1954/2000, Train Loss: 0.004547807, Train-Class-Acc: {0: '99.91%', 1: '99.84%'}, Val Loss: 0.080950578, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.31%', 1: '97.93%'}, LR: 0.000100000\n",
      "Epoch 1955/2000, Train Loss: 0.003950452, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.083737226, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.40%', 1: '97.79%'}, LR: 0.000100000\n",
      "Epoch 1956/2000, Train Loss: 0.003885966, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.082728039, Val Accuracy: 98.21%, Val-Class-Acc: {0: '98.46%', 1: '97.83%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.20%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1948.pth\n",
      "Model saved after epoch 1956 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1956.pth \n",
      "\n",
      "Epoch 1957/2000, Train Loss: 0.003659829, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.085804068, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.27%', 1: '98.04%'}, LR: 0.000100000\n",
      "Epoch 1958/2000, Train Loss: 0.003594912, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.085503785, Val Accuracy: 98.21%, Val-Class-Acc: {0: '98.36%', 1: '97.98%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.20%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1946.pth\n",
      "Model saved after epoch 1958 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1958.pth \n",
      "\n",
      "Epoch 1959/2000, Train Loss: 0.003402913, Train-Class-Acc: {0: '99.92%', 1: '99.88%'}, Val Loss: 0.088015170, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.45%', 1: '97.74%'}, LR: 0.000100000\n",
      "Epoch 1960/2000, Train Loss: 0.003411842, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.087600321, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.32%', 1: '97.97%'}, LR: 0.000100000\n",
      "Epoch 1961/2000, Train Loss: 0.003268393, Train-Class-Acc: {0: '99.92%', 1: '99.88%'}, Val Loss: 0.086987355, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.26%', 1: '98.07%'}, LR: 0.000100000\n",
      "Epoch 1962/2000, Train Loss: 0.003303142, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.089010904, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.44%', 1: '97.79%'}, LR: 0.000100000\n",
      "Epoch 1963/2000, Train Loss: 0.003260236, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.090017784, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.27%', 1: '97.99%'}, LR: 0.000100000\n",
      "Epoch 1964/2000, Train Loss: 0.003195771, Train-Class-Acc: {0: '99.92%', 1: '99.88%'}, Val Loss: 0.090069781, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.41%', 1: '97.83%'}, LR: 0.000100000\n",
      "Epoch 1965/2000, Train Loss: 0.003108997, Train-Class-Acc: {0: '99.93%', 1: '99.88%'}, Val Loss: 0.089669649, Val Accuracy: 98.21%, Val-Class-Acc: {0: '98.41%', 1: '97.90%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.21%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1958.pth\n",
      "Model saved after epoch 1965 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1965.pth \n",
      "\n",
      "Epoch 1966/2000, Train Loss: 0.003125474, Train-Class-Acc: {0: '99.93%', 1: '99.88%'}, Val Loss: 0.089094632, Val Accuracy: 98.18%, Val-Class-Acc: {0: '98.30%', 1: '98.00%'}, LR: 0.000100000\n",
      "Epoch 1967/2000, Train Loss: 0.003146560, Train-Class-Acc: {0: '99.92%', 1: '99.88%'}, Val Loss: 0.092499538, Val Accuracy: 98.14%, Val-Class-Acc: {0: '98.31%', 1: '97.89%'}, LR: 0.000100000\n",
      "Epoch 1968/2000, Train Loss: 0.003150639, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.092979635, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.39%', 1: '97.79%'}, LR: 0.000100000\n",
      "Epoch 1969/2000, Train Loss: 0.003063393, Train-Class-Acc: {0: '99.92%', 1: '99.88%'}, Val Loss: 0.091742312, Val Accuracy: 98.08%, Val-Class-Acc: {0: '98.01%', 1: '98.19%'}, LR: 0.000100000\n",
      "Epoch 1970/2000, Train Loss: 0.003244234, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.094147975, Val Accuracy: 98.15%, Val-Class-Acc: {0: '98.41%', 1: '97.75%'}, LR: 0.000100000\n",
      "Epoch 1971/2000, Train Loss: 0.003174248, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.092360388, Val Accuracy: 98.12%, Val-Class-Acc: {0: '98.17%', 1: '98.06%'}, LR: 0.000100000\n",
      "Epoch 1972/2000, Train Loss: 0.003139892, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.093409933, Val Accuracy: 98.20%, Val-Class-Acc: {0: '98.30%', 1: '98.06%'}, LR: 0.000100000\n",
      "Epoch 1973/2000, Train Loss: 0.002974381, Train-Class-Acc: {0: '99.92%', 1: '99.88%'}, Val Loss: 0.094097353, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.50%', 1: '97.65%'}, LR: 0.000100000\n",
      "Epoch 1974/2000, Train Loss: 0.003050450, Train-Class-Acc: {0: '99.92%', 1: '99.88%'}, Val Loss: 0.094338371, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.46%', 1: '97.73%'}, LR: 0.000100000\n",
      "Epoch 1975/2000, Train Loss: 0.003111813, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.098878148, Val Accuracy: 98.02%, Val-Class-Acc: {0: '98.60%', 1: '97.13%'}, LR: 0.000100000\n",
      "Epoch 1976/2000, Train Loss: 0.002959768, Train-Class-Acc: {0: '99.92%', 1: '99.88%'}, Val Loss: 0.099001271, Val Accuracy: 98.10%, Val-Class-Acc: {0: '98.37%', 1: '97.70%'}, LR: 0.000100000\n",
      "Epoch 1977/2000, Train Loss: 0.002998354, Train-Class-Acc: {0: '99.92%', 1: '99.88%'}, Val Loss: 0.096772097, Val Accuracy: 98.16%, Val-Class-Acc: {0: '98.49%', 1: '97.65%'}, LR: 0.000100000\n",
      "Epoch 1978/2000, Train Loss: 0.003077346, Train-Class-Acc: {0: '99.91%', 1: '99.87%'}, Val Loss: 0.095969462, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.35%', 1: '97.95%'}, LR: 0.000100000\n",
      "Epoch 1979/2000, Train Loss: 0.003239141, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.096345583, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.51%', 1: '97.71%'}, LR: 0.000100000\n",
      "Epoch 1980/2000, Train Loss: 0.387779785, Train-Class-Acc: {0: '92.36%', 1: '87.45%'}, Val Loss: 0.107538989, Val Accuracy: 96.30%, Val-Class-Acc: {0: '98.55%', 1: '92.85%'}, LR: 0.000100000\n",
      "Epoch 1981/2000, Train Loss: 0.039038325, Train-Class-Acc: {0: '99.16%', 1: '98.02%'}, Val Loss: 0.066574477, Val Accuracy: 98.17%, Val-Class-Acc: {0: '98.31%', 1: '97.94%'}, LR: 0.000100000\n",
      "Epoch 1982/2000, Train Loss: 0.011185855, Train-Class-Acc: {0: '99.84%', 1: '99.64%'}, Val Loss: 0.074445779, Val Accuracy: 98.22%, Val-Class-Acc: {0: '98.45%', 1: '97.87%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.21%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1965.pth\n",
      "Model saved after epoch 1982 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1982.pth \n",
      "\n",
      "Epoch 1983/2000, Train Loss: 0.007233458, Train-Class-Acc: {0: '99.89%', 1: '99.77%'}, Val Loss: 0.076435258, Val Accuracy: 98.30%, Val-Class-Acc: {0: '98.59%', 1: '97.86%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.21%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1615.pth\n",
      "Model saved after epoch 1983 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1983.pth \n",
      "\n",
      "Epoch 1984/2000, Train Loss: 0.005902283, Train-Class-Acc: {0: '99.90%', 1: '99.80%'}, Val Loss: 0.078133123, Val Accuracy: 98.32%, Val-Class-Acc: {0: '98.60%', 1: '97.88%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.21%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1956.pth\n",
      "Model saved after epoch 1984 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1984.pth \n",
      "\n",
      "Epoch 1985/2000, Train Loss: 0.006586034, Train-Class-Acc: {0: '99.84%', 1: '99.75%'}, Val Loss: 0.087338613, Val Accuracy: 97.97%, Val-Class-Acc: {0: '98.78%', 1: '96.74%'}, LR: 0.000100000\n",
      "Epoch 1986/2000, Train Loss: 0.005705502, Train-Class-Acc: {0: '99.87%', 1: '99.77%'}, Val Loss: 0.079556592, Val Accuracy: 98.35%, Val-Class-Acc: {0: '98.67%', 1: '97.86%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.22%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_401.pth\n",
      "Model saved after epoch 1986 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1986.pth \n",
      "\n",
      "Epoch 1987/2000, Train Loss: 0.004282389, Train-Class-Acc: {0: '99.92%', 1: '99.85%'}, Val Loss: 0.080810791, Val Accuracy: 98.35%, Val-Class-Acc: {0: '98.63%', 1: '97.92%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.22%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1982.pth\n",
      "Model saved after epoch 1987 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1987.pth \n",
      "\n",
      "Epoch 1988/2000, Train Loss: 0.004980465, Train-Class-Acc: {0: '99.88%', 1: '99.81%'}, Val Loss: 0.081019753, Val Accuracy: 98.21%, Val-Class-Acc: {0: '98.15%', 1: '98.30%'}, LR: 0.000100000\n",
      "Epoch 1989/2000, Train Loss: 0.004127318, Train-Class-Acc: {0: '99.91%', 1: '99.85%'}, Val Loss: 0.081761440, Val Accuracy: 98.33%, Val-Class-Acc: {0: '98.57%', 1: '97.96%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.30%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1983.pth\n",
      "Model saved after epoch 1989 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1989.pth \n",
      "\n",
      "Epoch 1990/2000, Train Loss: 0.004119948, Train-Class-Acc: {0: '99.90%', 1: '99.84%'}, Val Loss: 0.083815012, Val Accuracy: 98.26%, Val-Class-Acc: {0: '98.40%', 1: '98.05%'}, LR: 0.000100000\n",
      "Epoch 1991/2000, Train Loss: 0.003699951, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.085908542, Val Accuracy: 98.31%, Val-Class-Acc: {0: '98.68%', 1: '97.74%'}, LR: 0.000100000\n",
      "Epoch 1992/2000, Train Loss: 0.003551026, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.084037083, Val Accuracy: 98.28%, Val-Class-Acc: {0: '98.42%', 1: '98.05%'}, LR: 0.000100000\n",
      "Epoch 1993/2000, Train Loss: 0.003481898, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.084002547, Val Accuracy: 98.27%, Val-Class-Acc: {0: '98.40%', 1: '98.08%'}, LR: 0.000100000\n",
      "Epoch 1994/2000, Train Loss: 0.003473318, Train-Class-Acc: {0: '99.92%', 1: '99.88%'}, Val Loss: 0.085947424, Val Accuracy: 98.29%, Val-Class-Acc: {0: '98.53%', 1: '97.91%'}, LR: 0.000100000\n",
      "Epoch 1995/2000, Train Loss: 0.003464602, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.084821461, Val Accuracy: 98.31%, Val-Class-Acc: {0: '98.53%', 1: '97.98%'}, LR: 0.000100000\n",
      "Epoch 1996/2000, Train Loss: 0.003391660, Train-Class-Acc: {0: '99.92%', 1: '99.88%'}, Val Loss: 0.088281523, Val Accuracy: 98.28%, Val-Class-Acc: {0: '98.74%', 1: '97.58%'}, LR: 0.000100000\n",
      "Epoch 1997/2000, Train Loss: 0.003329088, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.090527261, Val Accuracy: 98.19%, Val-Class-Acc: {0: '98.77%', 1: '97.31%'}, LR: 0.000100000\n",
      "Epoch 1998/2000, Train Loss: 0.003344848, Train-Class-Acc: {0: '99.92%', 1: '99.87%'}, Val Loss: 0.087991502, Val Accuracy: 98.30%, Val-Class-Acc: {0: '98.59%', 1: '97.84%'}, LR: 0.000100000\n",
      "Epoch 1999/2000, Train Loss: 0.003456159, Train-Class-Acc: {0: '99.91%', 1: '99.86%'}, Val Loss: 0.088306877, Val Accuracy: 98.33%, Val-Class-Acc: {0: '98.72%', 1: '97.73%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 98.32%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1984.pth\n",
      "Model saved after epoch 1999 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1999.pth \n",
      "\n",
      "Epoch 2000/2000, Train Loss: 0.069607688, Train-Class-Acc: {0: '98.36%', 1: '97.80%'}, Val Loss: 0.076768133, Val Accuracy: 97.98%, Val-Class-Acc: {0: '98.10%', 1: '97.81%'}, LR: 0.000100000\n",
      "\n",
      "Final model saved to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_final.pth\n",
      "\n",
      "Training complete. \n",
      "\n",
      "Top 5 Models Sorted by Validation Accuracy: \n",
      "Epoch 1987/2000, Train Loss: 0.004282389, Train-Class-Acc: {0: '98.36%', 1: '97.80%'}, Val Loss: 0.080810791, Val Accuracy: 98.35%, Val-Class-Acc: {0: '98.10%', 1: '97.81%'}, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1987.pth\n",
      "Epoch 1986/2000, Train Loss: 0.005705502, Train-Class-Acc: {0: '98.36%', 1: '97.80%'}, Val Loss: 0.079556592, Val Accuracy: 98.35%, Val-Class-Acc: {0: '98.10%', 1: '97.81%'}, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1986.pth\n",
      "Epoch 1550/2000, Train Loss: 0.008332113, Train-Class-Acc: {0: '98.36%', 1: '97.80%'}, Val Loss: 0.064474121, Val Accuracy: 98.33%, Val-Class-Acc: {0: '98.10%', 1: '97.81%'}, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1550.pth\n",
      "Epoch 1989/2000, Train Loss: 0.004127318, Train-Class-Acc: {0: '98.36%', 1: '97.80%'}, Val Loss: 0.081761440, Val Accuracy: 98.33%, Val-Class-Acc: {0: '98.10%', 1: '97.81%'}, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1989.pth\n",
      "Epoch 1999/2000, Train Loss: 0.003456159, Train-Class-Acc: {0: '98.36%', 1: '97.80%'}, Val Loss: 0.088306877, Val Accuracy: 98.33%, Val-Class-Acc: {0: '98.10%', 1: '97.81%'}, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1999.pth\n",
      "\n",
      "\n",
      "Epoch 1987/2000, Train Loss: 0.0043, Val Loss: 0.0808, Val Accuracy: 98.35%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1987.pth\n",
      "Epoch 1986/2000, Train Loss: 0.0057, Val Loss: 0.0796, Val Accuracy: 98.35%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1986.pth\n",
      "Epoch 1550/2000, Train Loss: 0.0083, Val Loss: 0.0645, Val Accuracy: 98.33%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1550.pth\n",
      "Epoch 1989/2000, Train Loss: 0.0041, Val Loss: 0.0818, Val Accuracy: 98.33%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1989.pth\n",
      "Epoch 1999/2000, Train Loss: 0.0035, Val Loss: 0.0883, Val Accuracy: 98.33%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1999.pth\n",
      "\n",
      "class_gru_model: \n",
      "BiGRUWithAttention(\n",
      "  (gru): GRU(7, 64, num_layers=4, batch_first=True, bidirectional=True)\n",
      "  (attention_fc): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "\n",
      "unique_classes = [0 1]\n",
      "num_classes = 2\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# Initialize the list to store results across runs\n",
    "track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "# Model parameters\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/Baseline/Period_1/1st_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the model\n",
    "class_gru_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(class_gru_model.parameters(), lr=0.0001) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# train_and_validate(class_gru_model, output_size, criterion, optimizer, X_train_all, y_train_all, X_val_all, y_val_all, scheduler, \n",
    "train_and_validate(class_gru_model, output_size, criterion, optimizer, X_train, y_train, X_val, y_val, scheduler, \n",
    "                   False, num_epochs, batch_size, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model: \\n{class_gru_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 1 --> Training and saving in __*'2nd_try'*__ (BiGRUWithAttention, num_layers = 3) ---> Val acc = 98.31 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[0], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'train_and_validate' function started. \n",
      "\n",
      "Existing folder has been removed : Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\n",
      "\n",
      "y_train:\n",
      "<class 'torch.Tensor'>\n",
      "torch.int64\n",
      "torch.Size([3634, 1000])\n",
      "X_train:\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "torch.Size([3634, 1000, 7])\n",
      "\n",
      "y_val:\n",
      "<class 'torch.Tensor'>\n",
      "torch.int64\n",
      "torch.Size([454, 1000])\n",
      "X_val:\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "torch.Size([454, 1000, 7])\n",
      "\n",
      "Dataset Lengths:\n",
      "Train Dataset Length: 3634\n",
      "Validation Dataset Length: 454\n",
      "\n",
      "DataLoader Batch Sizes:\n",
      "Number of Batches in Train DataLoader: 57\n",
      "Number of Batches in Validation DataLoader: 8\n",
      "\n",
      "y_train Unique Values and Stats:\n",
      "Unique values in y_train: tensor([0, 1], device='cuda:0')\n",
      "y_train Min: 0, Max: 1\n",
      "\n",
      "y_val Unique Values and Stats:\n",
      "Unique values in y_val: tensor([0, 1], device='cuda:0')\n",
      "y_val Min: 0, Max: 1\n",
      "\n",
      "Device Info:\n",
      "X_train Device: cuda:0\n",
      "y_train Device: cuda:0\n",
      "X_val Device: cuda:0\n",
      "y_val Device: cuda:0\n",
      "\n",
      "Epoch 1/2000, Train Loss: 0.010724814, Val Loss: 0.011819029, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Model saved after epoch 1 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1.pth \n",
      "\n",
      "\n",
      "Unique target values: tensor([0, 1], device='cuda:0')\n",
      "Target dtype: torch.int64\n",
      "Min target: 0, Max target: 1\n",
      "Unique classes in y_train: tensor([0, 1], device='cuda:0')\n",
      "Unique classes in y_val: tensor([0, 1], device='cuda:0')\n",
      "\n",
      "\n",
      "Unique target values: tensor([0, 1], device='cuda:0')\n",
      "Target dtype: torch.int64\n",
      "Min target: 0, Max target: 1\n",
      "Unique classes in y_train: tensor([0, 1], device='cuda:0')\n",
      "Unique classes in y_val: tensor([0, 1], device='cuda:0')\n",
      "\n",
      "\n",
      "Unique target values: tensor([0, 1], device='cuda:0')\n",
      "Target dtype: torch.int64\n",
      "Min target: 0, Max target: 1\n",
      "Unique classes in y_train: tensor([0, 1], device='cuda:0')\n",
      "Unique classes in y_val: tensor([0, 1], device='cuda:0')\n",
      "\n",
      "Epoch 2/2000, Train Loss: 0.010339666, Val Loss: 0.011771941, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Model saved after epoch 2 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_2.pth \n",
      "\n",
      "Epoch 3/2000, Train Loss: 0.010337460, Val Loss: 0.011761453, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Model saved after epoch 3 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_3.pth \n",
      "\n",
      "Epoch 4/2000, Train Loss: 0.010333836, Val Loss: 0.011767223, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Model saved after epoch 4 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_4.pth \n",
      "\n",
      "Epoch 5/2000, Train Loss: 0.010333769, Val Loss: 0.011770000, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Model saved after epoch 5 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_5.pth \n",
      "\n",
      "Epoch 6/2000, Train Loss: 0.010330688, Val Loss: 0.011766681, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 7/2000, Train Loss: 0.010330320, Val Loss: 0.011756237, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 8/2000, Train Loss: 0.010332275, Val Loss: 0.011772879, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 9/2000, Train Loss: 0.010327020, Val Loss: 0.011751898, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 10/2000, Train Loss: 0.010327381, Val Loss: 0.011763328, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 11/2000, Train Loss: 0.010323909, Val Loss: 0.011753893, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 12/2000, Train Loss: 0.010323784, Val Loss: 0.011745506, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 13/2000, Train Loss: 0.010320362, Val Loss: 0.011748173, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 14/2000, Train Loss: 0.010316573, Val Loss: 0.011746307, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 15/2000, Train Loss: 0.010310862, Val Loss: 0.011731806, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 16/2000, Train Loss: 0.010304712, Val Loss: 0.011761889, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 17/2000, Train Loss: 0.010297971, Val Loss: 0.011698128, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 18/2000, Train Loss: 0.010284888, Val Loss: 0.011687701, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 19/2000, Train Loss: 0.010233847, Val Loss: 0.011538043, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 20/2000, Train Loss: 0.010133562, Val Loss: 0.012383857, Val Accuracy: 60.39%, LR: 0.000100000\n",
      "Epoch 21/2000, Train Loss: 0.010639910, Val Loss: 0.011200037, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 22/2000, Train Loss: 0.009679814, Val Loss: 0.012490320, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 23/2000, Train Loss: 0.010731319, Val Loss: 0.012102871, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 24/2000, Train Loss: 0.010534213, Val Loss: 0.011972334, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 25/2000, Train Loss: 0.010462092, Val Loss: 0.011895498, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 26/2000, Train Loss: 0.010409359, Val Loss: 0.011819725, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 27/2000, Train Loss: 0.010360660, Val Loss: 0.011778257, Val Accuracy: 60.61%, LR: 0.000100000\n",
      "Epoch 28/2000, Train Loss: 0.010317154, Val Loss: 0.011688577, Val Accuracy: 60.62%, LR: 0.000100000\n",
      "Removed old model with accuracy 60.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_5.pth\n",
      "Model saved after epoch 28 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_28.pth \n",
      "\n",
      "Epoch 29/2000, Train Loss: 0.010268404, Val Loss: 0.011596597, Val Accuracy: 60.72%, LR: 0.000100000\n",
      "Removed old model with accuracy 60.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_4.pth\n",
      "Model saved after epoch 29 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_29.pth \n",
      "\n",
      "Epoch 30/2000, Train Loss: 0.010188606, Val Loss: 0.011414999, Val Accuracy: 60.70%, LR: 0.000100000\n",
      "Removed old model with accuracy 60.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_3.pth\n",
      "Model saved after epoch 30 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_30.pth \n",
      "\n",
      "Epoch 31/2000, Train Loss: 0.010022727, Val Loss: 0.011045676, Val Accuracy: 61.81%, LR: 0.000100000\n",
      "Removed old model with accuracy 60.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_2.pth\n",
      "Model saved after epoch 31 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_31.pth \n",
      "\n",
      "Epoch 32/2000, Train Loss: 0.009477800, Val Loss: 0.009332728, Val Accuracy: 75.98%, LR: 0.000100000\n",
      "Removed old model with accuracy 60.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1.pth\n",
      "Model saved after epoch 32 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_32.pth \n",
      "\n",
      "Epoch 33/2000, Train Loss: 0.009547329, Val Loss: 0.009147653, Val Accuracy: 62.37%, LR: 0.000100000\n",
      "Removed old model with accuracy 60.62%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_28.pth\n",
      "Model saved after epoch 33 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_33.pth \n",
      "\n",
      "Epoch 34/2000, Train Loss: 0.008807835, Val Loss: 0.010237923, Val Accuracy: 72.23%, LR: 0.000100000\n",
      "Removed old model with accuracy 60.70%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_30.pth\n",
      "Model saved after epoch 34 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_34.pth \n",
      "\n",
      "Epoch 35/2000, Train Loss: 0.008528532, Val Loss: 0.008165464, Val Accuracy: 82.50%, LR: 0.000100000\n",
      "Removed old model with accuracy 60.72%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_29.pth\n",
      "Model saved after epoch 35 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_35.pth \n",
      "\n",
      "Epoch 36/2000, Train Loss: 0.007302443, Val Loss: 0.007000910, Val Accuracy: 87.19%, LR: 0.000100000\n",
      "Removed old model with accuracy 61.81%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_31.pth\n",
      "Model saved after epoch 36 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_36.pth \n",
      "\n",
      "Epoch 37/2000, Train Loss: 0.006623261, Val Loss: 0.006667072, Val Accuracy: 85.05%, LR: 0.000100000\n",
      "Removed old model with accuracy 62.37%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_33.pth\n",
      "Model saved after epoch 37 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_37.pth \n",
      "\n",
      "Epoch 38/2000, Train Loss: 0.006009037, Val Loss: 0.006517997, Val Accuracy: 87.24%, LR: 0.000100000\n",
      "Removed old model with accuracy 72.23%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_34.pth\n",
      "Model saved after epoch 38 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_38.pth \n",
      "\n",
      "Epoch 39/2000, Train Loss: 0.005669621, Val Loss: 0.006143103, Val Accuracy: 86.78%, LR: 0.000100000\n",
      "Removed old model with accuracy 75.98%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_32.pth\n",
      "Model saved after epoch 39 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_39.pth \n",
      "\n",
      "Epoch 40/2000, Train Loss: 0.005792431, Val Loss: 0.005705786, Val Accuracy: 88.37%, LR: 0.000100000\n",
      "Removed old model with accuracy 82.50%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_35.pth\n",
      "Model saved after epoch 40 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_40.pth \n",
      "\n",
      "Epoch 41/2000, Train Loss: 0.005707977, Val Loss: 0.005924175, Val Accuracy: 86.58%, LR: 0.000100000\n",
      "Removed old model with accuracy 85.05%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_37.pth\n",
      "Model saved after epoch 41 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_41.pth \n",
      "\n",
      "Epoch 42/2000, Train Loss: 0.005241273, Val Loss: 0.005365092, Val Accuracy: 89.35%, LR: 0.000100000\n",
      "Removed old model with accuracy 86.58%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_41.pth\n",
      "Model saved after epoch 42 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_42.pth \n",
      "\n",
      "Epoch 43/2000, Train Loss: 0.005202376, Val Loss: 0.005283621, Val Accuracy: 88.89%, LR: 0.000100000\n",
      "Removed old model with accuracy 86.78%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_39.pth\n",
      "Model saved after epoch 43 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_43.pth \n",
      "\n",
      "Epoch 44/2000, Train Loss: 0.004891464, Val Loss: 0.005187086, Val Accuracy: 88.98%, LR: 0.000100000\n",
      "Removed old model with accuracy 87.19%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_36.pth\n",
      "Model saved after epoch 44 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_44.pth \n",
      "\n",
      "Epoch 45/2000, Train Loss: 0.004692002, Val Loss: 0.004893432, Val Accuracy: 89.70%, LR: 0.000100000\n",
      "Removed old model with accuracy 87.24%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_38.pth\n",
      "Model saved after epoch 45 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_45.pth \n",
      "\n",
      "Epoch 46/2000, Train Loss: 0.004618234, Val Loss: 0.004661811, Val Accuracy: 90.24%, LR: 0.000100000\n",
      "Removed old model with accuracy 88.37%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_40.pth\n",
      "Model saved after epoch 46 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_46.pth \n",
      "\n",
      "Epoch 47/2000, Train Loss: 0.004415992, Val Loss: 0.004475481, Val Accuracy: 90.54%, LR: 0.000100000\n",
      "Removed old model with accuracy 88.89%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_43.pth\n",
      "Model saved after epoch 47 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_47.pth \n",
      "\n",
      "Epoch 48/2000, Train Loss: 0.004325301, Val Loss: 0.004376267, Val Accuracy: 90.59%, LR: 0.000100000\n",
      "Removed old model with accuracy 88.98%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_44.pth\n",
      "Model saved after epoch 48 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_48.pth \n",
      "\n",
      "Epoch 49/2000, Train Loss: 0.004397085, Val Loss: 0.004478277, Val Accuracy: 90.26%, LR: 0.000100000\n",
      "Removed old model with accuracy 89.35%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_42.pth\n",
      "Model saved after epoch 49 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_49.pth \n",
      "\n",
      "Epoch 50/2000, Train Loss: 0.004163122, Val Loss: 0.004063760, Val Accuracy: 91.02%, LR: 0.000100000\n",
      "Removed old model with accuracy 89.70%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_45.pth\n",
      "Model saved after epoch 50 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_50.pth \n",
      "\n",
      "Epoch 51/2000, Train Loss: 0.003979119, Val Loss: 0.003924089, Val Accuracy: 91.13%, LR: 0.000100000\n",
      "Removed old model with accuracy 90.24%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_46.pth\n",
      "Model saved after epoch 51 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_51.pth \n",
      "\n",
      "Epoch 52/2000, Train Loss: 0.003923946, Val Loss: 0.003926491, Val Accuracy: 90.86%, LR: 0.000100000\n",
      "Removed old model with accuracy 90.26%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_49.pth\n",
      "Model saved after epoch 52 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_52.pth \n",
      "\n",
      "Epoch 53/2000, Train Loss: 0.004009774, Val Loss: 0.003698730, Val Accuracy: 91.19%, LR: 0.000100000\n",
      "Removed old model with accuracy 90.54%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_47.pth\n",
      "Model saved after epoch 53 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_53.pth \n",
      "\n",
      "Epoch 54/2000, Train Loss: 0.003721685, Val Loss: 0.003586334, Val Accuracy: 91.29%, LR: 0.000100000\n",
      "Removed old model with accuracy 90.59%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_48.pth\n",
      "Model saved after epoch 54 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_54.pth \n",
      "\n",
      "Epoch 55/2000, Train Loss: 0.003631626, Val Loss: 0.003604400, Val Accuracy: 91.24%, LR: 0.000100000\n",
      "Removed old model with accuracy 90.86%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_52.pth\n",
      "Model saved after epoch 55 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_55.pth \n",
      "\n",
      "Epoch 56/2000, Train Loss: 0.003724240, Val Loss: 0.003517853, Val Accuracy: 91.42%, LR: 0.000100000\n",
      "Removed old model with accuracy 91.02%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_50.pth\n",
      "Model saved after epoch 56 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_56.pth \n",
      "\n",
      "Epoch 57/2000, Train Loss: 0.003662446, Val Loss: 0.003478522, Val Accuracy: 91.49%, LR: 0.000100000\n",
      "Removed old model with accuracy 91.13%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_51.pth\n",
      "Model saved after epoch 57 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_57.pth \n",
      "\n",
      "Epoch 58/2000, Train Loss: 0.003883760, Val Loss: 0.003854533, Val Accuracy: 90.76%, LR: 0.000100000\n",
      "Epoch 59/2000, Train Loss: 0.003552500, Val Loss: 0.003603256, Val Accuracy: 90.97%, LR: 0.000100000\n",
      "Epoch 60/2000, Train Loss: 0.003790227, Val Loss: 0.004158287, Val Accuracy: 89.82%, LR: 0.000100000\n",
      "Epoch 61/2000, Train Loss: 0.003536314, Val Loss: 0.003537758, Val Accuracy: 91.12%, LR: 0.000100000\n",
      "Epoch 62/2000, Train Loss: 0.003430143, Val Loss: 0.003410039, Val Accuracy: 91.57%, LR: 0.000100000\n",
      "Removed old model with accuracy 91.19%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_53.pth\n",
      "Model saved after epoch 62 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_62.pth \n",
      "\n",
      "Epoch 63/2000, Train Loss: 0.003386608, Val Loss: 0.003405845, Val Accuracy: 91.60%, LR: 0.000100000\n",
      "Removed old model with accuracy 91.24%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_55.pth\n",
      "Model saved after epoch 63 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_63.pth \n",
      "\n",
      "Epoch 64/2000, Train Loss: 0.003381979, Val Loss: 0.003348699, Val Accuracy: 91.62%, LR: 0.000100000\n",
      "Removed old model with accuracy 91.29%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_54.pth\n",
      "Model saved after epoch 64 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_64.pth \n",
      "\n",
      "Epoch 65/2000, Train Loss: 0.003295704, Val Loss: 0.003693228, Val Accuracy: 90.97%, LR: 0.000100000\n",
      "Epoch 66/2000, Train Loss: 0.003347790, Val Loss: 0.003330773, Val Accuracy: 91.80%, LR: 0.000100000\n",
      "Removed old model with accuracy 91.42%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_56.pth\n",
      "Model saved after epoch 66 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_66.pth \n",
      "\n",
      "Epoch 67/2000, Train Loss: 0.003463191, Val Loss: 0.004009956, Val Accuracy: 89.83%, LR: 0.000100000\n",
      "Epoch 68/2000, Train Loss: 0.003317947, Val Loss: 0.003502572, Val Accuracy: 91.33%, LR: 0.000100000\n",
      "Epoch 69/2000, Train Loss: 0.003282143, Val Loss: 0.003746135, Val Accuracy: 90.63%, LR: 0.000100000\n",
      "Epoch 70/2000, Train Loss: 0.003318067, Val Loss: 0.003269755, Val Accuracy: 92.03%, LR: 0.000100000\n",
      "Removed old model with accuracy 91.49%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_57.pth\n",
      "Model saved after epoch 70 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_70.pth \n",
      "\n",
      "Epoch 71/2000, Train Loss: 0.003319416, Val Loss: 0.003504520, Val Accuracy: 91.57%, LR: 0.000100000\n",
      "Epoch 72/2000, Train Loss: 0.003161086, Val Loss: 0.003352080, Val Accuracy: 91.77%, LR: 0.000100000\n",
      "Removed old model with accuracy 91.57%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_62.pth\n",
      "Model saved after epoch 72 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_72.pth \n",
      "\n",
      "Epoch 73/2000, Train Loss: 0.003447018, Val Loss: 0.003259589, Val Accuracy: 92.03%, LR: 0.000100000\n",
      "Removed old model with accuracy 91.60%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_63.pth\n",
      "Model saved after epoch 73 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_73.pth \n",
      "\n",
      "Epoch 74/2000, Train Loss: 0.003241693, Val Loss: 0.003208766, Val Accuracy: 92.02%, LR: 0.000100000\n",
      "Removed old model with accuracy 91.62%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_64.pth\n",
      "Model saved after epoch 74 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_74.pth \n",
      "\n",
      "Epoch 75/2000, Train Loss: 0.003113015, Val Loss: 0.003396222, Val Accuracy: 91.74%, LR: 0.000100000\n",
      "Epoch 76/2000, Train Loss: 0.003026021, Val Loss: 0.003164028, Val Accuracy: 92.33%, LR: 0.000100000\n",
      "Removed old model with accuracy 91.77%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_72.pth\n",
      "Model saved after epoch 76 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_76.pth \n",
      "\n",
      "Epoch 77/2000, Train Loss: 0.003036923, Val Loss: 0.003179816, Val Accuracy: 92.36%, LR: 0.000100000\n",
      "Removed old model with accuracy 91.80%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_66.pth\n",
      "Model saved after epoch 77 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_77.pth \n",
      "\n",
      "Epoch 78/2000, Train Loss: 0.003090018, Val Loss: 0.003142344, Val Accuracy: 92.45%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.02%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_74.pth\n",
      "Model saved after epoch 78 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_78.pth \n",
      "\n",
      "Epoch 79/2000, Train Loss: 0.002947295, Val Loss: 0.003134231, Val Accuracy: 92.30%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.03%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_70.pth\n",
      "Model saved after epoch 79 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_79.pth \n",
      "\n",
      "Epoch 80/2000, Train Loss: 0.003099814, Val Loss: 0.003092610, Val Accuracy: 92.61%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.03%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_73.pth\n",
      "Model saved after epoch 80 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_80.pth \n",
      "\n",
      "Epoch 81/2000, Train Loss: 0.003023656, Val Loss: 0.003001921, Val Accuracy: 92.64%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.30%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_79.pth\n",
      "Model saved after epoch 81 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_81.pth \n",
      "\n",
      "Epoch 82/2000, Train Loss: 0.003180922, Val Loss: 0.003032596, Val Accuracy: 92.68%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.33%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_76.pth\n",
      "Model saved after epoch 82 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_82.pth \n",
      "\n",
      "Epoch 83/2000, Train Loss: 0.002957007, Val Loss: 0.003049139, Val Accuracy: 92.76%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.36%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_77.pth\n",
      "Model saved after epoch 83 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_83.pth \n",
      "\n",
      "Epoch 84/2000, Train Loss: 0.002897854, Val Loss: 0.003087214, Val Accuracy: 92.85%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.45%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_78.pth\n",
      "Model saved after epoch 84 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_84.pth \n",
      "\n",
      "Epoch 85/2000, Train Loss: 0.002799205, Val Loss: 0.003229304, Val Accuracy: 92.14%, LR: 0.000100000\n",
      "Epoch 86/2000, Train Loss: 0.002795267, Val Loss: 0.002961922, Val Accuracy: 93.00%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_80.pth\n",
      "Model saved after epoch 86 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_86.pth \n",
      "\n",
      "Epoch 87/2000, Train Loss: 0.002726956, Val Loss: 0.002893509, Val Accuracy: 92.98%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.64%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_81.pth\n",
      "Model saved after epoch 87 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_87.pth \n",
      "\n",
      "Epoch 88/2000, Train Loss: 0.002982053, Val Loss: 0.003096230, Val Accuracy: 92.67%, LR: 0.000100000\n",
      "Epoch 89/2000, Train Loss: 0.002790685, Val Loss: 0.003169648, Val Accuracy: 92.41%, LR: 0.000100000\n",
      "Epoch 90/2000, Train Loss: 0.002676636, Val Loss: 0.002897184, Val Accuracy: 92.84%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.68%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_82.pth\n",
      "Model saved after epoch 90 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_90.pth \n",
      "\n",
      "Epoch 91/2000, Train Loss: 0.002749121, Val Loss: 0.003748186, Val Accuracy: 91.01%, LR: 0.000100000\n",
      "Epoch 92/2000, Train Loss: 0.003016796, Val Loss: 0.002875690, Val Accuracy: 93.35%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.76%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_83.pth\n",
      "Model saved after epoch 92 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_92.pth \n",
      "\n",
      "Epoch 93/2000, Train Loss: 0.002682981, Val Loss: 0.002894469, Val Accuracy: 92.71%, LR: 0.000100000\n",
      "Epoch 94/2000, Train Loss: 0.002931393, Val Loss: 0.002663078, Val Accuracy: 93.50%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.84%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_90.pth\n",
      "Model saved after epoch 94 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_94.pth \n",
      "\n",
      "Epoch 95/2000, Train Loss: 0.002791927, Val Loss: 0.002829158, Val Accuracy: 93.11%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.85%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_84.pth\n",
      "Model saved after epoch 95 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_95.pth \n",
      "\n",
      "Epoch 96/2000, Train Loss: 0.002546794, Val Loss: 0.002700429, Val Accuracy: 93.53%, LR: 0.000100000\n",
      "Removed old model with accuracy 92.98%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_87.pth\n",
      "Model saved after epoch 96 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_96.pth \n",
      "\n",
      "Epoch 97/2000, Train Loss: 0.002509714, Val Loss: 0.002592354, Val Accuracy: 93.64%, LR: 0.000100000\n",
      "Removed old model with accuracy 93.00%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_86.pth\n",
      "Model saved after epoch 97 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_97.pth \n",
      "\n",
      "Epoch 98/2000, Train Loss: 0.003417923, Val Loss: 0.003195310, Val Accuracy: 92.07%, LR: 0.000100000\n",
      "Epoch 99/2000, Train Loss: 0.002597538, Val Loss: 0.002741002, Val Accuracy: 93.23%, LR: 0.000100000\n",
      "Removed old model with accuracy 93.11%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_95.pth\n",
      "Model saved after epoch 99 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_99.pth \n",
      "\n",
      "Epoch 100/2000, Train Loss: 0.002567204, Val Loss: 0.002675637, Val Accuracy: 93.67%, LR: 0.000100000\n",
      "Removed old model with accuracy 93.23%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_99.pth\n",
      "Model saved after epoch 100 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_100.pth \n",
      "\n",
      "Epoch 101/2000, Train Loss: 0.002736048, Val Loss: 0.002674720, Val Accuracy: 93.69%, LR: 0.000100000\n",
      "Removed old model with accuracy 93.35%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_92.pth\n",
      "Model saved after epoch 101 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_101.pth \n",
      "\n",
      "Epoch 102/2000, Train Loss: 0.002533590, Val Loss: 0.002749304, Val Accuracy: 93.11%, LR: 0.000100000\n",
      "Epoch 103/2000, Train Loss: 0.002480702, Val Loss: 0.002543010, Val Accuracy: 93.65%, LR: 0.000100000\n",
      "Removed old model with accuracy 93.50%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_94.pth\n",
      "Model saved after epoch 103 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_103.pth \n",
      "\n",
      "Epoch 104/2000, Train Loss: 0.002757122, Val Loss: 0.002766276, Val Accuracy: 93.04%, LR: 0.000100000\n",
      "Epoch 105/2000, Train Loss: 0.002609712, Val Loss: 0.002559421, Val Accuracy: 94.08%, LR: 0.000100000\n",
      "Removed old model with accuracy 93.53%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_96.pth\n",
      "Model saved after epoch 105 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_105.pth \n",
      "\n",
      "Epoch 106/2000, Train Loss: 0.002865111, Val Loss: 0.003269467, Val Accuracy: 91.92%, LR: 0.000100000\n",
      "Epoch 107/2000, Train Loss: 0.002725927, Val Loss: 0.002500330, Val Accuracy: 93.87%, LR: 0.000100000\n",
      "Removed old model with accuracy 93.64%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_97.pth\n",
      "Model saved after epoch 107 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_107.pth \n",
      "\n",
      "Epoch 108/2000, Train Loss: 0.002355893, Val Loss: 0.002407319, Val Accuracy: 94.01%, LR: 0.000100000\n",
      "Removed old model with accuracy 93.65%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_103.pth\n",
      "Model saved after epoch 108 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_108.pth \n",
      "\n",
      "Epoch 109/2000, Train Loss: 0.002461644, Val Loss: 0.002516962, Val Accuracy: 94.06%, LR: 0.000100000\n",
      "Removed old model with accuracy 93.67%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_100.pth\n",
      "Model saved after epoch 109 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_109.pth \n",
      "\n",
      "Epoch 110/2000, Train Loss: 0.002532851, Val Loss: 0.002388342, Val Accuracy: 94.02%, LR: 0.000100000\n",
      "Removed old model with accuracy 93.69%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_101.pth\n",
      "Model saved after epoch 110 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_110.pth \n",
      "\n",
      "Epoch 111/2000, Train Loss: 0.002537661, Val Loss: 0.002447438, Val Accuracy: 94.35%, LR: 0.000100000\n",
      "Removed old model with accuracy 93.87%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_107.pth\n",
      "Model saved after epoch 111 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_111.pth \n",
      "\n",
      "Epoch 112/2000, Train Loss: 0.002300241, Val Loss: 0.002468329, Val Accuracy: 93.83%, LR: 0.000100000\n",
      "Epoch 113/2000, Train Loss: 0.002328470, Val Loss: 0.002365476, Val Accuracy: 94.32%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.01%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_108.pth\n",
      "Model saved after epoch 113 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_113.pth \n",
      "\n",
      "Epoch 114/2000, Train Loss: 0.002320982, Val Loss: 0.002481452, Val Accuracy: 93.78%, LR: 0.000100000\n",
      "Epoch 115/2000, Train Loss: 0.002376788, Val Loss: 0.002391315, Val Accuracy: 94.70%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.02%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_110.pth\n",
      "Model saved after epoch 115 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_115.pth \n",
      "\n",
      "Epoch 116/2000, Train Loss: 0.002810734, Val Loss: 0.002438578, Val Accuracy: 94.04%, LR: 0.000100000\n",
      "Epoch 117/2000, Train Loss: 0.002174987, Val Loss: 0.002431691, Val Accuracy: 94.21%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.06%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_109.pth\n",
      "Model saved after epoch 117 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_117.pth \n",
      "\n",
      "Epoch 118/2000, Train Loss: 0.002246932, Val Loss: 0.002348017, Val Accuracy: 94.61%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.08%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_105.pth\n",
      "Model saved after epoch 118 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_118.pth \n",
      "\n",
      "Epoch 119/2000, Train Loss: 0.002680449, Val Loss: 0.002321698, Val Accuracy: 94.56%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.21%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_117.pth\n",
      "Model saved after epoch 119 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_119.pth \n",
      "\n",
      "Epoch 120/2000, Train Loss: 0.002361449, Val Loss: 0.002449277, Val Accuracy: 94.08%, LR: 0.000100000\n",
      "Epoch 121/2000, Train Loss: 0.002330600, Val Loss: 0.002337979, Val Accuracy: 94.33%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.32%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_113.pth\n",
      "Model saved after epoch 121 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_121.pth \n",
      "\n",
      "Epoch 122/2000, Train Loss: 0.002618469, Val Loss: 0.002357270, Val Accuracy: 94.77%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.33%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_121.pth\n",
      "Model saved after epoch 122 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_122.pth \n",
      "\n",
      "Epoch 123/2000, Train Loss: 0.002440581, Val Loss: 0.002797955, Val Accuracy: 93.53%, LR: 0.000100000\n",
      "Epoch 124/2000, Train Loss: 0.002399825, Val Loss: 0.002270072, Val Accuracy: 94.83%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.35%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_111.pth\n",
      "Model saved after epoch 124 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_124.pth \n",
      "\n",
      "Epoch 125/2000, Train Loss: 0.002353787, Val Loss: 0.002468938, Val Accuracy: 94.00%, LR: 0.000100000\n",
      "Epoch 126/2000, Train Loss: 0.002175669, Val Loss: 0.002246665, Val Accuracy: 94.67%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.56%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_119.pth\n",
      "Model saved after epoch 126 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_126.pth \n",
      "\n",
      "Epoch 127/2000, Train Loss: 0.002091997, Val Loss: 0.002194894, Val Accuracy: 94.64%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_118.pth\n",
      "Model saved after epoch 127 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_127.pth \n",
      "\n",
      "Epoch 128/2000, Train Loss: 0.002951472, Val Loss: 0.003068027, Val Accuracy: 92.11%, LR: 0.000100000\n",
      "Epoch 129/2000, Train Loss: 0.002162391, Val Loss: 0.002357007, Val Accuracy: 94.26%, LR: 0.000100000\n",
      "Epoch 130/2000, Train Loss: 0.002373137, Val Loss: 0.002379019, Val Accuracy: 94.16%, LR: 0.000100000\n",
      "Epoch 131/2000, Train Loss: 0.002154155, Val Loss: 0.002360840, Val Accuracy: 94.24%, LR: 0.000100000\n",
      "Epoch 132/2000, Train Loss: 0.002034424, Val Loss: 0.002339919, Val Accuracy: 94.14%, LR: 0.000100000\n",
      "Epoch 133/2000, Train Loss: 0.002126638, Val Loss: 0.002116501, Val Accuracy: 95.21%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.64%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_127.pth\n",
      "Model saved after epoch 133 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_133.pth \n",
      "\n",
      "Epoch 134/2000, Train Loss: 0.002108875, Val Loss: 0.002273311, Val Accuracy: 94.32%, LR: 0.000100000\n",
      "Epoch 135/2000, Train Loss: 0.002028523, Val Loss: 0.002205551, Val Accuracy: 94.47%, LR: 0.000100000\n",
      "Epoch 136/2000, Train Loss: 0.002070458, Val Loss: 0.002079677, Val Accuracy: 95.17%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.67%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_126.pth\n",
      "Model saved after epoch 136 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_136.pth \n",
      "\n",
      "Epoch 137/2000, Train Loss: 0.002459806, Val Loss: 0.002827626, Val Accuracy: 92.73%, LR: 0.000100000\n",
      "Epoch 138/2000, Train Loss: 0.002476336, Val Loss: 0.002442340, Val Accuracy: 94.12%, LR: 0.000100000\n",
      "Epoch 139/2000, Train Loss: 0.002001450, Val Loss: 0.002125447, Val Accuracy: 95.23%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.70%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_115.pth\n",
      "Model saved after epoch 139 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_139.pth \n",
      "\n",
      "Epoch 140/2000, Train Loss: 0.001939338, Val Loss: 0.002124256, Val Accuracy: 94.98%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.77%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_122.pth\n",
      "Model saved after epoch 140 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_140.pth \n",
      "\n",
      "Epoch 141/2000, Train Loss: 0.002079102, Val Loss: 0.002216272, Val Accuracy: 94.58%, LR: 0.000100000\n",
      "Epoch 142/2000, Train Loss: 0.002012557, Val Loss: 0.002162959, Val Accuracy: 95.38%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.83%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_124.pth\n",
      "Model saved after epoch 142 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_142.pth \n",
      "\n",
      "Epoch 143/2000, Train Loss: 0.001991263, Val Loss: 0.002120198, Val Accuracy: 95.03%, LR: 0.000100000\n",
      "Removed old model with accuracy 94.98%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_140.pth\n",
      "Model saved after epoch 143 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_143.pth \n",
      "\n",
      "Epoch 144/2000, Train Loss: 0.002586835, Val Loss: 0.003145676, Val Accuracy: 91.95%, LR: 0.000100000\n",
      "Epoch 145/2000, Train Loss: 0.002267039, Val Loss: 0.002032757, Val Accuracy: 95.51%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.03%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_143.pth\n",
      "Model saved after epoch 145 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_145.pth \n",
      "\n",
      "Epoch 146/2000, Train Loss: 0.001998839, Val Loss: 0.002072588, Val Accuracy: 95.13%, LR: 0.000100000\n",
      "Epoch 147/2000, Train Loss: 0.002041495, Val Loss: 0.002055286, Val Accuracy: 95.56%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.17%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_136.pth\n",
      "Model saved after epoch 147 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_147.pth \n",
      "\n",
      "Epoch 148/2000, Train Loss: 0.001971037, Val Loss: 0.002511036, Val Accuracy: 93.68%, LR: 0.000100000\n",
      "Epoch 149/2000, Train Loss: 0.002260903, Val Loss: 0.002182061, Val Accuracy: 94.67%, LR: 0.000100000\n",
      "Epoch 150/2000, Train Loss: 0.001891815, Val Loss: 0.002154564, Val Accuracy: 95.45%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.21%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_133.pth\n",
      "Model saved after epoch 150 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_150.pth \n",
      "\n",
      "Epoch 151/2000, Train Loss: 0.001958585, Val Loss: 0.002356021, Val Accuracy: 94.00%, LR: 0.000100000\n",
      "Epoch 152/2000, Train Loss: 0.001941720, Val Loss: 0.002291743, Val Accuracy: 94.19%, LR: 0.000100000\n",
      "Epoch 153/2000, Train Loss: 0.001963393, Val Loss: 0.002011488, Val Accuracy: 95.65%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.23%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_139.pth\n",
      "Model saved after epoch 153 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_153.pth \n",
      "\n",
      "Epoch 154/2000, Train Loss: 0.001963477, Val Loss: 0.001954526, Val Accuracy: 95.70%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.38%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_142.pth\n",
      "Model saved after epoch 154 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_154.pth \n",
      "\n",
      "Epoch 155/2000, Train Loss: 0.002131520, Val Loss: 0.002689854, Val Accuracy: 94.10%, LR: 0.000100000\n",
      "Epoch 156/2000, Train Loss: 0.002324886, Val Loss: 0.002244008, Val Accuracy: 94.53%, LR: 0.000100000\n",
      "Epoch 157/2000, Train Loss: 0.001915269, Val Loss: 0.001999525, Val Accuracy: 95.52%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.45%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_150.pth\n",
      "Model saved after epoch 157 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_157.pth \n",
      "\n",
      "Epoch 158/2000, Train Loss: 0.001882510, Val Loss: 0.002017851, Val Accuracy: 95.71%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.51%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_145.pth\n",
      "Model saved after epoch 158 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_158.pth \n",
      "\n",
      "Epoch 159/2000, Train Loss: 0.001928081, Val Loss: 0.002206997, Val Accuracy: 95.28%, LR: 0.000100000\n",
      "Epoch 160/2000, Train Loss: 0.002236366, Val Loss: 0.002178512, Val Accuracy: 95.60%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.52%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_157.pth\n",
      "Model saved after epoch 160 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_160.pth \n",
      "\n",
      "Epoch 161/2000, Train Loss: 0.001929534, Val Loss: 0.002099033, Val Accuracy: 95.35%, LR: 0.000100000\n",
      "Epoch 162/2000, Train Loss: 0.001984745, Val Loss: 0.001976849, Val Accuracy: 95.75%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.56%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_147.pth\n",
      "Model saved after epoch 162 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_162.pth \n",
      "\n",
      "Epoch 163/2000, Train Loss: 0.001762386, Val Loss: 0.002358850, Val Accuracy: 94.12%, LR: 0.000100000\n",
      "Epoch 164/2000, Train Loss: 0.001950166, Val Loss: 0.002319402, Val Accuracy: 94.36%, LR: 0.000100000\n",
      "Epoch 165/2000, Train Loss: 0.001816715, Val Loss: 0.002001950, Val Accuracy: 95.80%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.60%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_160.pth\n",
      "Model saved after epoch 165 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_165.pth \n",
      "\n",
      "Epoch 166/2000, Train Loss: 0.002310502, Val Loss: 0.002101413, Val Accuracy: 95.56%, LR: 0.000100000\n",
      "Epoch 167/2000, Train Loss: 0.002103582, Val Loss: 0.001928441, Val Accuracy: 95.91%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.65%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_153.pth\n",
      "Model saved after epoch 167 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_167.pth \n",
      "\n",
      "Epoch 168/2000, Train Loss: 0.001703203, Val Loss: 0.002092950, Val Accuracy: 95.57%, LR: 0.000100000\n",
      "Epoch 169/2000, Train Loss: 0.001719268, Val Loss: 0.001959448, Val Accuracy: 95.96%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.70%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_154.pth\n",
      "Model saved after epoch 169 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_169.pth \n",
      "\n",
      "Epoch 170/2000, Train Loss: 0.001728437, Val Loss: 0.002082693, Val Accuracy: 94.96%, LR: 0.000100000\n",
      "Epoch 171/2000, Train Loss: 0.001998615, Val Loss: 0.001944062, Val Accuracy: 95.89%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.71%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_158.pth\n",
      "Model saved after epoch 171 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_171.pth \n",
      "\n",
      "Epoch 172/2000, Train Loss: 0.001976801, Val Loss: 0.002001151, Val Accuracy: 95.69%, LR: 0.000100000\n",
      "Epoch 173/2000, Train Loss: 0.001689748, Val Loss: 0.002001714, Val Accuracy: 95.80%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.75%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_162.pth\n",
      "Model saved after epoch 173 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_173.pth \n",
      "\n",
      "Epoch 174/2000, Train Loss: 0.001687533, Val Loss: 0.002081909, Val Accuracy: 95.34%, LR: 0.000100000\n",
      "Epoch 175/2000, Train Loss: 0.001705878, Val Loss: 0.002066654, Val Accuracy: 95.10%, LR: 0.000100000\n",
      "Epoch 176/2000, Train Loss: 0.001779563, Val Loss: 0.001999245, Val Accuracy: 95.81%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.80%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_165.pth\n",
      "Model saved after epoch 176 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_176.pth \n",
      "\n",
      "Epoch 177/2000, Train Loss: 0.001668176, Val Loss: 0.002201670, Val Accuracy: 95.37%, LR: 0.000100000\n",
      "Epoch 178/2000, Train Loss: 0.001971390, Val Loss: 0.002035003, Val Accuracy: 95.73%, LR: 0.000100000\n",
      "Epoch 179/2000, Train Loss: 0.001802010, Val Loss: 0.002221848, Val Accuracy: 94.77%, LR: 0.000100000\n",
      "Epoch 180/2000, Train Loss: 0.001703820, Val Loss: 0.002383023, Val Accuracy: 94.29%, LR: 0.000100000\n",
      "Epoch 181/2000, Train Loss: 0.001792387, Val Loss: 0.002365773, Val Accuracy: 95.12%, LR: 0.000100000\n",
      "Epoch 182/2000, Train Loss: 0.001796497, Val Loss: 0.001959357, Val Accuracy: 95.90%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.80%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_173.pth\n",
      "Model saved after epoch 182 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_182.pth \n",
      "\n",
      "Epoch 183/2000, Train Loss: 0.001691018, Val Loss: 0.002041742, Val Accuracy: 95.77%, LR: 0.000100000\n",
      "Epoch 184/2000, Train Loss: 0.002154908, Val Loss: 0.001909707, Val Accuracy: 96.06%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.81%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_176.pth\n",
      "Model saved after epoch 184 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_184.pth \n",
      "\n",
      "Epoch 185/2000, Train Loss: 0.001689348, Val Loss: 0.001810230, Val Accuracy: 96.32%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.89%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_171.pth\n",
      "Model saved after epoch 185 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_185.pth \n",
      "\n",
      "Epoch 186/2000, Train Loss: 0.001637685, Val Loss: 0.002300521, Val Accuracy: 94.51%, LR: 0.000100000\n",
      "Epoch 187/2000, Train Loss: 0.001624992, Val Loss: 0.002111415, Val Accuracy: 94.99%, LR: 0.000100000\n",
      "Epoch 188/2000, Train Loss: 0.001569658, Val Loss: 0.002041789, Val Accuracy: 96.03%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.90%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_182.pth\n",
      "Model saved after epoch 188 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_188.pth \n",
      "\n",
      "Epoch 189/2000, Train Loss: 0.001673505, Val Loss: 0.001852739, Val Accuracy: 96.17%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.91%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_167.pth\n",
      "Model saved after epoch 189 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_189.pth \n",
      "\n",
      "Epoch 190/2000, Train Loss: 0.001772367, Val Loss: 0.001918800, Val Accuracy: 96.07%, LR: 0.000100000\n",
      "Removed old model with accuracy 95.96%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_169.pth\n",
      "Model saved after epoch 190 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_190.pth \n",
      "\n",
      "Epoch 191/2000, Train Loss: 0.001620914, Val Loss: 0.002079892, Val Accuracy: 95.47%, LR: 0.000100000\n",
      "Epoch 192/2000, Train Loss: 0.001543881, Val Loss: 0.001930074, Val Accuracy: 95.73%, LR: 0.000100000\n",
      "Epoch 193/2000, Train Loss: 0.001632025, Val Loss: 0.002135440, Val Accuracy: 95.02%, LR: 0.000100000\n",
      "Epoch 194/2000, Train Loss: 0.001517272, Val Loss: 0.001908916, Val Accuracy: 96.01%, LR: 0.000100000\n",
      "Epoch 195/2000, Train Loss: 0.001622086, Val Loss: 0.002170494, Val Accuracy: 95.03%, LR: 0.000100000\n",
      "Epoch 196/2000, Train Loss: 0.001860123, Val Loss: 0.001947779, Val Accuracy: 96.10%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.03%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_188.pth\n",
      "Model saved after epoch 196 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_196.pth \n",
      "\n",
      "Epoch 197/2000, Train Loss: 0.001563311, Val Loss: 0.002113215, Val Accuracy: 95.29%, LR: 0.000100000\n",
      "Epoch 198/2000, Train Loss: 0.001858640, Val Loss: 0.002034229, Val Accuracy: 95.57%, LR: 0.000100000\n",
      "Epoch 199/2000, Train Loss: 0.001678109, Val Loss: 0.001844761, Val Accuracy: 96.37%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.06%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_184.pth\n",
      "Model saved after epoch 199 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_199.pth \n",
      "\n",
      "Epoch 200/2000, Train Loss: 0.001413500, Val Loss: 0.001902748, Val Accuracy: 96.02%, LR: 0.000100000\n",
      "Epoch 201/2000, Train Loss: 0.001858289, Val Loss: 0.002095255, Val Accuracy: 95.89%, LR: 0.000100000\n",
      "Epoch 202/2000, Train Loss: 0.001518483, Val Loss: 0.001825066, Val Accuracy: 96.40%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.07%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_190.pth\n",
      "Model saved after epoch 202 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_202.pth \n",
      "\n",
      "Epoch 203/2000, Train Loss: 0.001460187, Val Loss: 0.002059846, Val Accuracy: 96.06%, LR: 0.000100000\n",
      "Epoch 204/2000, Train Loss: 0.001434678, Val Loss: 0.001966751, Val Accuracy: 95.82%, LR: 0.000100000\n",
      "Epoch 205/2000, Train Loss: 0.001463090, Val Loss: 0.002216051, Val Accuracy: 95.23%, LR: 0.000100000\n",
      "Epoch 206/2000, Train Loss: 0.001489310, Val Loss: 0.002199403, Val Accuracy: 95.80%, LR: 0.000100000\n",
      "Epoch 207/2000, Train Loss: 0.001609667, Val Loss: 0.002001697, Val Accuracy: 96.00%, LR: 0.000100000\n",
      "Epoch 208/2000, Train Loss: 0.001488444, Val Loss: 0.002356049, Val Accuracy: 95.49%, LR: 0.000100000\n",
      "Epoch 209/2000, Train Loss: 0.001554118, Val Loss: 0.002200567, Val Accuracy: 95.20%, LR: 0.000100000\n",
      "Epoch 210/2000, Train Loss: 0.001435067, Val Loss: 0.001909170, Val Accuracy: 96.00%, LR: 0.000100000\n",
      "Epoch 211/2000, Train Loss: 0.001482942, Val Loss: 0.001846087, Val Accuracy: 96.51%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.10%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_196.pth\n",
      "Model saved after epoch 211 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_211.pth \n",
      "\n",
      "Epoch 212/2000, Train Loss: 0.001463114, Val Loss: 0.001864945, Val Accuracy: 96.57%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.17%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_189.pth\n",
      "Model saved after epoch 212 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_212.pth \n",
      "\n",
      "Epoch 213/2000, Train Loss: 0.001524525, Val Loss: 0.001716780, Val Accuracy: 96.83%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.32%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_185.pth\n",
      "Model saved after epoch 213 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_213.pth \n",
      "\n",
      "Epoch 214/2000, Train Loss: 0.001416672, Val Loss: 0.001961824, Val Accuracy: 96.41%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.37%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_199.pth\n",
      "Model saved after epoch 214 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_214.pth \n",
      "\n",
      "Epoch 215/2000, Train Loss: 0.001486706, Val Loss: 0.001708135, Val Accuracy: 96.88%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.40%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_202.pth\n",
      "Model saved after epoch 215 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_215.pth \n",
      "\n",
      "Epoch 216/2000, Train Loss: 0.001547071, Val Loss: 0.002480869, Val Accuracy: 94.72%, LR: 0.000100000\n",
      "Epoch 217/2000, Train Loss: 0.001430081, Val Loss: 0.001908272, Val Accuracy: 96.55%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.41%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_214.pth\n",
      "Model saved after epoch 217 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_217.pth \n",
      "\n",
      "Epoch 218/2000, Train Loss: 0.001763871, Val Loss: 0.001899414, Val Accuracy: 96.34%, LR: 0.000100000\n",
      "Epoch 219/2000, Train Loss: 0.001516993, Val Loss: 0.001695488, Val Accuracy: 96.84%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.51%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_211.pth\n",
      "Model saved after epoch 219 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_219.pth \n",
      "\n",
      "Epoch 220/2000, Train Loss: 0.001361988, Val Loss: 0.001834429, Val Accuracy: 96.23%, LR: 0.000100000\n",
      "Epoch 221/2000, Train Loss: 0.001681335, Val Loss: 0.002297207, Val Accuracy: 95.28%, LR: 0.000100000\n",
      "Epoch 222/2000, Train Loss: 0.001382906, Val Loss: 0.002026065, Val Accuracy: 96.50%, LR: 0.000100000\n",
      "Epoch 223/2000, Train Loss: 0.001425456, Val Loss: 0.001868583, Val Accuracy: 96.71%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.55%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_217.pth\n",
      "Model saved after epoch 223 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_223.pth \n",
      "\n",
      "Epoch 224/2000, Train Loss: 0.001415198, Val Loss: 0.002321525, Val Accuracy: 95.98%, LR: 0.000100000\n",
      "Epoch 225/2000, Train Loss: 0.001502696, Val Loss: 0.001963873, Val Accuracy: 95.74%, LR: 0.000100000\n",
      "Epoch 226/2000, Train Loss: 0.001484454, Val Loss: 0.001972584, Val Accuracy: 96.17%, LR: 0.000100000\n",
      "Epoch 227/2000, Train Loss: 0.001388120, Val Loss: 0.001789680, Val Accuracy: 96.85%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.57%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_212.pth\n",
      "Model saved after epoch 227 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_227.pth \n",
      "\n",
      "Epoch 228/2000, Train Loss: 0.001382540, Val Loss: 0.002017771, Val Accuracy: 96.59%, LR: 0.000100000\n",
      "Epoch 229/2000, Train Loss: 0.001402875, Val Loss: 0.002063043, Val Accuracy: 96.43%, LR: 0.000100000\n",
      "Epoch 230/2000, Train Loss: 0.001404105, Val Loss: 0.001717033, Val Accuracy: 96.99%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.71%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_223.pth\n",
      "Model saved after epoch 230 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_230.pth \n",
      "\n",
      "Epoch 231/2000, Train Loss: 0.001363151, Val Loss: 0.001739300, Val Accuracy: 97.00%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.83%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_213.pth\n",
      "Model saved after epoch 231 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_231.pth \n",
      "\n",
      "Epoch 232/2000, Train Loss: 0.001338067, Val Loss: 0.002036960, Val Accuracy: 96.04%, LR: 0.000100000\n",
      "Epoch 233/2000, Train Loss: 0.001835751, Val Loss: 0.002138109, Val Accuracy: 96.06%, LR: 0.000100000\n",
      "Epoch 234/2000, Train Loss: 0.001366806, Val Loss: 0.001780661, Val Accuracy: 96.95%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.84%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_219.pth\n",
      "Model saved after epoch 234 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_234.pth \n",
      "\n",
      "Epoch 235/2000, Train Loss: 0.001371675, Val Loss: 0.001807878, Val Accuracy: 96.70%, LR: 0.000100000\n",
      "Epoch 236/2000, Train Loss: 0.001404725, Val Loss: 0.001866856, Val Accuracy: 96.58%, LR: 0.000100000\n",
      "Epoch 237/2000, Train Loss: 0.001242751, Val Loss: 0.001968672, Val Accuracy: 96.74%, LR: 0.000100000\n",
      "Epoch 238/2000, Train Loss: 0.001422629, Val Loss: 0.001863081, Val Accuracy: 96.65%, LR: 0.000100000\n",
      "Epoch 239/2000, Train Loss: 0.001394934, Val Loss: 0.002168460, Val Accuracy: 95.62%, LR: 0.000100000\n",
      "Epoch 240/2000, Train Loss: 0.001453350, Val Loss: 0.001927830, Val Accuracy: 96.81%, LR: 0.000100000\n",
      "Epoch 241/2000, Train Loss: 0.001300870, Val Loss: 0.001719453, Val Accuracy: 96.99%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.85%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_227.pth\n",
      "Model saved after epoch 241 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_241.pth \n",
      "\n",
      "Epoch 242/2000, Train Loss: 0.001360334, Val Loss: 0.001978919, Val Accuracy: 96.78%, LR: 0.000100000\n",
      "Epoch 243/2000, Train Loss: 0.001251492, Val Loss: 0.002136646, Val Accuracy: 96.48%, LR: 0.000100000\n",
      "Epoch 244/2000, Train Loss: 0.001254181, Val Loss: 0.001852727, Val Accuracy: 96.31%, LR: 0.000100000\n",
      "Epoch 245/2000, Train Loss: 0.001257661, Val Loss: 0.001826836, Val Accuracy: 96.94%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.88%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_215.pth\n",
      "Model saved after epoch 245 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_245.pth \n",
      "\n",
      "Epoch 246/2000, Train Loss: 0.001408803, Val Loss: 0.001828043, Val Accuracy: 96.54%, LR: 0.000100000\n",
      "Epoch 247/2000, Train Loss: 0.001252905, Val Loss: 0.001855486, Val Accuracy: 96.93%, LR: 0.000100000\n",
      "Epoch 248/2000, Train Loss: 0.001270314, Val Loss: 0.002134741, Val Accuracy: 96.51%, LR: 0.000100000\n",
      "Epoch 249/2000, Train Loss: 0.001341338, Val Loss: 0.001978291, Val Accuracy: 96.21%, LR: 0.000100000\n",
      "Epoch 250/2000, Train Loss: 0.001407131, Val Loss: 0.001756968, Val Accuracy: 96.99%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.94%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_245.pth\n",
      "Model saved after epoch 250 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_250.pth \n",
      "\n",
      "Epoch 251/2000, Train Loss: 0.001214667, Val Loss: 0.001928042, Val Accuracy: 96.95%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.95%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_234.pth\n",
      "Model saved after epoch 251 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_251.pth \n",
      "\n",
      "Epoch 252/2000, Train Loss: 0.001299981, Val Loss: 0.002314941, Val Accuracy: 95.52%, LR: 0.000100000\n",
      "Epoch 253/2000, Train Loss: 0.001452479, Val Loss: 0.001852141, Val Accuracy: 97.03%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.95%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_251.pth\n",
      "Model saved after epoch 253 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_253.pth \n",
      "\n",
      "Epoch 254/2000, Train Loss: 0.001184617, Val Loss: 0.001834338, Val Accuracy: 96.97%, LR: 0.000100000\n",
      "Epoch 255/2000, Train Loss: 0.001279804, Val Loss: 0.002095909, Val Accuracy: 96.03%, LR: 0.000100000\n",
      "Epoch 256/2000, Train Loss: 0.001349280, Val Loss: 0.001773442, Val Accuracy: 97.10%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.99%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_250.pth\n",
      "Model saved after epoch 256 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_256.pth \n",
      "\n",
      "Epoch 257/2000, Train Loss: 0.001174585, Val Loss: 0.002261749, Val Accuracy: 95.58%, LR: 0.000100000\n",
      "Epoch 258/2000, Train Loss: 0.001658837, Val Loss: 0.001829058, Val Accuracy: 96.96%, LR: 0.000100000\n",
      "Epoch 259/2000, Train Loss: 0.001214787, Val Loss: 0.001751334, Val Accuracy: 97.08%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.99%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_241.pth\n",
      "Model saved after epoch 259 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_259.pth \n",
      "\n",
      "Epoch 260/2000, Train Loss: 0.001356924, Val Loss: 0.002455741, Val Accuracy: 95.50%, LR: 0.000100000\n",
      "Epoch 261/2000, Train Loss: 0.001229879, Val Loss: 0.001711400, Val Accuracy: 97.18%, LR: 0.000100000\n",
      "Removed old model with accuracy 96.99%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_230.pth\n",
      "Model saved after epoch 261 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_261.pth \n",
      "\n",
      "Epoch 262/2000, Train Loss: 0.001259965, Val Loss: 0.001815298, Val Accuracy: 96.62%, LR: 0.000100000\n",
      "Epoch 263/2000, Train Loss: 0.001254233, Val Loss: 0.002113580, Val Accuracy: 95.85%, LR: 0.000100000\n",
      "Epoch 264/2000, Train Loss: 0.001265642, Val Loss: 0.002190379, Val Accuracy: 96.26%, LR: 0.000100000\n",
      "Epoch 265/2000, Train Loss: 0.001399472, Val Loss: 0.002085199, Val Accuracy: 96.67%, LR: 0.000100000\n",
      "Epoch 266/2000, Train Loss: 0.001248740, Val Loss: 0.002106475, Val Accuracy: 96.66%, LR: 0.000100000\n",
      "Epoch 267/2000, Train Loss: 0.001479219, Val Loss: 0.001902436, Val Accuracy: 96.45%, LR: 0.000100000\n",
      "Epoch 268/2000, Train Loss: 0.001085200, Val Loss: 0.001811550, Val Accuracy: 97.09%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.00%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_231.pth\n",
      "Model saved after epoch 268 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_268.pth \n",
      "\n",
      "Epoch 269/2000, Train Loss: 0.001121707, Val Loss: 0.001756383, Val Accuracy: 96.49%, LR: 0.000100000\n",
      "Epoch 270/2000, Train Loss: 0.001469377, Val Loss: 0.002114178, Val Accuracy: 96.81%, LR: 0.000100000\n",
      "Epoch 271/2000, Train Loss: 0.001213994, Val Loss: 0.002080104, Val Accuracy: 96.93%, LR: 0.000100000\n",
      "Epoch 272/2000, Train Loss: 0.001145785, Val Loss: 0.002194061, Val Accuracy: 96.73%, LR: 0.000100000\n",
      "Epoch 273/2000, Train Loss: 0.001154112, Val Loss: 0.002410324, Val Accuracy: 95.76%, LR: 0.000100000\n",
      "Epoch 274/2000, Train Loss: 0.001216647, Val Loss: 0.001701900, Val Accuracy: 97.17%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.03%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_253.pth\n",
      "Model saved after epoch 274 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_274.pth \n",
      "\n",
      "Epoch 275/2000, Train Loss: 0.001244947, Val Loss: 0.001967949, Val Accuracy: 97.06%, LR: 0.000100000\n",
      "Epoch 276/2000, Train Loss: 0.001147722, Val Loss: 0.002430244, Val Accuracy: 96.27%, LR: 0.000100000\n",
      "Epoch 277/2000, Train Loss: 0.001217903, Val Loss: 0.001914549, Val Accuracy: 96.72%, LR: 0.000100000\n",
      "Epoch 278/2000, Train Loss: 0.001099317, Val Loss: 0.001801351, Val Accuracy: 96.99%, LR: 0.000100000\n",
      "Epoch 279/2000, Train Loss: 0.001158009, Val Loss: 0.001675529, Val Accuracy: 97.17%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.08%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_259.pth\n",
      "Model saved after epoch 279 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_279.pth \n",
      "\n",
      "Epoch 280/2000, Train Loss: 0.001404380, Val Loss: 0.001863603, Val Accuracy: 96.71%, LR: 0.000100000\n",
      "Epoch 281/2000, Train Loss: 0.001072297, Val Loss: 0.001863222, Val Accuracy: 96.87%, LR: 0.000100000\n",
      "Epoch 282/2000, Train Loss: 0.001236638, Val Loss: 0.001912760, Val Accuracy: 96.83%, LR: 0.000100000\n",
      "Epoch 283/2000, Train Loss: 0.001123053, Val Loss: 0.001820024, Val Accuracy: 97.11%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.09%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_268.pth\n",
      "Model saved after epoch 283 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_283.pth \n",
      "\n",
      "Epoch 284/2000, Train Loss: 0.001116357, Val Loss: 0.002048060, Val Accuracy: 96.40%, LR: 0.000100000\n",
      "Epoch 285/2000, Train Loss: 0.001108932, Val Loss: 0.002077971, Val Accuracy: 97.04%, LR: 0.000100000\n",
      "Epoch 286/2000, Train Loss: 0.001085407, Val Loss: 0.001795182, Val Accuracy: 97.07%, LR: 0.000100000\n",
      "Epoch 287/2000, Train Loss: 0.000984712, Val Loss: 0.001917562, Val Accuracy: 97.05%, LR: 0.000100000\n",
      "Epoch 288/2000, Train Loss: 0.001120163, Val Loss: 0.003576796, Val Accuracy: 94.40%, LR: 0.000100000\n",
      "Epoch 289/2000, Train Loss: 0.001317812, Val Loss: 0.002164333, Val Accuracy: 96.90%, LR: 0.000100000\n",
      "Epoch 290/2000, Train Loss: 0.001106963, Val Loss: 0.001855697, Val Accuracy: 97.14%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.10%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_256.pth\n",
      "Model saved after epoch 290 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_290.pth \n",
      "\n",
      "Epoch 291/2000, Train Loss: 0.001023360, Val Loss: 0.001794154, Val Accuracy: 97.25%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.11%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_283.pth\n",
      "Model saved after epoch 291 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_291.pth \n",
      "\n",
      "Epoch 292/2000, Train Loss: 0.001333349, Val Loss: 0.001795074, Val Accuracy: 97.32%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.14%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_290.pth\n",
      "Model saved after epoch 292 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_292.pth \n",
      "\n",
      "Epoch 293/2000, Train Loss: 0.001151263, Val Loss: 0.001956377, Val Accuracy: 97.14%, LR: 0.000100000\n",
      "Epoch 294/2000, Train Loss: 0.001015210, Val Loss: 0.001845993, Val Accuracy: 97.13%, LR: 0.000100000\n",
      "Epoch 295/2000, Train Loss: 0.001024183, Val Loss: 0.001911967, Val Accuracy: 97.13%, LR: 0.000100000\n",
      "Epoch 296/2000, Train Loss: 0.001022159, Val Loss: 0.002414736, Val Accuracy: 96.62%, LR: 0.000100000\n",
      "Epoch 297/2000, Train Loss: 0.001054056, Val Loss: 0.001911739, Val Accuracy: 97.15%, LR: 0.000100000\n",
      "Epoch 298/2000, Train Loss: 0.001282326, Val Loss: 0.001648835, Val Accuracy: 97.16%, LR: 0.000100000\n",
      "Epoch 299/2000, Train Loss: 0.000958661, Val Loss: 0.002015438, Val Accuracy: 96.85%, LR: 0.000100000\n",
      "Epoch 300/2000, Train Loss: 0.001391125, Val Loss: 0.001988489, Val Accuracy: 96.85%, LR: 0.000100000\n",
      "Epoch 301/2000, Train Loss: 0.001085756, Val Loss: 0.001789477, Val Accuracy: 96.56%, LR: 0.000100000\n",
      "Epoch 302/2000, Train Loss: 0.001041491, Val Loss: 0.001961032, Val Accuracy: 96.91%, LR: 0.000100000\n",
      "Epoch 303/2000, Train Loss: 0.001196778, Val Loss: 0.001822292, Val Accuracy: 96.97%, LR: 0.000100000\n",
      "Epoch 304/2000, Train Loss: 0.000995933, Val Loss: 0.002073329, Val Accuracy: 96.48%, LR: 0.000100000\n",
      "Epoch 305/2000, Train Loss: 0.001073697, Val Loss: 0.002188101, Val Accuracy: 97.14%, LR: 0.000100000\n",
      "Epoch 306/2000, Train Loss: 0.000911891, Val Loss: 0.002124139, Val Accuracy: 97.22%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.17%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_274.pth\n",
      "Model saved after epoch 306 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_306.pth \n",
      "\n",
      "Epoch 307/2000, Train Loss: 0.001030171, Val Loss: 0.002041928, Val Accuracy: 97.05%, LR: 0.000100000\n",
      "Epoch 308/2000, Train Loss: 0.000940950, Val Loss: 0.002033905, Val Accuracy: 97.25%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.17%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_279.pth\n",
      "Model saved after epoch 308 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_308.pth \n",
      "\n",
      "Epoch 309/2000, Train Loss: 0.000986011, Val Loss: 0.002057006, Val Accuracy: 97.13%, LR: 0.000100000\n",
      "Epoch 310/2000, Train Loss: 0.000954905, Val Loss: 0.002202432, Val Accuracy: 96.38%, LR: 0.000100000\n",
      "Epoch 311/2000, Train Loss: 0.001058690, Val Loss: 0.001791063, Val Accuracy: 96.85%, LR: 0.000100000\n",
      "Epoch 312/2000, Train Loss: 0.001346916, Val Loss: 0.001929036, Val Accuracy: 96.44%, LR: 0.000100000\n",
      "Epoch 313/2000, Train Loss: 0.001002402, Val Loss: 0.001877766, Val Accuracy: 97.32%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.18%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_261.pth\n",
      "Model saved after epoch 313 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_313.pth \n",
      "\n",
      "Epoch 314/2000, Train Loss: 0.000983781, Val Loss: 0.001871648, Val Accuracy: 97.22%, LR: 0.000100000\n",
      "Epoch 315/2000, Train Loss: 0.001018781, Val Loss: 0.001857966, Val Accuracy: 97.26%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.22%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_306.pth\n",
      "Model saved after epoch 315 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_315.pth \n",
      "\n",
      "Epoch 316/2000, Train Loss: 0.001001744, Val Loss: 0.001917406, Val Accuracy: 97.33%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.25%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_291.pth\n",
      "Model saved after epoch 316 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_316.pth \n",
      "\n",
      "Epoch 317/2000, Train Loss: 0.001151927, Val Loss: 0.001964639, Val Accuracy: 97.26%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.25%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_308.pth\n",
      "Model saved after epoch 317 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_317.pth \n",
      "\n",
      "Epoch 318/2000, Train Loss: 0.000984776, Val Loss: 0.002188890, Val Accuracy: 97.17%, LR: 0.000100000\n",
      "Epoch 319/2000, Train Loss: 0.000906229, Val Loss: 0.001900572, Val Accuracy: 97.19%, LR: 0.000100000\n",
      "Epoch 320/2000, Train Loss: 0.001073867, Val Loss: 0.002124971, Val Accuracy: 96.19%, LR: 0.000100000\n",
      "Epoch 321/2000, Train Loss: 0.000975913, Val Loss: 0.001912226, Val Accuracy: 97.15%, LR: 0.000100000\n",
      "Epoch 322/2000, Train Loss: 0.001288137, Val Loss: 0.002087414, Val Accuracy: 96.93%, LR: 0.000100000\n",
      "Epoch 323/2000, Train Loss: 0.001010926, Val Loss: 0.002133478, Val Accuracy: 96.97%, LR: 0.000100000\n",
      "Epoch 324/2000, Train Loss: 0.000930035, Val Loss: 0.002001580, Val Accuracy: 97.26%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.26%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_317.pth\n",
      "Model saved after epoch 324 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_324.pth \n",
      "\n",
      "Epoch 325/2000, Train Loss: 0.000894205, Val Loss: 0.002189647, Val Accuracy: 97.15%, LR: 0.000100000\n",
      "Epoch 326/2000, Train Loss: 0.000877889, Val Loss: 0.002119670, Val Accuracy: 97.31%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.26%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_324.pth\n",
      "Model saved after epoch 326 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_326.pth \n",
      "\n",
      "Epoch 327/2000, Train Loss: 0.000857593, Val Loss: 0.002001677, Val Accuracy: 97.36%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.26%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_315.pth\n",
      "Model saved after epoch 327 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_327.pth \n",
      "\n",
      "Epoch 328/2000, Train Loss: 0.001085592, Val Loss: 0.002745277, Val Accuracy: 96.04%, LR: 0.000100000\n",
      "Epoch 329/2000, Train Loss: 0.001314781, Val Loss: 0.001837148, Val Accuracy: 97.46%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.31%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_326.pth\n",
      "Model saved after epoch 329 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_329.pth \n",
      "\n",
      "Epoch 330/2000, Train Loss: 0.000968572, Val Loss: 0.002305839, Val Accuracy: 96.99%, LR: 0.000100000\n",
      "Epoch 331/2000, Train Loss: 0.000866644, Val Loss: 0.002123863, Val Accuracy: 97.20%, LR: 0.000100000\n",
      "Epoch 332/2000, Train Loss: 0.001326444, Val Loss: 0.002685508, Val Accuracy: 94.70%, LR: 0.000100000\n",
      "Epoch 333/2000, Train Loss: 0.001163477, Val Loss: 0.001857578, Val Accuracy: 97.26%, LR: 0.000100000\n",
      "Epoch 334/2000, Train Loss: 0.000849409, Val Loss: 0.002045358, Val Accuracy: 97.27%, LR: 0.000100000\n",
      "Epoch 335/2000, Train Loss: 0.000929312, Val Loss: 0.002184703, Val Accuracy: 96.46%, LR: 0.000100000\n",
      "Epoch 336/2000, Train Loss: 0.000962733, Val Loss: 0.001919087, Val Accuracy: 97.51%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.32%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_292.pth\n",
      "Model saved after epoch 336 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_336.pth \n",
      "\n",
      "Epoch 337/2000, Train Loss: 0.000836037, Val Loss: 0.002358999, Val Accuracy: 97.07%, LR: 0.000100000\n",
      "Epoch 338/2000, Train Loss: 0.001017551, Val Loss: 0.002106050, Val Accuracy: 97.44%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.32%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_313.pth\n",
      "Model saved after epoch 338 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_338.pth \n",
      "\n",
      "Epoch 339/2000, Train Loss: 0.000987981, Val Loss: 0.001996778, Val Accuracy: 97.01%, LR: 0.000100000\n",
      "Epoch 340/2000, Train Loss: 0.000900179, Val Loss: 0.001847076, Val Accuracy: 97.53%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.33%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_316.pth\n",
      "Model saved after epoch 340 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_340.pth \n",
      "\n",
      "Epoch 341/2000, Train Loss: 0.000844680, Val Loss: 0.002203321, Val Accuracy: 96.38%, LR: 0.000100000\n",
      "Epoch 342/2000, Train Loss: 0.001465820, Val Loss: 0.001930909, Val Accuracy: 97.46%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.36%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_327.pth\n",
      "Model saved after epoch 342 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_342.pth \n",
      "\n",
      "Epoch 343/2000, Train Loss: 0.000891515, Val Loss: 0.001688809, Val Accuracy: 97.56%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.44%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_338.pth\n",
      "Model saved after epoch 343 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_343.pth \n",
      "\n",
      "Epoch 344/2000, Train Loss: 0.000835831, Val Loss: 0.001932734, Val Accuracy: 97.42%, LR: 0.000100000\n",
      "Epoch 345/2000, Train Loss: 0.000871288, Val Loss: 0.002117280, Val Accuracy: 96.88%, LR: 0.000100000\n",
      "Epoch 346/2000, Train Loss: 0.000856810, Val Loss: 0.001883210, Val Accuracy: 97.48%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.46%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_342.pth\n",
      "Model saved after epoch 346 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_346.pth \n",
      "\n",
      "Epoch 347/2000, Train Loss: 0.001229524, Val Loss: 0.002004456, Val Accuracy: 96.66%, LR: 0.000100000\n",
      "Epoch 348/2000, Train Loss: 0.000852674, Val Loss: 0.002161558, Val Accuracy: 97.42%, LR: 0.000100000\n",
      "Epoch 349/2000, Train Loss: 0.001028688, Val Loss: 0.002119230, Val Accuracy: 96.66%, LR: 0.000100000\n",
      "Epoch 350/2000, Train Loss: 0.001038077, Val Loss: 0.001947737, Val Accuracy: 97.47%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.46%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_329.pth\n",
      "Model saved after epoch 350 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_350.pth \n",
      "\n",
      "Epoch 351/2000, Train Loss: 0.000881559, Val Loss: 0.001973783, Val Accuracy: 96.48%, LR: 0.000100000\n",
      "Epoch 352/2000, Train Loss: 0.000850192, Val Loss: 0.002152954, Val Accuracy: 96.55%, LR: 0.000100000\n",
      "Epoch 353/2000, Train Loss: 0.000832622, Val Loss: 0.001784364, Val Accuracy: 96.98%, LR: 0.000100000\n",
      "Epoch 354/2000, Train Loss: 0.000905320, Val Loss: 0.002446596, Val Accuracy: 96.07%, LR: 0.000100000\n",
      "Epoch 355/2000, Train Loss: 0.001015825, Val Loss: 0.001928969, Val Accuracy: 97.28%, LR: 0.000100000\n",
      "Epoch 356/2000, Train Loss: 0.000867602, Val Loss: 0.002419803, Val Accuracy: 96.78%, LR: 0.000100000\n",
      "Epoch 357/2000, Train Loss: 0.000834557, Val Loss: 0.002077622, Val Accuracy: 97.29%, LR: 0.000100000\n",
      "Epoch 358/2000, Train Loss: 0.000880075, Val Loss: 0.001779248, Val Accuracy: 97.36%, LR: 0.000100000\n",
      "Epoch 359/2000, Train Loss: 0.000901308, Val Loss: 0.001965941, Val Accuracy: 97.26%, LR: 0.000100000\n",
      "Epoch 360/2000, Train Loss: 0.001080306, Val Loss: 0.002252626, Val Accuracy: 97.04%, LR: 0.000100000\n",
      "Epoch 361/2000, Train Loss: 0.000851875, Val Loss: 0.002013351, Val Accuracy: 96.60%, LR: 0.000100000\n",
      "Epoch 362/2000, Train Loss: 0.000885166, Val Loss: 0.001747032, Val Accuracy: 97.27%, LR: 0.000100000\n",
      "Epoch 363/2000, Train Loss: 0.000809300, Val Loss: 0.002596117, Val Accuracy: 96.30%, LR: 0.000100000\n",
      "Epoch 364/2000, Train Loss: 0.000966565, Val Loss: 0.002122985, Val Accuracy: 97.01%, LR: 0.000100000\n",
      "Epoch 365/2000, Train Loss: 0.000778522, Val Loss: 0.002194020, Val Accuracy: 97.39%, LR: 0.000100000\n",
      "Epoch 366/2000, Train Loss: 0.000772760, Val Loss: 0.002305933, Val Accuracy: 97.27%, LR: 0.000100000\n",
      "Epoch 367/2000, Train Loss: 0.000940185, Val Loss: 0.002265484, Val Accuracy: 96.83%, LR: 0.000100000\n",
      "Epoch 368/2000, Train Loss: 0.000927706, Val Loss: 0.002396017, Val Accuracy: 95.76%, LR: 0.000100000\n",
      "Epoch 369/2000, Train Loss: 0.000924036, Val Loss: 0.002354220, Val Accuracy: 96.93%, LR: 0.000100000\n",
      "Epoch 370/2000, Train Loss: 0.000928653, Val Loss: 0.002050637, Val Accuracy: 97.33%, LR: 0.000100000\n",
      "Epoch 371/2000, Train Loss: 0.000906260, Val Loss: 0.001846661, Val Accuracy: 97.24%, LR: 0.000100000\n",
      "Epoch 372/2000, Train Loss: 0.000828413, Val Loss: 0.002147311, Val Accuracy: 96.90%, LR: 0.000100000\n",
      "Epoch 373/2000, Train Loss: 0.000783949, Val Loss: 0.002145148, Val Accuracy: 97.25%, LR: 0.000100000\n",
      "Epoch 374/2000, Train Loss: 0.000896298, Val Loss: 0.001767689, Val Accuracy: 97.36%, LR: 0.000100000\n",
      "Epoch 375/2000, Train Loss: 0.000838196, Val Loss: 0.001909212, Val Accuracy: 96.52%, LR: 0.000100000\n",
      "Epoch 376/2000, Train Loss: 0.000971268, Val Loss: 0.002126066, Val Accuracy: 97.50%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.47%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_350.pth\n",
      "Model saved after epoch 376 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_376.pth \n",
      "\n",
      "Epoch 377/2000, Train Loss: 0.000758841, Val Loss: 0.002036251, Val Accuracy: 97.34%, LR: 0.000100000\n",
      "Epoch 378/2000, Train Loss: 0.000880798, Val Loss: 0.002171082, Val Accuracy: 97.35%, LR: 0.000100000\n",
      "Epoch 379/2000, Train Loss: 0.000744997, Val Loss: 0.002300712, Val Accuracy: 97.34%, LR: 0.000100000\n",
      "Epoch 380/2000, Train Loss: 0.000843886, Val Loss: 0.002483212, Val Accuracy: 96.71%, LR: 0.000100000\n",
      "Epoch 381/2000, Train Loss: 0.000786209, Val Loss: 0.002138315, Val Accuracy: 97.39%, LR: 0.000100000\n",
      "Epoch 382/2000, Train Loss: 0.000805853, Val Loss: 0.002399515, Val Accuracy: 97.00%, LR: 0.000100000\n",
      "Epoch 383/2000, Train Loss: 0.000924329, Val Loss: 0.002022578, Val Accuracy: 97.45%, LR: 0.000100000\n",
      "Epoch 384/2000, Train Loss: 0.000734408, Val Loss: 0.002336072, Val Accuracy: 96.93%, LR: 0.000100000\n",
      "Epoch 385/2000, Train Loss: 0.000897300, Val Loss: 0.002191045, Val Accuracy: 97.24%, LR: 0.000100000\n",
      "Epoch 386/2000, Train Loss: 0.000986503, Val Loss: 0.002024598, Val Accuracy: 97.44%, LR: 0.000100000\n",
      "Epoch 387/2000, Train Loss: 0.000756613, Val Loss: 0.002165141, Val Accuracy: 97.25%, LR: 0.000100000\n",
      "Epoch 388/2000, Train Loss: 0.000723245, Val Loss: 0.002209600, Val Accuracy: 97.33%, LR: 0.000100000\n",
      "Epoch 389/2000, Train Loss: 0.000955839, Val Loss: 0.002224552, Val Accuracy: 96.16%, LR: 0.000100000\n",
      "Epoch 390/2000, Train Loss: 0.000944078, Val Loss: 0.001848092, Val Accuracy: 97.18%, LR: 0.000100000\n",
      "Epoch 391/2000, Train Loss: 0.000808166, Val Loss: 0.002203473, Val Accuracy: 97.46%, LR: 0.000100000\n",
      "Epoch 392/2000, Train Loss: 0.000927420, Val Loss: 0.002565981, Val Accuracy: 96.76%, LR: 0.000100000\n",
      "Epoch 393/2000, Train Loss: 0.000778672, Val Loss: 0.002033474, Val Accuracy: 97.38%, LR: 0.000100000\n",
      "Epoch 394/2000, Train Loss: 0.000775347, Val Loss: 0.001972031, Val Accuracy: 97.30%, LR: 0.000100000\n",
      "Epoch 395/2000, Train Loss: 0.000835279, Val Loss: 0.002023645, Val Accuracy: 97.20%, LR: 0.000100000\n",
      "Epoch 396/2000, Train Loss: 0.000784867, Val Loss: 0.002011690, Val Accuracy: 97.42%, LR: 0.000100000\n",
      "Epoch 397/2000, Train Loss: 0.000776535, Val Loss: 0.002099456, Val Accuracy: 97.23%, LR: 0.000100000\n",
      "Epoch 398/2000, Train Loss: 0.000819811, Val Loss: 0.001897453, Val Accuracy: 97.44%, LR: 0.000100000\n",
      "Epoch 399/2000, Train Loss: 0.000778750, Val Loss: 0.001751305, Val Accuracy: 97.38%, LR: 0.000100000\n",
      "Epoch 400/2000, Train Loss: 0.000699130, Val Loss: 0.002059887, Val Accuracy: 97.53%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.48%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_346.pth\n",
      "Model saved after epoch 400 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_400.pth \n",
      "\n",
      "Epoch 401/2000, Train Loss: 0.000884356, Val Loss: 0.001875125, Val Accuracy: 96.80%, LR: 0.000100000\n",
      "Epoch 402/2000, Train Loss: 0.000695163, Val Loss: 0.002791418, Val Accuracy: 96.76%, LR: 0.000100000\n",
      "Epoch 403/2000, Train Loss: 0.000841051, Val Loss: 0.001819280, Val Accuracy: 97.44%, LR: 0.000100000\n",
      "Epoch 404/2000, Train Loss: 0.000763602, Val Loss: 0.002356038, Val Accuracy: 96.41%, LR: 0.000100000\n",
      "Epoch 405/2000, Train Loss: 0.000821328, Val Loss: 0.002258749, Val Accuracy: 97.43%, LR: 0.000100000\n",
      "Epoch 406/2000, Train Loss: 0.000736274, Val Loss: 0.002263210, Val Accuracy: 97.49%, LR: 0.000100000\n",
      "Epoch 407/2000, Train Loss: 0.000712507, Val Loss: 0.002112219, Val Accuracy: 97.41%, LR: 0.000100000\n",
      "Epoch 408/2000, Train Loss: 0.000783438, Val Loss: 0.002661715, Val Accuracy: 97.03%, LR: 0.000100000\n",
      "Epoch 409/2000, Train Loss: 0.000694285, Val Loss: 0.002240913, Val Accuracy: 97.44%, LR: 0.000100000\n",
      "Epoch 410/2000, Train Loss: 0.000878112, Val Loss: 0.001822584, Val Accuracy: 96.91%, LR: 0.000100000\n",
      "Epoch 411/2000, Train Loss: 0.000710936, Val Loss: 0.002104144, Val Accuracy: 97.34%, LR: 0.000100000\n",
      "Epoch 412/2000, Train Loss: 0.000682464, Val Loss: 0.002745420, Val Accuracy: 96.92%, LR: 0.000100000\n",
      "Epoch 413/2000, Train Loss: 0.000707156, Val Loss: 0.002224996, Val Accuracy: 97.35%, LR: 0.000100000\n",
      "Epoch 414/2000, Train Loss: 0.000681272, Val Loss: 0.002302308, Val Accuracy: 97.06%, LR: 0.000100000\n",
      "Epoch 415/2000, Train Loss: 0.000767286, Val Loss: 0.002446482, Val Accuracy: 97.24%, LR: 0.000100000\n",
      "Epoch 416/2000, Train Loss: 0.000711939, Val Loss: 0.001884612, Val Accuracy: 96.85%, LR: 0.000100000\n",
      "Epoch 417/2000, Train Loss: 0.000871738, Val Loss: 0.002155542, Val Accuracy: 97.46%, LR: 0.000100000\n",
      "Epoch 418/2000, Train Loss: 0.000653295, Val Loss: 0.002265285, Val Accuracy: 97.30%, LR: 0.000100000\n",
      "Epoch 419/2000, Train Loss: 0.000673151, Val Loss: 0.002018540, Val Accuracy: 97.41%, LR: 0.000100000\n",
      "Epoch 420/2000, Train Loss: 0.000708536, Val Loss: 0.002156782, Val Accuracy: 97.55%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.50%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_376.pth\n",
      "Model saved after epoch 420 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_420.pth \n",
      "\n",
      "Epoch 421/2000, Train Loss: 0.000644358, Val Loss: 0.002110535, Val Accuracy: 97.44%, LR: 0.000100000\n",
      "Epoch 422/2000, Train Loss: 0.000625456, Val Loss: 0.002150558, Val Accuracy: 97.43%, LR: 0.000100000\n",
      "Epoch 423/2000, Train Loss: 0.000902840, Val Loss: 0.001891405, Val Accuracy: 97.26%, LR: 0.000100000\n",
      "Epoch 424/2000, Train Loss: 0.000603983, Val Loss: 0.002248776, Val Accuracy: 97.38%, LR: 0.000100000\n",
      "Epoch 425/2000, Train Loss: 0.001513550, Val Loss: 0.001724269, Val Accuracy: 97.19%, LR: 0.000100000\n",
      "Epoch 426/2000, Train Loss: 0.000794726, Val Loss: 0.002546360, Val Accuracy: 97.36%, LR: 0.000100000\n",
      "Epoch 427/2000, Train Loss: 0.000734888, Val Loss: 0.002159858, Val Accuracy: 97.53%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.51%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_336.pth\n",
      "Model saved after epoch 427 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_427.pth \n",
      "\n",
      "Epoch 428/2000, Train Loss: 0.000614321, Val Loss: 0.002392976, Val Accuracy: 97.39%, LR: 0.000100000\n",
      "Epoch 429/2000, Train Loss: 0.001119642, Val Loss: 0.001866958, Val Accuracy: 97.26%, LR: 0.000100000\n",
      "Epoch 430/2000, Train Loss: 0.000645004, Val Loss: 0.002419173, Val Accuracy: 97.25%, LR: 0.000100000\n",
      "Epoch 431/2000, Train Loss: 0.000601183, Val Loss: 0.002609381, Val Accuracy: 97.41%, LR: 0.000100000\n",
      "Epoch 432/2000, Train Loss: 0.000625293, Val Loss: 0.002451155, Val Accuracy: 97.47%, LR: 0.000100000\n",
      "Epoch 433/2000, Train Loss: 0.000635992, Val Loss: 0.002854914, Val Accuracy: 96.82%, LR: 0.000100000\n",
      "Epoch 434/2000, Train Loss: 0.000901507, Val Loss: 0.001876061, Val Accuracy: 97.39%, LR: 0.000100000\n",
      "Epoch 435/2000, Train Loss: 0.000658612, Val Loss: 0.002365587, Val Accuracy: 97.34%, LR: 0.000100000\n",
      "Epoch 436/2000, Train Loss: 0.000623808, Val Loss: 0.001778122, Val Accuracy: 97.07%, LR: 0.000100000\n",
      "Epoch 437/2000, Train Loss: 0.000666471, Val Loss: 0.002629059, Val Accuracy: 97.23%, LR: 0.000100000\n",
      "Epoch 438/2000, Train Loss: 0.000771814, Val Loss: 0.002895275, Val Accuracy: 96.77%, LR: 0.000100000\n",
      "Epoch 439/2000, Train Loss: 0.000983072, Val Loss: 0.002336833, Val Accuracy: 97.40%, LR: 0.000100000\n",
      "Epoch 440/2000, Train Loss: 0.000694909, Val Loss: 0.002233170, Val Accuracy: 96.50%, LR: 0.000100000\n",
      "Epoch 441/2000, Train Loss: 0.000681417, Val Loss: 0.002406165, Val Accuracy: 97.51%, LR: 0.000100000\n",
      "Epoch 442/2000, Train Loss: 0.000643494, Val Loss: 0.001954367, Val Accuracy: 97.48%, LR: 0.000100000\n",
      "Epoch 443/2000, Train Loss: 0.000686448, Val Loss: 0.001895860, Val Accuracy: 97.43%, LR: 0.000100000\n",
      "Epoch 444/2000, Train Loss: 0.000652051, Val Loss: 0.002242536, Val Accuracy: 97.53%, LR: 0.000100000\n",
      "Epoch 445/2000, Train Loss: 0.000592852, Val Loss: 0.002484027, Val Accuracy: 97.48%, LR: 0.000100000\n",
      "Epoch 446/2000, Train Loss: 0.000743188, Val Loss: 0.002097963, Val Accuracy: 97.54%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.53%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_400.pth\n",
      "Model saved after epoch 446 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_446.pth \n",
      "\n",
      "Epoch 447/2000, Train Loss: 0.000609455, Val Loss: 0.002053143, Val Accuracy: 97.59%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.53%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_427.pth\n",
      "Model saved after epoch 447 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_447.pth \n",
      "\n",
      "Epoch 448/2000, Train Loss: 0.000585498, Val Loss: 0.002402188, Val Accuracy: 97.53%, LR: 0.000100000\n",
      "Epoch 449/2000, Train Loss: 0.000695872, Val Loss: 0.002656525, Val Accuracy: 97.06%, LR: 0.000100000\n",
      "Epoch 450/2000, Train Loss: 0.000715031, Val Loss: 0.002434765, Val Accuracy: 97.40%, LR: 0.000100000\n",
      "Epoch 451/2000, Train Loss: 0.000856110, Val Loss: 0.001953679, Val Accuracy: 97.49%, LR: 0.000100000\n",
      "Epoch 452/2000, Train Loss: 0.000610301, Val Loss: 0.002340726, Val Accuracy: 97.50%, LR: 0.000100000\n",
      "Epoch 453/2000, Train Loss: 0.000694798, Val Loss: 0.002194112, Val Accuracy: 97.42%, LR: 0.000100000\n",
      "Epoch 454/2000, Train Loss: 0.000575960, Val Loss: 0.002132183, Val Accuracy: 97.64%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.53%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_340.pth\n",
      "Model saved after epoch 454 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_454.pth \n",
      "\n",
      "Epoch 455/2000, Train Loss: 0.000647340, Val Loss: 0.002280320, Val Accuracy: 97.39%, LR: 0.000100000\n",
      "Epoch 456/2000, Train Loss: 0.000637869, Val Loss: 0.002428258, Val Accuracy: 97.62%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.54%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_446.pth\n",
      "Model saved after epoch 456 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_456.pth \n",
      "\n",
      "Epoch 457/2000, Train Loss: 0.000689986, Val Loss: 0.002351765, Val Accuracy: 97.40%, LR: 0.000100000\n",
      "Epoch 458/2000, Train Loss: 0.000732146, Val Loss: 0.001847601, Val Accuracy: 97.37%, LR: 0.000100000\n",
      "Epoch 459/2000, Train Loss: 0.000613399, Val Loss: 0.001992295, Val Accuracy: 97.66%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.55%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_420.pth\n",
      "Model saved after epoch 459 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_459.pth \n",
      "\n",
      "Epoch 460/2000, Train Loss: 0.000601198, Val Loss: 0.002172434, Val Accuracy: 97.61%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.56%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_343.pth\n",
      "Model saved after epoch 460 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_460.pth \n",
      "\n",
      "Epoch 461/2000, Train Loss: 0.000607969, Val Loss: 0.002358729, Val Accuracy: 97.52%, LR: 0.000100000\n",
      "Epoch 462/2000, Train Loss: 0.000576410, Val Loss: 0.002480085, Val Accuracy: 97.60%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.59%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_447.pth\n",
      "Model saved after epoch 462 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_462.pth \n",
      "\n",
      "Epoch 463/2000, Train Loss: 0.000609186, Val Loss: 0.001914517, Val Accuracy: 97.58%, LR: 0.000100000\n",
      "Epoch 464/2000, Train Loss: 0.000561625, Val Loss: 0.001684375, Val Accuracy: 97.66%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.60%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_462.pth\n",
      "Model saved after epoch 464 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_464.pth \n",
      "\n",
      "Epoch 465/2000, Train Loss: 0.000567185, Val Loss: 0.002349863, Val Accuracy: 97.53%, LR: 0.000100000\n",
      "Epoch 466/2000, Train Loss: 0.000690406, Val Loss: 0.002010421, Val Accuracy: 97.56%, LR: 0.000100000\n",
      "Epoch 467/2000, Train Loss: 0.000878179, Val Loss: 0.002839161, Val Accuracy: 96.89%, LR: 0.000100000\n",
      "Epoch 468/2000, Train Loss: 0.000699398, Val Loss: 0.001622711, Val Accuracy: 97.56%, LR: 0.000100000\n",
      "Epoch 469/2000, Train Loss: 0.000524146, Val Loss: 0.002099988, Val Accuracy: 97.66%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_460.pth\n",
      "Model saved after epoch 469 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_469.pth \n",
      "\n",
      "Epoch 470/2000, Train Loss: 0.000529937, Val Loss: 0.002729944, Val Accuracy: 97.47%, LR: 0.000100000\n",
      "Epoch 471/2000, Train Loss: 0.000644280, Val Loss: 0.003060895, Val Accuracy: 96.79%, LR: 0.000100000\n",
      "Epoch 472/2000, Train Loss: 0.000687968, Val Loss: 0.001996778, Val Accuracy: 97.51%, LR: 0.000100000\n",
      "Epoch 473/2000, Train Loss: 0.000844734, Val Loss: 0.002112309, Val Accuracy: 97.46%, LR: 0.000100000\n",
      "Epoch 474/2000, Train Loss: 0.000568370, Val Loss: 0.002492581, Val Accuracy: 97.42%, LR: 0.000100000\n",
      "Epoch 475/2000, Train Loss: 0.000499200, Val Loss: 0.002038538, Val Accuracy: 97.63%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.62%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_456.pth\n",
      "Model saved after epoch 475 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_475.pth \n",
      "\n",
      "Epoch 476/2000, Train Loss: 0.000661860, Val Loss: 0.002283275, Val Accuracy: 97.43%, LR: 0.000100000\n",
      "Epoch 477/2000, Train Loss: 0.001091647, Val Loss: 0.002903557, Val Accuracy: 95.59%, LR: 0.000100000\n",
      "Epoch 478/2000, Train Loss: 0.000757338, Val Loss: 0.002174391, Val Accuracy: 97.48%, LR: 0.000100000\n",
      "Epoch 479/2000, Train Loss: 0.000542571, Val Loss: 0.002386872, Val Accuracy: 97.41%, LR: 0.000100000\n",
      "Epoch 480/2000, Train Loss: 0.000541439, Val Loss: 0.002169935, Val Accuracy: 97.58%, LR: 0.000100000\n",
      "Epoch 481/2000, Train Loss: 0.000688795, Val Loss: 0.002294350, Val Accuracy: 97.64%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.63%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_475.pth\n",
      "Model saved after epoch 481 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_481.pth \n",
      "\n",
      "Epoch 482/2000, Train Loss: 0.000504439, Val Loss: 0.002524593, Val Accuracy: 97.51%, LR: 0.000100000\n",
      "Epoch 483/2000, Train Loss: 0.000861735, Val Loss: 0.001607212, Val Accuracy: 97.61%, LR: 0.000100000\n",
      "Epoch 484/2000, Train Loss: 0.000586252, Val Loss: 0.002175892, Val Accuracy: 97.69%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.64%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_481.pth\n",
      "Model saved after epoch 484 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_484.pth \n",
      "\n",
      "Epoch 485/2000, Train Loss: 0.000564683, Val Loss: 0.002354246, Val Accuracy: 97.59%, LR: 0.000100000\n",
      "Epoch 486/2000, Train Loss: 0.000619064, Val Loss: 0.002379007, Val Accuracy: 97.51%, LR: 0.000100000\n",
      "Epoch 487/2000, Train Loss: 0.000500349, Val Loss: 0.002428847, Val Accuracy: 97.37%, LR: 0.000100000\n",
      "Epoch 488/2000, Train Loss: 0.000500149, Val Loss: 0.002620976, Val Accuracy: 97.33%, LR: 0.000100000\n",
      "Epoch 489/2000, Train Loss: 0.000543788, Val Loss: 0.002551815, Val Accuracy: 97.40%, LR: 0.000100000\n",
      "Epoch 490/2000, Train Loss: 0.000908448, Val Loss: 0.002210231, Val Accuracy: 96.95%, LR: 0.000100000\n",
      "Epoch 491/2000, Train Loss: 0.000683303, Val Loss: 0.002189584, Val Accuracy: 97.69%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.64%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_454.pth\n",
      "Model saved after epoch 491 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_491.pth \n",
      "\n",
      "Epoch 492/2000, Train Loss: 0.000568574, Val Loss: 0.003951201, Val Accuracy: 95.50%, LR: 0.000100000\n",
      "Epoch 493/2000, Train Loss: 0.000725638, Val Loss: 0.002375753, Val Accuracy: 97.50%, LR: 0.000100000\n",
      "Epoch 494/2000, Train Loss: 0.000466776, Val Loss: 0.002446578, Val Accuracy: 97.67%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.66%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_464.pth\n",
      "Model saved after epoch 494 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_494.pth \n",
      "\n",
      "Epoch 495/2000, Train Loss: 0.000532376, Val Loss: 0.002562963, Val Accuracy: 97.60%, LR: 0.000100000\n",
      "Epoch 496/2000, Train Loss: 0.000566500, Val Loss: 0.002068059, Val Accuracy: 97.74%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.66%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_459.pth\n",
      "Model saved after epoch 496 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_496.pth \n",
      "\n",
      "Epoch 497/2000, Train Loss: 0.000504583, Val Loss: 0.003212541, Val Accuracy: 96.88%, LR: 0.000100000\n",
      "Epoch 498/2000, Train Loss: 0.000877795, Val Loss: 0.002292296, Val Accuracy: 97.58%, LR: 0.000100000\n",
      "Epoch 499/2000, Train Loss: 0.000470038, Val Loss: 0.002814517, Val Accuracy: 97.44%, LR: 0.000100000\n",
      "Epoch 500/2000, Train Loss: 0.000745025, Val Loss: 0.002066637, Val Accuracy: 97.73%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.66%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_469.pth\n",
      "Model saved after epoch 500 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_500.pth \n",
      "\n",
      "Epoch 501/2000, Train Loss: 0.000539357, Val Loss: 0.002018852, Val Accuracy: 97.53%, LR: 0.000100000\n",
      "Epoch 502/2000, Train Loss: 0.000485212, Val Loss: 0.002647457, Val Accuracy: 97.44%, LR: 0.000100000\n",
      "Epoch 503/2000, Train Loss: 0.000737642, Val Loss: 0.001874188, Val Accuracy: 97.26%, LR: 0.000100000\n",
      "Epoch 504/2000, Train Loss: 0.000924419, Val Loss: 0.003092441, Val Accuracy: 96.66%, LR: 0.000100000\n",
      "Epoch 505/2000, Train Loss: 0.000545124, Val Loss: 0.002392722, Val Accuracy: 97.49%, LR: 0.000100000\n",
      "Epoch 506/2000, Train Loss: 0.000472438, Val Loss: 0.002193791, Val Accuracy: 97.67%, LR: 0.000100000\n",
      "Epoch 507/2000, Train Loss: 0.000502796, Val Loss: 0.002283320, Val Accuracy: 97.41%, LR: 0.000100000\n",
      "Epoch 508/2000, Train Loss: 0.000518699, Val Loss: 0.002481003, Val Accuracy: 97.67%, LR: 0.000100000\n",
      "Epoch 509/2000, Train Loss: 0.000511315, Val Loss: 0.001762965, Val Accuracy: 97.69%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.67%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_494.pth\n",
      "Model saved after epoch 509 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_509.pth \n",
      "\n",
      "Epoch 510/2000, Train Loss: 0.000440109, Val Loss: 0.001984309, Val Accuracy: 97.74%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.69%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_509.pth\n",
      "Model saved after epoch 510 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_510.pth \n",
      "\n",
      "Epoch 511/2000, Train Loss: 0.000427554, Val Loss: 0.002571815, Val Accuracy: 97.65%, LR: 0.000100000\n",
      "Epoch 512/2000, Train Loss: 0.000557098, Val Loss: 0.002928329, Val Accuracy: 97.13%, LR: 0.000100000\n",
      "Epoch 513/2000, Train Loss: 0.000486379, Val Loss: 0.002324234, Val Accuracy: 97.75%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.69%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_491.pth\n",
      "Model saved after epoch 513 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_513.pth \n",
      "\n",
      "Epoch 514/2000, Train Loss: 0.000518620, Val Loss: 0.002030618, Val Accuracy: 97.64%, LR: 0.000100000\n",
      "Epoch 515/2000, Train Loss: 0.000480208, Val Loss: 0.002552091, Val Accuracy: 97.67%, LR: 0.000100000\n",
      "Epoch 516/2000, Train Loss: 0.000765996, Val Loss: 0.002027215, Val Accuracy: 97.38%, LR: 0.000100000\n",
      "Epoch 517/2000, Train Loss: 0.000482035, Val Loss: 0.002760454, Val Accuracy: 97.56%, LR: 0.000100000\n",
      "Epoch 518/2000, Train Loss: 0.000706704, Val Loss: 0.002418547, Val Accuracy: 97.70%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.69%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_484.pth\n",
      "Model saved after epoch 518 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_518.pth \n",
      "\n",
      "Epoch 519/2000, Train Loss: 0.000450732, Val Loss: 0.002427075, Val Accuracy: 97.71%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.70%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_518.pth\n",
      "Model saved after epoch 519 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_519.pth \n",
      "\n",
      "Epoch 520/2000, Train Loss: 0.000425173, Val Loss: 0.002398100, Val Accuracy: 97.29%, LR: 0.000100000\n",
      "Epoch 521/2000, Train Loss: 0.000667606, Val Loss: 0.001805822, Val Accuracy: 96.61%, LR: 0.000100000\n",
      "Epoch 522/2000, Train Loss: 0.000701035, Val Loss: 0.002145182, Val Accuracy: 97.72%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.71%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_519.pth\n",
      "Model saved after epoch 522 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_522.pth \n",
      "\n",
      "Epoch 523/2000, Train Loss: 0.000435183, Val Loss: 0.002676500, Val Accuracy: 97.54%, LR: 0.000100000\n",
      "Epoch 524/2000, Train Loss: 0.000511583, Val Loss: 0.002653555, Val Accuracy: 97.70%, LR: 0.000100000\n",
      "Epoch 525/2000, Train Loss: 0.000490315, Val Loss: 0.002551817, Val Accuracy: 97.60%, LR: 0.000100000\n",
      "Epoch 526/2000, Train Loss: 0.000417137, Val Loss: 0.002499948, Val Accuracy: 97.73%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.72%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_522.pth\n",
      "Model saved after epoch 526 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_526.pth \n",
      "\n",
      "Epoch 527/2000, Train Loss: 0.000409549, Val Loss: 0.002941209, Val Accuracy: 97.48%, LR: 0.000100000\n",
      "Epoch 528/2000, Train Loss: 0.000562292, Val Loss: 0.002619998, Val Accuracy: 97.75%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.73%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_500.pth\n",
      "Model saved after epoch 528 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_528.pth \n",
      "\n",
      "Epoch 529/2000, Train Loss: 0.000407715, Val Loss: 0.002564253, Val Accuracy: 97.60%, LR: 0.000100000\n",
      "Epoch 530/2000, Train Loss: 0.000625854, Val Loss: 0.002275740, Val Accuracy: 97.48%, LR: 0.000100000\n",
      "Epoch 531/2000, Train Loss: 0.000434793, Val Loss: 0.002572849, Val Accuracy: 97.65%, LR: 0.000100000\n",
      "Epoch 532/2000, Train Loss: 0.000601466, Val Loss: 0.002329279, Val Accuracy: 97.59%, LR: 0.000100000\n",
      "Epoch 533/2000, Train Loss: 0.000405287, Val Loss: 0.002535255, Val Accuracy: 97.78%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.73%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_526.pth\n",
      "Model saved after epoch 533 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_533.pth \n",
      "\n",
      "Epoch 534/2000, Train Loss: 0.000421737, Val Loss: 0.002098190, Val Accuracy: 97.79%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.74%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_496.pth\n",
      "Model saved after epoch 534 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_534.pth \n",
      "\n",
      "Epoch 535/2000, Train Loss: 0.000440414, Val Loss: 0.002350598, Val Accuracy: 97.72%, LR: 0.000100000\n",
      "Epoch 536/2000, Train Loss: 0.000499827, Val Loss: 0.002839615, Val Accuracy: 97.44%, LR: 0.000100000\n",
      "Epoch 537/2000, Train Loss: 0.001087262, Val Loss: 0.002561044, Val Accuracy: 97.47%, LR: 0.000100000\n",
      "Epoch 538/2000, Train Loss: 0.000455391, Val Loss: 0.002229784, Val Accuracy: 97.69%, LR: 0.000100000\n",
      "Epoch 539/2000, Train Loss: 0.000454426, Val Loss: 0.002803602, Val Accuracy: 97.49%, LR: 0.000100000\n",
      "Epoch 540/2000, Train Loss: 0.000391504, Val Loss: 0.002483065, Val Accuracy: 97.75%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.74%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_510.pth\n",
      "Model saved after epoch 540 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_540.pth \n",
      "\n",
      "Epoch 541/2000, Train Loss: 0.000587672, Val Loss: 0.002306664, Val Accuracy: 97.70%, LR: 0.000100000\n",
      "Epoch 542/2000, Train Loss: 0.000423866, Val Loss: 0.002258572, Val Accuracy: 97.78%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.75%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_513.pth\n",
      "Model saved after epoch 542 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_542.pth \n",
      "\n",
      "Epoch 543/2000, Train Loss: 0.000401715, Val Loss: 0.002591808, Val Accuracy: 97.75%, LR: 0.000100000\n",
      "Epoch 544/2000, Train Loss: 0.000531750, Val Loss: 0.002501585, Val Accuracy: 97.75%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.75%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_540.pth\n",
      "Model saved after epoch 544 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_544.pth \n",
      "\n",
      "Epoch 545/2000, Train Loss: 0.000393388, Val Loss: 0.002604334, Val Accuracy: 97.75%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.75%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_544.pth\n",
      "Model saved after epoch 545 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_545.pth \n",
      "\n",
      "Epoch 546/2000, Train Loss: 0.000467204, Val Loss: 0.003033723, Val Accuracy: 97.52%, LR: 0.000100000\n",
      "Epoch 547/2000, Train Loss: 0.000392618, Val Loss: 0.002838228, Val Accuracy: 97.74%, LR: 0.000100000\n",
      "Epoch 548/2000, Train Loss: 0.000477466, Val Loss: 0.002428567, Val Accuracy: 97.60%, LR: 0.000100000\n",
      "Epoch 549/2000, Train Loss: 0.000417656, Val Loss: 0.002716450, Val Accuracy: 97.54%, LR: 0.000100000\n",
      "Epoch 550/2000, Train Loss: 0.000732849, Val Loss: 0.002509585, Val Accuracy: 97.80%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.75%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_545.pth\n",
      "Model saved after epoch 550 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_550.pth \n",
      "\n",
      "Epoch 551/2000, Train Loss: 0.000414430, Val Loss: 0.001741914, Val Accuracy: 97.79%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.75%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_528.pth\n",
      "Model saved after epoch 551 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_551.pth \n",
      "\n",
      "Epoch 552/2000, Train Loss: 0.000361403, Val Loss: 0.002613972, Val Accuracy: 97.66%, LR: 0.000100000\n",
      "Epoch 553/2000, Train Loss: 0.000438863, Val Loss: 0.002077447, Val Accuracy: 97.70%, LR: 0.000100000\n",
      "Epoch 554/2000, Train Loss: 0.000457433, Val Loss: 0.002418284, Val Accuracy: 97.63%, LR: 0.000100000\n",
      "Epoch 555/2000, Train Loss: 0.000399918, Val Loss: 0.002961007, Val Accuracy: 97.66%, LR: 0.000100000\n",
      "Epoch 556/2000, Train Loss: 0.000434049, Val Loss: 0.004089280, Val Accuracy: 96.45%, LR: 0.000100000\n",
      "Epoch 557/2000, Train Loss: 0.000526444, Val Loss: 0.002680430, Val Accuracy: 97.78%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.78%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_542.pth\n",
      "Model saved after epoch 557 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_557.pth \n",
      "\n",
      "Epoch 558/2000, Train Loss: 0.000377020, Val Loss: 0.002612953, Val Accuracy: 97.72%, LR: 0.000100000\n",
      "Epoch 559/2000, Train Loss: 0.000358256, Val Loss: 0.002266797, Val Accuracy: 97.78%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.78%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_533.pth\n",
      "Model saved after epoch 559 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_559.pth \n",
      "\n",
      "Epoch 560/2000, Train Loss: 0.001381859, Val Loss: 0.001578849, Val Accuracy: 97.66%, LR: 0.000100000\n",
      "Epoch 561/2000, Train Loss: 0.000393523, Val Loss: 0.002256343, Val Accuracy: 97.81%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.78%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_557.pth\n",
      "Model saved after epoch 561 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_561.pth \n",
      "\n",
      "Epoch 562/2000, Train Loss: 0.000482750, Val Loss: 0.002363185, Val Accuracy: 97.78%, LR: 0.000100000\n",
      "Epoch 563/2000, Train Loss: 0.000959447, Val Loss: 0.002070705, Val Accuracy: 97.76%, LR: 0.000100000\n",
      "Epoch 564/2000, Train Loss: 0.000388404, Val Loss: 0.002502214, Val Accuracy: 97.85%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.78%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_559.pth\n",
      "Model saved after epoch 564 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_564.pth \n",
      "\n",
      "Epoch 565/2000, Train Loss: 0.000357095, Val Loss: 0.002475448, Val Accuracy: 97.56%, LR: 0.000100000\n",
      "Epoch 566/2000, Train Loss: 0.000382585, Val Loss: 0.002206599, Val Accuracy: 97.85%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.79%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_534.pth\n",
      "Model saved after epoch 566 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_566.pth \n",
      "\n",
      "Epoch 567/2000, Train Loss: 0.000368825, Val Loss: 0.002398951, Val Accuracy: 97.84%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.79%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_551.pth\n",
      "Model saved after epoch 567 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_567.pth \n",
      "\n",
      "Epoch 568/2000, Train Loss: 0.000390140, Val Loss: 0.002331305, Val Accuracy: 97.61%, LR: 0.000100000\n",
      "Epoch 569/2000, Train Loss: 0.000380473, Val Loss: 0.002515362, Val Accuracy: 97.71%, LR: 0.000100000\n",
      "Epoch 570/2000, Train Loss: 0.000342917, Val Loss: 0.002535630, Val Accuracy: 97.84%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.80%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_550.pth\n",
      "Model saved after epoch 570 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_570.pth \n",
      "\n",
      "Epoch 571/2000, Train Loss: 0.000384445, Val Loss: 0.002967122, Val Accuracy: 97.57%, LR: 0.000100000\n",
      "Epoch 572/2000, Train Loss: 0.000444077, Val Loss: 0.001923148, Val Accuracy: 97.78%, LR: 0.000100000\n",
      "Epoch 573/2000, Train Loss: 0.000359024, Val Loss: 0.002711102, Val Accuracy: 97.65%, LR: 0.000100000\n",
      "Epoch 574/2000, Train Loss: 0.000615660, Val Loss: 0.002537751, Val Accuracy: 97.58%, LR: 0.000100000\n",
      "Epoch 575/2000, Train Loss: 0.000433568, Val Loss: 0.002689866, Val Accuracy: 97.03%, LR: 0.000100000\n",
      "Epoch 576/2000, Train Loss: 0.000451815, Val Loss: 0.002679229, Val Accuracy: 97.56%, LR: 0.000100000\n",
      "Epoch 577/2000, Train Loss: 0.000385028, Val Loss: 0.002775348, Val Accuracy: 97.62%, LR: 0.000100000\n",
      "Epoch 578/2000, Train Loss: 0.000449779, Val Loss: 0.002584576, Val Accuracy: 97.72%, LR: 0.000100000\n",
      "Epoch 579/2000, Train Loss: 0.000576787, Val Loss: 0.003884460, Val Accuracy: 96.39%, LR: 0.000100000\n",
      "Epoch 580/2000, Train Loss: 0.000784774, Val Loss: 0.002573041, Val Accuracy: 97.85%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.81%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_561.pth\n",
      "Model saved after epoch 580 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_580.pth \n",
      "\n",
      "Epoch 581/2000, Train Loss: 0.000344176, Val Loss: 0.002528761, Val Accuracy: 97.78%, LR: 0.000100000\n",
      "Epoch 582/2000, Train Loss: 0.000585191, Val Loss: 0.002317336, Val Accuracy: 97.55%, LR: 0.000100000\n",
      "Epoch 583/2000, Train Loss: 0.000379611, Val Loss: 0.002202743, Val Accuracy: 97.89%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.84%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_570.pth\n",
      "Model saved after epoch 583 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_583.pth \n",
      "\n",
      "Epoch 584/2000, Train Loss: 0.000361682, Val Loss: 0.003025126, Val Accuracy: 97.46%, LR: 0.000100000\n",
      "Epoch 585/2000, Train Loss: 0.000498389, Val Loss: 0.002568803, Val Accuracy: 97.73%, LR: 0.000100000\n",
      "Epoch 586/2000, Train Loss: 0.000350864, Val Loss: 0.002477732, Val Accuracy: 97.59%, LR: 0.000100000\n",
      "Epoch 587/2000, Train Loss: 0.000518571, Val Loss: 0.002467985, Val Accuracy: 97.60%, LR: 0.000100000\n",
      "Epoch 588/2000, Train Loss: 0.000396182, Val Loss: 0.002412150, Val Accuracy: 97.86%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.84%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_567.pth\n",
      "Model saved after epoch 588 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_588.pth \n",
      "\n",
      "Epoch 589/2000, Train Loss: 0.000406443, Val Loss: 0.002179552, Val Accuracy: 97.83%, LR: 0.000100000\n",
      "Epoch 590/2000, Train Loss: 0.000862135, Val Loss: 0.002236372, Val Accuracy: 96.69%, LR: 0.000100000\n",
      "Epoch 591/2000, Train Loss: 0.000484604, Val Loss: 0.002538397, Val Accuracy: 97.79%, LR: 0.000100000\n",
      "Epoch 592/2000, Train Loss: 0.000355740, Val Loss: 0.002414472, Val Accuracy: 97.84%, LR: 0.000100000\n",
      "Epoch 593/2000, Train Loss: 0.000355646, Val Loss: 0.002417714, Val Accuracy: 97.88%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.85%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_566.pth\n",
      "Model saved after epoch 593 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_593.pth \n",
      "\n",
      "Epoch 594/2000, Train Loss: 0.000323749, Val Loss: 0.002579026, Val Accuracy: 97.88%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.85%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_580.pth\n",
      "Model saved after epoch 594 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_594.pth \n",
      "\n",
      "Epoch 595/2000, Train Loss: 0.000380324, Val Loss: 0.002421757, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.85%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_564.pth\n",
      "Model saved after epoch 595 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_595.pth \n",
      "\n",
      "Epoch 596/2000, Train Loss: 0.000331541, Val Loss: 0.002053741, Val Accuracy: 97.09%, LR: 0.000100000\n",
      "Epoch 597/2000, Train Loss: 0.001196326, Val Loss: 0.002028220, Val Accuracy: 97.62%, LR: 0.000100000\n",
      "Epoch 598/2000, Train Loss: 0.000369620, Val Loss: 0.002286207, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.86%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_588.pth\n",
      "Model saved after epoch 598 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_598.pth \n",
      "\n",
      "Epoch 599/2000, Train Loss: 0.000376796, Val Loss: 0.002466878, Val Accuracy: 97.43%, LR: 0.000100000\n",
      "Epoch 600/2000, Train Loss: 0.000382577, Val Loss: 0.002441626, Val Accuracy: 97.85%, LR: 0.000100000\n",
      "Epoch 601/2000, Train Loss: 0.000318848, Val Loss: 0.002229644, Val Accuracy: 97.79%, LR: 0.000100000\n",
      "Epoch 602/2000, Train Loss: 0.000314181, Val Loss: 0.002712603, Val Accuracy: 97.87%, LR: 0.000100000\n",
      "Epoch 603/2000, Train Loss: 0.000355713, Val Loss: 0.002490676, Val Accuracy: 97.77%, LR: 0.000100000\n",
      "Epoch 604/2000, Train Loss: 0.000299672, Val Loss: 0.002560425, Val Accuracy: 97.82%, LR: 0.000100000\n",
      "Epoch 605/2000, Train Loss: 0.000402387, Val Loss: 0.001995778, Val Accuracy: 97.46%, LR: 0.000100000\n",
      "Epoch 606/2000, Train Loss: 0.000419179, Val Loss: 0.002159538, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.88%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_594.pth\n",
      "Model saved after epoch 606 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_606.pth \n",
      "\n",
      "Epoch 607/2000, Train Loss: 0.000974720, Val Loss: 0.002117122, Val Accuracy: 97.82%, LR: 0.000100000\n",
      "Epoch 608/2000, Train Loss: 0.000340578, Val Loss: 0.002219793, Val Accuracy: 97.88%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.88%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_593.pth\n",
      "Model saved after epoch 608 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_608.pth \n",
      "\n",
      "Epoch 609/2000, Train Loss: 0.000322147, Val Loss: 0.002687097, Val Accuracy: 97.70%, LR: 0.000100000\n",
      "Epoch 610/2000, Train Loss: 0.000318536, Val Loss: 0.003135191, Val Accuracy: 97.56%, LR: 0.000100000\n",
      "Epoch 611/2000, Train Loss: 0.000316124, Val Loss: 0.002422863, Val Accuracy: 97.88%, LR: 0.000100000\n",
      "Epoch 612/2000, Train Loss: 0.000313987, Val Loss: 0.002717206, Val Accuracy: 97.89%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.88%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_608.pth\n",
      "Model saved after epoch 612 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_612.pth \n",
      "\n",
      "Epoch 613/2000, Train Loss: 0.000309442, Val Loss: 0.002414180, Val Accuracy: 97.92%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.89%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_612.pth\n",
      "Model saved after epoch 613 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_613.pth \n",
      "\n",
      "Epoch 614/2000, Train Loss: 0.000351502, Val Loss: 0.002456232, Val Accuracy: 97.92%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.89%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_583.pth\n",
      "Model saved after epoch 614 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_614.pth \n",
      "\n",
      "Epoch 615/2000, Train Loss: 0.000313532, Val Loss: 0.002494058, Val Accuracy: 97.66%, LR: 0.000100000\n",
      "Epoch 616/2000, Train Loss: 0.000489880, Val Loss: 0.002757419, Val Accuracy: 97.36%, LR: 0.000100000\n",
      "Epoch 617/2000, Train Loss: 0.001121553, Val Loss: 0.001935579, Val Accuracy: 97.64%, LR: 0.000100000\n",
      "Epoch 618/2000, Train Loss: 0.000354858, Val Loss: 0.002306079, Val Accuracy: 97.94%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.91%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_606.pth\n",
      "Model saved after epoch 618 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_618.pth \n",
      "\n",
      "Epoch 619/2000, Train Loss: 0.000310686, Val Loss: 0.002573666, Val Accuracy: 97.84%, LR: 0.000100000\n",
      "Epoch 620/2000, Train Loss: 0.000314763, Val Loss: 0.002679430, Val Accuracy: 97.87%, LR: 0.000100000\n",
      "Epoch 621/2000, Train Loss: 0.000313928, Val Loss: 0.002835877, Val Accuracy: 97.83%, LR: 0.000100000\n",
      "Epoch 622/2000, Train Loss: 0.000325702, Val Loss: 0.002433997, Val Accuracy: 97.87%, LR: 0.000100000\n",
      "Epoch 623/2000, Train Loss: 0.000326299, Val Loss: 0.002405905, Val Accuracy: 97.93%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.91%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_595.pth\n",
      "Model saved after epoch 623 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_623.pth \n",
      "\n",
      "Epoch 624/2000, Train Loss: 0.000296788, Val Loss: 0.002961838, Val Accuracy: 97.68%, LR: 0.000100000\n",
      "Epoch 625/2000, Train Loss: 0.000382955, Val Loss: 0.002454827, Val Accuracy: 96.61%, LR: 0.000100000\n",
      "Epoch 626/2000, Train Loss: 0.000407027, Val Loss: 0.002696058, Val Accuracy: 97.92%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.91%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_598.pth\n",
      "Model saved after epoch 626 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_626.pth \n",
      "\n",
      "Epoch 627/2000, Train Loss: 0.000580239, Val Loss: 0.001878003, Val Accuracy: 97.66%, LR: 0.000100000\n",
      "Epoch 628/2000, Train Loss: 0.000413693, Val Loss: 0.001838036, Val Accuracy: 97.78%, LR: 0.000100000\n",
      "Epoch 629/2000, Train Loss: 0.000422058, Val Loss: 0.002644451, Val Accuracy: 97.70%, LR: 0.000100000\n",
      "Epoch 630/2000, Train Loss: 0.000300755, Val Loss: 0.002520018, Val Accuracy: 97.86%, LR: 0.000100000\n",
      "Epoch 631/2000, Train Loss: 0.000299793, Val Loss: 0.002692119, Val Accuracy: 97.84%, LR: 0.000100000\n",
      "Epoch 632/2000, Train Loss: 0.000288673, Val Loss: 0.002067013, Val Accuracy: 97.69%, LR: 0.000100000\n",
      "Epoch 633/2000, Train Loss: 0.000424949, Val Loss: 0.001943375, Val Accuracy: 97.11%, LR: 0.000100000\n",
      "Epoch 634/2000, Train Loss: 0.000354922, Val Loss: 0.002727438, Val Accuracy: 97.87%, LR: 0.000100000\n",
      "Epoch 635/2000, Train Loss: 0.000354374, Val Loss: 0.003535009, Val Accuracy: 97.05%, LR: 0.000100000\n",
      "Epoch 636/2000, Train Loss: 0.000468756, Val Loss: 0.002018959, Val Accuracy: 97.81%, LR: 0.000100000\n",
      "Epoch 637/2000, Train Loss: 0.000386521, Val Loss: 0.002730803, Val Accuracy: 97.64%, LR: 0.000100000\n",
      "Epoch 638/2000, Train Loss: 0.000279117, Val Loss: 0.002585394, Val Accuracy: 97.83%, LR: 0.000100000\n",
      "Epoch 639/2000, Train Loss: 0.000487564, Val Loss: 0.002504274, Val Accuracy: 97.70%, LR: 0.000100000\n",
      "Epoch 640/2000, Train Loss: 0.000314314, Val Loss: 0.002635687, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.92%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_613.pth\n",
      "Model saved after epoch 640 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_640.pth \n",
      "\n",
      "Epoch 641/2000, Train Loss: 0.000292442, Val Loss: 0.003025391, Val Accuracy: 97.61%, LR: 0.000100000\n",
      "Epoch 642/2000, Train Loss: 0.000732632, Val Loss: 0.002710909, Val Accuracy: 97.85%, LR: 0.000100000\n",
      "Epoch 643/2000, Train Loss: 0.000302640, Val Loss: 0.002478673, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.92%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_626.pth\n",
      "Model saved after epoch 643 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_643.pth \n",
      "\n",
      "Epoch 644/2000, Train Loss: 0.000280311, Val Loss: 0.002652993, Val Accuracy: 97.94%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.92%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_614.pth\n",
      "Model saved after epoch 644 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_644.pth \n",
      "\n",
      "Epoch 645/2000, Train Loss: 0.000305220, Val Loss: 0.002593833, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.93%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_623.pth\n",
      "Model saved after epoch 645 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_645.pth \n",
      "\n",
      "Epoch 646/2000, Train Loss: 0.000281761, Val Loss: 0.002806224, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.94%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_618.pth\n",
      "Model saved after epoch 646 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_646.pth \n",
      "\n",
      "Epoch 647/2000, Train Loss: 0.000382659, Val Loss: 0.003023556, Val Accuracy: 97.34%, LR: 0.000100000\n",
      "Epoch 648/2000, Train Loss: 0.000393644, Val Loss: 0.002168013, Val Accuracy: 97.94%, LR: 0.000100000\n",
      "Epoch 649/2000, Train Loss: 0.000306973, Val Loss: 0.002638510, Val Accuracy: 97.94%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.94%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_644.pth\n",
      "Model saved after epoch 649 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_649.pth \n",
      "\n",
      "Epoch 650/2000, Train Loss: 0.000278322, Val Loss: 0.002590297, Val Accuracy: 97.92%, LR: 0.000100000\n",
      "Epoch 651/2000, Train Loss: 0.000302907, Val Loss: 0.002698600, Val Accuracy: 97.84%, LR: 0.000100000\n",
      "Epoch 652/2000, Train Loss: 0.001186574, Val Loss: 0.002760176, Val Accuracy: 97.51%, LR: 0.000100000\n",
      "Epoch 653/2000, Train Loss: 0.000343049, Val Loss: 0.002586310, Val Accuracy: 97.94%, LR: 0.000100000\n",
      "Epoch 654/2000, Train Loss: 0.000273977, Val Loss: 0.002543905, Val Accuracy: 97.82%, LR: 0.000100000\n",
      "Epoch 655/2000, Train Loss: 0.000291585, Val Loss: 0.002566862, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.94%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_649.pth\n",
      "Model saved after epoch 655 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_655.pth \n",
      "\n",
      "Epoch 656/2000, Train Loss: 0.000366705, Val Loss: 0.003620547, Val Accuracy: 96.91%, LR: 0.000100000\n",
      "Epoch 657/2000, Train Loss: 0.000551683, Val Loss: 0.002517188, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Epoch 658/2000, Train Loss: 0.000283848, Val Loss: 0.002427769, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.95%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_643.pth\n",
      "Model saved after epoch 658 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_658.pth \n",
      "\n",
      "Epoch 659/2000, Train Loss: 0.000284221, Val Loss: 0.002695203, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.96%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_646.pth\n",
      "Model saved after epoch 659 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_659.pth \n",
      "\n",
      "Epoch 660/2000, Train Loss: 0.000274512, Val Loss: 0.002637954, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.96%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_645.pth\n",
      "Model saved after epoch 660 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_660.pth \n",
      "\n",
      "Epoch 661/2000, Train Loss: 0.000274985, Val Loss: 0.002283027, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Removed old model with accuracy 97.96%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_640.pth\n",
      "Model saved after epoch 661 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_661.pth \n",
      "\n",
      "Epoch 662/2000, Train Loss: 0.000420855, Val Loss: 0.002694898, Val Accuracy: 97.88%, LR: 0.000100000\n",
      "Epoch 663/2000, Train Loss: 0.000265196, Val Loss: 0.002659478, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.00%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_659.pth\n",
      "Model saved after epoch 663 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_663.pth \n",
      "\n",
      "Epoch 664/2000, Train Loss: 0.000435444, Val Loss: 0.002118061, Val Accuracy: 97.81%, LR: 0.000100000\n",
      "Epoch 665/2000, Train Loss: 0.000287187, Val Loss: 0.002822516, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 666/2000, Train Loss: 0.000453188, Val Loss: 0.002113804, Val Accuracy: 97.82%, LR: 0.000100000\n",
      "Epoch 667/2000, Train Loss: 0.000284017, Val Loss: 0.002529944, Val Accuracy: 97.79%, LR: 0.000100000\n",
      "Epoch 668/2000, Train Loss: 0.000266551, Val Loss: 0.002703790, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 669/2000, Train Loss: 0.000644927, Val Loss: 0.002230655, Val Accuracy: 97.66%, LR: 0.000100000\n",
      "Epoch 670/2000, Train Loss: 0.000267766, Val Loss: 0.002747812, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.02%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_663.pth\n",
      "Model saved after epoch 670 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_670.pth \n",
      "\n",
      "Epoch 671/2000, Train Loss: 0.000253643, Val Loss: 0.002955545, Val Accuracy: 97.90%, LR: 0.000100000\n",
      "Epoch 672/2000, Train Loss: 0.000264202, Val Loss: 0.003169338, Val Accuracy: 97.45%, LR: 0.000100000\n",
      "Epoch 673/2000, Train Loss: 0.000981504, Val Loss: 0.002166208, Val Accuracy: 97.40%, LR: 0.000100000\n",
      "Epoch 674/2000, Train Loss: 0.000317015, Val Loss: 0.003318103, Val Accuracy: 97.20%, LR: 0.000100000\n",
      "Epoch 675/2000, Train Loss: 0.000335673, Val Loss: 0.002482447, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.02%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_661.pth\n",
      "Model saved after epoch 675 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_675.pth \n",
      "\n",
      "Epoch 676/2000, Train Loss: 0.000256220, Val Loss: 0.002639958, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 677/2000, Train Loss: 0.000253882, Val Loss: 0.002694750, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 678/2000, Train Loss: 0.000247118, Val Loss: 0.002906547, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 679/2000, Train Loss: 0.000255609, Val Loss: 0.002590557, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 680/2000, Train Loss: 0.000324793, Val Loss: 0.003009960, Val Accuracy: 97.87%, LR: 0.000100000\n",
      "Epoch 681/2000, Train Loss: 0.000306791, Val Loss: 0.002592356, Val Accuracy: 97.76%, LR: 0.000100000\n",
      "Epoch 682/2000, Train Loss: 0.000682644, Val Loss: 0.002525706, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Epoch 683/2000, Train Loss: 0.000271963, Val Loss: 0.002538111, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.03%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_655.pth\n",
      "Model saved after epoch 683 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_683.pth \n",
      "\n",
      "Epoch 684/2000, Train Loss: 0.000260573, Val Loss: 0.002755272, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 685/2000, Train Loss: 0.000389918, Val Loss: 0.002832246, Val Accuracy: 97.77%, LR: 0.000100000\n",
      "Epoch 686/2000, Train Loss: 0.000664545, Val Loss: 0.002151347, Val Accuracy: 97.60%, LR: 0.000100000\n",
      "Epoch 687/2000, Train Loss: 0.000283339, Val Loss: 0.002761713, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 688/2000, Train Loss: 0.000261711, Val Loss: 0.002616257, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 689/2000, Train Loss: 0.000247718, Val Loss: 0.002655863, Val Accuracy: 97.86%, LR: 0.000100000\n",
      "Epoch 690/2000, Train Loss: 0.000260744, Val Loss: 0.003061874, Val Accuracy: 97.62%, LR: 0.000100000\n",
      "Epoch 691/2000, Train Loss: 0.000259542, Val Loss: 0.002356598, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 692/2000, Train Loss: 0.000693588, Val Loss: 0.002495244, Val Accuracy: 97.70%, LR: 0.000100000\n",
      "Epoch 693/2000, Train Loss: 0.000263864, Val Loss: 0.002426868, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.04%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_658.pth\n",
      "Model saved after epoch 693 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_693.pth \n",
      "\n",
      "Epoch 694/2000, Train Loss: 0.000250253, Val Loss: 0.002576865, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.05%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_660.pth\n",
      "Model saved after epoch 694 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_694.pth \n",
      "\n",
      "Epoch 695/2000, Train Loss: 0.000269215, Val Loss: 0.002369135, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.05%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_683.pth\n",
      "Model saved after epoch 695 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_695.pth \n",
      "\n",
      "Epoch 696/2000, Train Loss: 0.000239345, Val Loss: 0.002694222, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.05%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_695.pth\n",
      "Model saved after epoch 696 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_696.pth \n",
      "\n",
      "Epoch 697/2000, Train Loss: 0.002031811, Val Loss: 0.001748240, Val Accuracy: 96.70%, LR: 0.000100000\n",
      "Epoch 698/2000, Train Loss: 0.000401705, Val Loss: 0.002349627, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 699/2000, Train Loss: 0.000269401, Val Loss: 0.002180851, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.06%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_696.pth\n",
      "Model saved after epoch 699 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_699.pth \n",
      "\n",
      "Epoch 700/2000, Train Loss: 0.000247938, Val Loss: 0.002073273, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.08%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_694.pth\n",
      "Model saved after epoch 700 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_700.pth \n",
      "\n",
      "Epoch 701/2000, Train Loss: 0.000243160, Val Loss: 0.002478944, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.08%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_675.pth\n",
      "Model saved after epoch 701 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_701.pth \n",
      "\n",
      "Epoch 702/2000, Train Loss: 0.000336416, Val Loss: 0.003338914, Val Accuracy: 96.95%, LR: 0.000100000\n",
      "Epoch 703/2000, Train Loss: 0.000285024, Val Loss: 0.002491190, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 704/2000, Train Loss: 0.000890651, Val Loss: 0.001783600, Val Accuracy: 97.88%, LR: 0.000100000\n",
      "Epoch 705/2000, Train Loss: 0.000283981, Val Loss: 0.002572562, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 706/2000, Train Loss: 0.000254817, Val Loss: 0.002502052, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 707/2000, Train Loss: 0.000671691, Val Loss: 0.001517956, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 708/2000, Train Loss: 0.000261166, Val Loss: 0.002680292, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Epoch 709/2000, Train Loss: 0.000242634, Val Loss: 0.002545956, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 710/2000, Train Loss: 0.000236199, Val Loss: 0.002804380, Val Accuracy: 97.90%, LR: 0.000100000\n",
      "Epoch 711/2000, Train Loss: 0.001012163, Val Loss: 0.002045793, Val Accuracy: 97.10%, LR: 0.000100000\n",
      "Epoch 712/2000, Train Loss: 0.000432893, Val Loss: 0.002619717, Val Accuracy: 97.94%, LR: 0.000100000\n",
      "Epoch 713/2000, Train Loss: 0.000251199, Val Loss: 0.002570315, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.08%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_699.pth\n",
      "Model saved after epoch 713 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_713.pth \n",
      "\n",
      "Epoch 714/2000, Train Loss: 0.000244191, Val Loss: 0.002827864, Val Accuracy: 97.86%, LR: 0.000100000\n",
      "Epoch 715/2000, Train Loss: 0.000257542, Val Loss: 0.002736054, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 716/2000, Train Loss: 0.000231245, Val Loss: 0.002769796, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 717/2000, Train Loss: 0.000234505, Val Loss: 0.002705280, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 718/2000, Train Loss: 0.000233766, Val Loss: 0.002574737, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 719/2000, Train Loss: 0.000236773, Val Loss: 0.002616452, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 720/2000, Train Loss: 0.000255464, Val Loss: 0.002883707, Val Accuracy: 97.92%, LR: 0.000100000\n",
      "Epoch 721/2000, Train Loss: 0.000237123, Val Loss: 0.002958984, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Epoch 722/2000, Train Loss: 0.000227040, Val Loss: 0.002702179, Val Accuracy: 97.97%, LR: 0.000100000\n",
      "Epoch 723/2000, Train Loss: 0.000306501, Val Loss: 0.002849095, Val Accuracy: 97.73%, LR: 0.000100000\n",
      "Epoch 724/2000, Train Loss: 0.000230779, Val Loss: 0.002925770, Val Accuracy: 97.76%, LR: 0.000100000\n",
      "Epoch 725/2000, Train Loss: 0.000258678, Val Loss: 0.003086400, Val Accuracy: 97.37%, LR: 0.000100000\n",
      "Epoch 726/2000, Train Loss: 0.000243407, Val Loss: 0.002824241, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 727/2000, Train Loss: 0.000233340, Val Loss: 0.002762311, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 728/2000, Train Loss: 0.000291344, Val Loss: 0.002977868, Val Accuracy: 97.82%, LR: 0.000100000\n",
      "Epoch 729/2000, Train Loss: 0.000911603, Val Loss: 0.001985716, Val Accuracy: 97.76%, LR: 0.000100000\n",
      "Epoch 730/2000, Train Loss: 0.000252555, Val Loss: 0.002525777, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 731/2000, Train Loss: 0.000227338, Val Loss: 0.002655439, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 732/2000, Train Loss: 0.000232530, Val Loss: 0.002731340, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 733/2000, Train Loss: 0.000784200, Val Loss: 0.003476451, Val Accuracy: 96.51%, LR: 0.000100000\n",
      "Epoch 734/2000, Train Loss: 0.000608709, Val Loss: 0.002548514, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 735/2000, Train Loss: 0.000248682, Val Loss: 0.002701334, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 736/2000, Train Loss: 0.000235644, Val Loss: 0.002384283, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.10%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_713.pth\n",
      "Model saved after epoch 736 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_736.pth \n",
      "\n",
      "Epoch 737/2000, Train Loss: 0.000225405, Val Loss: 0.002799180, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 738/2000, Train Loss: 0.000221099, Val Loss: 0.002984448, Val Accuracy: 97.86%, LR: 0.000100000\n",
      "Epoch 739/2000, Train Loss: 0.000223696, Val Loss: 0.002896560, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 740/2000, Train Loss: 0.000216197, Val Loss: 0.002624951, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 741/2000, Train Loss: 0.000765025, Val Loss: 0.003572509, Val Accuracy: 96.60%, LR: 0.000100000\n",
      "Epoch 742/2000, Train Loss: 0.000762013, Val Loss: 0.002406566, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 743/2000, Train Loss: 0.000243852, Val Loss: 0.002537988, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 744/2000, Train Loss: 0.000297038, Val Loss: 0.002544158, Val Accuracy: 97.68%, LR: 0.000100000\n",
      "Epoch 745/2000, Train Loss: 0.000802480, Val Loss: 0.002458285, Val Accuracy: 97.87%, LR: 0.000100000\n",
      "Epoch 746/2000, Train Loss: 0.000347230, Val Loss: 0.002338775, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 747/2000, Train Loss: 0.000249259, Val Loss: 0.002620543, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 748/2000, Train Loss: 0.000223476, Val Loss: 0.002640585, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 749/2000, Train Loss: 0.000224446, Val Loss: 0.002701812, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Epoch 750/2000, Train Loss: 0.000214528, Val Loss: 0.002794645, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Epoch 751/2000, Train Loss: 0.000216846, Val Loss: 0.002624039, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 752/2000, Train Loss: 0.000244625, Val Loss: 0.003202152, Val Accuracy: 97.58%, LR: 0.000100000\n",
      "Epoch 753/2000, Train Loss: 0.000234663, Val Loss: 0.002800714, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Epoch 754/2000, Train Loss: 0.000234769, Val Loss: 0.003112896, Val Accuracy: 97.48%, LR: 0.000100000\n",
      "Epoch 755/2000, Train Loss: 0.000278837, Val Loss: 0.002917304, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Epoch 756/2000, Train Loss: 0.000267961, Val Loss: 0.002631353, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Epoch 757/2000, Train Loss: 0.000251756, Val Loss: 0.002773913, Val Accuracy: 97.93%, LR: 0.000100000\n",
      "Epoch 758/2000, Train Loss: 0.000224653, Val Loss: 0.002702119, Val Accuracy: 97.97%, LR: 0.000100000\n",
      "Epoch 759/2000, Train Loss: 0.000204045, Val Loss: 0.002790262, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 760/2000, Train Loss: 0.000204611, Val Loss: 0.002844711, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Epoch 761/2000, Train Loss: 0.000220988, Val Loss: 0.002882144, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 762/2000, Train Loss: 0.000238752, Val Loss: 0.002641257, Val Accuracy: 97.72%, LR: 0.000100000\n",
      "Epoch 763/2000, Train Loss: 0.001093198, Val Loss: 0.002104490, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 764/2000, Train Loss: 0.000230867, Val Loss: 0.002845968, Val Accuracy: 97.73%, LR: 0.000100000\n",
      "Epoch 765/2000, Train Loss: 0.000211627, Val Loss: 0.002613204, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.10%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_670.pth\n",
      "Model saved after epoch 765 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_765.pth \n",
      "\n",
      "Epoch 766/2000, Train Loss: 0.000262314, Val Loss: 0.002805827, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 767/2000, Train Loss: 0.000221155, Val Loss: 0.002814155, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 768/2000, Train Loss: 0.000208559, Val Loss: 0.002873017, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 769/2000, Train Loss: 0.000213669, Val Loss: 0.002667392, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Epoch 770/2000, Train Loss: 0.000202885, Val Loss: 0.002803923, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 771/2000, Train Loss: 0.000219481, Val Loss: 0.003051932, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 772/2000, Train Loss: 0.000211681, Val Loss: 0.003069875, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Epoch 773/2000, Train Loss: 0.000602641, Val Loss: 0.001669483, Val Accuracy: 97.47%, LR: 0.000100000\n",
      "Epoch 774/2000, Train Loss: 0.000408069, Val Loss: 0.002789948, Val Accuracy: 97.68%, LR: 0.000100000\n",
      "Epoch 775/2000, Train Loss: 0.000220771, Val Loss: 0.002701047, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.10%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_701.pth\n",
      "Model saved after epoch 775 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_775.pth \n",
      "\n",
      "Epoch 776/2000, Train Loss: 0.000213339, Val Loss: 0.003049691, Val Accuracy: 97.88%, LR: 0.000100000\n",
      "Epoch 777/2000, Train Loss: 0.001125497, Val Loss: 0.002443497, Val Accuracy: 95.84%, LR: 0.000100000\n",
      "Epoch 778/2000, Train Loss: 0.000486454, Val Loss: 0.002692463, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 779/2000, Train Loss: 0.000224622, Val Loss: 0.002716492, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 780/2000, Train Loss: 0.000217302, Val Loss: 0.002653914, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 781/2000, Train Loss: 0.000206521, Val Loss: 0.002923597, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 782/2000, Train Loss: 0.000200327, Val Loss: 0.002870426, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 783/2000, Train Loss: 0.000201886, Val Loss: 0.002832513, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 784/2000, Train Loss: 0.000201403, Val Loss: 0.002761550, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 785/2000, Train Loss: 0.000195496, Val Loss: 0.002879971, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 786/2000, Train Loss: 0.000503433, Val Loss: 0.002477909, Val Accuracy: 97.52%, LR: 0.000100000\n",
      "Epoch 787/2000, Train Loss: 0.000226786, Val Loss: 0.002977388, Val Accuracy: 97.77%, LR: 0.000100000\n",
      "Epoch 788/2000, Train Loss: 0.000213559, Val Loss: 0.002756750, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 789/2000, Train Loss: 0.000196648, Val Loss: 0.002742223, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.11%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_736.pth\n",
      "Model saved after epoch 789 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_789.pth \n",
      "\n",
      "Epoch 790/2000, Train Loss: 0.000210442, Val Loss: 0.002998212, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 791/2000, Train Loss: 0.000198623, Val Loss: 0.002962984, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 792/2000, Train Loss: 0.000234901, Val Loss: 0.003052562, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 793/2000, Train Loss: 0.000549412, Val Loss: 0.003001644, Val Accuracy: 95.75%, LR: 0.000100000\n",
      "Epoch 794/2000, Train Loss: 0.000815591, Val Loss: 0.002469810, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.12%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_765.pth\n",
      "Model saved after epoch 794 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_794.pth \n",
      "\n",
      "Epoch 795/2000, Train Loss: 0.000213846, Val Loss: 0.002605152, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.12%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_693.pth\n",
      "Model saved after epoch 795 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_795.pth \n",
      "\n",
      "Epoch 796/2000, Train Loss: 0.000212410, Val Loss: 0.002779104, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 797/2000, Train Loss: 0.000262485, Val Loss: 0.002884818, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 798/2000, Train Loss: 0.000239352, Val Loss: 0.002741226, Val Accuracy: 97.69%, LR: 0.000100000\n",
      "Epoch 799/2000, Train Loss: 0.000208421, Val Loss: 0.002612860, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 800/2000, Train Loss: 0.000197549, Val Loss: 0.002701553, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 801/2000, Train Loss: 0.000196751, Val Loss: 0.002984539, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 802/2000, Train Loss: 0.000199419, Val Loss: 0.002833397, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 803/2000, Train Loss: 0.000214733, Val Loss: 0.002669233, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 804/2000, Train Loss: 0.000195138, Val Loss: 0.003120253, Val Accuracy: 97.84%, LR: 0.000100000\n",
      "Epoch 805/2000, Train Loss: 0.000191253, Val Loss: 0.002953705, Val Accuracy: 97.93%, LR: 0.000100000\n",
      "Epoch 806/2000, Train Loss: 0.000341717, Val Loss: 0.002476335, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 807/2000, Train Loss: 0.001522874, Val Loss: 0.002936724, Val Accuracy: 96.39%, LR: 0.000100000\n",
      "Epoch 808/2000, Train Loss: 0.000579307, Val Loss: 0.002586525, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 809/2000, Train Loss: 0.000228603, Val Loss: 0.002605291, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 810/2000, Train Loss: 0.000204664, Val Loss: 0.002776106, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 811/2000, Train Loss: 0.000197089, Val Loss: 0.002764080, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 812/2000, Train Loss: 0.000194909, Val Loss: 0.002824600, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.12%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_700.pth\n",
      "Model saved after epoch 812 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_812.pth \n",
      "\n",
      "Epoch 813/2000, Train Loss: 0.000192991, Val Loss: 0.002772000, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 814/2000, Train Loss: 0.000203986, Val Loss: 0.002691129, Val Accuracy: 97.63%, LR: 0.000100000\n",
      "Epoch 815/2000, Train Loss: 0.000252565, Val Loss: 0.002698857, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 816/2000, Train Loss: 0.000190257, Val Loss: 0.002969803, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 817/2000, Train Loss: 0.000184658, Val Loss: 0.002924912, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Epoch 818/2000, Train Loss: 0.000187671, Val Loss: 0.002770064, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 819/2000, Train Loss: 0.000263472, Val Loss: 0.002674554, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 820/2000, Train Loss: 0.000182751, Val Loss: 0.002934254, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 821/2000, Train Loss: 0.000200868, Val Loss: 0.002947797, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 822/2000, Train Loss: 0.000192714, Val Loss: 0.002923177, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 823/2000, Train Loss: 0.001445273, Val Loss: 0.001379208, Val Accuracy: 97.93%, LR: 0.000100000\n",
      "Epoch 824/2000, Train Loss: 0.000289982, Val Loss: 0.002113354, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.12%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_812.pth\n",
      "Model saved after epoch 824 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_824.pth \n",
      "\n",
      "Epoch 825/2000, Train Loss: 0.000208582, Val Loss: 0.001811805, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.12%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_789.pth\n",
      "Model saved after epoch 825 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_825.pth \n",
      "\n",
      "Epoch 826/2000, Train Loss: 0.000197919, Val Loss: 0.002644513, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 827/2000, Train Loss: 0.000189471, Val Loss: 0.002467624, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 828/2000, Train Loss: 0.000203915, Val Loss: 0.002551371, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 829/2000, Train Loss: 0.000185598, Val Loss: 0.002373039, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 830/2000, Train Loss: 0.000186913, Val Loss: 0.002927431, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 831/2000, Train Loss: 0.000190320, Val Loss: 0.002538641, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 832/2000, Train Loss: 0.000571216, Val Loss: 0.001762009, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 833/2000, Train Loss: 0.000200474, Val Loss: 0.002272968, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.12%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_795.pth\n",
      "Model saved after epoch 833 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_833.pth \n",
      "\n",
      "Epoch 834/2000, Train Loss: 0.000200603, Val Loss: 0.002076828, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.13%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_775.pth\n",
      "Model saved after epoch 834 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_834.pth \n",
      "\n",
      "Epoch 835/2000, Train Loss: 0.000194508, Val Loss: 0.002900257, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 836/2000, Train Loss: 0.000845866, Val Loss: 0.002014488, Val Accuracy: 97.00%, LR: 0.000100000\n",
      "Epoch 837/2000, Train Loss: 0.000673460, Val Loss: 0.002588225, Val Accuracy: 97.71%, LR: 0.000100000\n",
      "Epoch 838/2000, Train Loss: 0.000236302, Val Loss: 0.002274589, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.14%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_794.pth\n",
      "Model saved after epoch 838 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_838.pth \n",
      "\n",
      "Epoch 839/2000, Train Loss: 0.000193891, Val Loss: 0.002559219, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 840/2000, Train Loss: 0.000187158, Val Loss: 0.002375302, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.14%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_834.pth\n",
      "Model saved after epoch 840 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_840.pth \n",
      "\n",
      "Epoch 841/2000, Train Loss: 0.000189245, Val Loss: 0.002615650, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 842/2000, Train Loss: 0.000184703, Val Loss: 0.002499214, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 843/2000, Train Loss: 0.000182048, Val Loss: 0.003062216, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 844/2000, Train Loss: 0.000187789, Val Loss: 0.002875805, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 845/2000, Train Loss: 0.000176186, Val Loss: 0.002950971, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 846/2000, Train Loss: 0.000178206, Val Loss: 0.003474544, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Epoch 847/2000, Train Loss: 0.000183108, Val Loss: 0.002838432, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 848/2000, Train Loss: 0.000183138, Val Loss: 0.002476834, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 849/2000, Train Loss: 0.000179262, Val Loss: 0.003016450, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 850/2000, Train Loss: 0.002754682, Val Loss: 0.005470730, Val Accuracy: 92.85%, LR: 0.000100000\n",
      "Epoch 851/2000, Train Loss: 0.001941017, Val Loss: 0.002255437, Val Accuracy: 97.79%, LR: 0.000100000\n",
      "Epoch 852/2000, Train Loss: 0.000277418, Val Loss: 0.002219602, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.15%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_833.pth\n",
      "Model saved after epoch 852 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_852.pth \n",
      "\n",
      "Epoch 853/2000, Train Loss: 0.000213910, Val Loss: 0.002139185, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.16%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_824.pth\n",
      "Model saved after epoch 853 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_853.pth \n",
      "\n",
      "Epoch 854/2000, Train Loss: 0.000206874, Val Loss: 0.002183277, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 855/2000, Train Loss: 0.000192924, Val Loss: 0.002268912, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.17%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_825.pth\n",
      "Model saved after epoch 855 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_855.pth \n",
      "\n",
      "Epoch 856/2000, Train Loss: 0.000204688, Val Loss: 0.002486391, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.17%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_855.pth\n",
      "Model saved after epoch 856 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_856.pth \n",
      "\n",
      "Epoch 857/2000, Train Loss: 0.000181804, Val Loss: 0.002458770, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.17%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_838.pth\n",
      "Model saved after epoch 857 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_857.pth \n",
      "\n",
      "Epoch 858/2000, Train Loss: 0.000182024, Val Loss: 0.002617241, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 859/2000, Train Loss: 0.000183008, Val Loss: 0.002624468, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 860/2000, Train Loss: 0.000183899, Val Loss: 0.002652089, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 861/2000, Train Loss: 0.000179093, Val Loss: 0.002409850, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 862/2000, Train Loss: 0.000180488, Val Loss: 0.002777998, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 863/2000, Train Loss: 0.001501593, Val Loss: 0.006127682, Val Accuracy: 91.09%, LR: 0.000100000\n",
      "Epoch 864/2000, Train Loss: 0.001231883, Val Loss: 0.001765923, Val Accuracy: 97.94%, LR: 0.000100000\n",
      "Epoch 865/2000, Train Loss: 0.000233917, Val Loss: 0.002250823, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.17%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_857.pth\n",
      "Model saved after epoch 865 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_865.pth \n",
      "\n",
      "Epoch 866/2000, Train Loss: 0.000204697, Val Loss: 0.002705763, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 867/2000, Train Loss: 0.000190529, Val Loss: 0.002558781, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 868/2000, Train Loss: 0.000191270, Val Loss: 0.002357386, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.18%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_865.pth\n",
      "Model saved after epoch 868 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_868.pth \n",
      "\n",
      "Epoch 869/2000, Train Loss: 0.000184410, Val Loss: 0.002354779, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 870/2000, Train Loss: 0.000180778, Val Loss: 0.002613587, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 871/2000, Train Loss: 0.000196647, Val Loss: 0.002484907, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 872/2000, Train Loss: 0.000180633, Val Loss: 0.002804803, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 873/2000, Train Loss: 0.000176782, Val Loss: 0.002739440, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 874/2000, Train Loss: 0.000187279, Val Loss: 0.002749322, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 875/2000, Train Loss: 0.000932019, Val Loss: 0.002379861, Val Accuracy: 97.08%, LR: 0.000100000\n",
      "Epoch 876/2000, Train Loss: 0.000304063, Val Loss: 0.002127438, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 877/2000, Train Loss: 0.000189540, Val Loss: 0.002543067, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 878/2000, Train Loss: 0.000182855, Val Loss: 0.002405713, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.18%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_840.pth\n",
      "Model saved after epoch 878 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_878.pth \n",
      "\n",
      "Epoch 879/2000, Train Loss: 0.000185216, Val Loss: 0.002497860, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 880/2000, Train Loss: 0.000177737, Val Loss: 0.002701393, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 881/2000, Train Loss: 0.000173576, Val Loss: 0.002421384, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.18%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_856.pth\n",
      "Model saved after epoch 881 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_881.pth \n",
      "\n",
      "Epoch 882/2000, Train Loss: 0.000217025, Val Loss: 0.002432208, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 883/2000, Train Loss: 0.000170397, Val Loss: 0.002620327, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 884/2000, Train Loss: 0.000180802, Val Loss: 0.002394785, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 885/2000, Train Loss: 0.000184959, Val Loss: 0.002839239, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 886/2000, Train Loss: 0.000178335, Val Loss: 0.003213030, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 887/2000, Train Loss: 0.000211866, Val Loss: 0.002835597, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Epoch 888/2000, Train Loss: 0.003801454, Val Loss: 0.002230137, Val Accuracy: 96.94%, LR: 0.000100000\n",
      "Epoch 889/2000, Train Loss: 0.000511912, Val Loss: 0.002146688, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 890/2000, Train Loss: 0.000238688, Val Loss: 0.002356679, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 891/2000, Train Loss: 0.000205883, Val Loss: 0.002450203, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.18%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_881.pth\n",
      "Model saved after epoch 891 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_891.pth \n",
      "\n",
      "Epoch 892/2000, Train Loss: 0.000195798, Val Loss: 0.002553231, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 893/2000, Train Loss: 0.000185983, Val Loss: 0.002555994, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 894/2000, Train Loss: 0.000187141, Val Loss: 0.002756867, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 895/2000, Train Loss: 0.000658507, Val Loss: 0.003043258, Val Accuracy: 97.25%, LR: 0.000100000\n",
      "Epoch 896/2000, Train Loss: 0.000272755, Val Loss: 0.002362175, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 897/2000, Train Loss: 0.000188171, Val Loss: 0.002408427, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 898/2000, Train Loss: 0.000192533, Val Loss: 0.002453377, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 899/2000, Train Loss: 0.000176789, Val Loss: 0.002633283, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 900/2000, Train Loss: 0.000174740, Val Loss: 0.002696861, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 901/2000, Train Loss: 0.000176723, Val Loss: 0.002755776, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 902/2000, Train Loss: 0.000177152, Val Loss: 0.002758631, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 903/2000, Train Loss: 0.000171225, Val Loss: 0.002812199, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 904/2000, Train Loss: 0.000190730, Val Loss: 0.002617858, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 905/2000, Train Loss: 0.000170145, Val Loss: 0.002579718, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 906/2000, Train Loss: 0.001103880, Val Loss: 0.004015192, Val Accuracy: 94.92%, LR: 0.000100000\n",
      "Epoch 907/2000, Train Loss: 0.000888340, Val Loss: 0.002181415, Val Accuracy: 97.88%, LR: 0.000100000\n",
      "Epoch 908/2000, Train Loss: 0.000216782, Val Loss: 0.002205834, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 909/2000, Train Loss: 0.000194813, Val Loss: 0.002165205, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.18%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_868.pth\n",
      "Model saved after epoch 909 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_909.pth \n",
      "\n",
      "Epoch 910/2000, Train Loss: 0.000181406, Val Loss: 0.002626346, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 911/2000, Train Loss: 0.000176383, Val Loss: 0.002566816, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 912/2000, Train Loss: 0.000190944, Val Loss: 0.002917104, Val Accuracy: 97.90%, LR: 0.000100000\n",
      "Epoch 913/2000, Train Loss: 0.000175749, Val Loss: 0.002812092, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 914/2000, Train Loss: 0.000171740, Val Loss: 0.002549027, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 915/2000, Train Loss: 0.000204922, Val Loss: 0.002582403, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 916/2000, Train Loss: 0.000168842, Val Loss: 0.002595976, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 917/2000, Train Loss: 0.000170512, Val Loss: 0.002651438, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 918/2000, Train Loss: 0.000385900, Val Loss: 0.003785523, Val Accuracy: 96.07%, LR: 0.000100000\n",
      "Epoch 919/2000, Train Loss: 0.000577129, Val Loss: 0.002436549, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 920/2000, Train Loss: 0.000191626, Val Loss: 0.002664715, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 921/2000, Train Loss: 0.000178959, Val Loss: 0.002635107, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 922/2000, Train Loss: 0.000174183, Val Loss: 0.002993610, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 923/2000, Train Loss: 0.000163684, Val Loss: 0.002691605, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 924/2000, Train Loss: 0.000179618, Val Loss: 0.002660144, Val Accuracy: 97.63%, LR: 0.000100000\n",
      "Epoch 925/2000, Train Loss: 0.000701000, Val Loss: 0.001884555, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 926/2000, Train Loss: 0.000181577, Val Loss: 0.002843922, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 927/2000, Train Loss: 0.000177458, Val Loss: 0.002884215, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 928/2000, Train Loss: 0.000166907, Val Loss: 0.002927334, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 929/2000, Train Loss: 0.000162610, Val Loss: 0.002919962, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 930/2000, Train Loss: 0.000163833, Val Loss: 0.002786944, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 931/2000, Train Loss: 0.000192658, Val Loss: 0.003515044, Val Accuracy: 97.64%, LR: 0.000100000\n",
      "Epoch 932/2000, Train Loss: 0.000611509, Val Loss: 0.003522932, Val Accuracy: 97.26%, LR: 0.000100000\n",
      "Epoch 933/2000, Train Loss: 0.000504087, Val Loss: 0.002013868, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 934/2000, Train Loss: 0.000178718, Val Loss: 0.002386795, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 935/2000, Train Loss: 0.000165990, Val Loss: 0.002585045, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 936/2000, Train Loss: 0.000167112, Val Loss: 0.002880279, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 937/2000, Train Loss: 0.000159121, Val Loss: 0.002614618, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 938/2000, Train Loss: 0.000161113, Val Loss: 0.002683914, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 939/2000, Train Loss: 0.000167958, Val Loss: 0.002460287, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 940/2000, Train Loss: 0.000169074, Val Loss: 0.002426682, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 941/2000, Train Loss: 0.000168325, Val Loss: 0.003017935, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 942/2000, Train Loss: 0.000159051, Val Loss: 0.002905701, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 943/2000, Train Loss: 0.000156929, Val Loss: 0.002722102, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 944/2000, Train Loss: 0.000159022, Val Loss: 0.002928997, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 945/2000, Train Loss: 0.000868059, Val Loss: 0.001864695, Val Accuracy: 97.14%, LR: 0.000100000\n",
      "Epoch 946/2000, Train Loss: 0.000249151, Val Loss: 0.002459074, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 947/2000, Train Loss: 0.000169463, Val Loss: 0.002872381, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 948/2000, Train Loss: 0.000160706, Val Loss: 0.002682319, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 949/2000, Train Loss: 0.000157513, Val Loss: 0.003099282, Val Accuracy: 97.97%, LR: 0.000100000\n",
      "Epoch 950/2000, Train Loss: 0.000216024, Val Loss: 0.002868948, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 951/2000, Train Loss: 0.000157287, Val Loss: 0.002770569, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 952/2000, Train Loss: 0.000161807, Val Loss: 0.002828882, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 953/2000, Train Loss: 0.000156358, Val Loss: 0.003159651, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 954/2000, Train Loss: 0.000151209, Val Loss: 0.002989986, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 955/2000, Train Loss: 0.000170030, Val Loss: 0.002551482, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 956/2000, Train Loss: 0.000163919, Val Loss: 0.003027513, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 957/2000, Train Loss: 0.000178305, Val Loss: 0.003263752, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 958/2000, Train Loss: 0.000194755, Val Loss: 0.002930451, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 959/2000, Train Loss: 0.000155858, Val Loss: 0.003120670, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 960/2000, Train Loss: 0.000164446, Val Loss: 0.002837003, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 961/2000, Train Loss: 0.001290851, Val Loss: 0.002515283, Val Accuracy: 96.84%, LR: 0.000100000\n",
      "Epoch 962/2000, Train Loss: 0.000290709, Val Loss: 0.002810606, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 963/2000, Train Loss: 0.000178263, Val Loss: 0.002888096, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 964/2000, Train Loss: 0.000164436, Val Loss: 0.002673089, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.18%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_909.pth\n",
      "Model saved after epoch 964 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_964.pth \n",
      "\n",
      "Epoch 965/2000, Train Loss: 0.000156551, Val Loss: 0.002902919, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 966/2000, Train Loss: 0.000155283, Val Loss: 0.002620951, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.19%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_964.pth\n",
      "Model saved after epoch 966 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_966.pth \n",
      "\n",
      "Epoch 967/2000, Train Loss: 0.000205862, Val Loss: 0.003236446, Val Accuracy: 97.85%, LR: 0.000100000\n",
      "Epoch 968/2000, Train Loss: 0.001253249, Val Loss: 0.001870020, Val Accuracy: 96.97%, LR: 0.000100000\n",
      "Epoch 969/2000, Train Loss: 0.000409344, Val Loss: 0.002172667, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 970/2000, Train Loss: 0.000177682, Val Loss: 0.002492955, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 971/2000, Train Loss: 0.000162658, Val Loss: 0.002585263, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 972/2000, Train Loss: 0.000158705, Val Loss: 0.002711919, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 973/2000, Train Loss: 0.000159901, Val Loss: 0.002839544, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 974/2000, Train Loss: 0.000168567, Val Loss: 0.002503027, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 975/2000, Train Loss: 0.000150351, Val Loss: 0.002792204, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 976/2000, Train Loss: 0.000149732, Val Loss: 0.002959693, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 977/2000, Train Loss: 0.000152570, Val Loss: 0.002743414, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 978/2000, Train Loss: 0.000152629, Val Loss: 0.003012418, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 979/2000, Train Loss: 0.000151779, Val Loss: 0.002984459, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 980/2000, Train Loss: 0.000152357, Val Loss: 0.002908810, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 981/2000, Train Loss: 0.000155327, Val Loss: 0.003057032, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 982/2000, Train Loss: 0.000145692, Val Loss: 0.003081003, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 983/2000, Train Loss: 0.000162762, Val Loss: 0.002773176, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 984/2000, Train Loss: 0.000241676, Val Loss: 0.006865863, Val Accuracy: 94.18%, LR: 0.000100000\n",
      "Epoch 985/2000, Train Loss: 0.001423203, Val Loss: 0.001864046, Val Accuracy: 97.49%, LR: 0.000100000\n",
      "Epoch 986/2000, Train Loss: 0.000240455, Val Loss: 0.002254423, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 987/2000, Train Loss: 0.000167278, Val Loss: 0.002493362, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 988/2000, Train Loss: 0.000160095, Val Loss: 0.002494916, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.19%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_878.pth\n",
      "Model saved after epoch 988 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_988.pth \n",
      "\n",
      "Epoch 989/2000, Train Loss: 0.000154817, Val Loss: 0.002562335, Val Accuracy: 98.23%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.19%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_966.pth\n",
      "Model saved after epoch 989 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_989.pth \n",
      "\n",
      "Epoch 990/2000, Train Loss: 0.000150637, Val Loss: 0.002797523, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 991/2000, Train Loss: 0.000148826, Val Loss: 0.002970310, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 992/2000, Train Loss: 0.000145135, Val Loss: 0.002925743, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 993/2000, Train Loss: 0.000145742, Val Loss: 0.002912522, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 994/2000, Train Loss: 0.000144593, Val Loss: 0.002979011, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 995/2000, Train Loss: 0.000147009, Val Loss: 0.002826599, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 996/2000, Train Loss: 0.001514183, Val Loss: 0.002834365, Val Accuracy: 97.33%, LR: 0.000100000\n",
      "Epoch 997/2000, Train Loss: 0.000505897, Val Loss: 0.002343169, Val Accuracy: 97.86%, LR: 0.000100000\n",
      "Epoch 998/2000, Train Loss: 0.000183407, Val Loss: 0.002566511, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 999/2000, Train Loss: 0.000162004, Val Loss: 0.002640733, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1000/2000, Train Loss: 0.000154229, Val Loss: 0.002591282, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1001/2000, Train Loss: 0.000162376, Val Loss: 0.002813368, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1002/2000, Train Loss: 0.000160963, Val Loss: 0.002764125, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1003/2000, Train Loss: 0.000148258, Val Loss: 0.002778237, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1004/2000, Train Loss: 0.000146368, Val Loss: 0.002758533, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1005/2000, Train Loss: 0.000156402, Val Loss: 0.002963784, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1006/2000, Train Loss: 0.000205288, Val Loss: 0.002708716, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1007/2000, Train Loss: 0.000148494, Val Loss: 0.002750237, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1008/2000, Train Loss: 0.000148555, Val Loss: 0.002796281, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1009/2000, Train Loss: 0.000140935, Val Loss: 0.002817063, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1010/2000, Train Loss: 0.000153138, Val Loss: 0.002986110, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1011/2000, Train Loss: 0.000146899, Val Loss: 0.002789951, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1012/2000, Train Loss: 0.000140637, Val Loss: 0.002981800, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1013/2000, Train Loss: 0.000142513, Val Loss: 0.002838974, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1014/2000, Train Loss: 0.000138670, Val Loss: 0.002902760, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1015/2000, Train Loss: 0.000823289, Val Loss: 0.003547263, Val Accuracy: 97.07%, LR: 0.000100000\n",
      "Epoch 1016/2000, Train Loss: 0.001141684, Val Loss: 0.002551320, Val Accuracy: 97.76%, LR: 0.000100000\n",
      "Epoch 1017/2000, Train Loss: 0.000205033, Val Loss: 0.002710435, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1018/2000, Train Loss: 0.000157483, Val Loss: 0.002688826, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1019/2000, Train Loss: 0.000152068, Val Loss: 0.002730912, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.20%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_852.pth\n",
      "Model saved after epoch 1019 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1019.pth \n",
      "\n",
      "Epoch 1020/2000, Train Loss: 0.000148797, Val Loss: 0.002914333, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1021/2000, Train Loss: 0.000145250, Val Loss: 0.002820363, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1022/2000, Train Loss: 0.000144728, Val Loss: 0.002957348, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1023/2000, Train Loss: 0.000145165, Val Loss: 0.003113174, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 1024/2000, Train Loss: 0.000144489, Val Loss: 0.002901031, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1025/2000, Train Loss: 0.000147949, Val Loss: 0.003002043, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1026/2000, Train Loss: 0.000135121, Val Loss: 0.002860030, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1027/2000, Train Loss: 0.000162788, Val Loss: 0.002881670, Val Accuracy: 97.57%, LR: 0.000100000\n",
      "Epoch 1028/2000, Train Loss: 0.000739618, Val Loss: 0.002603430, Val Accuracy: 97.69%, LR: 0.000100000\n",
      "Epoch 1029/2000, Train Loss: 0.000181841, Val Loss: 0.002772796, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1030/2000, Train Loss: 0.000147360, Val Loss: 0.002805012, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1031/2000, Train Loss: 0.000144228, Val Loss: 0.002969966, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1032/2000, Train Loss: 0.000139573, Val Loss: 0.002863201, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1033/2000, Train Loss: 0.000145015, Val Loss: 0.002965573, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1034/2000, Train Loss: 0.000135742, Val Loss: 0.002981618, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1035/2000, Train Loss: 0.000134349, Val Loss: 0.003112328, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1036/2000, Train Loss: 0.000142172, Val Loss: 0.003177008, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1037/2000, Train Loss: 0.000139709, Val Loss: 0.002937583, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1038/2000, Train Loss: 0.000132816, Val Loss: 0.002993244, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1039/2000, Train Loss: 0.000135195, Val Loss: 0.003185594, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1040/2000, Train Loss: 0.000142158, Val Loss: 0.003095705, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1041/2000, Train Loss: 0.000129972, Val Loss: 0.002919463, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1042/2000, Train Loss: 0.000134836, Val Loss: 0.003067851, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1043/2000, Train Loss: 0.003445345, Val Loss: 0.001812034, Val Accuracy: 96.53%, LR: 0.000100000\n",
      "Epoch 1044/2000, Train Loss: 0.000482415, Val Loss: 0.001994843, Val Accuracy: 97.89%, LR: 0.000100000\n",
      "Epoch 1045/2000, Train Loss: 0.000205464, Val Loss: 0.002564890, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1046/2000, Train Loss: 0.000170837, Val Loss: 0.002493702, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1047/2000, Train Loss: 0.000156102, Val Loss: 0.002717740, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1048/2000, Train Loss: 0.000150303, Val Loss: 0.002552448, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1049/2000, Train Loss: 0.000147712, Val Loss: 0.002869807, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1050/2000, Train Loss: 0.000152147, Val Loss: 0.002771837, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1051/2000, Train Loss: 0.000146244, Val Loss: 0.002993156, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1052/2000, Train Loss: 0.000164292, Val Loss: 0.001850941, Val Accuracy: 97.70%, LR: 0.000100000\n",
      "Epoch 1053/2000, Train Loss: 0.000162256, Val Loss: 0.002884647, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1054/2000, Train Loss: 0.000139019, Val Loss: 0.002922605, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1055/2000, Train Loss: 0.000152133, Val Loss: 0.003470493, Val Accuracy: 97.80%, LR: 0.000100000\n",
      "Epoch 1056/2000, Train Loss: 0.000159766, Val Loss: 0.002800754, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1057/2000, Train Loss: 0.000140910, Val Loss: 0.003240636, Val Accuracy: 97.97%, LR: 0.000100000\n",
      "Epoch 1058/2000, Train Loss: 0.000169095, Val Loss: 0.002759409, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1059/2000, Train Loss: 0.000148735, Val Loss: 0.002851748, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1060/2000, Train Loss: 0.002247659, Val Loss: 0.003118442, Val Accuracy: 96.14%, LR: 0.000100000\n",
      "Epoch 1061/2000, Train Loss: 0.000513553, Val Loss: 0.002388037, Val Accuracy: 97.94%, LR: 0.000100000\n",
      "Epoch 1062/2000, Train Loss: 0.000200256, Val Loss: 0.002680180, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1063/2000, Train Loss: 0.000160387, Val Loss: 0.002704891, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1064/2000, Train Loss: 0.000158298, Val Loss: 0.002829708, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1065/2000, Train Loss: 0.000145346, Val Loss: 0.002792856, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1066/2000, Train Loss: 0.000148768, Val Loss: 0.002939578, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1067/2000, Train Loss: 0.000138891, Val Loss: 0.002773073, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1068/2000, Train Loss: 0.000146984, Val Loss: 0.003022050, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1069/2000, Train Loss: 0.000141169, Val Loss: 0.003040753, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1070/2000, Train Loss: 0.000145793, Val Loss: 0.003080058, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 1071/2000, Train Loss: 0.000137355, Val Loss: 0.002944868, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1072/2000, Train Loss: 0.000130951, Val Loss: 0.002958214, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1073/2000, Train Loss: 0.000132972, Val Loss: 0.002898061, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1074/2000, Train Loss: 0.000133583, Val Loss: 0.002959899, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1075/2000, Train Loss: 0.000137660, Val Loss: 0.002858760, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1076/2000, Train Loss: 0.000143449, Val Loss: 0.003160308, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1077/2000, Train Loss: 0.000148830, Val Loss: 0.003042500, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1078/2000, Train Loss: 0.000166678, Val Loss: 0.009253141, Val Accuracy: 92.95%, LR: 0.000100000\n",
      "Epoch 1079/2000, Train Loss: 0.001181683, Val Loss: 0.002322721, Val Accuracy: 97.55%, LR: 0.000100000\n",
      "Epoch 1080/2000, Train Loss: 0.000159069, Val Loss: 0.002572574, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1081/2000, Train Loss: 0.000140817, Val Loss: 0.002881478, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1082/2000, Train Loss: 0.000140260, Val Loss: 0.002920977, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1083/2000, Train Loss: 0.000134177, Val Loss: 0.002923733, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1084/2000, Train Loss: 0.000131734, Val Loss: 0.002982445, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1085/2000, Train Loss: 0.000138017, Val Loss: 0.003084010, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1086/2000, Train Loss: 0.000145021, Val Loss: 0.003408803, Val Accuracy: 97.72%, LR: 0.000100000\n",
      "Epoch 1087/2000, Train Loss: 0.001042514, Val Loss: 0.002168205, Val Accuracy: 97.73%, LR: 0.000100000\n",
      "Epoch 1088/2000, Train Loss: 0.000160282, Val Loss: 0.002680041, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1089/2000, Train Loss: 0.000141671, Val Loss: 0.002874763, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1090/2000, Train Loss: 0.000134318, Val Loss: 0.002854001, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1091/2000, Train Loss: 0.000132596, Val Loss: 0.002987238, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1092/2000, Train Loss: 0.000130711, Val Loss: 0.002973030, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1093/2000, Train Loss: 0.000128356, Val Loss: 0.002900968, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1094/2000, Train Loss: 0.000128672, Val Loss: 0.002950542, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1095/2000, Train Loss: 0.000128899, Val Loss: 0.003095309, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1096/2000, Train Loss: 0.000131827, Val Loss: 0.002798841, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1097/2000, Train Loss: 0.000134932, Val Loss: 0.003295801, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1098/2000, Train Loss: 0.000140450, Val Loss: 0.003051329, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1099/2000, Train Loss: 0.000124910, Val Loss: 0.003060471, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1100/2000, Train Loss: 0.000128309, Val Loss: 0.002727547, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1101/2000, Train Loss: 0.000139934, Val Loss: 0.002986713, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1102/2000, Train Loss: 0.000125321, Val Loss: 0.002953395, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1103/2000, Train Loss: 0.000136601, Val Loss: 0.003293148, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1104/2000, Train Loss: 0.000128335, Val Loss: 0.003188762, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1105/2000, Train Loss: 0.000126891, Val Loss: 0.003036440, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1106/2000, Train Loss: 0.000123322, Val Loss: 0.002954366, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1107/2000, Train Loss: 0.003829817, Val Loss: 0.007206488, Val Accuracy: 91.46%, LR: 0.000100000\n",
      "Epoch 1108/2000, Train Loss: 0.001409069, Val Loss: 0.002530923, Val Accuracy: 97.66%, LR: 0.000100000\n",
      "Epoch 1109/2000, Train Loss: 0.000246024, Val Loss: 0.002654948, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Epoch 1110/2000, Train Loss: 0.000303585, Val Loss: 0.003503526, Val Accuracy: 97.36%, LR: 0.000100000\n",
      "Epoch 1111/2000, Train Loss: 0.000597280, Val Loss: 0.002324073, Val Accuracy: 97.86%, LR: 0.000100000\n",
      "Epoch 1112/2000, Train Loss: 0.000182853, Val Loss: 0.002831371, Val Accuracy: 97.94%, LR: 0.000100000\n",
      "Epoch 1113/2000, Train Loss: 0.000151959, Val Loss: 0.002774929, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1114/2000, Train Loss: 0.000144710, Val Loss: 0.002794548, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1115/2000, Train Loss: 0.000142882, Val Loss: 0.002731175, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1116/2000, Train Loss: 0.000141151, Val Loss: 0.002833918, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1117/2000, Train Loss: 0.000135847, Val Loss: 0.002912592, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1118/2000, Train Loss: 0.000140383, Val Loss: 0.002925691, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1119/2000, Train Loss: 0.000133373, Val Loss: 0.002892073, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1120/2000, Train Loss: 0.000130203, Val Loss: 0.002913362, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1121/2000, Train Loss: 0.000129850, Val Loss: 0.003066451, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1122/2000, Train Loss: 0.000130446, Val Loss: 0.002923715, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1123/2000, Train Loss: 0.000130573, Val Loss: 0.002952146, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1124/2000, Train Loss: 0.000127107, Val Loss: 0.002995813, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1125/2000, Train Loss: 0.000129317, Val Loss: 0.003001462, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1126/2000, Train Loss: 0.000536757, Val Loss: 0.004379372, Val Accuracy: 96.54%, LR: 0.000100000\n",
      "Epoch 1127/2000, Train Loss: 0.001099833, Val Loss: 0.002073146, Val Accuracy: 97.58%, LR: 0.000100000\n",
      "Epoch 1128/2000, Train Loss: 0.000198011, Val Loss: 0.002550368, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1129/2000, Train Loss: 0.000147716, Val Loss: 0.002476578, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1130/2000, Train Loss: 0.000139342, Val Loss: 0.002691802, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1131/2000, Train Loss: 0.000135007, Val Loss: 0.002699055, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1132/2000, Train Loss: 0.000130122, Val Loss: 0.002718869, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1133/2000, Train Loss: 0.000130092, Val Loss: 0.002822511, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1134/2000, Train Loss: 0.000128536, Val Loss: 0.002851208, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1135/2000, Train Loss: 0.000135260, Val Loss: 0.003039444, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 1136/2000, Train Loss: 0.000128950, Val Loss: 0.002879241, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1137/2000, Train Loss: 0.000125094, Val Loss: 0.003005983, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1138/2000, Train Loss: 0.000121921, Val Loss: 0.002948836, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1139/2000, Train Loss: 0.000125269, Val Loss: 0.002916141, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1140/2000, Train Loss: 0.000124240, Val Loss: 0.003082189, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1141/2000, Train Loss: 0.000159068, Val Loss: 0.002972877, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1142/2000, Train Loss: 0.000278385, Val Loss: 0.003408921, Val Accuracy: 97.57%, LR: 0.000100000\n",
      "Epoch 1143/2000, Train Loss: 0.000160671, Val Loss: 0.002861113, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1144/2000, Train Loss: 0.000134837, Val Loss: 0.002858516, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1145/2000, Train Loss: 0.001308483, Val Loss: 0.003232272, Val Accuracy: 96.75%, LR: 0.000100000\n",
      "Epoch 1146/2000, Train Loss: 0.000346084, Val Loss: 0.002501940, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1147/2000, Train Loss: 0.000151470, Val Loss: 0.002760095, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1148/2000, Train Loss: 0.000139541, Val Loss: 0.002764463, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1149/2000, Train Loss: 0.000134959, Val Loss: 0.002802201, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1150/2000, Train Loss: 0.000130803, Val Loss: 0.002809583, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1151/2000, Train Loss: 0.000125681, Val Loss: 0.002921293, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1152/2000, Train Loss: 0.000130959, Val Loss: 0.002977626, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1153/2000, Train Loss: 0.000124197, Val Loss: 0.002878582, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1154/2000, Train Loss: 0.000120686, Val Loss: 0.002733455, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1155/2000, Train Loss: 0.000121625, Val Loss: 0.002959918, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1156/2000, Train Loss: 0.000123521, Val Loss: 0.003051861, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1157/2000, Train Loss: 0.000122167, Val Loss: 0.002984084, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1158/2000, Train Loss: 0.000119831, Val Loss: 0.002890204, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1159/2000, Train Loss: 0.000118582, Val Loss: 0.002937373, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1160/2000, Train Loss: 0.000116632, Val Loss: 0.003035884, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1161/2000, Train Loss: 0.000115460, Val Loss: 0.002976545, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1162/2000, Train Loss: 0.000896715, Val Loss: 0.003809604, Val Accuracy: 95.86%, LR: 0.000100000\n",
      "Epoch 1163/2000, Train Loss: 0.000361990, Val Loss: 0.002532457, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1164/2000, Train Loss: 0.000141651, Val Loss: 0.002525973, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1165/2000, Train Loss: 0.000129670, Val Loss: 0.002585702, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1166/2000, Train Loss: 0.000127697, Val Loss: 0.002553370, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1167/2000, Train Loss: 0.000120758, Val Loss: 0.002850716, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1168/2000, Train Loss: 0.000122099, Val Loss: 0.002879636, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1169/2000, Train Loss: 0.000119697, Val Loss: 0.002891854, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1170/2000, Train Loss: 0.000156045, Val Loss: 0.002903180, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1171/2000, Train Loss: 0.000116624, Val Loss: 0.002708539, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1172/2000, Train Loss: 0.000516664, Val Loss: 0.004547245, Val Accuracy: 95.95%, LR: 0.000100000\n",
      "Epoch 1173/2000, Train Loss: 0.001313078, Val Loss: 0.002397129, Val Accuracy: 97.85%, LR: 0.000100000\n",
      "Epoch 1174/2000, Train Loss: 0.000169697, Val Loss: 0.002433231, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1175/2000, Train Loss: 0.000139044, Val Loss: 0.002557684, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1176/2000, Train Loss: 0.000130765, Val Loss: 0.002626848, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1177/2000, Train Loss: 0.000127687, Val Loss: 0.002702433, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1178/2000, Train Loss: 0.000122007, Val Loss: 0.002610385, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1179/2000, Train Loss: 0.000121663, Val Loss: 0.002630133, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1180/2000, Train Loss: 0.000121921, Val Loss: 0.002917970, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1181/2000, Train Loss: 0.000121595, Val Loss: 0.002759332, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1182/2000, Train Loss: 0.000119978, Val Loss: 0.002913120, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1183/2000, Train Loss: 0.000116425, Val Loss: 0.002764608, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1184/2000, Train Loss: 0.000116889, Val Loss: 0.002931057, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1185/2000, Train Loss: 0.000116025, Val Loss: 0.002872166, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1186/2000, Train Loss: 0.000114213, Val Loss: 0.002902600, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1187/2000, Train Loss: 0.000116295, Val Loss: 0.002923798, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1188/2000, Train Loss: 0.000139728, Val Loss: 0.002929071, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1189/2000, Train Loss: 0.000127341, Val Loss: 0.002852311, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1190/2000, Train Loss: 0.001937845, Val Loss: 0.002254506, Val Accuracy: 97.35%, LR: 0.000100000\n",
      "Epoch 1191/2000, Train Loss: 0.000293328, Val Loss: 0.002421464, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1192/2000, Train Loss: 0.000148665, Val Loss: 0.002454946, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1193/2000, Train Loss: 0.000132020, Val Loss: 0.002607093, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1194/2000, Train Loss: 0.000130652, Val Loss: 0.002733788, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1195/2000, Train Loss: 0.000122612, Val Loss: 0.002731779, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1196/2000, Train Loss: 0.000124556, Val Loss: 0.002680984, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1197/2000, Train Loss: 0.000121927, Val Loss: 0.002790661, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1198/2000, Train Loss: 0.000122256, Val Loss: 0.002749097, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1199/2000, Train Loss: 0.000120697, Val Loss: 0.002792383, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1200/2000, Train Loss: 0.000116526, Val Loss: 0.002692548, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1201/2000, Train Loss: 0.000115857, Val Loss: 0.002938493, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1202/2000, Train Loss: 0.000116141, Val Loss: 0.002773491, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1203/2000, Train Loss: 0.000968690, Val Loss: 0.002770923, Val Accuracy: 97.51%, LR: 0.000100000\n",
      "Epoch 1204/2000, Train Loss: 0.000191151, Val Loss: 0.002687278, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1205/2000, Train Loss: 0.000129442, Val Loss: 0.002637995, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1206/2000, Train Loss: 0.000124232, Val Loss: 0.002793151, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1207/2000, Train Loss: 0.000119211, Val Loss: 0.002779874, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1208/2000, Train Loss: 0.000116455, Val Loss: 0.002776278, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1209/2000, Train Loss: 0.000117680, Val Loss: 0.002802858, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1210/2000, Train Loss: 0.000115291, Val Loss: 0.002877378, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1211/2000, Train Loss: 0.000114348, Val Loss: 0.002780963, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1212/2000, Train Loss: 0.000114642, Val Loss: 0.002757966, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1213/2000, Train Loss: 0.000114274, Val Loss: 0.002699949, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1214/2000, Train Loss: 0.000112095, Val Loss: 0.002813774, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1215/2000, Train Loss: 0.000133566, Val Loss: 0.002870647, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1216/2000, Train Loss: 0.000115885, Val Loss: 0.002857396, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1217/2000, Train Loss: 0.000114489, Val Loss: 0.003012120, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1218/2000, Train Loss: 0.000108192, Val Loss: 0.002924477, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1219/2000, Train Loss: 0.000109656, Val Loss: 0.002950313, Val Accuracy: 97.93%, LR: 0.000100000\n",
      "Epoch 1220/2000, Train Loss: 0.000126080, Val Loss: 0.003112670, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1221/2000, Train Loss: 0.000151019, Val Loss: 0.003117621, Val Accuracy: 96.87%, LR: 0.000100000\n",
      "Epoch 1222/2000, Train Loss: 0.001363874, Val Loss: 0.002232800, Val Accuracy: 97.78%, LR: 0.000100000\n",
      "Epoch 1223/2000, Train Loss: 0.000142707, Val Loss: 0.002786900, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1224/2000, Train Loss: 0.000123355, Val Loss: 0.002665119, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1225/2000, Train Loss: 0.000117999, Val Loss: 0.002708561, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1226/2000, Train Loss: 0.000113612, Val Loss: 0.002781971, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1227/2000, Train Loss: 0.000112779, Val Loss: 0.002860911, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1228/2000, Train Loss: 0.000118615, Val Loss: 0.002779216, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1229/2000, Train Loss: 0.000109727, Val Loss: 0.002754330, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1230/2000, Train Loss: 0.000109251, Val Loss: 0.002902913, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1231/2000, Train Loss: 0.000106293, Val Loss: 0.002826998, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1232/2000, Train Loss: 0.000108667, Val Loss: 0.002863435, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1233/2000, Train Loss: 0.000108343, Val Loss: 0.002846883, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1234/2000, Train Loss: 0.000139384, Val Loss: 0.006431203, Val Accuracy: 94.93%, LR: 0.000100000\n",
      "Epoch 1235/2000, Train Loss: 0.002644537, Val Loss: 0.002145231, Val Accuracy: 97.81%, LR: 0.000100000\n",
      "Epoch 1236/2000, Train Loss: 0.000185973, Val Loss: 0.002590253, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1237/2000, Train Loss: 0.000143677, Val Loss: 0.002582440, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1238/2000, Train Loss: 0.000128263, Val Loss: 0.002579774, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1239/2000, Train Loss: 0.000123761, Val Loss: 0.002751750, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1240/2000, Train Loss: 0.000118290, Val Loss: 0.002683578, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1241/2000, Train Loss: 0.000116652, Val Loss: 0.002688402, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1242/2000, Train Loss: 0.000116874, Val Loss: 0.002764928, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1243/2000, Train Loss: 0.000118045, Val Loss: 0.002613289, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1244/2000, Train Loss: 0.000115124, Val Loss: 0.002803833, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1245/2000, Train Loss: 0.000113441, Val Loss: 0.002965022, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1246/2000, Train Loss: 0.000110796, Val Loss: 0.002854338, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1247/2000, Train Loss: 0.000116692, Val Loss: 0.002834632, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1248/2000, Train Loss: 0.000108324, Val Loss: 0.002850968, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1249/2000, Train Loss: 0.000115472, Val Loss: 0.002978885, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1250/2000, Train Loss: 0.000109040, Val Loss: 0.002994338, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1251/2000, Train Loss: 0.000141660, Val Loss: 0.002755350, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1252/2000, Train Loss: 0.000127861, Val Loss: 0.002780443, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1253/2000, Train Loss: 0.000111617, Val Loss: 0.002941317, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1254/2000, Train Loss: 0.000105453, Val Loss: 0.002826267, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1255/2000, Train Loss: 0.002057233, Val Loss: 0.001888636, Val Accuracy: 97.00%, LR: 0.000100000\n",
      "Epoch 1256/2000, Train Loss: 0.000345739, Val Loss: 0.002029057, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 1257/2000, Train Loss: 0.000147429, Val Loss: 0.002316874, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1258/2000, Train Loss: 0.000127087, Val Loss: 0.002384227, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1259/2000, Train Loss: 0.000118961, Val Loss: 0.002508882, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1260/2000, Train Loss: 0.000117716, Val Loss: 0.002605171, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1261/2000, Train Loss: 0.000118425, Val Loss: 0.002484652, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1262/2000, Train Loss: 0.000109963, Val Loss: 0.002541522, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1263/2000, Train Loss: 0.000123761, Val Loss: 0.002565478, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1264/2000, Train Loss: 0.000115647, Val Loss: 0.002498689, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1265/2000, Train Loss: 0.000119163, Val Loss: 0.002551703, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1266/2000, Train Loss: 0.000109239, Val Loss: 0.002721713, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1267/2000, Train Loss: 0.000106070, Val Loss: 0.002640630, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1268/2000, Train Loss: 0.000105164, Val Loss: 0.002789409, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1269/2000, Train Loss: 0.000116181, Val Loss: 0.002538303, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 1270/2000, Train Loss: 0.000118642, Val Loss: 0.002743249, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1271/2000, Train Loss: 0.000118487, Val Loss: 0.002840127, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1272/2000, Train Loss: 0.000129140, Val Loss: 0.003124028, Val Accuracy: 97.86%, LR: 0.000100000\n",
      "Epoch 1273/2000, Train Loss: 0.000121164, Val Loss: 0.002891358, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1274/2000, Train Loss: 0.000106430, Val Loss: 0.002749099, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1275/2000, Train Loss: 0.000104916, Val Loss: 0.002736643, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1276/2000, Train Loss: 0.000102804, Val Loss: 0.002625289, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1277/2000, Train Loss: 0.000107209, Val Loss: 0.002863722, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1278/2000, Train Loss: 0.000112590, Val Loss: 0.002973335, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1279/2000, Train Loss: 0.003515949, Val Loss: 0.002890969, Val Accuracy: 97.33%, LR: 0.000100000\n",
      "Epoch 1280/2000, Train Loss: 0.000760136, Val Loss: 0.002193781, Val Accuracy: 97.31%, LR: 0.000100000\n",
      "Epoch 1281/2000, Train Loss: 0.000212155, Val Loss: 0.002466603, Val Accuracy: 97.89%, LR: 0.000100000\n",
      "Epoch 1282/2000, Train Loss: 0.000141178, Val Loss: 0.002548990, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 1283/2000, Train Loss: 0.000126781, Val Loss: 0.002540661, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1284/2000, Train Loss: 0.000122712, Val Loss: 0.002583837, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1285/2000, Train Loss: 0.000116538, Val Loss: 0.002668545, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1286/2000, Train Loss: 0.000115907, Val Loss: 0.002714863, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1287/2000, Train Loss: 0.000114457, Val Loss: 0.002706043, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1288/2000, Train Loss: 0.000111294, Val Loss: 0.002680271, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1289/2000, Train Loss: 0.000114825, Val Loss: 0.002767060, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1290/2000, Train Loss: 0.000110777, Val Loss: 0.002719975, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1291/2000, Train Loss: 0.000107662, Val Loss: 0.002828967, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1292/2000, Train Loss: 0.000115607, Val Loss: 0.002858312, Val Accuracy: 97.90%, LR: 0.000100000\n",
      "Epoch 1293/2000, Train Loss: 0.000124193, Val Loss: 0.002705421, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1294/2000, Train Loss: 0.000113973, Val Loss: 0.002707554, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1295/2000, Train Loss: 0.000114573, Val Loss: 0.002695367, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1296/2000, Train Loss: 0.000103040, Val Loss: 0.002717445, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1297/2000, Train Loss: 0.000130601, Val Loss: 0.002704959, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Epoch 1298/2000, Train Loss: 0.000154804, Val Loss: 0.002666511, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1299/2000, Train Loss: 0.000447650, Val Loss: 0.002391726, Val Accuracy: 97.61%, LR: 0.000100000\n",
      "Epoch 1300/2000, Train Loss: 0.000172628, Val Loss: 0.002673754, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1301/2000, Train Loss: 0.000107634, Val Loss: 0.002809984, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1302/2000, Train Loss: 0.000104421, Val Loss: 0.002667811, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1303/2000, Train Loss: 0.000106630, Val Loss: 0.002844247, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1304/2000, Train Loss: 0.000111451, Val Loss: 0.002791729, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1305/2000, Train Loss: 0.000104774, Val Loss: 0.002780763, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1306/2000, Train Loss: 0.000105340, Val Loss: 0.002879149, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1307/2000, Train Loss: 0.000104600, Val Loss: 0.002834986, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1308/2000, Train Loss: 0.000100253, Val Loss: 0.002837245, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1309/2000, Train Loss: 0.000099497, Val Loss: 0.002814995, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1310/2000, Train Loss: 0.000100247, Val Loss: 0.002940178, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1311/2000, Train Loss: 0.003535378, Val Loss: 0.002111379, Val Accuracy: 96.56%, LR: 0.000100000\n",
      "Epoch 1312/2000, Train Loss: 0.000398977, Val Loss: 0.002068550, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 1313/2000, Train Loss: 0.000161474, Val Loss: 0.002085874, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1314/2000, Train Loss: 0.000133235, Val Loss: 0.002221840, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1315/2000, Train Loss: 0.000125752, Val Loss: 0.002254427, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1316/2000, Train Loss: 0.000116642, Val Loss: 0.002299639, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1317/2000, Train Loss: 0.000117693, Val Loss: 0.002480221, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1318/2000, Train Loss: 0.000111681, Val Loss: 0.002416204, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1319/2000, Train Loss: 0.000108185, Val Loss: 0.002457379, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1320/2000, Train Loss: 0.000108051, Val Loss: 0.002494083, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1321/2000, Train Loss: 0.000105440, Val Loss: 0.002485287, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1322/2000, Train Loss: 0.000104965, Val Loss: 0.002551308, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1323/2000, Train Loss: 0.000111527, Val Loss: 0.002651759, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1324/2000, Train Loss: 0.000110064, Val Loss: 0.002577967, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1325/2000, Train Loss: 0.000631804, Val Loss: 0.002621172, Val Accuracy: 97.66%, LR: 0.000100000\n",
      "Epoch 1326/2000, Train Loss: 0.000761221, Val Loss: 0.002382415, Val Accuracy: 97.82%, LR: 0.000100000\n",
      "Epoch 1327/2000, Train Loss: 0.000155700, Val Loss: 0.002359278, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1328/2000, Train Loss: 0.000126801, Val Loss: 0.002459182, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1329/2000, Train Loss: 0.000114023, Val Loss: 0.002480410, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1330/2000, Train Loss: 0.000108583, Val Loss: 0.002505375, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1331/2000, Train Loss: 0.000109463, Val Loss: 0.002561131, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1332/2000, Train Loss: 0.000107044, Val Loss: 0.002489067, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1333/2000, Train Loss: 0.000103791, Val Loss: 0.002649152, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1334/2000, Train Loss: 0.000103030, Val Loss: 0.002629129, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1335/2000, Train Loss: 0.000106842, Val Loss: 0.002610516, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1336/2000, Train Loss: 0.000102460, Val Loss: 0.002614253, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1337/2000, Train Loss: 0.000313224, Val Loss: 0.003259842, Val Accuracy: 97.42%, LR: 0.000100000\n",
      "Epoch 1338/2000, Train Loss: 0.000726672, Val Loss: 0.002458609, Val Accuracy: 97.45%, LR: 0.000100000\n",
      "Epoch 1339/2000, Train Loss: 0.000178591, Val Loss: 0.002453246, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 1340/2000, Train Loss: 0.000123779, Val Loss: 0.002506448, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1341/2000, Train Loss: 0.000108688, Val Loss: 0.002494603, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1342/2000, Train Loss: 0.000106150, Val Loss: 0.002688634, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1343/2000, Train Loss: 0.000103365, Val Loss: 0.002610189, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1344/2000, Train Loss: 0.000102497, Val Loss: 0.002635247, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1345/2000, Train Loss: 0.000100624, Val Loss: 0.002647602, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1346/2000, Train Loss: 0.000111495, Val Loss: 0.002945045, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 1347/2000, Train Loss: 0.000109543, Val Loss: 0.002662081, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1348/2000, Train Loss: 0.000101356, Val Loss: 0.002841543, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1349/2000, Train Loss: 0.000108179, Val Loss: 0.002632130, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1350/2000, Train Loss: 0.000099299, Val Loss: 0.002727095, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1351/2000, Train Loss: 0.000099798, Val Loss: 0.002726846, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1352/2000, Train Loss: 0.000104330, Val Loss: 0.002812219, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1353/2000, Train Loss: 0.000095612, Val Loss: 0.002715543, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1354/2000, Train Loss: 0.000102037, Val Loss: 0.002715864, Val Accuracy: 97.87%, LR: 0.000100000\n",
      "Epoch 1355/2000, Train Loss: 0.001051575, Val Loss: 0.002442527, Val Accuracy: 96.47%, LR: 0.000100000\n",
      "Epoch 1356/2000, Train Loss: 0.000458845, Val Loss: 0.002148289, Val Accuracy: 97.89%, LR: 0.000100000\n",
      "Epoch 1357/2000, Train Loss: 0.000126594, Val Loss: 0.002548188, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1358/2000, Train Loss: 0.000111512, Val Loss: 0.002381549, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1359/2000, Train Loss: 0.000104891, Val Loss: 0.002507614, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1360/2000, Train Loss: 0.000103082, Val Loss: 0.002553384, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1361/2000, Train Loss: 0.000099363, Val Loss: 0.002699695, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1362/2000, Train Loss: 0.000101092, Val Loss: 0.002733185, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1363/2000, Train Loss: 0.000097765, Val Loss: 0.002670252, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1364/2000, Train Loss: 0.000095923, Val Loss: 0.002724548, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1365/2000, Train Loss: 0.000094999, Val Loss: 0.002636942, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1366/2000, Train Loss: 0.000094244, Val Loss: 0.002615226, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1367/2000, Train Loss: 0.000099833, Val Loss: 0.002790600, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1368/2000, Train Loss: 0.000095616, Val Loss: 0.002716786, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 1369/2000, Train Loss: 0.000100071, Val Loss: 0.002935703, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1370/2000, Train Loss: 0.000096324, Val Loss: 0.002921824, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1371/2000, Train Loss: 0.000093996, Val Loss: 0.002896870, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1372/2000, Train Loss: 0.000096506, Val Loss: 0.002819296, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1373/2000, Train Loss: 0.000803578, Val Loss: 0.003462584, Val Accuracy: 96.39%, LR: 0.000100000\n",
      "Epoch 1374/2000, Train Loss: 0.000399947, Val Loss: 0.002393633, Val Accuracy: 97.93%, LR: 0.000100000\n",
      "Epoch 1375/2000, Train Loss: 0.000114604, Val Loss: 0.002500009, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1376/2000, Train Loss: 0.000103208, Val Loss: 0.002556964, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1377/2000, Train Loss: 0.000098709, Val Loss: 0.002588792, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1378/2000, Train Loss: 0.000096170, Val Loss: 0.002674997, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1379/2000, Train Loss: 0.000096133, Val Loss: 0.002740078, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1380/2000, Train Loss: 0.000095192, Val Loss: 0.002684753, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1381/2000, Train Loss: 0.000093217, Val Loss: 0.002906937, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1382/2000, Train Loss: 0.000479851, Val Loss: 0.007798961, Val Accuracy: 93.75%, LR: 0.000100000\n",
      "Epoch 1383/2000, Train Loss: 0.000757716, Val Loss: 0.002584774, Val Accuracy: 97.85%, LR: 0.000100000\n",
      "Epoch 1384/2000, Train Loss: 0.000130912, Val Loss: 0.002643568, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1385/2000, Train Loss: 0.000106178, Val Loss: 0.002614404, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1386/2000, Train Loss: 0.000102413, Val Loss: 0.002593894, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1387/2000, Train Loss: 0.000098472, Val Loss: 0.002774671, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1388/2000, Train Loss: 0.000096506, Val Loss: 0.002706829, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1389/2000, Train Loss: 0.000094517, Val Loss: 0.002676214, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1390/2000, Train Loss: 0.000093391, Val Loss: 0.002799504, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1391/2000, Train Loss: 0.000094194, Val Loss: 0.002710437, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1392/2000, Train Loss: 0.000092232, Val Loss: 0.002709595, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1393/2000, Train Loss: 0.000096133, Val Loss: 0.002776883, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1394/2000, Train Loss: 0.000094195, Val Loss: 0.002779797, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1395/2000, Train Loss: 0.000089782, Val Loss: 0.002836657, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1396/2000, Train Loss: 0.000089687, Val Loss: 0.002871432, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1397/2000, Train Loss: 0.000089901, Val Loss: 0.002901169, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 1398/2000, Train Loss: 0.000090498, Val Loss: 0.002844025, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1399/2000, Train Loss: 0.000119153, Val Loss: 0.002811186, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 1400/2000, Train Loss: 0.000091893, Val Loss: 0.002851881, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1401/2000, Train Loss: 0.000088053, Val Loss: 0.002742340, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1402/2000, Train Loss: 0.000088860, Val Loss: 0.002827190, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 1403/2000, Train Loss: 0.000088198, Val Loss: 0.002861714, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1404/2000, Train Loss: 0.000094884, Val Loss: 0.002965512, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 1405/2000, Train Loss: 0.000090204, Val Loss: 0.002848624, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 1406/2000, Train Loss: 0.000108597, Val Loss: 0.002914798, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 1407/2000, Train Loss: 0.000085736, Val Loss: 0.002995852, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1408/2000, Train Loss: 0.000092665, Val Loss: 0.002899184, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1409/2000, Train Loss: 0.000085708, Val Loss: 0.003012018, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1410/2000, Train Loss: 0.001027664, Val Loss: 0.001682834, Val Accuracy: 97.30%, LR: 0.000100000\n",
      "Epoch 1411/2000, Train Loss: 0.000184478, Val Loss: 0.002463036, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 1412/2000, Train Loss: 0.000098932, Val Loss: 0.002598205, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1413/2000, Train Loss: 0.000093138, Val Loss: 0.002635983, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1414/2000, Train Loss: 0.000091935, Val Loss: 0.002607677, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1415/2000, Train Loss: 0.000088347, Val Loss: 0.002727290, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1416/2000, Train Loss: 0.000091301, Val Loss: 0.002653190, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1417/2000, Train Loss: 0.000086023, Val Loss: 0.002730964, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1418/2000, Train Loss: 0.000087784, Val Loss: 0.002762053, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1419/2000, Train Loss: 0.000094024, Val Loss: 0.002801968, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 1420/2000, Train Loss: 0.000085767, Val Loss: 0.002842790, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1421/2000, Train Loss: 0.000085349, Val Loss: 0.002835705, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1422/2000, Train Loss: 0.000085233, Val Loss: 0.002953279, Val Accuracy: 97.97%, LR: 0.000100000\n",
      "Epoch 1423/2000, Train Loss: 0.000090287, Val Loss: 0.002841613, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1424/2000, Train Loss: 0.000083075, Val Loss: 0.002861282, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1425/2000, Train Loss: 0.000085455, Val Loss: 0.003013695, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 1426/2000, Train Loss: 0.000092848, Val Loss: 0.002848530, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1427/2000, Train Loss: 0.000083430, Val Loss: 0.002951129, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1428/2000, Train Loss: 0.001947351, Val Loss: 0.017592006, Val Accuracy: 84.26%, LR: 0.000100000\n",
      "Epoch 1429/2000, Train Loss: 0.002481381, Val Loss: 0.002184543, Val Accuracy: 97.56%, LR: 0.000100000\n",
      "Epoch 1430/2000, Train Loss: 0.000242543, Val Loss: 0.002331609, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1431/2000, Train Loss: 0.000167897, Val Loss: 0.002500069, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 1432/2000, Train Loss: 0.000133176, Val Loss: 0.002488665, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1433/2000, Train Loss: 0.000112817, Val Loss: 0.002613162, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1434/2000, Train Loss: 0.000105766, Val Loss: 0.002593355, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1435/2000, Train Loss: 0.000113015, Val Loss: 0.002589382, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1436/2000, Train Loss: 0.000099176, Val Loss: 0.002771567, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1437/2000, Train Loss: 0.000140800, Val Loss: 0.002525889, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Epoch 1438/2000, Train Loss: 0.000101988, Val Loss: 0.002602587, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1439/2000, Train Loss: 0.000975525, Val Loss: 0.003911631, Val Accuracy: 96.16%, LR: 0.000100000\n",
      "Epoch 1440/2000, Train Loss: 0.000403915, Val Loss: 0.002167963, Val Accuracy: 97.81%, LR: 0.000100000\n",
      "Epoch 1441/2000, Train Loss: 0.000119788, Val Loss: 0.002409971, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1442/2000, Train Loss: 0.000105033, Val Loss: 0.002389134, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1443/2000, Train Loss: 0.000102279, Val Loss: 0.002505096, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1444/2000, Train Loss: 0.000096776, Val Loss: 0.002517170, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1445/2000, Train Loss: 0.000096942, Val Loss: 0.002540766, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1446/2000, Train Loss: 0.000093552, Val Loss: 0.002598027, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1447/2000, Train Loss: 0.000090115, Val Loss: 0.002641524, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1448/2000, Train Loss: 0.000091354, Val Loss: 0.002604307, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1449/2000, Train Loss: 0.000092474, Val Loss: 0.002735006, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1450/2000, Train Loss: 0.000090059, Val Loss: 0.002587682, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1451/2000, Train Loss: 0.000091278, Val Loss: 0.002699939, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1452/2000, Train Loss: 0.000088076, Val Loss: 0.002674084, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1453/2000, Train Loss: 0.000085551, Val Loss: 0.002682283, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1454/2000, Train Loss: 0.000084986, Val Loss: 0.002673834, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1455/2000, Train Loss: 0.000083901, Val Loss: 0.002677701, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1456/2000, Train Loss: 0.000086817, Val Loss: 0.002662772, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1457/2000, Train Loss: 0.000089352, Val Loss: 0.002704651, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1458/2000, Train Loss: 0.000082851, Val Loss: 0.002696526, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1459/2000, Train Loss: 0.000084338, Val Loss: 0.002778718, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1460/2000, Train Loss: 0.000092635, Val Loss: 0.002653794, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Epoch 1461/2000, Train Loss: 0.000094391, Val Loss: 0.002714130, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1462/2000, Train Loss: 0.000082865, Val Loss: 0.002736939, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1463/2000, Train Loss: 0.000087694, Val Loss: 0.002872135, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1464/2000, Train Loss: 0.000082589, Val Loss: 0.002827770, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1465/2000, Train Loss: 0.000088249, Val Loss: 0.002907770, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1466/2000, Train Loss: 0.000083896, Val Loss: 0.002893243, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1467/2000, Train Loss: 0.000094343, Val Loss: 0.002771837, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1468/2000, Train Loss: 0.000081334, Val Loss: 0.002874984, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1469/2000, Train Loss: 0.000087037, Val Loss: 0.002845641, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1470/2000, Train Loss: 0.001630307, Val Loss: 0.002101170, Val Accuracy: 96.79%, LR: 0.000100000\n",
      "Epoch 1471/2000, Train Loss: 0.000234159, Val Loss: 0.002136541, Val Accuracy: 97.83%, LR: 0.000100000\n",
      "Epoch 1472/2000, Train Loss: 0.000111085, Val Loss: 0.002747850, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1473/2000, Train Loss: 0.000101989, Val Loss: 0.002587536, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1474/2000, Train Loss: 0.000095709, Val Loss: 0.002629475, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1475/2000, Train Loss: 0.000088042, Val Loss: 0.002569467, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1476/2000, Train Loss: 0.000089240, Val Loss: 0.002626650, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1477/2000, Train Loss: 0.000097842, Val Loss: 0.002630896, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1478/2000, Train Loss: 0.000084409, Val Loss: 0.002662068, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1479/2000, Train Loss: 0.000131804, Val Loss: 0.002610964, Val Accuracy: 97.93%, LR: 0.000100000\n",
      "Epoch 1480/2000, Train Loss: 0.000754746, Val Loss: 0.002283978, Val Accuracy: 97.84%, LR: 0.000100000\n",
      "Epoch 1481/2000, Train Loss: 0.000107979, Val Loss: 0.002541867, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1482/2000, Train Loss: 0.000093820, Val Loss: 0.002691031, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1483/2000, Train Loss: 0.000089536, Val Loss: 0.002619918, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1484/2000, Train Loss: 0.000087691, Val Loss: 0.002729363, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1485/2000, Train Loss: 0.000086745, Val Loss: 0.002633836, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1486/2000, Train Loss: 0.000084473, Val Loss: 0.002658280, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1487/2000, Train Loss: 0.000084136, Val Loss: 0.002758355, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1488/2000, Train Loss: 0.000084165, Val Loss: 0.002707938, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1489/2000, Train Loss: 0.000082863, Val Loss: 0.002814087, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1490/2000, Train Loss: 0.000084185, Val Loss: 0.002927718, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1491/2000, Train Loss: 0.000907416, Val Loss: 0.002391961, Val Accuracy: 97.97%, LR: 0.000100000\n",
      "Epoch 1492/2000, Train Loss: 0.000105904, Val Loss: 0.002420245, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1493/2000, Train Loss: 0.000093564, Val Loss: 0.002606484, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1494/2000, Train Loss: 0.000089848, Val Loss: 0.002549243, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1495/2000, Train Loss: 0.000085734, Val Loss: 0.002697051, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1496/2000, Train Loss: 0.000084256, Val Loss: 0.002717686, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1497/2000, Train Loss: 0.000081605, Val Loss: 0.002654675, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1498/2000, Train Loss: 0.000081519, Val Loss: 0.002714121, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1499/2000, Train Loss: 0.000081076, Val Loss: 0.002688762, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1500/2000, Train Loss: 0.000079759, Val Loss: 0.002617252, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1501/2000, Train Loss: 0.000080228, Val Loss: 0.002761942, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1502/2000, Train Loss: 0.000082464, Val Loss: 0.002873028, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1503/2000, Train Loss: 0.000093608, Val Loss: 0.002768445, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1504/2000, Train Loss: 0.000083203, Val Loss: 0.002921327, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1505/2000, Train Loss: 0.000088087, Val Loss: 0.002845035, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1506/2000, Train Loss: 0.000077422, Val Loss: 0.002911016, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1507/2000, Train Loss: 0.000080378, Val Loss: 0.002969728, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1508/2000, Train Loss: 0.000082634, Val Loss: 0.002818437, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1509/2000, Train Loss: 0.000082122, Val Loss: 0.003026348, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1510/2000, Train Loss: 0.001363889, Val Loss: 0.002407910, Val Accuracy: 97.34%, LR: 0.000100000\n",
      "Epoch 1511/2000, Train Loss: 0.000189545, Val Loss: 0.002414679, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1512/2000, Train Loss: 0.000096971, Val Loss: 0.002454699, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1513/2000, Train Loss: 0.000089270, Val Loss: 0.002536939, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1514/2000, Train Loss: 0.000084835, Val Loss: 0.002646438, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1515/2000, Train Loss: 0.000083431, Val Loss: 0.002628010, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1516/2000, Train Loss: 0.000083537, Val Loss: 0.002654730, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1517/2000, Train Loss: 0.000079830, Val Loss: 0.002657375, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1518/2000, Train Loss: 0.000088089, Val Loss: 0.002757465, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1519/2000, Train Loss: 0.000080073, Val Loss: 0.002699500, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1520/2000, Train Loss: 0.000083013, Val Loss: 0.002693386, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1521/2000, Train Loss: 0.000079441, Val Loss: 0.002723177, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1522/2000, Train Loss: 0.000076190, Val Loss: 0.002741806, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1523/2000, Train Loss: 0.000078458, Val Loss: 0.002790748, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1524/2000, Train Loss: 0.000078736, Val Loss: 0.002776023, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1525/2000, Train Loss: 0.000081067, Val Loss: 0.002786051, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1526/2000, Train Loss: 0.000075205, Val Loss: 0.002892229, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1527/2000, Train Loss: 0.000075877, Val Loss: 0.002821630, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1528/2000, Train Loss: 0.000077868, Val Loss: 0.002950259, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1529/2000, Train Loss: 0.000078021, Val Loss: 0.002974918, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1530/2000, Train Loss: 0.000084488, Val Loss: 0.002964452, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1531/2000, Train Loss: 0.000075954, Val Loss: 0.003086418, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1532/2000, Train Loss: 0.000076388, Val Loss: 0.002849007, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 1533/2000, Train Loss: 0.000078118, Val Loss: 0.002833517, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1534/2000, Train Loss: 0.000074781, Val Loss: 0.002866845, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1535/2000, Train Loss: 0.001355080, Val Loss: 0.004256838, Val Accuracy: 94.16%, LR: 0.000100000\n",
      "Epoch 1536/2000, Train Loss: 0.000992151, Val Loss: 0.002218132, Val Accuracy: 97.59%, LR: 0.000100000\n",
      "Epoch 1537/2000, Train Loss: 0.000135467, Val Loss: 0.002447019, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Epoch 1538/2000, Train Loss: 0.000097809, Val Loss: 0.002520194, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1539/2000, Train Loss: 0.000090009, Val Loss: 0.002621054, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1540/2000, Train Loss: 0.000086160, Val Loss: 0.002666009, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1541/2000, Train Loss: 0.000086257, Val Loss: 0.002688425, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1542/2000, Train Loss: 0.000086330, Val Loss: 0.002828720, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1543/2000, Train Loss: 0.000085173, Val Loss: 0.002678688, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1544/2000, Train Loss: 0.000078892, Val Loss: 0.002743885, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1545/2000, Train Loss: 0.000084143, Val Loss: 0.002770872, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1546/2000, Train Loss: 0.000077646, Val Loss: 0.002756999, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1547/2000, Train Loss: 0.000076502, Val Loss: 0.002819769, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1548/2000, Train Loss: 0.000075536, Val Loss: 0.002707958, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1549/2000, Train Loss: 0.000076579, Val Loss: 0.002772268, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1550/2000, Train Loss: 0.000074586, Val Loss: 0.002786505, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1551/2000, Train Loss: 0.000075698, Val Loss: 0.002694022, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1552/2000, Train Loss: 0.000082350, Val Loss: 0.002827671, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1553/2000, Train Loss: 0.000077001, Val Loss: 0.002766227, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1554/2000, Train Loss: 0.000075765, Val Loss: 0.002977715, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1555/2000, Train Loss: 0.000082199, Val Loss: 0.002830214, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1556/2000, Train Loss: 0.000073895, Val Loss: 0.002706281, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1557/2000, Train Loss: 0.000073064, Val Loss: 0.002849483, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1558/2000, Train Loss: 0.000071923, Val Loss: 0.002888632, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1559/2000, Train Loss: 0.000075015, Val Loss: 0.002823922, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1560/2000, Train Loss: 0.001823298, Val Loss: 0.002340582, Val Accuracy: 96.87%, LR: 0.000100000\n",
      "Epoch 1561/2000, Train Loss: 0.000552147, Val Loss: 0.003773540, Val Accuracy: 97.50%, LR: 0.000100000\n",
      "Epoch 1562/2000, Train Loss: 0.000241150, Val Loss: 0.003176251, Val Accuracy: 97.87%, LR: 0.000100000\n",
      "Epoch 1563/2000, Train Loss: 0.000176816, Val Loss: 0.002757054, Val Accuracy: 97.98%, LR: 0.000100000\n",
      "Epoch 1564/2000, Train Loss: 0.000512356, Val Loss: 0.004939118, Val Accuracy: 96.05%, LR: 0.000100000\n",
      "Epoch 1565/2000, Train Loss: 0.000332713, Val Loss: 0.002816793, Val Accuracy: 97.86%, LR: 0.000100000\n",
      "Epoch 1566/2000, Train Loss: 0.000154957, Val Loss: 0.002639903, Val Accuracy: 97.97%, LR: 0.000100000\n",
      "Epoch 1567/2000, Train Loss: 0.000137437, Val Loss: 0.002650248, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 1568/2000, Train Loss: 0.000134449, Val Loss: 0.002842494, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1569/2000, Train Loss: 0.000118208, Val Loss: 0.002814217, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1570/2000, Train Loss: 0.000120919, Val Loss: 0.002930036, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1571/2000, Train Loss: 0.000111108, Val Loss: 0.002974782, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1572/2000, Train Loss: 0.000104005, Val Loss: 0.003076927, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 1573/2000, Train Loss: 0.000110419, Val Loss: 0.002844984, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1574/2000, Train Loss: 0.000087280, Val Loss: 0.002822115, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.20%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_853.pth\n",
      "Model saved after epoch 1574 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1574.pth \n",
      "\n",
      "Epoch 1575/2000, Train Loss: 0.000082429, Val Loss: 0.002916599, Val Accuracy: 98.25%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.20%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_891.pth\n",
      "Model saved after epoch 1575 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1575.pth \n",
      "\n",
      "Epoch 1576/2000, Train Loss: 0.000080005, Val Loss: 0.002937514, Val Accuracy: 98.26%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.21%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1019.pth\n",
      "Model saved after epoch 1576 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1576.pth \n",
      "\n",
      "Epoch 1577/2000, Train Loss: 0.000079995, Val Loss: 0.002801883, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1578/2000, Train Loss: 0.000080274, Val Loss: 0.002932368, Val Accuracy: 98.30%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.21%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1574.pth\n",
      "Model saved after epoch 1578 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1578.pth \n",
      "\n",
      "Epoch 1579/2000, Train Loss: 0.000079309, Val Loss: 0.002847831, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1580/2000, Train Loss: 0.000079226, Val Loss: 0.002841492, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1581/2000, Train Loss: 0.000080132, Val Loss: 0.002912208, Val Accuracy: 98.26%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.22%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_988.pth\n",
      "Model saved after epoch 1581 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1581.pth \n",
      "\n",
      "Epoch 1582/2000, Train Loss: 0.000078301, Val Loss: 0.002782125, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1583/2000, Train Loss: 0.000076208, Val Loss: 0.002946701, Val Accuracy: 98.29%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.23%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_989.pth\n",
      "Model saved after epoch 1583 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1583.pth \n",
      "\n",
      "Epoch 1584/2000, Train Loss: 0.000074760, Val Loss: 0.002929529, Val Accuracy: 98.31%, LR: 0.000100000\n",
      "Removed old model with accuracy 98.25%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1575.pth\n",
      "Model saved after epoch 1584 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1584.pth \n",
      "\n",
      "Epoch 1585/2000, Train Loss: 0.000074335, Val Loss: 0.002886648, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1586/2000, Train Loss: 0.000073778, Val Loss: 0.002826556, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1587/2000, Train Loss: 0.002578150, Val Loss: 0.007121645, Val Accuracy: 88.50%, LR: 0.000100000\n",
      "Epoch 1588/2000, Train Loss: 0.002845848, Val Loss: 0.001876820, Val Accuracy: 97.82%, LR: 0.000100000\n",
      "Epoch 1589/2000, Train Loss: 0.000241159, Val Loss: 0.002262713, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1590/2000, Train Loss: 0.000130354, Val Loss: 0.002454389, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1591/2000, Train Loss: 0.000108187, Val Loss: 0.002509865, Val Accuracy: 98.23%, LR: 0.000100000\n",
      "Epoch 1592/2000, Train Loss: 0.000096860, Val Loss: 0.002642467, Val Accuracy: 98.24%, LR: 0.000100000\n",
      "Epoch 1593/2000, Train Loss: 0.000090745, Val Loss: 0.002635037, Val Accuracy: 98.24%, LR: 0.000100000\n",
      "Epoch 1594/2000, Train Loss: 0.000088470, Val Loss: 0.002636777, Val Accuracy: 98.23%, LR: 0.000100000\n",
      "Epoch 1595/2000, Train Loss: 0.000084257, Val Loss: 0.002570893, Val Accuracy: 98.24%, LR: 0.000100000\n",
      "Epoch 1596/2000, Train Loss: 0.000082609, Val Loss: 0.002618337, Val Accuracy: 98.24%, LR: 0.000100000\n",
      "Epoch 1597/2000, Train Loss: 0.000081115, Val Loss: 0.002722441, Val Accuracy: 98.23%, LR: 0.000100000\n",
      "Epoch 1598/2000, Train Loss: 0.000081187, Val Loss: 0.002582161, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1599/2000, Train Loss: 0.000078493, Val Loss: 0.002660724, Val Accuracy: 98.23%, LR: 0.000100000\n",
      "Epoch 1600/2000, Train Loss: 0.000081643, Val Loss: 0.002668257, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1601/2000, Train Loss: 0.000089744, Val Loss: 0.002646173, Val Accuracy: 98.23%, LR: 0.000100000\n",
      "Epoch 1602/2000, Train Loss: 0.000076395, Val Loss: 0.002699625, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1603/2000, Train Loss: 0.000077619, Val Loss: 0.002750407, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1604/2000, Train Loss: 0.000086504, Val Loss: 0.002659386, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1605/2000, Train Loss: 0.000092830, Val Loss: 0.002757921, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1606/2000, Train Loss: 0.000073999, Val Loss: 0.002671288, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1607/2000, Train Loss: 0.000075099, Val Loss: 0.002637038, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1608/2000, Train Loss: 0.000078011, Val Loss: 0.002723356, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1609/2000, Train Loss: 0.000075206, Val Loss: 0.002787798, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1610/2000, Train Loss: 0.000090394, Val Loss: 0.002601073, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1611/2000, Train Loss: 0.000076676, Val Loss: 0.002633541, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1612/2000, Train Loss: 0.000076462, Val Loss: 0.002661353, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1613/2000, Train Loss: 0.000070607, Val Loss: 0.002788390, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1614/2000, Train Loss: 0.000073602, Val Loss: 0.002666834, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1615/2000, Train Loss: 0.000070714, Val Loss: 0.002609324, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1616/2000, Train Loss: 0.001987034, Val Loss: 0.004548859, Val Accuracy: 94.04%, LR: 0.000100000\n",
      "Epoch 1617/2000, Train Loss: 0.000961970, Val Loss: 0.002452826, Val Accuracy: 97.97%, LR: 0.000100000\n",
      "Epoch 1618/2000, Train Loss: 0.000133537, Val Loss: 0.002439074, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1619/2000, Train Loss: 0.000102412, Val Loss: 0.002292066, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1620/2000, Train Loss: 0.000093384, Val Loss: 0.002482950, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1621/2000, Train Loss: 0.000091155, Val Loss: 0.002567248, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1622/2000, Train Loss: 0.000085169, Val Loss: 0.002650826, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1623/2000, Train Loss: 0.000084219, Val Loss: 0.002683036, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1624/2000, Train Loss: 0.000081353, Val Loss: 0.002614589, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1625/2000, Train Loss: 0.000077324, Val Loss: 0.002612883, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1626/2000, Train Loss: 0.000077216, Val Loss: 0.002659291, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1627/2000, Train Loss: 0.000079381, Val Loss: 0.002694973, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1628/2000, Train Loss: 0.000078537, Val Loss: 0.002678272, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1629/2000, Train Loss: 0.000075383, Val Loss: 0.002637269, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1630/2000, Train Loss: 0.000074166, Val Loss: 0.002843307, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1631/2000, Train Loss: 0.000074064, Val Loss: 0.002724508, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1632/2000, Train Loss: 0.000073094, Val Loss: 0.002863255, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1633/2000, Train Loss: 0.000072116, Val Loss: 0.002800017, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1634/2000, Train Loss: 0.000074452, Val Loss: 0.002803192, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1635/2000, Train Loss: 0.000074262, Val Loss: 0.002789106, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1636/2000, Train Loss: 0.000084798, Val Loss: 0.002806701, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1637/2000, Train Loss: 0.000077287, Val Loss: 0.002922228, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1638/2000, Train Loss: 0.000081642, Val Loss: 0.002839333, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1639/2000, Train Loss: 0.000081450, Val Loss: 0.002764866, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1640/2000, Train Loss: 0.000077760, Val Loss: 0.002786992, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1641/2000, Train Loss: 0.000074410, Val Loss: 0.002777565, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1642/2000, Train Loss: 0.003411549, Val Loss: 0.002069324, Val Accuracy: 97.85%, LR: 0.000100000\n",
      "Epoch 1643/2000, Train Loss: 0.000345962, Val Loss: 0.002416948, Val Accuracy: 97.72%, LR: 0.000100000\n",
      "Epoch 1644/2000, Train Loss: 0.000124868, Val Loss: 0.002108804, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1645/2000, Train Loss: 0.000098119, Val Loss: 0.002305887, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1646/2000, Train Loss: 0.000094123, Val Loss: 0.002292952, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1647/2000, Train Loss: 0.000084457, Val Loss: 0.002368760, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1648/2000, Train Loss: 0.000083839, Val Loss: 0.002290095, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1649/2000, Train Loss: 0.000081249, Val Loss: 0.002378344, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1650/2000, Train Loss: 0.000079822, Val Loss: 0.002360851, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1651/2000, Train Loss: 0.000077829, Val Loss: 0.002469912, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1652/2000, Train Loss: 0.000079778, Val Loss: 0.002464191, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1653/2000, Train Loss: 0.000077055, Val Loss: 0.002412335, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1654/2000, Train Loss: 0.000076693, Val Loss: 0.002461849, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1655/2000, Train Loss: 0.000074976, Val Loss: 0.002465053, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1656/2000, Train Loss: 0.000073742, Val Loss: 0.002473423, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1657/2000, Train Loss: 0.000071440, Val Loss: 0.002538818, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1658/2000, Train Loss: 0.000072382, Val Loss: 0.002491310, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1659/2000, Train Loss: 0.000074423, Val Loss: 0.002491911, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1660/2000, Train Loss: 0.000072685, Val Loss: 0.002500055, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1661/2000, Train Loss: 0.000072201, Val Loss: 0.002522704, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1662/2000, Train Loss: 0.000071341, Val Loss: 0.002635347, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1663/2000, Train Loss: 0.002453416, Val Loss: 0.004052032, Val Accuracy: 93.64%, LR: 0.000100000\n",
      "Epoch 1664/2000, Train Loss: 0.001274477, Val Loss: 0.002035195, Val Accuracy: 97.82%, LR: 0.000100000\n",
      "Epoch 1665/2000, Train Loss: 0.000173258, Val Loss: 0.002236265, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1666/2000, Train Loss: 0.000103385, Val Loss: 0.002298075, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1667/2000, Train Loss: 0.000093452, Val Loss: 0.002384165, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1668/2000, Train Loss: 0.000087851, Val Loss: 0.002388158, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1669/2000, Train Loss: 0.000084953, Val Loss: 0.002388333, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1670/2000, Train Loss: 0.000082266, Val Loss: 0.002391106, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1671/2000, Train Loss: 0.000081967, Val Loss: 0.002337313, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1672/2000, Train Loss: 0.000078406, Val Loss: 0.002384339, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1673/2000, Train Loss: 0.000078919, Val Loss: 0.002425693, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1674/2000, Train Loss: 0.000079261, Val Loss: 0.002468071, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1675/2000, Train Loss: 0.000079126, Val Loss: 0.002396785, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1676/2000, Train Loss: 0.000074395, Val Loss: 0.002409472, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1677/2000, Train Loss: 0.000073078, Val Loss: 0.002476502, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1678/2000, Train Loss: 0.000072515, Val Loss: 0.002415791, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1679/2000, Train Loss: 0.000073075, Val Loss: 0.002471079, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1680/2000, Train Loss: 0.001704136, Val Loss: 0.002055322, Val Accuracy: 96.47%, LR: 0.000100000\n",
      "Epoch 1681/2000, Train Loss: 0.000369057, Val Loss: 0.002127452, Val Accuracy: 98.01%, LR: 0.000100000\n",
      "Epoch 1682/2000, Train Loss: 0.000112108, Val Loss: 0.002289459, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1683/2000, Train Loss: 0.000092954, Val Loss: 0.002350659, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1684/2000, Train Loss: 0.000086927, Val Loss: 0.002390502, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1685/2000, Train Loss: 0.000082019, Val Loss: 0.002469307, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1686/2000, Train Loss: 0.000079742, Val Loss: 0.002405849, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1687/2000, Train Loss: 0.000077753, Val Loss: 0.002414113, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1688/2000, Train Loss: 0.000076793, Val Loss: 0.002467400, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1689/2000, Train Loss: 0.000076079, Val Loss: 0.002447917, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1690/2000, Train Loss: 0.000073666, Val Loss: 0.002460972, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1691/2000, Train Loss: 0.000074955, Val Loss: 0.002463252, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1692/2000, Train Loss: 0.000076033, Val Loss: 0.002516930, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1693/2000, Train Loss: 0.000075576, Val Loss: 0.002548816, Val Accuracy: 98.24%, LR: 0.000100000\n",
      "Epoch 1694/2000, Train Loss: 0.000072618, Val Loss: 0.002504299, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1695/2000, Train Loss: 0.000071207, Val Loss: 0.002563348, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1696/2000, Train Loss: 0.000069594, Val Loss: 0.002585423, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1697/2000, Train Loss: 0.000070690, Val Loss: 0.002620931, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1698/2000, Train Loss: 0.001470381, Val Loss: 0.002726648, Val Accuracy: 97.51%, LR: 0.000100000\n",
      "Epoch 1699/2000, Train Loss: 0.000139857, Val Loss: 0.002268642, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1700/2000, Train Loss: 0.000089319, Val Loss: 0.002358343, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1701/2000, Train Loss: 0.000083357, Val Loss: 0.002448155, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1702/2000, Train Loss: 0.000079109, Val Loss: 0.002425567, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1703/2000, Train Loss: 0.000076016, Val Loss: 0.002467913, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1704/2000, Train Loss: 0.000075264, Val Loss: 0.002458756, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1705/2000, Train Loss: 0.000074707, Val Loss: 0.002531003, Val Accuracy: 98.25%, LR: 0.000100000\n",
      "Epoch 1706/2000, Train Loss: 0.000072833, Val Loss: 0.002507683, Val Accuracy: 98.23%, LR: 0.000100000\n",
      "Epoch 1707/2000, Train Loss: 0.000073880, Val Loss: 0.002517810, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1708/2000, Train Loss: 0.000071020, Val Loss: 0.002496053, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1709/2000, Train Loss: 0.000071190, Val Loss: 0.002550681, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1710/2000, Train Loss: 0.000071482, Val Loss: 0.002541672, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1711/2000, Train Loss: 0.000070403, Val Loss: 0.002565198, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1712/2000, Train Loss: 0.000075668, Val Loss: 0.002604774, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1713/2000, Train Loss: 0.000072792, Val Loss: 0.002536727, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1714/2000, Train Loss: 0.000073458, Val Loss: 0.002774256, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1715/2000, Train Loss: 0.000070648, Val Loss: 0.002606056, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1716/2000, Train Loss: 0.000068097, Val Loss: 0.002831343, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1717/2000, Train Loss: 0.000070723, Val Loss: 0.002595151, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1718/2000, Train Loss: 0.000072508, Val Loss: 0.002640403, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1719/2000, Train Loss: 0.000081796, Val Loss: 0.002705464, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1720/2000, Train Loss: 0.001493002, Val Loss: 0.002367370, Val Accuracy: 97.24%, LR: 0.000100000\n",
      "Epoch 1721/2000, Train Loss: 0.000176202, Val Loss: 0.002325614, Val Accuracy: 98.02%, LR: 0.000100000\n",
      "Epoch 1722/2000, Train Loss: 0.000094768, Val Loss: 0.002399400, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1723/2000, Train Loss: 0.000082519, Val Loss: 0.002431635, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1724/2000, Train Loss: 0.000077376, Val Loss: 0.002508416, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1725/2000, Train Loss: 0.000074721, Val Loss: 0.002536673, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1726/2000, Train Loss: 0.000074553, Val Loss: 0.002497499, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1727/2000, Train Loss: 0.000071175, Val Loss: 0.002552433, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1728/2000, Train Loss: 0.000070220, Val Loss: 0.002627256, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1729/2000, Train Loss: 0.000081845, Val Loss: 0.002587393, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1730/2000, Train Loss: 0.000071437, Val Loss: 0.002530576, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1731/2000, Train Loss: 0.000067471, Val Loss: 0.002582966, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1732/2000, Train Loss: 0.000066886, Val Loss: 0.002578991, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1733/2000, Train Loss: 0.000067278, Val Loss: 0.002667875, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1734/2000, Train Loss: 0.000068703, Val Loss: 0.002594540, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1735/2000, Train Loss: 0.000068006, Val Loss: 0.002593393, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1736/2000, Train Loss: 0.000066264, Val Loss: 0.002679458, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1737/2000, Train Loss: 0.000082866, Val Loss: 0.002857653, Val Accuracy: 97.63%, LR: 0.000100000\n",
      "Epoch 1738/2000, Train Loss: 0.000106539, Val Loss: 0.002772352, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1739/2000, Train Loss: 0.000066138, Val Loss: 0.002625906, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1740/2000, Train Loss: 0.000062983, Val Loss: 0.002670952, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1741/2000, Train Loss: 0.000066911, Val Loss: 0.002630484, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1742/2000, Train Loss: 0.000062749, Val Loss: 0.002660480, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1743/2000, Train Loss: 0.000068331, Val Loss: 0.002735181, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1744/2000, Train Loss: 0.000065389, Val Loss: 0.002737329, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1745/2000, Train Loss: 0.000062694, Val Loss: 0.002722690, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1746/2000, Train Loss: 0.000061952, Val Loss: 0.002867014, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1747/2000, Train Loss: 0.000067337, Val Loss: 0.002722019, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1748/2000, Train Loss: 0.000064368, Val Loss: 0.002683620, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1749/2000, Train Loss: 0.000062735, Val Loss: 0.002812201, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1750/2000, Train Loss: 0.002812412, Val Loss: 0.009866527, Val Accuracy: 79.80%, LR: 0.000100000\n",
      "Epoch 1751/2000, Train Loss: 0.002647948, Val Loss: 0.002104826, Val Accuracy: 97.10%, LR: 0.000100000\n",
      "Epoch 1752/2000, Train Loss: 0.000520669, Val Loss: 0.002346313, Val Accuracy: 97.53%, LR: 0.000100000\n",
      "Epoch 1753/2000, Train Loss: 0.000214957, Val Loss: 0.002319531, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1754/2000, Train Loss: 0.000117075, Val Loss: 0.002474893, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1755/2000, Train Loss: 0.000093702, Val Loss: 0.002477612, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1756/2000, Train Loss: 0.000084279, Val Loss: 0.002427371, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1757/2000, Train Loss: 0.000081092, Val Loss: 0.002498375, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1758/2000, Train Loss: 0.000078548, Val Loss: 0.002433003, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1759/2000, Train Loss: 0.000078054, Val Loss: 0.002573638, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1760/2000, Train Loss: 0.000073603, Val Loss: 0.002598808, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1761/2000, Train Loss: 0.000072485, Val Loss: 0.002533534, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1762/2000, Train Loss: 0.000069728, Val Loss: 0.002589653, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1763/2000, Train Loss: 0.000070189, Val Loss: 0.002599692, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1764/2000, Train Loss: 0.000067912, Val Loss: 0.002535114, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1765/2000, Train Loss: 0.000069675, Val Loss: 0.002701903, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1766/2000, Train Loss: 0.000069848, Val Loss: 0.002618229, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1767/2000, Train Loss: 0.000074730, Val Loss: 0.002484712, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1768/2000, Train Loss: 0.000066898, Val Loss: 0.002625598, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1769/2000, Train Loss: 0.000078910, Val Loss: 0.002852709, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1770/2000, Train Loss: 0.000086457, Val Loss: 0.002624621, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1771/2000, Train Loss: 0.000070281, Val Loss: 0.002571398, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1772/2000, Train Loss: 0.000069218, Val Loss: 0.002508197, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1773/2000, Train Loss: 0.000066671, Val Loss: 0.002587414, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 1774/2000, Train Loss: 0.000074075, Val Loss: 0.002660189, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1775/2000, Train Loss: 0.003029230, Val Loss: 0.003318875, Val Accuracy: 95.80%, LR: 0.000100000\n",
      "Epoch 1776/2000, Train Loss: 0.000885913, Val Loss: 0.002391419, Val Accuracy: 97.54%, LR: 0.000100000\n",
      "Epoch 1777/2000, Train Loss: 0.000300346, Val Loss: 0.002208896, Val Accuracy: 97.79%, LR: 0.000100000\n",
      "Epoch 1778/2000, Train Loss: 0.000148702, Val Loss: 0.002351947, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1779/2000, Train Loss: 0.000098156, Val Loss: 0.002408254, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1780/2000, Train Loss: 0.000086977, Val Loss: 0.002487256, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1781/2000, Train Loss: 0.000082159, Val Loss: 0.002541715, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1782/2000, Train Loss: 0.000079753, Val Loss: 0.002447215, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1783/2000, Train Loss: 0.000076950, Val Loss: 0.002482501, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1784/2000, Train Loss: 0.000075324, Val Loss: 0.002545804, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1785/2000, Train Loss: 0.000073376, Val Loss: 0.002573706, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1786/2000, Train Loss: 0.000071656, Val Loss: 0.002571098, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1787/2000, Train Loss: 0.000070248, Val Loss: 0.002530485, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1788/2000, Train Loss: 0.000070880, Val Loss: 0.002602002, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1789/2000, Train Loss: 0.000070904, Val Loss: 0.002612843, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1790/2000, Train Loss: 0.000070320, Val Loss: 0.002625477, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1791/2000, Train Loss: 0.000069015, Val Loss: 0.002775020, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1792/2000, Train Loss: 0.000086492, Val Loss: 0.002592460, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1793/2000, Train Loss: 0.000067051, Val Loss: 0.002575591, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1794/2000, Train Loss: 0.000081487, Val Loss: 0.002665317, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1795/2000, Train Loss: 0.000075084, Val Loss: 0.002594394, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1796/2000, Train Loss: 0.000080635, Val Loss: 0.002605067, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1797/2000, Train Loss: 0.000064994, Val Loss: 0.002606738, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1798/2000, Train Loss: 0.000071356, Val Loss: 0.002639928, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1799/2000, Train Loss: 0.000069977, Val Loss: 0.002683315, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1800/2000, Train Loss: 0.000082696, Val Loss: 0.002689893, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1801/2000, Train Loss: 0.000064481, Val Loss: 0.002671244, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1802/2000, Train Loss: 0.000064073, Val Loss: 0.002668535, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1803/2000, Train Loss: 0.000070232, Val Loss: 0.002744578, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1804/2000, Train Loss: 0.000063471, Val Loss: 0.002647169, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1805/2000, Train Loss: 0.000071359, Val Loss: 0.002779256, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1806/2000, Train Loss: 0.004208903, Val Loss: 0.002032899, Val Accuracy: 97.38%, LR: 0.000100000\n",
      "Epoch 1807/2000, Train Loss: 0.000259480, Val Loss: 0.002094603, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1808/2000, Train Loss: 0.000116827, Val Loss: 0.002185741, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1809/2000, Train Loss: 0.000095835, Val Loss: 0.002249128, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1810/2000, Train Loss: 0.000088667, Val Loss: 0.002302670, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1811/2000, Train Loss: 0.000083083, Val Loss: 0.002327290, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1812/2000, Train Loss: 0.000076793, Val Loss: 0.002361870, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1813/2000, Train Loss: 0.000075766, Val Loss: 0.002422488, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1814/2000, Train Loss: 0.000073790, Val Loss: 0.002401439, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1815/2000, Train Loss: 0.000072147, Val Loss: 0.002357487, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1816/2000, Train Loss: 0.000070769, Val Loss: 0.002429820, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1817/2000, Train Loss: 0.000072743, Val Loss: 0.002419819, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1818/2000, Train Loss: 0.000068846, Val Loss: 0.002423986, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1819/2000, Train Loss: 0.000067264, Val Loss: 0.002456069, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1820/2000, Train Loss: 0.000074272, Val Loss: 0.002463697, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1821/2000, Train Loss: 0.000072296, Val Loss: 0.002445551, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1822/2000, Train Loss: 0.000066672, Val Loss: 0.002498981, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1823/2000, Train Loss: 0.000068897, Val Loss: 0.002497601, Val Accuracy: 97.89%, LR: 0.000100000\n",
      "Epoch 1824/2000, Train Loss: 0.001513647, Val Loss: 0.002574137, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1825/2000, Train Loss: 0.000107855, Val Loss: 0.002145090, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1826/2000, Train Loss: 0.000082689, Val Loss: 0.002206468, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1827/2000, Train Loss: 0.000076387, Val Loss: 0.002259052, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1828/2000, Train Loss: 0.000073069, Val Loss: 0.002316570, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1829/2000, Train Loss: 0.000072312, Val Loss: 0.002322492, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1830/2000, Train Loss: 0.000074571, Val Loss: 0.002295783, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1831/2000, Train Loss: 0.000070579, Val Loss: 0.002353927, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1832/2000, Train Loss: 0.000066501, Val Loss: 0.002330763, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1833/2000, Train Loss: 0.000069517, Val Loss: 0.002319864, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1834/2000, Train Loss: 0.000066033, Val Loss: 0.002405069, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1835/2000, Train Loss: 0.000064299, Val Loss: 0.002359110, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1836/2000, Train Loss: 0.000063485, Val Loss: 0.002413783, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1837/2000, Train Loss: 0.000062852, Val Loss: 0.002432755, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1838/2000, Train Loss: 0.000064938, Val Loss: 0.002490659, Val Accuracy: 98.24%, LR: 0.000100000\n",
      "Epoch 1839/2000, Train Loss: 0.000065835, Val Loss: 0.002420256, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1840/2000, Train Loss: 0.000061591, Val Loss: 0.002492192, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1841/2000, Train Loss: 0.000061997, Val Loss: 0.002453756, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1842/2000, Train Loss: 0.000064882, Val Loss: 0.002496128, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1843/2000, Train Loss: 0.000063653, Val Loss: 0.002657830, Val Accuracy: 98.25%, LR: 0.000100000\n",
      "Epoch 1844/2000, Train Loss: 0.000067315, Val Loss: 0.002480837, Val Accuracy: 97.90%, LR: 0.000100000\n",
      "Epoch 1845/2000, Train Loss: 0.000070240, Val Loss: 0.002579830, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1846/2000, Train Loss: 0.000062339, Val Loss: 0.002458099, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1847/2000, Train Loss: 0.000060910, Val Loss: 0.002552253, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1848/2000, Train Loss: 0.000060478, Val Loss: 0.002574144, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1849/2000, Train Loss: 0.000061216, Val Loss: 0.002599118, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1850/2000, Train Loss: 0.000070621, Val Loss: 0.002475899, Val Accuracy: 97.96%, LR: 0.000100000\n",
      "Epoch 1851/2000, Train Loss: 0.006720756, Val Loss: 0.001797612, Val Accuracy: 97.07%, LR: 0.000100000\n",
      "Epoch 1852/2000, Train Loss: 0.000578041, Val Loss: 0.002258416, Val Accuracy: 97.74%, LR: 0.000100000\n",
      "Epoch 1853/2000, Train Loss: 0.000230942, Val Loss: 0.002167082, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 1854/2000, Train Loss: 0.000147548, Val Loss: 0.002239107, Val Accuracy: 97.95%, LR: 0.000100000\n",
      "Epoch 1855/2000, Train Loss: 0.000128010, Val Loss: 0.002220271, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1856/2000, Train Loss: 0.000119217, Val Loss: 0.002367113, Val Accuracy: 97.88%, LR: 0.000100000\n",
      "Epoch 1857/2000, Train Loss: 0.000108855, Val Loss: 0.002272789, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1858/2000, Train Loss: 0.000122948, Val Loss: 0.002263460, Val Accuracy: 98.00%, LR: 0.000100000\n",
      "Epoch 1859/2000, Train Loss: 0.000124456, Val Loss: 0.002248627, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1860/2000, Train Loss: 0.000088853, Val Loss: 0.002301611, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1861/2000, Train Loss: 0.000087504, Val Loss: 0.002318025, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1862/2000, Train Loss: 0.000111575, Val Loss: 0.002313180, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1863/2000, Train Loss: 0.000078489, Val Loss: 0.002302063, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1864/2000, Train Loss: 0.000076849, Val Loss: 0.002302661, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1865/2000, Train Loss: 0.000075355, Val Loss: 0.002307437, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1866/2000, Train Loss: 0.000075234, Val Loss: 0.002459648, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1867/2000, Train Loss: 0.000853654, Val Loss: 0.002049264, Val Accuracy: 97.91%, LR: 0.000100000\n",
      "Epoch 1868/2000, Train Loss: 0.000097954, Val Loss: 0.002114895, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1869/2000, Train Loss: 0.000081594, Val Loss: 0.002175103, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1870/2000, Train Loss: 0.000077392, Val Loss: 0.002316391, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1871/2000, Train Loss: 0.000075121, Val Loss: 0.002219806, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1872/2000, Train Loss: 0.000075711, Val Loss: 0.002212777, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1873/2000, Train Loss: 0.000072349, Val Loss: 0.002307451, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1874/2000, Train Loss: 0.000069742, Val Loss: 0.002196595, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1875/2000, Train Loss: 0.000067572, Val Loss: 0.002276468, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1876/2000, Train Loss: 0.000066378, Val Loss: 0.002228947, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1877/2000, Train Loss: 0.000064638, Val Loss: 0.002277826, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1878/2000, Train Loss: 0.000065277, Val Loss: 0.002238338, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1879/2000, Train Loss: 0.000067834, Val Loss: 0.002219447, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1880/2000, Train Loss: 0.000064992, Val Loss: 0.002282127, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1881/2000, Train Loss: 0.000074252, Val Loss: 0.002284454, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1882/2000, Train Loss: 0.000072019, Val Loss: 0.002405500, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1883/2000, Train Loss: 0.000095917, Val Loss: 0.002193093, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1884/2000, Train Loss: 0.000066683, Val Loss: 0.002334510, Val Accuracy: 98.10%, LR: 0.000100000\n",
      "Epoch 1885/2000, Train Loss: 0.000061613, Val Loss: 0.002274401, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1886/2000, Train Loss: 0.002378067, Val Loss: 0.008279683, Val Accuracy: 83.67%, LR: 0.000100000\n",
      "Epoch 1887/2000, Train Loss: 0.004092809, Val Loss: 0.002797960, Val Accuracy: 96.02%, LR: 0.000100000\n",
      "Epoch 1888/2000, Train Loss: 0.000776932, Val Loss: 0.001686805, Val Accuracy: 97.79%, LR: 0.000100000\n",
      "Epoch 1889/2000, Train Loss: 0.000293961, Val Loss: 0.001985454, Val Accuracy: 97.97%, LR: 0.000100000\n",
      "Epoch 1890/2000, Train Loss: 0.000182907, Val Loss: 0.001954928, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1891/2000, Train Loss: 0.000147982, Val Loss: 0.001932870, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1892/2000, Train Loss: 0.000112663, Val Loss: 0.001856574, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1893/2000, Train Loss: 0.000090791, Val Loss: 0.002064675, Val Accuracy: 98.25%, LR: 0.000100000\n",
      "Epoch 1894/2000, Train Loss: 0.000083103, Val Loss: 0.002048632, Val Accuracy: 98.25%, LR: 0.000100000\n",
      "Epoch 1895/2000, Train Loss: 0.000080059, Val Loss: 0.002130435, Val Accuracy: 98.25%, LR: 0.000100000\n",
      "Epoch 1896/2000, Train Loss: 0.000078711, Val Loss: 0.002079904, Val Accuracy: 98.25%, LR: 0.000100000\n",
      "Epoch 1897/2000, Train Loss: 0.000080556, Val Loss: 0.002089936, Val Accuracy: 98.24%, LR: 0.000100000\n",
      "Epoch 1898/2000, Train Loss: 0.000072140, Val Loss: 0.002125953, Val Accuracy: 98.24%, LR: 0.000100000\n",
      "Epoch 1899/2000, Train Loss: 0.000070906, Val Loss: 0.002156197, Val Accuracy: 98.24%, LR: 0.000100000\n",
      "Epoch 1900/2000, Train Loss: 0.000069736, Val Loss: 0.002174474, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1901/2000, Train Loss: 0.000068813, Val Loss: 0.002239073, Val Accuracy: 98.23%, LR: 0.000100000\n",
      "Epoch 1902/2000, Train Loss: 0.000068883, Val Loss: 0.002185211, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1903/2000, Train Loss: 0.000066287, Val Loss: 0.002240946, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1904/2000, Train Loss: 0.000066739, Val Loss: 0.002171489, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1905/2000, Train Loss: 0.000066972, Val Loss: 0.002186246, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1906/2000, Train Loss: 0.000066001, Val Loss: 0.002298562, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1907/2000, Train Loss: 0.000095474, Val Loss: 0.002620493, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1908/2000, Train Loss: 0.001094909, Val Loss: 0.002049966, Val Accuracy: 97.21%, LR: 0.000100000\n",
      "Epoch 1909/2000, Train Loss: 0.000175705, Val Loss: 0.002302556, Val Accuracy: 98.03%, LR: 0.000100000\n",
      "Epoch 1910/2000, Train Loss: 0.000084295, Val Loss: 0.002119485, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1911/2000, Train Loss: 0.000074810, Val Loss: 0.002200314, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1912/2000, Train Loss: 0.000071456, Val Loss: 0.002217610, Val Accuracy: 98.08%, LR: 0.000100000\n",
      "Epoch 1913/2000, Train Loss: 0.000071284, Val Loss: 0.002213684, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1914/2000, Train Loss: 0.000068844, Val Loss: 0.002285737, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1915/2000, Train Loss: 0.000064741, Val Loss: 0.002243282, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1916/2000, Train Loss: 0.000066019, Val Loss: 0.002162154, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1917/2000, Train Loss: 0.000073592, Val Loss: 0.002273451, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1918/2000, Train Loss: 0.000064189, Val Loss: 0.002241395, Val Accuracy: 98.11%, LR: 0.000100000\n",
      "Epoch 1919/2000, Train Loss: 0.000065177, Val Loss: 0.002302869, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1920/2000, Train Loss: 0.000065078, Val Loss: 0.002207093, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1921/2000, Train Loss: 0.000060276, Val Loss: 0.002337391, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1922/2000, Train Loss: 0.000060391, Val Loss: 0.002298206, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1923/2000, Train Loss: 0.000060342, Val Loss: 0.002391013, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1924/2000, Train Loss: 0.000065437, Val Loss: 0.002293752, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1925/2000, Train Loss: 0.000059988, Val Loss: 0.002313583, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1926/2000, Train Loss: 0.000059067, Val Loss: 0.002306203, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1927/2000, Train Loss: 0.000061086, Val Loss: 0.002329941, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1928/2000, Train Loss: 0.000059155, Val Loss: 0.002330299, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1929/2000, Train Loss: 0.000058185, Val Loss: 0.002304575, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1930/2000, Train Loss: 0.000057916, Val Loss: 0.002343874, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1931/2000, Train Loss: 0.000061641, Val Loss: 0.002325372, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1932/2000, Train Loss: 0.000075259, Val Loss: 0.002313740, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1933/2000, Train Loss: 0.000059336, Val Loss: 0.002458037, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1934/2000, Train Loss: 0.000068509, Val Loss: 0.002237090, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1935/2000, Train Loss: 0.000058819, Val Loss: 0.002432641, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1936/2000, Train Loss: 0.000061891, Val Loss: 0.002254089, Val Accuracy: 98.23%, LR: 0.000100000\n",
      "Epoch 1937/2000, Train Loss: 0.000055173, Val Loss: 0.002274569, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1938/2000, Train Loss: 0.001393229, Val Loss: 0.002063820, Val Accuracy: 97.50%, LR: 0.000100000\n",
      "Epoch 1939/2000, Train Loss: 0.000211972, Val Loss: 0.001937371, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1940/2000, Train Loss: 0.000081956, Val Loss: 0.002068318, Val Accuracy: 98.09%, LR: 0.000100000\n",
      "Epoch 1941/2000, Train Loss: 0.000074725, Val Loss: 0.002222583, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1942/2000, Train Loss: 0.000065424, Val Loss: 0.002152779, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1943/2000, Train Loss: 0.000062374, Val Loss: 0.002123111, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1944/2000, Train Loss: 0.000059559, Val Loss: 0.002131437, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1945/2000, Train Loss: 0.000059409, Val Loss: 0.002220104, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1946/2000, Train Loss: 0.000057241, Val Loss: 0.002210618, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1947/2000, Train Loss: 0.000056726, Val Loss: 0.002174405, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1948/2000, Train Loss: 0.000057709, Val Loss: 0.002238689, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1949/2000, Train Loss: 0.000057568, Val Loss: 0.002244248, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1950/2000, Train Loss: 0.000058593, Val Loss: 0.002350905, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1951/2000, Train Loss: 0.000056541, Val Loss: 0.002260585, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1952/2000, Train Loss: 0.000055920, Val Loss: 0.002199209, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1953/2000, Train Loss: 0.000056589, Val Loss: 0.002347026, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1954/2000, Train Loss: 0.000060601, Val Loss: 0.002314040, Val Accuracy: 98.07%, LR: 0.000100000\n",
      "Epoch 1955/2000, Train Loss: 0.000065833, Val Loss: 0.002384016, Val Accuracy: 98.12%, LR: 0.000100000\n",
      "Epoch 1956/2000, Train Loss: 0.000061115, Val Loss: 0.002414667, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1957/2000, Train Loss: 0.000053835, Val Loss: 0.002412300, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1958/2000, Train Loss: 0.000980790, Val Loss: 0.002149278, Val Accuracy: 97.49%, LR: 0.000100000\n",
      "Epoch 1959/2000, Train Loss: 0.000144779, Val Loss: 0.002247495, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1960/2000, Train Loss: 0.000067272, Val Loss: 0.002210552, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1961/2000, Train Loss: 0.000061470, Val Loss: 0.002236977, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1962/2000, Train Loss: 0.000062666, Val Loss: 0.002299339, Val Accuracy: 98.05%, LR: 0.000100000\n",
      "Epoch 1963/2000, Train Loss: 0.000058005, Val Loss: 0.002320946, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1964/2000, Train Loss: 0.000056110, Val Loss: 0.002329172, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1965/2000, Train Loss: 0.000055110, Val Loss: 0.002330694, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1966/2000, Train Loss: 0.000054597, Val Loss: 0.002313453, Val Accuracy: 98.21%, LR: 0.000100000\n",
      "Epoch 1967/2000, Train Loss: 0.000054908, Val Loss: 0.002389420, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1968/2000, Train Loss: 0.000053380, Val Loss: 0.002376550, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1969/2000, Train Loss: 0.000052726, Val Loss: 0.002399364, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1970/2000, Train Loss: 0.000059667, Val Loss: 0.002301952, Val Accuracy: 98.04%, LR: 0.000100000\n",
      "Epoch 1971/2000, Train Loss: 0.000064945, Val Loss: 0.002337182, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1972/2000, Train Loss: 0.000054021, Val Loss: 0.002356770, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1973/2000, Train Loss: 0.000053955, Val Loss: 0.002439878, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1974/2000, Train Loss: 0.000051571, Val Loss: 0.002348426, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1975/2000, Train Loss: 0.000052772, Val Loss: 0.002305848, Val Accuracy: 98.24%, LR: 0.000100000\n",
      "Epoch 1976/2000, Train Loss: 0.000051424, Val Loss: 0.002311775, Val Accuracy: 98.18%, LR: 0.000100000\n",
      "Epoch 1977/2000, Train Loss: 0.000051249, Val Loss: 0.002403293, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1978/2000, Train Loss: 0.000059699, Val Loss: 0.002450319, Val Accuracy: 98.15%, LR: 0.000100000\n",
      "Epoch 1979/2000, Train Loss: 0.000050447, Val Loss: 0.002421643, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1980/2000, Train Loss: 0.002226729, Val Loss: 0.002106533, Val Accuracy: 97.49%, LR: 0.000100000\n",
      "Epoch 1981/2000, Train Loss: 0.000277943, Val Loss: 0.002094773, Val Accuracy: 97.99%, LR: 0.000100000\n",
      "Epoch 1982/2000, Train Loss: 0.000085186, Val Loss: 0.001939753, Val Accuracy: 98.06%, LR: 0.000100000\n",
      "Epoch 1983/2000, Train Loss: 0.000069353, Val Loss: 0.002085025, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1984/2000, Train Loss: 0.000064360, Val Loss: 0.002139238, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1985/2000, Train Loss: 0.000060674, Val Loss: 0.002135321, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1986/2000, Train Loss: 0.000058504, Val Loss: 0.002264805, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1987/2000, Train Loss: 0.000057569, Val Loss: 0.002229447, Val Accuracy: 98.14%, LR: 0.000100000\n",
      "Epoch 1988/2000, Train Loss: 0.000058480, Val Loss: 0.002194610, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1989/2000, Train Loss: 0.000054862, Val Loss: 0.002293465, Val Accuracy: 98.19%, LR: 0.000100000\n",
      "Epoch 1990/2000, Train Loss: 0.000054632, Val Loss: 0.002273279, Val Accuracy: 98.23%, LR: 0.000100000\n",
      "Epoch 1991/2000, Train Loss: 0.000054268, Val Loss: 0.002225494, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1992/2000, Train Loss: 0.000055159, Val Loss: 0.002334756, Val Accuracy: 98.17%, LR: 0.000100000\n",
      "Epoch 1993/2000, Train Loss: 0.000053250, Val Loss: 0.002344458, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "Epoch 1994/2000, Train Loss: 0.000057836, Val Loss: 0.002284483, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1995/2000, Train Loss: 0.000051908, Val Loss: 0.002438633, Val Accuracy: 98.13%, LR: 0.000100000\n",
      "Epoch 1996/2000, Train Loss: 0.000051332, Val Loss: 0.002465495, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1997/2000, Train Loss: 0.000051254, Val Loss: 0.002381972, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 1998/2000, Train Loss: 0.000051917, Val Loss: 0.002367135, Val Accuracy: 98.20%, LR: 0.000100000\n",
      "Epoch 1999/2000, Train Loss: 0.000052445, Val Loss: 0.002368919, Val Accuracy: 98.16%, LR: 0.000100000\n",
      "Epoch 2000/2000, Train Loss: 0.000050444, Val Loss: 0.002390567, Val Accuracy: 98.22%, LR: 0.000100000\n",
      "\n",
      "Final model saved to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_final.pth\n",
      "\n",
      "Training complete. \n",
      "\n",
      "Top 5 Models Sorted by Validation Accuracy: \n",
      "Epoch 1584/2000, Train Loss: 0.000074760, Val Loss: 0.002929529, Val Accuracy: 98.31%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1584.pth\n",
      "Epoch 1578/2000, Train Loss: 0.000080274, Val Loss: 0.002932368, Val Accuracy: 98.30%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1578.pth\n",
      "Epoch 1583/2000, Train Loss: 0.000076208, Val Loss: 0.002946701, Val Accuracy: 98.29%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1583.pth\n",
      "Epoch 1581/2000, Train Loss: 0.000080132, Val Loss: 0.002912208, Val Accuracy: 98.26%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1581.pth\n",
      "Epoch 1576/2000, Train Loss: 0.000080005, Val Loss: 0.002937514, Val Accuracy: 98.26%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1576.pth\n",
      "\n",
      "\n",
      "Epoch 1584/2000, Train Loss: 0.0001, Val Loss: 0.0029, Val Accuracy: 98.31%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1584.pth\n",
      "Epoch 1578/2000, Train Loss: 0.0001, Val Loss: 0.0029, Val Accuracy: 98.30%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1578.pth\n",
      "Epoch 1583/2000, Train Loss: 0.0001, Val Loss: 0.0029, Val Accuracy: 98.29%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1583.pth\n",
      "Epoch 1581/2000, Train Loss: 0.0001, Val Loss: 0.0029, Val Accuracy: 98.26%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1581.pth\n",
      "Epoch 1576/2000, Train Loss: 0.0001, Val Loss: 0.0029, Val Accuracy: 98.26%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\2nd_try\\BiGRUWithAttention_epoch_1576.pth\n",
      "\n",
      "class_gru_model: \n",
      "BiGRUWithAttention(\n",
      "  (gru): GRU(7, 64, num_layers=3, batch_first=True, bidirectional=True)\n",
      "  (attention_fc): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "\n",
      "unique_classes = [0 1]\n",
      "num_classes = 2\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 3  # Number of GRU layers\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/Baseline/Period_1/2nd_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the model\n",
    "class_gru_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(class_gru_model.parameters(), lr=0.0001) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "# train_and_validate(class_gru_model, output_size, criterion, optimizer, X_train_all, y_train_all, X_val_all, y_val_all, scheduler, \n",
    "train_and_validate(class_gru_model, output_size, criterion, optimizer, X_train, y_train, X_val, y_val, scheduler, \n",
    "                   False, num_epochs, batch_size, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model: \\n{class_gru_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------> Fisher Matrix computation for __*Period 1 '1st_try'*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1]\n",
      "num_classes = 2\n",
      "dict_keys(['epoch', 'train_loss', 'val_loss', 'model_state_dict', 'optimizer_state_dict', 'learning_rate']) \n",
      "\n",
      "epoch: (type: <class 'int'>) \n",
      "1987\n",
      "train_loss: (type: <class 'float'>) \n",
      "0.004282388898165231\n",
      "val_loss: (type: <class 'float'>) \n",
      "0.08081079054508966\n",
      "learning_rate: (type: <class 'float'>) \n",
      "0.0001\n",
      "Loaded preious model from: \n",
      "\tClass_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1987.pth\n",
      "\n",
      "Calculating EWC state with sample_size = All...\n",
      "Starting Fisher Information Matrix calculation (v3: train mode for RNN backward)...\n",
      "Model temporarily set to TRAIN mode for Fisher calculation.\n",
      "Dropout layers temporarily disabled during forward pass.\n",
      "Processing data batches on device: cuda\n",
      "Restoring original Dropout layer states...\n",
      "Model mode restored to original state (training=True).\n",
      "Finished accumulating gradients over 3634 samples.\n",
      "Normalizing Fisher matrix...\n",
      "Fisher Information Matrix calculation complete.\n",
      "EWC Fisher and Params computed (All Samples).\n",
      "\n",
      "--- Inspecting Computed Fisher Values (All Samples) ---\n",
      "Total Fisher Sum: 1.2840e+02\n",
      "Overall Max Fisher Abs Value: 3.1890e+01\n",
      "Overall Min Positive Fisher Value: 6.4935e-23\n",
      "Number of layers with all-zero Fisher: 0 / 36\n",
      "--- Finished Inspecting Computed Fisher Values (All Samples) ---\n",
      "\n",
      "\n",
      "Calculating EWC state with sample_size = 100...\n",
      "Starting Fisher Information Matrix calculation (v3: train mode for RNN backward)...\n",
      "Model temporarily set to TRAIN mode for Fisher calculation.\n",
      "Dropout layers temporarily disabled during forward pass.\n",
      "Processing data batches on device: cuda\n",
      "Stopping Fisher computation early after 100 samples.\n",
      "Restoring original Dropout layer states...\n",
      "Model mode restored to original state (training=True).\n",
      "Finished accumulating gradients over 100 samples.\n",
      "Normalizing Fisher matrix...\n",
      "Fisher Information Matrix calculation complete.\n",
      "EWC Fisher and Params computed (100 Samples).\n",
      "\n",
      "\n",
      "--- Inspecting Computed Fisher Values (100 Samples) ---\n",
      "Total Fisher Sum: 8.6069e+01\n",
      "Overall Max Fisher Abs Value: 2.1405e+01\n",
      "Overall Min Positive Fisher Value: 1.9780e-25\n",
      "Number of layers with all-zero Fisher: 0 / 36\n",
      "--- Finished Inspecting Computed Fisher Values (100 Samples) ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[0], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Model parameters\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "fisher_calc_batch_size= 50 \n",
    "model_name = 'BiGRUWithAttentionEWC' # Name of the model to use for saving\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#-----------------\n",
    "previous_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "best_model_path = r\"Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1987.pth\"\n",
    "prev_checkpoint_path = os.path.normpath(best_model_path)\n",
    "prev_checkpoint = torch.load(prev_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{prev_checkpoint}\\n\")\n",
    "previous_model.load_state_dict(prev_checkpoint['model_state_dict'])\n",
    "#-----------------\n",
    "print(prev_checkpoint.keys(), \"\\n\")\n",
    "skip_keys = {\"model_state_dict\", \"optimizer_state_dict\"}\n",
    "for name, content in prev_checkpoint.items():\n",
    "    if name in skip_keys:\n",
    "        continue\n",
    "    print(f\"{name}: (type: {type(content)}) \\n{content}\")\n",
    "# for param_name, tensor in prev_checkpoint['model_state_dict'].items():\n",
    "#     print(f\"{param_name}: {tensor.shape}\")\n",
    "print(f\"Loaded preious model from: \\n\\t{prev_checkpoint_path}\")\n",
    "#-----------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Create a dataloader from Period 1 training data for Fisher computation\n",
    "train_dataset_period1 = TensorDataset(torch.tensor(X_train, dtype=torch.float32), \n",
    "                                        torch.tensor(y_train, dtype=torch.long))\n",
    "train_loader_period1 = DataLoader(train_dataset_period1, batch_size=fisher_calc_batch_size, shuffle=True) # Shuffle is good practice\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# == Case 1: Compute EWC using ALL samples ==\n",
    "print(f\"\\nCalculating EWC state with sample_size = All...\")\n",
    "sample_size_all = None\n",
    "# Call the static method to compute Fisher and Params\n",
    "try:\n",
    "    ewc_fisher_dict_all, ewc_params_dict_all = EWC.compute_fisher_and_params(\n",
    "        model=previous_model,       # Pass the loaded Period 1 model\n",
    "        dataloader=train_loader_period1,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        sample_size=sample_size_all # Use all samples\n",
    "    )\n",
    "    print(\"EWC Fisher and Params computed (All Samples).\")\n",
    "    #----------------------------------------<<<<<<<<<<<<<<<\n",
    "    # --- !! START INSPECTION HERE !! ---\n",
    "    inspect_fisher_info(ewc_fisher_dict_all, label=\"Computed Fisher Values (All Samples)\")\n",
    "    # --- !! END INSPECTION !! ---\n",
    "    #----------------------------------------<<<<<<<<<<<<<<<\n",
    "    # Prepare a copy of the original checkpoint dictionary to add EWC state to it\n",
    "    checkpoint_to_save_all = prev_checkpoint.copy()\n",
    "    # Add computed EWC state (save to CPU for better compatibility)\n",
    "    checkpoint_to_save_all['ewc_fisher'] = ewc_fisher_dict_all\n",
    "    checkpoint_to_save_all['ewc_params'] = ewc_params_dict_all\n",
    "    #-----------------\n",
    "    save_checkpoint_dir = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/EWC_CIL/Period_1_weights_with_ewc/EWC_with_All_samples\"))\n",
    "    ensure_folder(save_checkpoint_dir)\n",
    "    save_checkpoint_path = os.path.normpath(os.path.join(save_checkpoint_dir, f\"{model_name}_epoch_{prev_checkpoint['epoch']}_ewc_All.pth\"))\n",
    "    #-----------------\n",
    "    torch.save(checkpoint_to_save_all, save_checkpoint_path)\n",
    "    del ewc_fisher_dict_all, ewc_params_dict_all, checkpoint_to_save_all, save_checkpoint_dir, save_checkpoint_path\n",
    "except Exception as e:\n",
    "    print(f\"ERROR calculating or saving EWC state (All Samples): {e}\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# == Case 2: Compute EWC using 100 samples ==\n",
    "print(f\"\\nCalculating EWC state with sample_size = 100...\")\n",
    "sample_size_100 = 100\n",
    "# Call the static method again for the 100-sample case\n",
    "try:\n",
    "    ewc_fisher_dict_100, ewc_params_dict_100 = EWC.compute_fisher_and_params(\n",
    "        model=previous_model,             # Use the same loaded model\n",
    "        dataloader=train_loader_period1, # Use the same dataloader\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        sample_size=sample_size_100      # Use 100 samples this time\n",
    "    )\n",
    "    print(\"EWC Fisher and Params computed (100 Samples).\\n\")\n",
    "    #----------------------------------------<<<<<<<<<<<<<<<\n",
    "    # --- !! START INSPECTION HERE !! ---\n",
    "    inspect_fisher_info(ewc_fisher_dict_100, label=\"Computed Fisher Values (100 Samples)\")\n",
    "    # --- !! END INSPECTION !! ---\n",
    "    #----------------------------------------<<<<<<<<<<<<<<<\n",
    "    # Prepare another copy of the original checkpoint\n",
    "    checkpoint_to_save_100 = prev_checkpoint.copy()\n",
    "    # Add computed EWC state (save to CPU)\n",
    "    checkpoint_to_save_100['ewc_fisher'] = ewc_fisher_dict_100\n",
    "    checkpoint_to_save_100['ewc_params'] = ewc_params_dict_100\n",
    "    #-----------------\n",
    "    save_dir_100 = os.path.normpath(os.path.join('Class_Incremental_CL', f\"Classif_Bi_Dir_GRU_Model/Trained_models/EWC_CIL/Period_1_weights_with_ewc/EWC_with_{sample_size_100}_samples\"))\n",
    "    ensure_folder(save_dir_100) # Ensure the directory exists\n",
    "    save_path_100 = os.path.normpath(os.path.join(save_dir_100, f\"{model_name}_epoch_{prev_checkpoint['epoch']}_ewc_{sample_size_100}.pth\"))\n",
    "    #-----------------\n",
    "    torch.save(checkpoint_to_save_100, save_path_100)\n",
    "    del ewc_fisher_dict_100, ewc_params_dict_100, checkpoint_to_save_100, save_dir_100, save_path_100\n",
    "except Exception as e:\n",
    "    print(f\"ERROR calculating or saving EWC state (100 Samples): {e}\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"fisher_calc_batch_size\", \"train_dataset_period1\", \n",
    "            \"train_loader_period1\", \"Number_features\", \"unique_classes\", \"num_classes\", \"previous_model\", \"ewc_period_1\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n",
    "#-----------------\n",
    "del prev_checkpoint, best_model_path, prev_checkpoint_path\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 2 --> Training and saving in __*'1st_try'*__ (BiGRUWithAttention, lambda_ewc= 40, learning_rate= 0.0001) ---> Val acc = 98.10 %\n",
    "### Val-Class-Acc: {0: '99.50%', 1: '97.64%', 2: '85.81%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2]\n",
      "num_classes = 3\n",
      "\n",
      "Class Distribution for 'y_train':       Class 0   Percent:  53.41% || Class 1   Percent:  36.03% || Class 2   Percent:  10.55%\n",
      "Class Distribution for 'y_val':         Class 0   Percent:  52.72% || Class 1   Percent:  36.38% || Class 2   Percent:  10.90%\n",
      "Class Distribution for 'y_test':        Class 0   Percent:  49.11% || Class 1   Percent:  32.27% || Class 2   Percent:  18.62%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[1], # Change\n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\\n\")\n",
    "\n",
    "print_class_distribution(y_train, \"y_train\")\n",
    "print_class_distribution(y_val, \"y_val\")\n",
    "print_class_distribution(y_test, \"y_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previous period checkpoint from: \n",
      "\tClass_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_1_weights_with_ewc\\EWC_with_All_samples\\BiGRUWithAttentionEWC_epoch_1987_ewc_All.pth\n",
      "\n",
      "--- Inspecting Loaded Fisher Values (All Samples) ---\n",
      "Total Fisher Sum: 1.2840e+02\n",
      "Overall Max Fisher Abs Value: 3.1890e+01\n",
      "Overall Min Positive Fisher Value: 6.4935e-23\n",
      "Number of layers with all-zero Fisher: 0 / 36\n",
      "--- Finished Inspecting Loaded Fisher Values (All Samples) ---\n",
      "\n",
      "Transferring compatible weights to the new model...\n",
      "  Weights loaded. Keys missing in loaded dict (expected: fc layer): ['fc.weight', 'fc.bias']\n",
      "  Keys in loaded dict but not in model (should be empty): []\n",
      "\n",
      "Current Period Model Structure: \n",
      "BiGRUWithAttention(\n",
      "  (gru): GRU(7, 64, num_layers=4, batch_first=True, bidirectional=True)\n",
      "  (attention_fc): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "\n",
      "Instantiating EWC object using loaded state...\n",
      "'train_and_validate_ewc' function started.\n",
      "\n",
      "Existing folder has been removed : Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\n",
      "\n",
      "y_train:\n",
      "<class 'torch.Tensor'>\n",
      "torch.int64\n",
      "torch.Size([3634, 1000])\n",
      "X_train:\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "torch.Size([3634, 1000, 7])\n",
      "\n",
      "y_val:\n",
      "<class 'torch.Tensor'>\n",
      "torch.int64\n",
      "torch.Size([454, 1000])\n",
      "X_val:\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "torch.Size([454, 1000, 7])\n",
      "\n",
      "Dataset Lengths:\n",
      "Train Dataset Length: 3634\n",
      "Validation Dataset Length: 454\n",
      "\n",
      "DataLoader Batch Sizes:\n",
      "Number of Batches in Train DataLoader: 57\n",
      "Number of Batches in Validation DataLoader: 8\n",
      "\n",
      "y_train Unique Values and Stats:\n",
      "Unique values in y_train: tensor([0, 1, 2], device='cuda:0')\n",
      "y_train Min: 0, Max: 2\n",
      "\n",
      "y_val Unique Values and Stats:\n",
      "Unique values in y_val: tensor([0, 1, 2], device='cuda:0')\n",
      "y_val Min: 0, Max: 2\n",
      "\n",
      "Device Info:\n",
      "X_train Device: cuda:0\n",
      "y_train Device: cuda:0\n",
      "X_val Device: cuda:0\n",
      "y_val Device: cuda:0\n",
      "\n",
      "Epoch 1/2000, Train Loss: 0.516646182, Train-Class-Acc: {0: '95.43%', 1: '71.56%', 2: '43.45%'}, Val Loss: 0.314456881, Val Accuracy: 89.76%, Val-Class-Acc: {0: '96.95%', 1: '90.02%', 2: '54.17%'}, LR: 0.000100000\n",
      "Model saved after epoch 1 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_1.pth \n",
      "\n",
      "\n",
      "Unique target values: tensor([0, 1, 2], device='cuda:0')\n",
      "Target dtype: torch.int64\n",
      "Min target: 0, Max target: 2\n",
      "Unique classes in y_train: tensor([0, 1, 2], device='cuda:0')\n",
      "Unique classes in y_val: tensor([0, 1, 2], device='cuda:0')\n",
      "\n",
      "\n",
      "Unique target values: tensor([0, 1, 2], device='cuda:0')\n",
      "Target dtype: torch.int64\n",
      "Min target: 0, Max target: 2\n",
      "Unique classes in y_train: tensor([0, 1, 2], device='cuda:0')\n",
      "Unique classes in y_val: tensor([0, 1, 2], device='cuda:0')\n",
      "\n",
      "\n",
      "Unique target values: tensor([0, 1, 2], device='cuda:0')\n",
      "Target dtype: torch.int64\n",
      "Min target: 0, Max target: 2\n",
      "Unique classes in y_train: tensor([0, 1, 2], device='cuda:0')\n",
      "Unique classes in y_val: tensor([0, 1, 2], device='cuda:0')\n",
      "\n",
      "Epoch 2/2000, Train Loss: 0.247082876, Train-Class-Acc: {0: '96.50%', 1: '91.96%', 2: '66.67%'}, Val Loss: 0.215612208, Val Accuracy: 92.68%, Val-Class-Acc: {0: '97.63%', 1: '94.22%', 2: '63.58%'}, LR: 0.000100000\n",
      "Model saved after epoch 2 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_2.pth \n",
      "\n",
      "Epoch 3/2000, Train Loss: 0.166168391, Train-Class-Acc: {0: '97.00%', 1: '94.43%', 2: '81.35%'}, Val Loss: 0.160465348, Val Accuracy: 94.52%, Val-Class-Acc: {0: '98.04%', 1: '95.60%', 2: '73.94%'}, LR: 0.000100000\n",
      "Model saved after epoch 3 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_3.pth \n",
      "\n",
      "Epoch 4/2000, Train Loss: 0.124965630, Train-Class-Acc: {0: '97.48%', 1: '95.55%', 2: '89.27%'}, Val Loss: 0.124394979, Val Accuracy: 95.55%, Val-Class-Acc: {0: '97.65%', 1: '96.26%', 2: '82.99%'}, LR: 0.000100000\n",
      "Model saved after epoch 4 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_4.pth \n",
      "\n",
      "Epoch 5/2000, Train Loss: 0.104959967, Train-Class-Acc: {0: '97.87%', 1: '95.97%', 2: '91.91%'}, Val Loss: 0.117886488, Val Accuracy: 95.65%, Val-Class-Acc: {0: '99.19%', 1: '93.40%', 2: '86.05%'}, LR: 0.000100000\n",
      "Model saved after epoch 5 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_5.pth \n",
      "\n",
      "Epoch 6/2000, Train Loss: 0.090284552, Train-Class-Acc: {0: '98.18%', 1: '96.36%', 2: '93.49%'}, Val Loss: 0.093285344, Val Accuracy: 96.51%, Val-Class-Acc: {0: '98.18%', 1: '96.35%', 2: '88.96%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 89.76%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_1.pth\n",
      "Model saved after epoch 6 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_6.pth \n",
      "\n",
      "Epoch 7/2000, Train Loss: 0.081027286, Train-Class-Acc: {0: '98.28%', 1: '96.61%', 2: '94.54%'}, Val Loss: 0.090480234, Val Accuracy: 96.58%, Val-Class-Acc: {0: '98.52%', 1: '96.83%', 2: '86.38%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 92.68%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_2.pth\n",
      "Model saved after epoch 7 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_7.pth \n",
      "\n",
      "Epoch 8/2000, Train Loss: 0.074761209, Train-Class-Acc: {0: '98.36%', 1: '96.87%', 2: '95.11%'}, Val Loss: 0.092230345, Val Accuracy: 96.40%, Val-Class-Acc: {0: '98.74%', 1: '97.03%', 2: '83.00%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 94.52%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_3.pth\n",
      "Model saved after epoch 8 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_8.pth \n",
      "\n",
      "Epoch 9/2000, Train Loss: 0.069364211, Train-Class-Acc: {0: '98.43%', 1: '97.03%', 2: '95.64%'}, Val Loss: 0.081598086, Val Accuracy: 96.61%, Val-Class-Acc: {0: '98.20%', 1: '97.45%', 2: '86.12%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.55%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_4.pth\n",
      "Model saved after epoch 9 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_9.pth \n",
      "\n",
      "Epoch 10/2000, Train Loss: 0.063258917, Train-Class-Acc: {0: '98.53%', 1: '97.27%', 2: '96.54%'}, Val Loss: 0.074056491, Val Accuracy: 97.12%, Val-Class-Acc: {0: '98.04%', 1: '97.40%', 2: '91.68%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 95.65%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_5.pth\n",
      "Model saved after epoch 10 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_10.pth \n",
      "\n",
      "Epoch 11/2000, Train Loss: 0.060803311, Train-Class-Acc: {0: '98.51%', 1: '97.36%', 2: '96.59%'}, Val Loss: 0.070958919, Val Accuracy: 97.16%, Val-Class-Acc: {0: '98.66%', 1: '96.91%', 2: '90.69%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.40%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_8.pth\n",
      "Model saved after epoch 11 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_11.pth \n",
      "\n",
      "Epoch 12/2000, Train Loss: 0.055312459, Train-Class-Acc: {0: '98.64%', 1: '97.63%', 2: '97.07%'}, Val Loss: 0.070098835, Val Accuracy: 97.26%, Val-Class-Acc: {0: '98.99%', 1: '95.64%', 2: '94.34%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.51%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_6.pth\n",
      "Model saved after epoch 12 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_12.pth \n",
      "\n",
      "Epoch 13/2000, Train Loss: 0.050769085, Train-Class-Acc: {0: '98.76%', 1: '97.80%', 2: '97.44%'}, Val Loss: 0.073731165, Val Accuracy: 96.86%, Val-Class-Acc: {0: '98.61%', 1: '97.73%', 2: '85.47%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.58%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_7.pth\n",
      "Model saved after epoch 13 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_13.pth \n",
      "\n",
      "Epoch 14/2000, Train Loss: 0.048969863, Train-Class-Acc: {0: '98.77%', 1: '97.86%', 2: '97.52%'}, Val Loss: 0.069206351, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.05%', 1: '94.95%', 2: '96.39%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_9.pth\n",
      "Model saved after epoch 14 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_14.pth \n",
      "\n",
      "Epoch 15/2000, Train Loss: 0.046742413, Train-Class-Acc: {0: '98.79%', 1: '97.93%', 2: '97.66%'}, Val Loss: 0.058810201, Val Accuracy: 97.58%, Val-Class-Acc: {0: '98.84%', 1: '97.04%', 2: '93.28%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 96.86%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_13.pth\n",
      "Model saved after epoch 15 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_15.pth \n",
      "\n",
      "Epoch 16/2000, Train Loss: 0.043672775, Train-Class-Acc: {0: '98.87%', 1: '97.99%', 2: '97.89%'}, Val Loss: 0.059722598, Val Accuracy: 97.76%, Val-Class-Acc: {0: '98.76%', 1: '97.21%', 2: '94.73%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.12%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_10.pth\n",
      "Model saved after epoch 16 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_16.pth \n",
      "\n",
      "Epoch 17/2000, Train Loss: 0.044208688, Train-Class-Acc: {0: '98.77%', 1: '97.92%', 2: '98.09%'}, Val Loss: 0.064885613, Val Accuracy: 97.35%, Val-Class-Acc: {0: '99.25%', 1: '95.96%', 2: '92.80%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.16%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_11.pth\n",
      "Model saved after epoch 17 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_17.pth \n",
      "\n",
      "Epoch 18/2000, Train Loss: 0.040072296, Train-Class-Acc: {0: '98.90%', 1: '98.12%', 2: '98.44%'}, Val Loss: 0.076323332, Val Accuracy: 96.74%, Val-Class-Acc: {0: '97.22%', 1: '95.88%', 2: '97.30%'}, LR: 0.000100000\n",
      "Epoch 19/2000, Train Loss: 0.037940572, Train-Class-Acc: {0: '98.95%', 1: '98.30%', 2: '98.59%'}, Val Loss: 0.063919989, Val Accuracy: 97.39%, Val-Class-Acc: {0: '99.38%', 1: '96.66%', 2: '90.20%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.26%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_12.pth\n",
      "Model saved after epoch 19 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_19.pth \n",
      "\n",
      "Epoch 20/2000, Train Loss: 0.035706738, Train-Class-Acc: {0: '98.99%', 1: '98.44%', 2: '98.61%'}, Val Loss: 0.055910393, Val Accuracy: 97.77%, Val-Class-Acc: {0: '98.88%', 1: '97.42%', 2: '93.60%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.27%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_14.pth\n",
      "Model saved after epoch 20 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_20.pth \n",
      "\n",
      "Epoch 21/2000, Train Loss: 0.034113684, Train-Class-Acc: {0: '99.04%', 1: '98.44%', 2: '98.85%'}, Val Loss: 0.055848229, Val Accuracy: 97.69%, Val-Class-Acc: {0: '98.81%', 1: '97.41%', 2: '93.20%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.35%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_17.pth\n",
      "Model saved after epoch 21 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_21.pth \n",
      "\n",
      "Epoch 22/2000, Train Loss: 0.038397786, Train-Class-Acc: {0: '98.89%', 1: '98.17%', 2: '98.49%'}, Val Loss: 0.059884258, Val Accuracy: 97.56%, Val-Class-Acc: {0: '98.96%', 1: '97.24%', 2: '91.82%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.39%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_19.pth\n",
      "Model saved after epoch 22 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_22.pth \n",
      "\n",
      "Epoch 23/2000, Train Loss: 0.032301167, Train-Class-Acc: {0: '99.04%', 1: '98.57%', 2: '99.02%'}, Val Loss: 0.057142296, Val Accuracy: 97.72%, Val-Class-Acc: {0: '98.92%', 1: '96.66%', 2: '95.43%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.56%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_22.pth\n",
      "Model saved after epoch 23 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_23.pth \n",
      "\n",
      "Epoch 24/2000, Train Loss: 0.030055119, Train-Class-Acc: {0: '99.11%', 1: '98.69%', 2: '99.19%'}, Val Loss: 0.068460165, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.65%', 1: '96.36%', 2: '89.42%'}, LR: 0.000100000\n",
      "Epoch 25/2000, Train Loss: 0.031595601, Train-Class-Acc: {0: '99.04%', 1: '98.54%', 2: '99.06%'}, Val Loss: 0.073882015, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.31%', 1: '97.55%', 2: '86.22%'}, LR: 0.000100000\n",
      "Epoch 26/2000, Train Loss: 0.033633976, Train-Class-Acc: {0: '98.97%', 1: '98.54%', 2: '98.93%'}, Val Loss: 0.075032863, Val Accuracy: 96.95%, Val-Class-Acc: {0: '97.29%', 1: '96.38%', 2: '97.18%'}, LR: 0.000100000\n",
      "Epoch 27/2000, Train Loss: 0.033098843, Train-Class-Acc: {0: '99.06%', 1: '98.40%', 2: '98.91%'}, Val Loss: 0.065150263, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.32%', 1: '96.74%', 2: '91.31%'}, LR: 0.000100000\n",
      "Epoch 28/2000, Train Loss: 0.027622954, Train-Class-Acc: {0: '99.18%', 1: '98.80%', 2: '99.20%'}, Val Loss: 0.061130145, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.10%', 1: '97.05%', 2: '92.23%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.58%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_15.pth\n",
      "Model saved after epoch 28 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_28.pth \n",
      "\n",
      "Epoch 29/2000, Train Loss: 0.026358412, Train-Class-Acc: {0: '99.20%', 1: '98.86%', 2: '99.32%'}, Val Loss: 0.061274333, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.46%', 1: '97.37%', 2: '90.54%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.61%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_28.pth\n",
      "Model saved after epoch 29 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_29.pth \n",
      "\n",
      "Epoch 30/2000, Train Loss: 0.026390455, Train-Class-Acc: {0: '99.18%', 1: '98.85%', 2: '99.24%'}, Val Loss: 0.064763940, Val Accuracy: 97.72%, Val-Class-Acc: {0: '99.46%', 1: '97.39%', 2: '90.42%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.69%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_21.pth\n",
      "Model saved after epoch 30 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_30.pth \n",
      "\n",
      "Epoch 31/2000, Train Loss: 0.029138582, Train-Class-Acc: {0: '99.11%', 1: '98.62%', 2: '99.15%'}, Val Loss: 0.104665271, Val Accuracy: 96.89%, Val-Class-Acc: {0: '99.42%', 1: '97.95%', 2: '81.07%'}, LR: 0.000100000\n",
      "Epoch 32/2000, Train Loss: 0.028476915, Train-Class-Acc: {0: '99.17%', 1: '98.70%', 2: '98.94%'}, Val Loss: 0.062206364, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.36%', 1: '97.20%', 2: '91.80%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.72%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_30.pth\n",
      "Model saved after epoch 32 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_32.pth \n",
      "\n",
      "Epoch 33/2000, Train Loss: 0.024353075, Train-Class-Acc: {0: '99.24%', 1: '98.93%', 2: '99.36%'}, Val Loss: 0.061112647, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.21%', 1: '97.18%', 2: '92.82%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.72%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_23.pth\n",
      "Model saved after epoch 33 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_33.pth \n",
      "\n",
      "Epoch 34/2000, Train Loss: 0.025093674, Train-Class-Acc: {0: '99.20%', 1: '98.85%', 2: '99.34%'}, Val Loss: 0.061264481, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.07%', 1: '96.54%', 2: '95.23%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.73%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_29.pth\n",
      "Model saved after epoch 34 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_34.pth \n",
      "\n",
      "Epoch 35/2000, Train Loss: 0.024427234, Train-Class-Acc: {0: '99.22%', 1: '98.87%', 2: '99.38%'}, Val Loss: 0.069827662, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.60%', 1: '97.03%', 2: '90.51%'}, LR: 0.000100000\n",
      "Epoch 36/2000, Train Loss: 0.024465354, Train-Class-Acc: {0: '99.23%', 1: '98.88%', 2: '99.33%'}, Val Loss: 0.067506884, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.14%', 1: '97.51%', 2: '90.82%'}, LR: 0.000100000\n",
      "Epoch 37/2000, Train Loss: 0.023707923, Train-Class-Acc: {0: '99.25%', 1: '98.92%', 2: '99.37%'}, Val Loss: 0.073019060, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.12%', 1: '97.66%', 2: '89.41%'}, LR: 0.000100000\n",
      "Epoch 38/2000, Train Loss: 0.022671147, Train-Class-Acc: {0: '99.29%', 1: '98.99%', 2: '99.41%'}, Val Loss: 0.065815348, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.58%', 1: '96.93%', 2: '92.22%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.73%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_34.pth\n",
      "Model saved after epoch 38 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_38.pth \n",
      "\n",
      "Epoch 39/2000, Train Loss: 0.022312661, Train-Class-Acc: {0: '99.29%', 1: '98.98%', 2: '99.46%'}, Val Loss: 0.078827333, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.59%', 1: '96.70%', 2: '89.51%'}, LR: 0.000100000\n",
      "Epoch 40/2000, Train Loss: 0.023069235, Train-Class-Acc: {0: '99.25%', 1: '98.94%', 2: '99.44%'}, Val Loss: 0.080072491, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.70%', 1: '96.42%', 2: '90.66%'}, LR: 0.000100000\n",
      "Epoch 41/2000, Train Loss: 0.023676665, Train-Class-Acc: {0: '99.25%', 1: '98.90%', 2: '99.29%'}, Val Loss: 0.079522069, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.55%', 1: '96.23%', 2: '91.30%'}, LR: 0.000100000\n",
      "Epoch 42/2000, Train Loss: 0.020370420, Train-Class-Acc: {0: '99.34%', 1: '99.11%', 2: '99.53%'}, Val Loss: 0.075465846, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.30%', 1: '96.33%', 2: '92.63%'}, LR: 0.000100000\n",
      "Epoch 43/2000, Train Loss: 0.019752991, Train-Class-Acc: {0: '99.37%', 1: '99.12%', 2: '99.54%'}, Val Loss: 0.075727409, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.45%', 1: '96.97%', 2: '90.97%'}, LR: 0.000100000\n",
      "Epoch 44/2000, Train Loss: 0.028439060, Train-Class-Acc: {0: '99.15%', 1: '98.66%', 2: '98.93%'}, Val Loss: 0.072973027, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.18%', 1: '96.85%', 2: '91.93%'}, LR: 0.000100000\n",
      "Epoch 45/2000, Train Loss: 0.019462226, Train-Class-Acc: {0: '99.36%', 1: '99.16%', 2: '99.56%'}, Val Loss: 0.078539136, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.70%', 1: '96.70%', 2: '89.93%'}, LR: 0.000100000\n",
      "Epoch 46/2000, Train Loss: 0.019451556, Train-Class-Acc: {0: '99.36%', 1: '99.14%', 2: '99.58%'}, Val Loss: 0.075084483, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.62%', 1: '96.73%', 2: '91.91%'}, LR: 0.000100000\n",
      "Epoch 47/2000, Train Loss: 0.018667782, Train-Class-Acc: {0: '99.39%', 1: '99.17%', 2: '99.59%'}, Val Loss: 0.079643569, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.49%', 1: '97.20%', 2: '88.85%'}, LR: 0.000100000\n",
      "Epoch 48/2000, Train Loss: 0.018813798, Train-Class-Acc: {0: '99.37%', 1: '99.17%', 2: '99.58%'}, Val Loss: 0.080947920, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.69%', 1: '96.60%', 2: '90.41%'}, LR: 0.000100000\n",
      "Epoch 49/2000, Train Loss: 0.018412351, Train-Class-Acc: {0: '99.39%', 1: '99.19%', 2: '99.62%'}, Val Loss: 0.075386492, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.26%', 1: '96.66%', 2: '93.38%'}, LR: 0.000100000\n",
      "Epoch 50/2000, Train Loss: 0.019249460, Train-Class-Acc: {0: '99.37%', 1: '99.10%', 2: '99.60%'}, Val Loss: 0.080739879, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.13%', 1: '96.61%', 2: '90.30%'}, LR: 0.000100000\n",
      "Epoch 51/2000, Train Loss: 0.028920085, Train-Class-Acc: {0: '99.04%', 1: '98.61%', 2: '99.08%'}, Val Loss: 0.068957568, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.04%', 1: '96.45%', 2: '94.72%'}, LR: 0.000100000\n",
      "Epoch 52/2000, Train Loss: 0.025370944, Train-Class-Acc: {0: '99.14%', 1: '98.78%', 2: '99.33%'}, Val Loss: 0.058782248, Val Accuracy: 97.94%, Val-Class-Acc: {0: '98.97%', 1: '97.83%', 2: '93.30%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.75%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_32.pth\n",
      "Model saved after epoch 52 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_52.pth \n",
      "\n",
      "Epoch 53/2000, Train Loss: 0.018250485, Train-Class-Acc: {0: '99.40%', 1: '99.17%', 2: '99.63%'}, Val Loss: 0.077290281, Val Accuracy: 97.80%, Val-Class-Acc: {0: '99.59%', 1: '97.89%', 2: '88.83%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.76%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_16.pth\n",
      "Model saved after epoch 53 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_53.pth \n",
      "\n",
      "Epoch 54/2000, Train Loss: 0.017324169, Train-Class-Acc: {0: '99.42%', 1: '99.26%', 2: '99.67%'}, Val Loss: 0.076724546, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.63%', 1: '96.70%', 2: '91.42%'}, LR: 0.000100000\n",
      "Epoch 55/2000, Train Loss: 0.017041039, Train-Class-Acc: {0: '99.44%', 1: '99.22%', 2: '99.67%'}, Val Loss: 0.077968152, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.44%', 1: '96.83%', 2: '91.39%'}, LR: 0.000100000\n",
      "Epoch 56/2000, Train Loss: 0.016898569, Train-Class-Acc: {0: '99.43%', 1: '99.26%', 2: '99.67%'}, Val Loss: 0.080447216, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.35%', 1: '96.53%', 2: '91.78%'}, LR: 0.000100000\n",
      "Epoch 57/2000, Train Loss: 0.016770496, Train-Class-Acc: {0: '99.43%', 1: '99.25%', 2: '99.68%'}, Val Loss: 0.075316121, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.35%', 1: '97.24%', 2: '90.70%'}, LR: 0.000100000\n",
      "Epoch 58/2000, Train Loss: 0.016278102, Train-Class-Acc: {0: '99.45%', 1: '99.30%', 2: '99.71%'}, Val Loss: 0.078735659, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.62%', 1: '97.04%', 2: '90.21%'}, LR: 0.000100000\n",
      "Epoch 59/2000, Train Loss: 0.016355956, Train-Class-Acc: {0: '99.45%', 1: '99.27%', 2: '99.66%'}, Val Loss: 0.079317274, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.64%', 1: '96.71%', 2: '90.30%'}, LR: 0.000100000\n",
      "Epoch 60/2000, Train Loss: 0.017552357, Train-Class-Acc: {0: '99.40%', 1: '99.17%', 2: '99.64%'}, Val Loss: 0.081866692, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.65%', 1: '96.54%', 2: '91.39%'}, LR: 0.000100000\n",
      "Epoch 61/2000, Train Loss: 0.015705450, Train-Class-Acc: {0: '99.47%', 1: '99.31%', 2: '99.70%'}, Val Loss: 0.077111543, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.58%', 1: '96.46%', 2: '92.75%'}, LR: 0.000100000\n",
      "Epoch 62/2000, Train Loss: 0.015453277, Train-Class-Acc: {0: '99.46%', 1: '99.32%', 2: '99.74%'}, Val Loss: 0.083890954, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.45%', 1: '97.07%', 2: '89.55%'}, LR: 0.000100000\n",
      "Epoch 63/2000, Train Loss: 0.014930556, Train-Class-Acc: {0: '99.48%', 1: '99.34%', 2: '99.75%'}, Val Loss: 0.074386833, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.48%', 1: '97.49%', 2: '89.80%'}, LR: 0.000100000\n",
      "Epoch 64/2000, Train Loss: 0.017173893, Train-Class-Acc: {0: '99.41%', 1: '99.19%', 2: '99.67%'}, Val Loss: 0.078871319, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.22%', 1: '96.90%', 2: '92.33%'}, LR: 0.000100000\n",
      "Epoch 65/2000, Train Loss: 0.019491251, Train-Class-Acc: {0: '99.32%', 1: '99.07%', 2: '99.54%'}, Val Loss: 0.080270587, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.37%', 1: '96.35%', 2: '93.80%'}, LR: 0.000100000\n",
      "Epoch 66/2000, Train Loss: 0.016925687, Train-Class-Acc: {0: '99.40%', 1: '99.17%', 2: '99.68%'}, Val Loss: 0.074814763, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.09%', 1: '96.69%', 2: '94.92%'}, LR: 0.000100000\n",
      "Epoch 67/2000, Train Loss: 0.014823990, Train-Class-Acc: {0: '99.49%', 1: '99.34%', 2: '99.73%'}, Val Loss: 0.079185903, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.63%', 1: '96.91%', 2: '91.64%'}, LR: 0.000100000\n",
      "Epoch 68/2000, Train Loss: 0.014247263, Train-Class-Acc: {0: '99.50%', 1: '99.37%', 2: '99.75%'}, Val Loss: 0.072697062, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.18%', 1: '97.09%', 2: '93.17%'}, LR: 0.000100000\n",
      "Epoch 69/2000, Train Loss: 0.014137210, Train-Class-Acc: {0: '99.51%', 1: '99.38%', 2: '99.75%'}, Val Loss: 0.078271388, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.46%', 1: '97.11%', 2: '91.80%'}, LR: 0.000100000\n",
      "Epoch 70/2000, Train Loss: 0.016584909, Train-Class-Acc: {0: '99.47%', 1: '99.19%', 2: '99.67%'}, Val Loss: 0.089328464, Val Accuracy: 97.12%, Val-Class-Acc: {0: '97.31%', 1: '97.90%', 2: '93.64%'}, LR: 0.000100000\n",
      "Epoch 71/2000, Train Loss: 0.073958574, Train-Class-Acc: {0: '98.30%', 1: '97.15%', 2: '96.16%'}, Val Loss: 0.074987444, Val Accuracy: 97.54%, Val-Class-Acc: {0: '98.48%', 1: '97.52%', 2: '93.09%'}, LR: 0.000100000\n",
      "Epoch 72/2000, Train Loss: 0.019858842, Train-Class-Acc: {0: '99.34%', 1: '99.11%', 2: '99.61%'}, Val Loss: 0.068167109, Val Accuracy: 97.83%, Val-Class-Acc: {0: '99.55%', 1: '96.82%', 2: '92.85%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.77%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_20.pth\n",
      "Model saved after epoch 72 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_72.pth \n",
      "\n",
      "Epoch 73/2000, Train Loss: 0.014561378, Train-Class-Acc: {0: '99.52%', 1: '99.39%', 2: '99.75%'}, Val Loss: 0.071431679, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.31%', 1: '97.10%', 2: '91.86%'}, LR: 0.000100000\n",
      "Epoch 74/2000, Train Loss: 0.014020713, Train-Class-Acc: {0: '99.53%', 1: '99.42%', 2: '99.77%'}, Val Loss: 0.071867476, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.38%', 1: '97.35%', 2: '90.74%'}, LR: 0.000100000\n",
      "Epoch 75/2000, Train Loss: 0.013496278, Train-Class-Acc: {0: '99.54%', 1: '99.43%', 2: '99.77%'}, Val Loss: 0.075332405, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.47%', 1: '97.06%', 2: '90.83%'}, LR: 0.000100000\n",
      "Epoch 76/2000, Train Loss: 0.013190324, Train-Class-Acc: {0: '99.54%', 1: '99.44%', 2: '99.77%'}, Val Loss: 0.078257627, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.65%', 1: '96.66%', 2: '90.75%'}, LR: 0.000100000\n",
      "Epoch 77/2000, Train Loss: 0.013199738, Train-Class-Acc: {0: '99.55%', 1: '99.42%', 2: '99.78%'}, Val Loss: 0.074503356, Val Accuracy: 97.74%, Val-Class-Acc: {0: '99.50%', 1: '96.75%', 2: '92.58%'}, LR: 0.000100000\n",
      "Epoch 78/2000, Train Loss: 0.013062022, Train-Class-Acc: {0: '99.54%', 1: '99.43%', 2: '99.77%'}, Val Loss: 0.082122940, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.65%', 1: '97.14%', 2: '89.23%'}, LR: 0.000100000\n",
      "Epoch 79/2000, Train Loss: 0.012754420, Train-Class-Acc: {0: '99.56%', 1: '99.44%', 2: '99.78%'}, Val Loss: 0.078932818, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.51%', 1: '96.90%', 2: '90.63%'}, LR: 0.000100000\n",
      "Epoch 80/2000, Train Loss: 0.014522679, Train-Class-Acc: {0: '99.49%', 1: '99.33%', 2: '99.75%'}, Val Loss: 0.082068844, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.36%', 1: '97.80%', 2: '89.01%'}, LR: 0.000100000\n",
      "Epoch 81/2000, Train Loss: 0.012838488, Train-Class-Acc: {0: '99.56%', 1: '99.43%', 2: '99.76%'}, Val Loss: 0.079782436, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.41%', 1: '96.50%', 2: '92.21%'}, LR: 0.000100000\n",
      "Epoch 82/2000, Train Loss: 0.012431171, Train-Class-Acc: {0: '99.57%', 1: '99.45%', 2: '99.79%'}, Val Loss: 0.079474808, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.65%', 1: '96.61%', 2: '92.12%'}, LR: 0.000100000\n",
      "Epoch 83/2000, Train Loss: 0.012178557, Train-Class-Acc: {0: '99.58%', 1: '99.46%', 2: '99.80%'}, Val Loss: 0.079505395, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.64%', 1: '96.57%', 2: '91.99%'}, LR: 0.000100000\n",
      "Epoch 84/2000, Train Loss: 0.012236825, Train-Class-Acc: {0: '99.58%', 1: '99.45%', 2: '99.80%'}, Val Loss: 0.081909976, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.55%', 1: '97.23%', 2: '89.86%'}, LR: 0.000100000\n",
      "Epoch 85/2000, Train Loss: 0.012234893, Train-Class-Acc: {0: '99.57%', 1: '99.46%', 2: '99.81%'}, Val Loss: 0.087534296, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.53%', 1: '97.32%', 2: '88.98%'}, LR: 0.000100000\n",
      "Epoch 86/2000, Train Loss: 0.012789007, Train-Class-Acc: {0: '99.54%', 1: '99.42%', 2: '99.80%'}, Val Loss: 0.107970577, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.92%', 1: '95.81%', 2: '88.67%'}, LR: 0.000100000\n",
      "Epoch 87/2000, Train Loss: 0.014484722, Train-Class-Acc: {0: '99.50%', 1: '99.31%', 2: '99.71%'}, Val Loss: 0.088682786, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.64%', 1: '97.40%', 2: '88.43%'}, LR: 0.000100000\n",
      "Epoch 88/2000, Train Loss: 0.011774848, Train-Class-Acc: {0: '99.59%', 1: '99.47%', 2: '99.81%'}, Val Loss: 0.088759395, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.69%', 1: '97.01%', 2: '88.89%'}, LR: 0.000100000\n",
      "Epoch 89/2000, Train Loss: 0.011788885, Train-Class-Acc: {0: '99.59%', 1: '99.47%', 2: '99.80%'}, Val Loss: 0.094096136, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.82%', 1: '97.23%', 2: '87.72%'}, LR: 0.000100000\n",
      "Epoch 90/2000, Train Loss: 0.012125010, Train-Class-Acc: {0: '99.58%', 1: '99.44%', 2: '99.81%'}, Val Loss: 0.089396579, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.67%', 1: '97.50%', 2: '88.11%'}, LR: 0.000100000\n",
      "Epoch 91/2000, Train Loss: 0.011300169, Train-Class-Acc: {0: '99.62%', 1: '99.50%', 2: '99.80%'}, Val Loss: 0.086085919, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.65%', 1: '97.03%', 2: '89.65%'}, LR: 0.000100000\n",
      "Epoch 92/2000, Train Loss: 0.011772364, Train-Class-Acc: {0: '99.58%', 1: '99.46%', 2: '99.81%'}, Val Loss: 0.093918587, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.74%', 1: '96.96%', 2: '89.14%'}, LR: 0.000100000\n",
      "Epoch 93/2000, Train Loss: 0.011256326, Train-Class-Acc: {0: '99.62%', 1: '99.49%', 2: '99.82%'}, Val Loss: 0.083756259, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.03%', 1: '97.83%', 2: '90.70%'}, LR: 0.000100000\n",
      "Epoch 94/2000, Train Loss: 0.012916785, Train-Class-Acc: {0: '99.54%', 1: '99.40%', 2: '99.79%'}, Val Loss: 0.090283979, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.22%', 1: '98.09%', 2: '88.22%'}, LR: 0.000100000\n",
      "Epoch 95/2000, Train Loss: 0.011297500, Train-Class-Acc: {0: '99.60%', 1: '99.48%', 2: '99.82%'}, Val Loss: 0.090929600, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.30%', 1: '97.34%', 2: '89.55%'}, LR: 0.000100000\n",
      "Epoch 96/2000, Train Loss: 0.011828375, Train-Class-Acc: {0: '99.60%', 1: '99.46%', 2: '99.76%'}, Val Loss: 0.090753367, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.64%', 1: '96.55%', 2: '91.92%'}, LR: 0.000100000\n",
      "Epoch 97/2000, Train Loss: 0.011351285, Train-Class-Acc: {0: '99.61%', 1: '99.47%', 2: '99.81%'}, Val Loss: 0.081012235, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.06%', 1: '96.77%', 2: '94.71%'}, LR: 0.000100000\n",
      "Epoch 98/2000, Train Loss: 0.031366141, Train-Class-Acc: {0: '99.16%', 1: '98.67%', 2: '98.93%'}, Val Loss: 0.092423316, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.62%', 1: '97.45%', 2: '88.98%'}, LR: 0.000100000\n",
      "Epoch 99/2000, Train Loss: 0.012073605, Train-Class-Acc: {0: '99.59%', 1: '99.45%', 2: '99.76%'}, Val Loss: 0.095972701, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.52%', 1: '97.77%', 2: '87.03%'}, LR: 0.000100000\n",
      "Epoch 100/2000, Train Loss: 0.010697794, Train-Class-Acc: {0: '99.63%', 1: '99.52%', 2: '99.83%'}, Val Loss: 0.088331199, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.30%', 1: '97.70%', 2: '88.33%'}, LR: 0.000100000\n",
      "Epoch 101/2000, Train Loss: 0.010681058, Train-Class-Acc: {0: '99.63%', 1: '99.52%', 2: '99.82%'}, Val Loss: 0.089013936, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.68%', 1: '97.31%', 2: '89.52%'}, LR: 0.000100000\n",
      "Epoch 102/2000, Train Loss: 0.010398865, Train-Class-Acc: {0: '99.65%', 1: '99.54%', 2: '99.83%'}, Val Loss: 0.078981667, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.23%', 1: '97.58%', 2: '91.18%'}, LR: 0.000100000\n",
      "Epoch 103/2000, Train Loss: 0.014875370, Train-Class-Acc: {0: '99.48%', 1: '99.30%', 2: '99.74%'}, Val Loss: 0.099221375, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.88%', 1: '97.06%', 2: '88.32%'}, LR: 0.000100000\n",
      "Epoch 104/2000, Train Loss: 0.011986414, Train-Class-Acc: {0: '99.58%', 1: '99.43%', 2: '99.78%'}, Val Loss: 0.081187479, Val Accuracy: 97.84%, Val-Class-Acc: {0: '99.49%', 1: '97.66%', 2: '90.43%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.78%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_33.pth\n",
      "Model saved after epoch 104 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_104.pth \n",
      "\n",
      "Epoch 105/2000, Train Loss: 0.010171314, Train-Class-Acc: {0: '99.66%', 1: '99.54%', 2: '99.85%'}, Val Loss: 0.086959769, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.22%', 1: '98.16%', 2: '88.51%'}, LR: 0.000100000\n",
      "Epoch 106/2000, Train Loss: 0.009879114, Train-Class-Acc: {0: '99.66%', 1: '99.56%', 2: '99.85%'}, Val Loss: 0.101804845, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.82%', 1: '97.34%', 2: '86.95%'}, LR: 0.000100000\n",
      "Epoch 107/2000, Train Loss: 0.013211532, Train-Class-Acc: {0: '99.53%', 1: '99.32%', 2: '99.81%'}, Val Loss: 0.092522743, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.14%', 1: '97.26%', 2: '90.71%'}, LR: 0.000100000\n",
      "Epoch 108/2000, Train Loss: 0.010179290, Train-Class-Acc: {0: '99.64%', 1: '99.54%', 2: '99.84%'}, Val Loss: 0.094060288, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.71%', 1: '97.77%', 2: '87.61%'}, LR: 0.000100000\n",
      "Epoch 109/2000, Train Loss: 0.009514541, Train-Class-Acc: {0: '99.68%', 1: '99.58%', 2: '99.85%'}, Val Loss: 0.089887278, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.28%', 1: '97.65%', 2: '89.48%'}, LR: 0.000100000\n",
      "Epoch 110/2000, Train Loss: 0.009300454, Train-Class-Acc: {0: '99.69%', 1: '99.59%', 2: '99.86%'}, Val Loss: 0.084317772, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.15%', 1: '97.69%', 2: '90.24%'}, LR: 0.000100000\n",
      "Epoch 111/2000, Train Loss: 0.009737153, Train-Class-Acc: {0: '99.67%', 1: '99.56%', 2: '99.85%'}, Val Loss: 0.097620163, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.66%', 1: '97.39%', 2: '88.68%'}, LR: 0.000100000\n",
      "Epoch 112/2000, Train Loss: 0.031664853, Train-Class-Acc: {0: '99.29%', 1: '98.74%', 2: '98.90%'}, Val Loss: 0.101466332, Val Accuracy: 96.94%, Val-Class-Acc: {0: '97.49%', 1: '96.77%', 2: '94.81%'}, LR: 0.000100000\n",
      "Epoch 113/2000, Train Loss: 0.025938765, Train-Class-Acc: {0: '99.25%', 1: '98.80%', 2: '99.08%'}, Val Loss: 0.077258879, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.34%', 1: '97.69%', 2: '89.17%'}, LR: 0.000100000\n",
      "Epoch 114/2000, Train Loss: 0.009996288, Train-Class-Acc: {0: '99.68%', 1: '99.57%', 2: '99.84%'}, Val Loss: 0.082337282, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.52%', 1: '97.70%', 2: '87.94%'}, LR: 0.000100000\n",
      "Epoch 115/2000, Train Loss: 0.009364015, Train-Class-Acc: {0: '99.69%', 1: '99.61%', 2: '99.85%'}, Val Loss: 0.091331050, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.78%', 1: '97.58%', 2: '86.83%'}, LR: 0.000100000\n",
      "Epoch 116/2000, Train Loss: 0.009267436, Train-Class-Acc: {0: '99.70%', 1: '99.59%', 2: '99.85%'}, Val Loss: 0.086210757, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.60%', 1: '97.68%', 2: '87.36%'}, LR: 0.000100000\n",
      "Epoch 117/2000, Train Loss: 0.008959270, Train-Class-Acc: {0: '99.71%', 1: '99.62%', 2: '99.86%'}, Val Loss: 0.085006082, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.72%', 1: '97.55%', 2: '88.37%'}, LR: 0.000100000\n",
      "Epoch 118/2000, Train Loss: 0.008772295, Train-Class-Acc: {0: '99.72%', 1: '99.62%', 2: '99.87%'}, Val Loss: 0.095164557, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.72%', 1: '97.86%', 2: '86.52%'}, LR: 0.000100000\n",
      "Epoch 119/2000, Train Loss: 0.008884927, Train-Class-Acc: {0: '99.71%', 1: '99.60%', 2: '99.87%'}, Val Loss: 0.095165458, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.71%', 1: '97.85%', 2: '86.27%'}, LR: 0.000100000\n",
      "Epoch 120/2000, Train Loss: 0.008897151, Train-Class-Acc: {0: '99.70%', 1: '99.62%', 2: '99.85%'}, Val Loss: 0.082289713, Val Accuracy: 97.80%, Val-Class-Acc: {0: '99.72%', 1: '97.53%', 2: '89.41%'}, LR: 0.000100000\n",
      "Epoch 121/2000, Train Loss: 0.008597919, Train-Class-Acc: {0: '99.73%', 1: '99.62%', 2: '99.87%'}, Val Loss: 0.079184106, Val Accuracy: 97.87%, Val-Class-Acc: {0: '99.47%', 1: '97.58%', 2: '91.12%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.80%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_53.pth\n",
      "Model saved after epoch 121 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_121.pth \n",
      "\n",
      "Epoch 122/2000, Train Loss: 0.008609266, Train-Class-Acc: {0: '99.72%', 1: '99.62%', 2: '99.87%'}, Val Loss: 0.081654723, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.40%', 1: '97.76%', 2: '90.32%'}, LR: 0.000100000\n",
      "Epoch 123/2000, Train Loss: 0.009057408, Train-Class-Acc: {0: '99.70%', 1: '99.58%', 2: '99.85%'}, Val Loss: 0.083127354, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.19%', 1: '98.01%', 2: '89.75%'}, LR: 0.000100000\n",
      "Epoch 124/2000, Train Loss: 0.009514316, Train-Class-Acc: {0: '99.67%', 1: '99.56%', 2: '99.86%'}, Val Loss: 0.093022176, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.23%', 1: '98.30%', 2: '86.97%'}, LR: 0.000100000\n",
      "Epoch 125/2000, Train Loss: 0.009152772, Train-Class-Acc: {0: '99.69%', 1: '99.57%', 2: '99.86%'}, Val Loss: 0.078289759, Val Accuracy: 97.86%, Val-Class-Acc: {0: '98.97%', 1: '97.49%', 2: '93.75%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.81%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_38.pth\n",
      "Model saved after epoch 125 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_125.pth \n",
      "\n",
      "Epoch 126/2000, Train Loss: 0.012566953, Train-Class-Acc: {0: '99.55%', 1: '99.37%', 2: '99.82%'}, Val Loss: 0.092150066, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.29%', 1: '98.06%', 2: '87.35%'}, LR: 0.000100000\n",
      "Epoch 127/2000, Train Loss: 0.008839112, Train-Class-Acc: {0: '99.70%', 1: '99.61%', 2: '99.87%'}, Val Loss: 0.097883659, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.73%', 1: '97.67%', 2: '87.50%'}, LR: 0.000100000\n",
      "Epoch 128/2000, Train Loss: 0.008105783, Train-Class-Acc: {0: '99.74%', 1: '99.65%', 2: '99.88%'}, Val Loss: 0.093844715, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.76%', 1: '97.78%', 2: '87.78%'}, LR: 0.000100000\n",
      "Epoch 129/2000, Train Loss: 0.009368800, Train-Class-Acc: {0: '99.68%', 1: '99.56%', 2: '99.87%'}, Val Loss: 0.114757956, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.75%', 1: '97.65%', 2: '86.24%'}, LR: 0.000100000\n",
      "Epoch 130/2000, Train Loss: 0.008552188, Train-Class-Acc: {0: '99.71%', 1: '99.61%', 2: '99.87%'}, Val Loss: 0.105697649, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.83%', 1: '97.27%', 2: '87.20%'}, LR: 0.000100000\n",
      "Epoch 131/2000, Train Loss: 0.016746396, Train-Class-Acc: {0: '99.45%', 1: '99.19%', 2: '99.53%'}, Val Loss: 0.128799592, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.94%', 1: '95.90%', 2: '87.39%'}, LR: 0.000100000\n",
      "Epoch 132/2000, Train Loss: 0.010220413, Train-Class-Acc: {0: '99.64%', 1: '99.50%', 2: '99.85%'}, Val Loss: 0.105724299, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.78%', 1: '97.12%', 2: '86.80%'}, LR: 0.000100000\n",
      "Epoch 133/2000, Train Loss: 0.008141663, Train-Class-Acc: {0: '99.74%', 1: '99.64%', 2: '99.88%'}, Val Loss: 0.110688228, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.78%', 1: '97.57%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 134/2000, Train Loss: 0.007848663, Train-Class-Acc: {0: '99.75%', 1: '99.66%', 2: '99.88%'}, Val Loss: 0.100177369, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.50%', 1: '97.42%', 2: '87.33%'}, LR: 0.000100000\n",
      "Epoch 135/2000, Train Loss: 0.007849297, Train-Class-Acc: {0: '99.75%', 1: '99.65%', 2: '99.89%'}, Val Loss: 0.103144511, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.77%', 1: '97.07%', 2: '87.74%'}, LR: 0.000100000\n",
      "Epoch 136/2000, Train Loss: 0.011031058, Train-Class-Acc: {0: '99.62%', 1: '99.47%', 2: '99.84%'}, Val Loss: 0.103195663, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.86%', 1: '96.86%', 2: '88.37%'}, LR: 0.000100000\n",
      "Epoch 137/2000, Train Loss: 0.007781825, Train-Class-Acc: {0: '99.75%', 1: '99.65%', 2: '99.90%'}, Val Loss: 0.101014053, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.77%', 1: '97.50%', 2: '87.09%'}, LR: 0.000100000\n",
      "Epoch 138/2000, Train Loss: 0.007984075, Train-Class-Acc: {0: '99.73%', 1: '99.64%', 2: '99.89%'}, Val Loss: 0.112336995, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.78%', 1: '97.60%', 2: '86.29%'}, LR: 0.000100000\n",
      "Epoch 139/2000, Train Loss: 0.007733567, Train-Class-Acc: {0: '99.75%', 1: '99.64%', 2: '99.89%'}, Val Loss: 0.102439969, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.40%', 1: '97.90%', 2: '87.28%'}, LR: 0.000100000\n",
      "Epoch 140/2000, Train Loss: 0.007390382, Train-Class-Acc: {0: '99.75%', 1: '99.68%', 2: '99.89%'}, Val Loss: 0.093871196, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.74%', 1: '96.97%', 2: '89.32%'}, LR: 0.000100000\n",
      "Epoch 141/2000, Train Loss: 0.007429648, Train-Class-Acc: {0: '99.76%', 1: '99.67%', 2: '99.89%'}, Val Loss: 0.107585917, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.72%', 1: '97.02%', 2: '87.61%'}, LR: 0.000100000\n",
      "Epoch 142/2000, Train Loss: 0.009273700, Train-Class-Acc: {0: '99.68%', 1: '99.54%', 2: '99.86%'}, Val Loss: 0.092141836, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.16%', 1: '97.91%', 2: '88.99%'}, LR: 0.000100000\n",
      "Epoch 143/2000, Train Loss: 0.007446914, Train-Class-Acc: {0: '99.75%', 1: '99.67%', 2: '99.90%'}, Val Loss: 0.104635304, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.78%', 1: '97.91%', 2: '86.56%'}, LR: 0.000100000\n",
      "Epoch 144/2000, Train Loss: 0.007093110, Train-Class-Acc: {0: '99.77%', 1: '99.69%', 2: '99.90%'}, Val Loss: 0.100020110, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.69%', 1: '97.87%', 2: '88.05%'}, LR: 0.000100000\n",
      "Epoch 145/2000, Train Loss: 0.045540733, Train-Class-Acc: {0: '99.22%', 1: '98.55%', 2: '98.62%'}, Val Loss: 0.136710082, Val Accuracy: 96.91%, Val-Class-Acc: {0: '99.63%', 1: '94.23%', 2: '92.68%'}, LR: 0.000100000\n",
      "Epoch 146/2000, Train Loss: 0.029380814, Train-Class-Acc: {0: '99.21%', 1: '98.64%', 2: '98.71%'}, Val Loss: 0.073903188, Val Accuracy: 97.85%, Val-Class-Acc: {0: '99.13%', 1: '97.83%', 2: '91.76%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.83%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_72.pth\n",
      "Model saved after epoch 146 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_146.pth \n",
      "\n",
      "Epoch 147/2000, Train Loss: 0.008521193, Train-Class-Acc: {0: '99.74%', 1: '99.65%', 2: '99.86%'}, Val Loss: 0.080129462, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.61%', 1: '97.42%', 2: '90.06%'}, LR: 0.000100000\n",
      "Epoch 148/2000, Train Loss: 0.007579760, Train-Class-Acc: {0: '99.77%', 1: '99.70%', 2: '99.90%'}, Val Loss: 0.084467144, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.64%', 1: '97.59%', 2: '88.56%'}, LR: 0.000100000\n",
      "Epoch 149/2000, Train Loss: 0.007229143, Train-Class-Acc: {0: '99.77%', 1: '99.71%', 2: '99.91%'}, Val Loss: 0.083127824, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.64%', 1: '97.64%', 2: '89.14%'}, LR: 0.000100000\n",
      "Epoch 150/2000, Train Loss: 0.007482019, Train-Class-Acc: {0: '99.76%', 1: '99.68%', 2: '99.89%'}, Val Loss: 0.079974646, Val Accuracy: 97.86%, Val-Class-Acc: {0: '99.49%', 1: '97.75%', 2: '90.31%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.84%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_104.pth\n",
      "Model saved after epoch 150 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_150.pth \n",
      "\n",
      "Epoch 151/2000, Train Loss: 0.006946389, Train-Class-Acc: {0: '99.78%', 1: '99.71%', 2: '99.91%'}, Val Loss: 0.088865276, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.59%', 1: '97.85%', 2: '88.05%'}, LR: 0.000100000\n",
      "Epoch 152/2000, Train Loss: 0.006838974, Train-Class-Acc: {0: '99.78%', 1: '99.72%', 2: '99.91%'}, Val Loss: 0.089220569, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.60%', 1: '97.91%', 2: '88.28%'}, LR: 0.000100000\n",
      "Epoch 153/2000, Train Loss: 0.006880833, Train-Class-Acc: {0: '99.78%', 1: '99.71%', 2: '99.91%'}, Val Loss: 0.084278996, Val Accuracy: 97.74%, Val-Class-Acc: {0: '99.39%', 1: '97.73%', 2: '89.82%'}, LR: 0.000100000\n",
      "Epoch 154/2000, Train Loss: 0.007246759, Train-Class-Acc: {0: '99.76%', 1: '99.68%', 2: '99.90%'}, Val Loss: 0.089107029, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.44%', 1: '97.97%', 2: '89.07%'}, LR: 0.000100000\n",
      "Epoch 155/2000, Train Loss: 0.006691135, Train-Class-Acc: {0: '99.79%', 1: '99.71%', 2: '99.91%'}, Val Loss: 0.096822734, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.69%', 1: '97.82%', 2: '87.64%'}, LR: 0.000100000\n",
      "Epoch 156/2000, Train Loss: 0.007307569, Train-Class-Acc: {0: '99.75%', 1: '99.67%', 2: '99.89%'}, Val Loss: 0.093750270, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.84%', 1: '97.38%', 2: '88.92%'}, LR: 0.000100000\n",
      "Epoch 157/2000, Train Loss: 0.006561970, Train-Class-Acc: {0: '99.79%', 1: '99.71%', 2: '99.92%'}, Val Loss: 0.086517024, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.30%', 1: '97.90%', 2: '90.03%'}, LR: 0.000100000\n",
      "Epoch 158/2000, Train Loss: 0.006521386, Train-Class-Acc: {0: '99.79%', 1: '99.72%', 2: '99.91%'}, Val Loss: 0.092507694, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.74%', 1: '97.77%', 2: '88.61%'}, LR: 0.000100000\n",
      "Epoch 159/2000, Train Loss: 0.006381712, Train-Class-Acc: {0: '99.79%', 1: '99.73%', 2: '99.91%'}, Val Loss: 0.093373719, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.67%', 1: '97.87%', 2: '88.60%'}, LR: 0.000100000\n",
      "Epoch 160/2000, Train Loss: 0.007101295, Train-Class-Acc: {0: '99.76%', 1: '99.66%', 2: '99.92%'}, Val Loss: 0.087344768, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.04%', 1: '97.93%', 2: '91.22%'}, LR: 0.000100000\n",
      "Epoch 161/2000, Train Loss: 0.006801677, Train-Class-Acc: {0: '99.77%', 1: '99.70%', 2: '99.91%'}, Val Loss: 0.090996665, Val Accuracy: 97.84%, Val-Class-Acc: {0: '99.34%', 1: '98.08%', 2: '89.71%'}, LR: 0.000100000\n",
      "Epoch 162/2000, Train Loss: 0.008589172, Train-Class-Acc: {0: '99.71%', 1: '99.60%', 2: '99.87%'}, Val Loss: 0.094413422, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.54%', 1: '97.93%', 2: '89.05%'}, LR: 0.000100000\n",
      "Epoch 163/2000, Train Loss: 0.006454072, Train-Class-Acc: {0: '99.79%', 1: '99.72%', 2: '99.92%'}, Val Loss: 0.096941883, Val Accuracy: 97.83%, Val-Class-Acc: {0: '99.58%', 1: '97.91%', 2: '89.07%'}, LR: 0.000100000\n",
      "Epoch 164/2000, Train Loss: 0.006235039, Train-Class-Acc: {0: '99.80%', 1: '99.73%', 2: '99.92%'}, Val Loss: 0.096741166, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.47%', 1: '97.94%', 2: '89.08%'}, LR: 0.000100000\n",
      "Epoch 165/2000, Train Loss: 0.006237116, Train-Class-Acc: {0: '99.79%', 1: '99.73%', 2: '99.92%'}, Val Loss: 0.093896000, Val Accuracy: 97.83%, Val-Class-Acc: {0: '99.64%', 1: '97.79%', 2: '89.22%'}, LR: 0.000100000\n",
      "Epoch 166/2000, Train Loss: 0.006110402, Train-Class-Acc: {0: '99.80%', 1: '99.73%', 2: '99.92%'}, Val Loss: 0.103076459, Val Accuracy: 97.74%, Val-Class-Acc: {0: '99.73%', 1: '97.87%', 2: '87.68%'}, LR: 0.000100000\n",
      "Epoch 167/2000, Train Loss: 0.011832200, Train-Class-Acc: {0: '99.59%', 1: '99.44%', 2: '99.86%'}, Val Loss: 0.100270627, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.84%', 1: '97.44%', 2: '88.25%'}, LR: 0.000100000\n",
      "Epoch 168/2000, Train Loss: 0.007650619, Train-Class-Acc: {0: '99.74%', 1: '99.63%', 2: '99.90%'}, Val Loss: 0.110204165, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.80%', 1: '97.75%', 2: '86.83%'}, LR: 0.000100000\n",
      "Epoch 169/2000, Train Loss: 0.006190547, Train-Class-Acc: {0: '99.80%', 1: '99.73%', 2: '99.91%'}, Val Loss: 0.100948308, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.69%', 1: '97.75%', 2: '88.90%'}, LR: 0.000100000\n",
      "Epoch 170/2000, Train Loss: 0.005990592, Train-Class-Acc: {0: '99.80%', 1: '99.74%', 2: '99.93%'}, Val Loss: 0.094229295, Val Accuracy: 97.80%, Val-Class-Acc: {0: '99.55%', 1: '97.64%', 2: '89.90%'}, LR: 0.000100000\n",
      "Epoch 171/2000, Train Loss: 0.006023652, Train-Class-Acc: {0: '99.80%', 1: '99.74%', 2: '99.92%'}, Val Loss: 0.105991963, Val Accuracy: 97.80%, Val-Class-Acc: {0: '99.76%', 1: '97.83%', 2: '88.19%'}, LR: 0.000100000\n",
      "Epoch 172/2000, Train Loss: 0.005877835, Train-Class-Acc: {0: '99.81%', 1: '99.74%', 2: '99.92%'}, Val Loss: 0.103008632, Val Accuracy: 97.79%, Val-Class-Acc: {0: '99.62%', 1: '98.01%', 2: '88.28%'}, LR: 0.000100000\n",
      "Epoch 173/2000, Train Loss: 0.009046521, Train-Class-Acc: {0: '99.71%', 1: '99.59%', 2: '99.86%'}, Val Loss: 0.116125253, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.90%', 1: '96.74%', 2: '88.61%'}, LR: 0.000100000\n",
      "Epoch 174/2000, Train Loss: 0.007137766, Train-Class-Acc: {0: '99.76%', 1: '99.68%', 2: '99.90%'}, Val Loss: 0.103078656, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.74%', 1: '97.65%', 2: '88.60%'}, LR: 0.000100000\n",
      "Epoch 175/2000, Train Loss: 0.005889187, Train-Class-Acc: {0: '99.81%', 1: '99.74%', 2: '99.92%'}, Val Loss: 0.103892132, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.74%', 1: '97.78%', 2: '88.07%'}, LR: 0.000100000\n",
      "Epoch 176/2000, Train Loss: 0.006123441, Train-Class-Acc: {0: '99.80%', 1: '99.72%', 2: '99.89%'}, Val Loss: 0.104230920, Val Accuracy: 97.79%, Val-Class-Acc: {0: '99.66%', 1: '98.12%', 2: '87.62%'}, LR: 0.000100000\n",
      "Epoch 177/2000, Train Loss: 0.006200658, Train-Class-Acc: {0: '99.80%', 1: '99.72%', 2: '99.87%'}, Val Loss: 0.099892149, Val Accuracy: 97.82%, Val-Class-Acc: {0: '99.75%', 1: '97.61%', 2: '89.12%'}, LR: 0.000100000\n",
      "Epoch 178/2000, Train Loss: 0.029119376, Train-Class-Acc: {0: '99.38%', 1: '98.94%', 2: '98.89%'}, Val Loss: 0.168937908, Val Accuracy: 96.44%, Val-Class-Acc: {0: '99.94%', 1: '94.74%', 2: '85.25%'}, LR: 0.000100000\n",
      "Epoch 179/2000, Train Loss: 0.009458349, Train-Class-Acc: {0: '99.72%', 1: '99.58%', 2: '99.66%'}, Val Loss: 0.088026537, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.58%', 1: '97.19%', 2: '90.24%'}, LR: 0.000100000\n",
      "Epoch 180/2000, Train Loss: 0.006070607, Train-Class-Acc: {0: '99.81%', 1: '99.75%', 2: '99.92%'}, Val Loss: 0.092333537, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.56%', 1: '97.90%', 2: '89.03%'}, LR: 0.000100000\n",
      "Epoch 181/2000, Train Loss: 0.005777340, Train-Class-Acc: {0: '99.82%', 1: '99.76%', 2: '99.93%'}, Val Loss: 0.093433091, Val Accuracy: 97.80%, Val-Class-Acc: {0: '99.64%', 1: '97.74%', 2: '89.09%'}, LR: 0.000100000\n",
      "Epoch 182/2000, Train Loss: 0.005792326, Train-Class-Acc: {0: '99.81%', 1: '99.76%', 2: '99.92%'}, Val Loss: 0.096375178, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.77%', 1: '97.49%', 2: '89.03%'}, LR: 0.000100000\n",
      "Epoch 183/2000, Train Loss: 0.005597720, Train-Class-Acc: {0: '99.82%', 1: '99.76%', 2: '99.92%'}, Val Loss: 0.089470431, Val Accuracy: 97.83%, Val-Class-Acc: {0: '99.49%', 1: '97.79%', 2: '89.95%'}, LR: 0.000100000\n",
      "Epoch 184/2000, Train Loss: 0.005645284, Train-Class-Acc: {0: '99.82%', 1: '99.75%', 2: '99.93%'}, Val Loss: 0.092980920, Val Accuracy: 97.85%, Val-Class-Acc: {0: '99.68%', 1: '97.64%', 2: '89.73%'}, LR: 0.000100000\n",
      "Epoch 185/2000, Train Loss: 0.005573544, Train-Class-Acc: {0: '99.81%', 1: '99.76%', 2: '99.93%'}, Val Loss: 0.100270160, Val Accuracy: 97.79%, Val-Class-Acc: {0: '99.71%', 1: '97.75%', 2: '88.66%'}, LR: 0.000100000\n",
      "Epoch 186/2000, Train Loss: 0.005758561, Train-Class-Acc: {0: '99.81%', 1: '99.75%', 2: '99.93%'}, Val Loss: 0.097140902, Val Accuracy: 97.85%, Val-Class-Acc: {0: '99.77%', 1: '97.62%', 2: '89.34%'}, LR: 0.000100000\n",
      "Epoch 187/2000, Train Loss: 0.030719945, Train-Class-Acc: {0: '99.05%', 1: '98.73%', 2: '99.31%'}, Val Loss: 0.106414946, Val Accuracy: 97.43%, Val-Class-Acc: {0: '99.56%', 1: '97.03%', 2: '88.41%'}, LR: 0.000100000\n",
      "Epoch 188/2000, Train Loss: 0.010841509, Train-Class-Acc: {0: '99.67%', 1: '99.44%', 2: '99.80%'}, Val Loss: 0.109120126, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.69%', 1: '97.64%', 2: '85.96%'}, LR: 0.000100000\n",
      "Epoch 189/2000, Train Loss: 0.006067303, Train-Class-Acc: {0: '99.81%', 1: '99.75%', 2: '99.91%'}, Val Loss: 0.093613213, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.69%', 1: '97.53%', 2: '89.60%'}, LR: 0.000100000\n",
      "Epoch 190/2000, Train Loss: 0.005757224, Train-Class-Acc: {0: '99.81%', 1: '99.77%', 2: '99.92%'}, Val Loss: 0.096837591, Val Accuracy: 97.80%, Val-Class-Acc: {0: '99.75%', 1: '97.61%', 2: '89.01%'}, LR: 0.000100000\n",
      "Epoch 191/2000, Train Loss: 0.005567471, Train-Class-Acc: {0: '99.82%', 1: '99.77%', 2: '99.93%'}, Val Loss: 0.101840501, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.73%', 1: '97.84%', 2: '88.08%'}, LR: 0.000100000\n",
      "Epoch 192/2000, Train Loss: 0.005456141, Train-Class-Acc: {0: '99.82%', 1: '99.77%', 2: '99.94%'}, Val Loss: 0.098202686, Val Accuracy: 97.82%, Val-Class-Acc: {0: '99.60%', 1: '97.88%', 2: '89.02%'}, LR: 0.000100000\n",
      "Epoch 193/2000, Train Loss: 0.005382099, Train-Class-Acc: {0: '99.83%', 1: '99.77%', 2: '99.93%'}, Val Loss: 0.102802339, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.74%', 1: '97.66%', 2: '88.43%'}, LR: 0.000100000\n",
      "Epoch 194/2000, Train Loss: 0.005457009, Train-Class-Acc: {0: '99.82%', 1: '99.76%', 2: '99.93%'}, Val Loss: 0.102941896, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.71%', 1: '97.86%', 2: '88.49%'}, LR: 0.000100000\n",
      "Epoch 195/2000, Train Loss: 0.005366690, Train-Class-Acc: {0: '99.82%', 1: '99.77%', 2: '99.93%'}, Val Loss: 0.104621375, Val Accuracy: 97.82%, Val-Class-Acc: {0: '99.71%', 1: '97.87%', 2: '88.49%'}, LR: 0.000100000\n",
      "Epoch 196/2000, Train Loss: 0.005377092, Train-Class-Acc: {0: '99.82%', 1: '99.76%', 2: '99.94%'}, Val Loss: 0.106858415, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.79%', 1: '97.74%', 2: '88.03%'}, LR: 0.000100000\n",
      "Epoch 197/2000, Train Loss: 0.005234408, Train-Class-Acc: {0: '99.83%', 1: '99.77%', 2: '99.93%'}, Val Loss: 0.104275353, Val Accuracy: 97.86%, Val-Class-Acc: {0: '99.67%', 1: '97.94%', 2: '88.81%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.85%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_146.pth\n",
      "Model saved after epoch 197 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_197.pth \n",
      "\n",
      "Epoch 198/2000, Train Loss: 0.005176549, Train-Class-Acc: {0: '99.83%', 1: '99.78%', 2: '99.94%'}, Val Loss: 0.108828127, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.79%', 1: '97.45%', 2: '88.45%'}, LR: 0.000100000\n",
      "Epoch 199/2000, Train Loss: 0.007823967, Train-Class-Acc: {0: '99.71%', 1: '99.62%', 2: '99.91%'}, Val Loss: 0.111000263, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.86%', 1: '97.37%', 2: '87.91%'}, LR: 0.000100000\n",
      "Epoch 200/2000, Train Loss: 0.008904148, Train-Class-Acc: {0: '99.69%', 1: '99.54%', 2: '99.88%'}, Val Loss: 0.100718272, Val Accuracy: 97.85%, Val-Class-Acc: {0: '99.68%', 1: '97.69%', 2: '89.55%'}, LR: 0.000100000\n",
      "Epoch 201/2000, Train Loss: 0.005398933, Train-Class-Acc: {0: '99.82%', 1: '99.76%', 2: '99.93%'}, Val Loss: 0.101790600, Val Accuracy: 97.89%, Val-Class-Acc: {0: '99.69%', 1: '97.91%', 2: '89.11%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.86%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_197.pth\n",
      "Model saved after epoch 201 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_201.pth \n",
      "\n",
      "Epoch 202/2000, Train Loss: 0.005184969, Train-Class-Acc: {0: '99.83%', 1: '99.77%', 2: '99.94%'}, Val Loss: 0.109109075, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.72%', 1: '97.91%', 2: '87.99%'}, LR: 0.000100000\n",
      "Epoch 203/2000, Train Loss: 0.029812679, Train-Class-Acc: {0: '99.23%', 1: '98.85%', 2: '99.32%'}, Val Loss: 0.093421932, Val Accuracy: 97.50%, Val-Class-Acc: {0: '98.52%', 1: '96.59%', 2: '95.59%'}, LR: 0.000100000\n",
      "Epoch 204/2000, Train Loss: 0.012103546, Train-Class-Acc: {0: '99.56%', 1: '99.42%', 2: '99.73%'}, Val Loss: 0.107831945, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.62%', 1: '97.67%', 2: '87.30%'}, LR: 0.000100000\n",
      "Epoch 205/2000, Train Loss: 0.005845410, Train-Class-Acc: {0: '99.83%', 1: '99.76%', 2: '99.91%'}, Val Loss: 0.099132718, Val Accuracy: 97.72%, Val-Class-Acc: {0: '99.56%', 1: '98.18%', 2: '87.24%'}, LR: 0.000100000\n",
      "Epoch 206/2000, Train Loss: 0.005359719, Train-Class-Acc: {0: '99.83%', 1: '99.78%', 2: '99.93%'}, Val Loss: 0.104366053, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.61%', 1: '97.88%', 2: '87.31%'}, LR: 0.000100000\n",
      "Epoch 207/2000, Train Loss: 0.005310214, Train-Class-Acc: {0: '99.83%', 1: '99.78%', 2: '99.93%'}, Val Loss: 0.101330380, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.74%', 1: '97.87%', 2: '87.94%'}, LR: 0.000100000\n",
      "Epoch 208/2000, Train Loss: 0.005196434, Train-Class-Acc: {0: '99.83%', 1: '99.77%', 2: '99.94%'}, Val Loss: 0.109739286, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.77%', 1: '97.89%', 2: '86.89%'}, LR: 0.000100000\n",
      "Epoch 209/2000, Train Loss: 0.005071369, Train-Class-Acc: {0: '99.84%', 1: '99.78%', 2: '99.94%'}, Val Loss: 0.104038125, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.72%', 1: '97.92%', 2: '87.76%'}, LR: 0.000100000\n",
      "Epoch 210/2000, Train Loss: 0.004987928, Train-Class-Acc: {0: '99.84%', 1: '99.79%', 2: '99.94%'}, Val Loss: 0.103248770, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.65%', 1: '98.16%', 2: '87.69%'}, LR: 0.000100000\n",
      "Epoch 211/2000, Train Loss: 0.004931050, Train-Class-Acc: {0: '99.84%', 1: '99.79%', 2: '99.94%'}, Val Loss: 0.097698814, Val Accuracy: 97.86%, Val-Class-Acc: {0: '99.70%', 1: '97.93%', 2: '88.74%'}, LR: 0.000100000\n",
      "Epoch 212/2000, Train Loss: 0.004963036, Train-Class-Acc: {0: '99.84%', 1: '99.78%', 2: '99.94%'}, Val Loss: 0.105752088, Val Accuracy: 97.82%, Val-Class-Acc: {0: '99.70%', 1: '97.96%', 2: '88.29%'}, LR: 0.000100000\n",
      "Epoch 213/2000, Train Loss: 0.004876945, Train-Class-Acc: {0: '99.84%', 1: '99.79%', 2: '99.94%'}, Val Loss: 0.107429046, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.70%', 1: '98.01%', 2: '87.67%'}, LR: 0.000100000\n",
      "Epoch 214/2000, Train Loss: 0.004808446, Train-Class-Acc: {0: '99.85%', 1: '99.79%', 2: '99.95%'}, Val Loss: 0.094864418, Val Accuracy: 97.95%, Val-Class-Acc: {0: '99.62%', 1: '97.83%', 2: '90.32%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.86%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_150.pth\n",
      "Model saved after epoch 214 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_214.pth \n",
      "\n",
      "Epoch 215/2000, Train Loss: 0.004851632, Train-Class-Acc: {0: '99.84%', 1: '99.79%', 2: '99.94%'}, Val Loss: 0.110731214, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.76%', 1: '97.87%', 2: '87.69%'}, LR: 0.000100000\n",
      "Epoch 216/2000, Train Loss: 0.004818549, Train-Class-Acc: {0: '99.84%', 1: '99.78%', 2: '99.94%'}, Val Loss: 0.095839721, Val Accuracy: 97.94%, Val-Class-Acc: {0: '99.64%', 1: '97.87%', 2: '89.96%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.86%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_125.pth\n",
      "Model saved after epoch 216 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_216.pth \n",
      "\n",
      "Epoch 217/2000, Train Loss: 0.004821358, Train-Class-Acc: {0: '99.84%', 1: '99.79%', 2: '99.94%'}, Val Loss: 0.101275383, Val Accuracy: 97.86%, Val-Class-Acc: {0: '99.67%', 1: '97.99%', 2: '88.67%'}, LR: 0.000100000\n",
      "Epoch 218/2000, Train Loss: 0.005006083, Train-Class-Acc: {0: '99.83%', 1: '99.77%', 2: '99.94%'}, Val Loss: 0.108950035, Val Accuracy: 97.79%, Val-Class-Acc: {0: '99.73%', 1: '97.95%', 2: '87.91%'}, LR: 0.000100000\n",
      "Epoch 219/2000, Train Loss: 0.004847876, Train-Class-Acc: {0: '99.84%', 1: '99.78%', 2: '99.94%'}, Val Loss: 0.109551833, Val Accuracy: 97.79%, Val-Class-Acc: {0: '99.67%', 1: '98.03%', 2: '87.90%'}, LR: 0.000100000\n",
      "Epoch 220/2000, Train Loss: 0.004858088, Train-Class-Acc: {0: '99.84%', 1: '99.78%', 2: '99.95%'}, Val Loss: 0.102364999, Val Accuracy: 97.90%, Val-Class-Acc: {0: '99.65%', 1: '97.83%', 2: '89.66%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.87%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_121.pth\n",
      "Model saved after epoch 220 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_220.pth \n",
      "\n",
      "Epoch 221/2000, Train Loss: 0.004585167, Train-Class-Acc: {0: '99.85%', 1: '99.80%', 2: '99.95%'}, Val Loss: 0.108237708, Val Accuracy: 97.82%, Val-Class-Acc: {0: '99.72%', 1: '97.87%', 2: '88.44%'}, LR: 0.000100000\n",
      "Epoch 222/2000, Train Loss: 0.004655118, Train-Class-Acc: {0: '99.85%', 1: '99.79%', 2: '99.94%'}, Val Loss: 0.115061051, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.79%', 1: '97.76%', 2: '88.12%'}, LR: 0.000100000\n",
      "Epoch 223/2000, Train Loss: 0.004554180, Train-Class-Acc: {0: '99.85%', 1: '99.79%', 2: '99.94%'}, Val Loss: 0.110690753, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.67%', 1: '98.01%', 2: '88.11%'}, LR: 0.000100000\n",
      "Epoch 224/2000, Train Loss: 0.004674081, Train-Class-Acc: {0: '99.84%', 1: '99.79%', 2: '99.94%'}, Val Loss: 0.108837709, Val Accuracy: 97.85%, Val-Class-Acc: {0: '99.63%', 1: '98.03%', 2: '88.61%'}, LR: 0.000100000\n",
      "Epoch 225/2000, Train Loss: 0.014519828, Train-Class-Acc: {0: '99.58%', 1: '99.43%', 2: '99.72%'}, Val Loss: 0.178393356, Val Accuracy: 96.82%, Val-Class-Acc: {0: '99.96%', 1: '96.45%', 2: '82.85%'}, LR: 0.000100000\n",
      "Epoch 226/2000, Train Loss: 0.006544667, Train-Class-Acc: {0: '99.79%', 1: '99.68%', 2: '99.90%'}, Val Loss: 0.117807090, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.63%', 1: '98.07%', 2: '87.17%'}, LR: 0.000100000\n",
      "Epoch 227/2000, Train Loss: 0.004630645, Train-Class-Acc: {0: '99.85%', 1: '99.81%', 2: '99.94%'}, Val Loss: 0.118419977, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.65%', 1: '98.20%', 2: '87.32%'}, LR: 0.000100000\n",
      "Epoch 228/2000, Train Loss: 0.004558079, Train-Class-Acc: {0: '99.85%', 1: '99.80%', 2: '99.95%'}, Val Loss: 0.115135222, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.57%', 1: '98.22%', 2: '87.50%'}, LR: 0.000100000\n",
      "Epoch 229/2000, Train Loss: 0.004445311, Train-Class-Acc: {0: '99.85%', 1: '99.81%', 2: '99.95%'}, Val Loss: 0.112169014, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.56%', 1: '98.12%', 2: '87.95%'}, LR: 0.000100000\n",
      "Epoch 230/2000, Train Loss: 0.004520479, Train-Class-Acc: {0: '99.85%', 1: '99.80%', 2: '99.95%'}, Val Loss: 0.117091930, Val Accuracy: 97.79%, Val-Class-Acc: {0: '99.70%', 1: '98.06%', 2: '87.65%'}, LR: 0.000100000\n",
      "Epoch 231/2000, Train Loss: 0.005181331, Train-Class-Acc: {0: '99.82%', 1: '99.76%', 2: '99.94%'}, Val Loss: 0.120757422, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.73%', 1: '98.09%', 2: '87.25%'}, LR: 0.000100000\n",
      "Epoch 232/2000, Train Loss: 0.004315164, Train-Class-Acc: {0: '99.86%', 1: '99.81%', 2: '99.95%'}, Val Loss: 0.118156562, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.69%', 1: '98.06%', 2: '87.51%'}, LR: 0.000100000\n",
      "Epoch 233/2000, Train Loss: 0.005107566, Train-Class-Acc: {0: '99.82%', 1: '99.76%', 2: '99.95%'}, Val Loss: 0.127555486, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.81%', 1: '97.37%', 2: '87.07%'}, LR: 0.000100000\n",
      "Epoch 234/2000, Train Loss: 0.004720690, Train-Class-Acc: {0: '99.84%', 1: '99.78%', 2: '99.94%'}, Val Loss: 0.126378985, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.82%', 1: '97.52%', 2: '86.89%'}, LR: 0.000100000\n",
      "Epoch 235/2000, Train Loss: 0.004765161, Train-Class-Acc: {0: '99.84%', 1: '99.78%', 2: '99.95%'}, Val Loss: 0.129894943, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.91%', 1: '97.35%', 2: '87.23%'}, LR: 0.000100000\n",
      "Epoch 236/2000, Train Loss: 0.004499024, Train-Class-Acc: {0: '99.85%', 1: '99.79%', 2: '99.95%'}, Val Loss: 0.117307905, Val Accuracy: 97.80%, Val-Class-Acc: {0: '99.66%', 1: '98.08%', 2: '87.88%'}, LR: 0.000100000\n",
      "Epoch 237/2000, Train Loss: 0.004378808, Train-Class-Acc: {0: '99.85%', 1: '99.80%', 2: '99.95%'}, Val Loss: 0.119395043, Val Accuracy: 97.79%, Val-Class-Acc: {0: '99.71%', 1: '98.10%', 2: '87.48%'}, LR: 0.000100000\n",
      "Epoch 238/2000, Train Loss: 0.092250918, Train-Class-Acc: {0: '98.53%', 1: '97.59%', 2: '96.94%'}, Val Loss: 0.246683303, Val Accuracy: 95.00%, Val-Class-Acc: {0: '99.61%', 1: '95.87%', 2: '69.81%'}, LR: 0.000100000\n",
      "Epoch 239/2000, Train Loss: 0.022776010, Train-Class-Acc: {0: '99.33%', 1: '99.00%', 2: '98.85%'}, Val Loss: 0.096015487, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.71%', 1: '96.94%', 2: '87.47%'}, LR: 0.000100000\n",
      "Epoch 240/2000, Train Loss: 0.006998534, Train-Class-Acc: {0: '99.79%', 1: '99.72%', 2: '99.85%'}, Val Loss: 0.090464086, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.65%', 1: '97.71%', 2: '87.35%'}, LR: 0.000100000\n",
      "Epoch 241/2000, Train Loss: 0.005366383, Train-Class-Acc: {0: '99.84%', 1: '99.79%', 2: '99.91%'}, Val Loss: 0.092260051, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.59%', 1: '98.14%', 2: '86.78%'}, LR: 0.000100000\n",
      "Epoch 242/2000, Train Loss: 0.004886120, Train-Class-Acc: {0: '99.85%', 1: '99.80%', 2: '99.93%'}, Val Loss: 0.104649172, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.77%', 1: '97.85%', 2: '85.25%'}, LR: 0.000100000\n",
      "Epoch 243/2000, Train Loss: 0.004644320, Train-Class-Acc: {0: '99.86%', 1: '99.81%', 2: '99.95%'}, Val Loss: 0.099021414, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.73%', 1: '97.98%', 2: '86.28%'}, LR: 0.000100000\n",
      "Epoch 244/2000, Train Loss: 0.004506685, Train-Class-Acc: {0: '99.86%', 1: '99.81%', 2: '99.95%'}, Val Loss: 0.102631537, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.72%', 1: '98.12%', 2: '85.85%'}, LR: 0.000100000\n",
      "Epoch 245/2000, Train Loss: 0.004451330, Train-Class-Acc: {0: '99.86%', 1: '99.81%', 2: '99.95%'}, Val Loss: 0.109695992, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.79%', 1: '97.90%', 2: '85.46%'}, LR: 0.000100000\n",
      "Epoch 246/2000, Train Loss: 0.004546854, Train-Class-Acc: {0: '99.86%', 1: '99.80%', 2: '99.95%'}, Val Loss: 0.104760367, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.69%', 1: '98.04%', 2: '86.07%'}, LR: 0.000100000\n",
      "Epoch 247/2000, Train Loss: 0.004302370, Train-Class-Acc: {0: '99.86%', 1: '99.82%', 2: '99.96%'}, Val Loss: 0.106400993, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.69%', 1: '98.05%', 2: '86.04%'}, LR: 0.000100000\n",
      "Epoch 248/2000, Train Loss: 0.004384233, Train-Class-Acc: {0: '99.86%', 1: '99.81%', 2: '99.95%'}, Val Loss: 0.111513188, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.81%', 1: '97.66%', 2: '85.87%'}, LR: 0.000100000\n",
      "Epoch 249/2000, Train Loss: 0.004494858, Train-Class-Acc: {0: '99.85%', 1: '99.80%', 2: '99.95%'}, Val Loss: 0.106704097, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.68%', 1: '98.03%', 2: '86.17%'}, LR: 0.000100000\n",
      "Epoch 250/2000, Train Loss: 0.004178689, Train-Class-Acc: {0: '99.86%', 1: '99.82%', 2: '99.96%'}, Val Loss: 0.101564187, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.74%', 1: '97.82%', 2: '87.98%'}, LR: 0.000100000\n",
      "Epoch 251/2000, Train Loss: 0.004210032, Train-Class-Acc: {0: '99.87%', 1: '99.82%', 2: '99.96%'}, Val Loss: 0.112657949, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.71%', 1: '97.95%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 252/2000, Train Loss: 0.004153627, Train-Class-Acc: {0: '99.87%', 1: '99.82%', 2: '99.96%'}, Val Loss: 0.098008364, Val Accuracy: 97.89%, Val-Class-Acc: {0: '99.58%', 1: '98.29%', 2: '88.39%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.89%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_201.pth\n",
      "Model saved after epoch 252 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_252.pth \n",
      "\n",
      "Epoch 253/2000, Train Loss: 0.004322813, Train-Class-Acc: {0: '99.86%', 1: '99.81%', 2: '99.95%'}, Val Loss: 0.108055323, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.69%', 1: '97.92%', 2: '86.96%'}, LR: 0.000100000\n",
      "Epoch 254/2000, Train Loss: 0.004215465, Train-Class-Acc: {0: '99.86%', 1: '99.82%', 2: '99.95%'}, Val Loss: 0.119219429, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.80%', 1: '97.83%', 2: '85.27%'}, LR: 0.000100000\n",
      "Epoch 255/2000, Train Loss: 0.004071030, Train-Class-Acc: {0: '99.87%', 1: '99.82%', 2: '99.96%'}, Val Loss: 0.106127312, Val Accuracy: 97.74%, Val-Class-Acc: {0: '99.74%', 1: '97.87%', 2: '87.67%'}, LR: 0.000100000\n",
      "Epoch 256/2000, Train Loss: 0.004137354, Train-Class-Acc: {0: '99.87%', 1: '99.82%', 2: '99.95%'}, Val Loss: 0.115881689, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.70%', 1: '98.06%', 2: '86.00%'}, LR: 0.000100000\n",
      "Epoch 257/2000, Train Loss: 0.004060285, Train-Class-Acc: {0: '99.87%', 1: '99.82%', 2: '99.95%'}, Val Loss: 0.114468402, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.66%', 1: '98.08%', 2: '86.18%'}, LR: 0.000100000\n",
      "Epoch 258/2000, Train Loss: 0.004062453, Train-Class-Acc: {0: '99.87%', 1: '99.82%', 2: '99.95%'}, Val Loss: 0.113144991, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.79%', 1: '97.77%', 2: '86.74%'}, LR: 0.000100000\n",
      "Epoch 259/2000, Train Loss: 0.004255327, Train-Class-Acc: {0: '99.87%', 1: '99.81%', 2: '99.95%'}, Val Loss: 0.106310227, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.68%', 1: '97.93%', 2: '88.42%'}, LR: 0.000100000\n",
      "Epoch 260/2000, Train Loss: 0.004193694, Train-Class-Acc: {0: '99.86%', 1: '99.81%', 2: '99.95%'}, Val Loss: 0.105326196, Val Accuracy: 97.83%, Val-Class-Acc: {0: '99.48%', 1: '98.36%', 2: '88.12%'}, LR: 0.000100000\n",
      "Epoch 261/2000, Train Loss: 0.014018671, Train-Class-Acc: {0: '99.62%', 1: '99.45%', 2: '99.81%'}, Val Loss: 0.113942560, Val Accuracy: 97.56%, Val-Class-Acc: {0: '98.58%', 1: '98.10%', 2: '90.86%'}, LR: 0.000100000\n",
      "Epoch 262/2000, Train Loss: 0.011163640, Train-Class-Acc: {0: '99.64%', 1: '99.45%', 2: '99.69%'}, Val Loss: 0.093252986, Val Accuracy: 97.88%, Val-Class-Acc: {0: '99.56%', 1: '98.08%', 2: '89.02%'}, LR: 0.000100000\n",
      "Epoch 263/2000, Train Loss: 0.004254119, Train-Class-Acc: {0: '99.87%', 1: '99.82%', 2: '99.96%'}, Val Loss: 0.099383341, Val Accuracy: 97.88%, Val-Class-Acc: {0: '99.51%', 1: '98.31%', 2: '88.57%'}, LR: 0.000100000\n",
      "Epoch 264/2000, Train Loss: 0.004155727, Train-Class-Acc: {0: '99.87%', 1: '99.82%', 2: '99.95%'}, Val Loss: 0.102877513, Val Accuracy: 97.86%, Val-Class-Acc: {0: '99.53%', 1: '98.47%', 2: '87.72%'}, LR: 0.000100000\n",
      "Epoch 265/2000, Train Loss: 0.004097819, Train-Class-Acc: {0: '99.87%', 1: '99.82%', 2: '99.95%'}, Val Loss: 0.113355984, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.77%', 1: '98.05%', 2: '86.02%'}, LR: 0.000100000\n",
      "Epoch 266/2000, Train Loss: 0.003932650, Train-Class-Acc: {0: '99.88%', 1: '99.83%', 2: '99.96%'}, Val Loss: 0.107344781, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.71%', 1: '98.18%', 2: '87.04%'}, LR: 0.000100000\n",
      "Epoch 267/2000, Train Loss: 0.003857513, Train-Class-Acc: {0: '99.88%', 1: '99.84%', 2: '99.96%'}, Val Loss: 0.114726128, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.77%', 1: '97.91%', 2: '86.24%'}, LR: 0.000100000\n",
      "Epoch 268/2000, Train Loss: 0.003778934, Train-Class-Acc: {0: '99.88%', 1: '99.84%', 2: '99.96%'}, Val Loss: 0.106762027, Val Accuracy: 97.82%, Val-Class-Acc: {0: '99.71%', 1: '98.13%', 2: '87.65%'}, LR: 0.000100000\n",
      "Epoch 269/2000, Train Loss: 0.003831223, Train-Class-Acc: {0: '99.88%', 1: '99.84%', 2: '99.96%'}, Val Loss: 0.109952565, Val Accuracy: 97.81%, Val-Class-Acc: {0: '99.68%', 1: '98.11%', 2: '87.74%'}, LR: 0.000100000\n",
      "Epoch 270/2000, Train Loss: 0.004127128, Train-Class-Acc: {0: '99.86%', 1: '99.81%', 2: '99.96%'}, Val Loss: 0.106232906, Val Accuracy: 97.88%, Val-Class-Acc: {0: '99.70%', 1: '98.16%', 2: '88.14%'}, LR: 0.000100000\n",
      "Epoch 271/2000, Train Loss: 0.003722087, Train-Class-Acc: {0: '99.88%', 1: '99.84%', 2: '99.96%'}, Val Loss: 0.116810304, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.74%', 1: '98.05%', 2: '86.80%'}, LR: 0.000100000\n",
      "Epoch 272/2000, Train Loss: 0.003718734, Train-Class-Acc: {0: '99.88%', 1: '99.84%', 2: '99.96%'}, Val Loss: 0.111971993, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.75%', 1: '97.93%', 2: '87.76%'}, LR: 0.000100000\n",
      "Epoch 273/2000, Train Loss: 0.003703802, Train-Class-Acc: {0: '99.88%', 1: '99.84%', 2: '99.96%'}, Val Loss: 0.109517492, Val Accuracy: 97.85%, Val-Class-Acc: {0: '99.69%', 1: '98.02%', 2: '88.39%'}, LR: 0.000100000\n",
      "Epoch 274/2000, Train Loss: 0.004002531, Train-Class-Acc: {0: '99.87%', 1: '99.82%', 2: '99.96%'}, Val Loss: 0.105709957, Val Accuracy: 97.88%, Val-Class-Acc: {0: '99.30%', 1: '98.55%', 2: '88.81%'}, LR: 0.000100000\n",
      "Epoch 275/2000, Train Loss: 0.003967566, Train-Class-Acc: {0: '99.86%', 1: '99.82%', 2: '99.95%'}, Val Loss: 0.111975177, Val Accuracy: 97.82%, Val-Class-Acc: {0: '99.74%', 1: '98.05%', 2: '87.71%'}, LR: 0.000100000\n",
      "Epoch 276/2000, Train Loss: 0.003696572, Train-Class-Acc: {0: '99.88%', 1: '99.84%', 2: '99.96%'}, Val Loss: 0.122795881, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.69%', 1: '98.13%', 2: '86.03%'}, LR: 0.000100000\n",
      "Epoch 277/2000, Train Loss: 0.012674205, Train-Class-Acc: {0: '99.66%', 1: '99.49%', 2: '99.68%'}, Val Loss: 0.166136794, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.81%', 1: '93.29%', 2: '95.98%'}, LR: 0.000100000\n",
      "Epoch 278/2000, Train Loss: 0.011324812, Train-Class-Acc: {0: '99.66%', 1: '99.49%', 2: '99.71%'}, Val Loss: 0.124583667, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.63%', 1: '98.06%', 2: '86.10%'}, LR: 0.000100000\n",
      "Epoch 279/2000, Train Loss: 0.004078760, Train-Class-Acc: {0: '99.87%', 1: '99.83%', 2: '99.96%'}, Val Loss: 0.104773162, Val Accuracy: 97.83%, Val-Class-Acc: {0: '99.57%', 1: '98.32%', 2: '87.79%'}, LR: 0.000100000\n",
      "Epoch 280/2000, Train Loss: 0.003780280, Train-Class-Acc: {0: '99.88%', 1: '99.84%', 2: '99.96%'}, Val Loss: 0.109268559, Val Accuracy: 97.89%, Val-Class-Acc: {0: '99.72%', 1: '98.33%', 2: '87.54%'}, LR: 0.000100000\n",
      "Epoch 281/2000, Train Loss: 0.003695986, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.96%'}, Val Loss: 0.116848204, Val Accuracy: 97.79%, Val-Class-Acc: {0: '99.76%', 1: '98.13%', 2: '87.09%'}, LR: 0.000100000\n",
      "Epoch 282/2000, Train Loss: 0.003692075, Train-Class-Acc: {0: '99.88%', 1: '99.84%', 2: '99.97%'}, Val Loss: 0.120867959, Val Accuracy: 97.72%, Val-Class-Acc: {0: '99.80%', 1: '97.87%', 2: '87.17%'}, LR: 0.000100000\n",
      "Epoch 283/2000, Train Loss: 0.003693442, Train-Class-Acc: {0: '99.88%', 1: '99.84%', 2: '99.96%'}, Val Loss: 0.123415938, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.78%', 1: '98.02%', 2: '87.06%'}, LR: 0.000100000\n",
      "Epoch 284/2000, Train Loss: 0.003977832, Train-Class-Acc: {0: '99.87%', 1: '99.82%', 2: '99.96%'}, Val Loss: 0.116787009, Val Accuracy: 97.85%, Val-Class-Acc: {0: '99.65%', 1: '98.49%', 2: '87.05%'}, LR: 0.000100000\n",
      "Epoch 285/2000, Train Loss: 0.003606976, Train-Class-Acc: {0: '99.88%', 1: '99.85%', 2: '99.96%'}, Val Loss: 0.114247901, Val Accuracy: 97.83%, Val-Class-Acc: {0: '99.69%', 1: '98.20%', 2: '87.63%'}, LR: 0.000100000\n",
      "Epoch 286/2000, Train Loss: 0.003499575, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.97%'}, Val Loss: 0.112856456, Val Accuracy: 97.86%, Val-Class-Acc: {0: '99.66%', 1: '98.32%', 2: '87.66%'}, LR: 0.000100000\n",
      "Epoch 287/2000, Train Loss: 0.003501081, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.96%'}, Val Loss: 0.115952436, Val Accuracy: 97.80%, Val-Class-Acc: {0: '99.77%', 1: '98.05%', 2: '87.48%'}, LR: 0.000100000\n",
      "Epoch 288/2000, Train Loss: 0.003964437, Train-Class-Acc: {0: '99.87%', 1: '99.81%', 2: '99.96%'}, Val Loss: 0.106312231, Val Accuracy: 97.90%, Val-Class-Acc: {0: '99.63%', 1: '98.41%', 2: '87.86%'}, LR: 0.000100000\n",
      "Removed old model with accuracy 97.89%, and file was at Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_252.pth\n",
      "Model saved after epoch 288 to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_288.pth \n",
      "\n",
      "Epoch 289/2000, Train Loss: 0.003564773, Train-Class-Acc: {0: '99.88%', 1: '99.84%', 2: '99.96%'}, Val Loss: 0.114241166, Val Accuracy: 97.86%, Val-Class-Acc: {0: '99.49%', 1: '98.39%', 2: '88.22%'}, LR: 0.000100000\n",
      "Epoch 290/2000, Train Loss: 0.003603987, Train-Class-Acc: {0: '99.88%', 1: '99.84%', 2: '99.96%'}, Val Loss: 0.128083403, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.77%', 1: '98.09%', 2: '85.85%'}, LR: 0.000100000\n",
      "Epoch 291/2000, Train Loss: 0.014675877, Train-Class-Acc: {0: '99.69%', 1: '99.48%', 2: '99.80%'}, Val Loss: 0.107531532, Val Accuracy: 97.38%, Val-Class-Acc: {0: '98.56%', 1: '96.93%', 2: '93.18%'}, LR: 0.000100000\n",
      "Epoch 292/2000, Train Loss: 0.036452796, Train-Class-Acc: {0: '99.06%', 1: '98.51%', 2: '98.87%'}, Val Loss: 0.098461655, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.15%', 1: '98.36%', 2: '86.48%'}, LR: 0.000100000\n",
      "Epoch 293/2000, Train Loss: 0.005526071, Train-Class-Acc: {0: '99.83%', 1: '99.75%', 2: '99.93%'}, Val Loss: 0.108437324, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.54%', 1: '98.12%', 2: '85.52%'}, LR: 0.000100000\n",
      "Epoch 294/2000, Train Loss: 0.004072306, Train-Class-Acc: {0: '99.88%', 1: '99.83%', 2: '99.96%'}, Val Loss: 0.105187325, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.65%', 1: '98.06%', 2: '86.36%'}, LR: 0.000100000\n",
      "Epoch 295/2000, Train Loss: 0.003797351, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.97%'}, Val Loss: 0.117176317, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.73%', 1: '97.99%', 2: '84.62%'}, LR: 0.000100000\n",
      "Epoch 296/2000, Train Loss: 0.003651183, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.97%'}, Val Loss: 0.114496761, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.72%', 1: '98.03%', 2: '85.33%'}, LR: 0.000100000\n",
      "Epoch 297/2000, Train Loss: 0.003625936, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.97%'}, Val Loss: 0.121895849, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.78%', 1: '97.84%', 2: '84.85%'}, LR: 0.000100000\n",
      "Epoch 298/2000, Train Loss: 0.003542774, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.97%'}, Val Loss: 0.111054990, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.75%', 1: '98.01%', 2: '86.14%'}, LR: 0.000100000\n",
      "Epoch 299/2000, Train Loss: 0.003457401, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.119608216, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.76%', 1: '97.91%', 2: '85.62%'}, LR: 0.000100000\n",
      "Epoch 300/2000, Train Loss: 0.003422253, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.113714028, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.71%', 1: '98.08%', 2: '86.18%'}, LR: 0.000100000\n",
      "Epoch 301/2000, Train Loss: 0.003481899, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.97%'}, Val Loss: 0.110321114, Val Accuracy: 97.74%, Val-Class-Acc: {0: '99.72%', 1: '98.19%', 2: '86.66%'}, LR: 0.000100000\n",
      "Epoch 302/2000, Train Loss: 0.003368766, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.117805800, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.72%', 1: '98.12%', 2: '85.75%'}, LR: 0.000100000\n",
      "Epoch 303/2000, Train Loss: 0.003396252, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.97%'}, Val Loss: 0.114704173, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.77%', 1: '97.91%', 2: '86.56%'}, LR: 0.000100000\n",
      "Epoch 304/2000, Train Loss: 0.003332410, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.119507766, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.70%', 1: '98.24%', 2: '85.66%'}, LR: 0.000100000\n",
      "Epoch 305/2000, Train Loss: 0.003350137, Train-Class-Acc: {0: '99.89%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.118600679, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.75%', 1: '97.95%', 2: '86.22%'}, LR: 0.000100000\n",
      "Epoch 306/2000, Train Loss: 0.003249077, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.119129124, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.71%', 1: '98.20%', 2: '85.78%'}, LR: 0.000100000\n",
      "Epoch 307/2000, Train Loss: 0.003193060, Train-Class-Acc: {0: '99.90%', 1: '99.87%', 2: '99.97%'}, Val Loss: 0.119014771, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.73%', 1: '98.21%', 2: '86.03%'}, LR: 0.000100000\n",
      "Epoch 308/2000, Train Loss: 0.003295869, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.97%'}, Val Loss: 0.129733619, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.77%', 1: '97.99%', 2: '85.11%'}, LR: 0.000100000\n",
      "Epoch 309/2000, Train Loss: 0.003215695, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.131148190, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.70%', 1: '98.19%', 2: '85.39%'}, LR: 0.000100000\n",
      "Epoch 310/2000, Train Loss: 0.003330945, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.97%'}, Val Loss: 0.129190960, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.69%', 1: '98.16%', 2: '85.74%'}, LR: 0.000100000\n",
      "Epoch 311/2000, Train Loss: 0.003265587, Train-Class-Acc: {0: '99.89%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.126163946, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.71%', 1: '98.27%', 2: '85.55%'}, LR: 0.000100000\n",
      "Epoch 312/2000, Train Loss: 0.003386791, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.97%'}, Val Loss: 0.120023607, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.71%', 1: '98.24%', 2: '86.50%'}, LR: 0.000100000\n",
      "Epoch 313/2000, Train Loss: 0.003194391, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.127222048, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.76%', 1: '97.98%', 2: '85.68%'}, LR: 0.000100000\n",
      "Epoch 314/2000, Train Loss: 0.003193275, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.119519040, Val Accuracy: 97.85%, Val-Class-Acc: {0: '99.65%', 1: '98.35%', 2: '87.46%'}, LR: 0.000100000\n",
      "Epoch 315/2000, Train Loss: 0.009264389, Train-Class-Acc: {0: '99.70%', 1: '99.59%', 2: '99.92%'}, Val Loss: 0.127768388, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.68%', 1: '98.02%', 2: '85.57%'}, LR: 0.000100000\n",
      "Epoch 316/2000, Train Loss: 0.003974029, Train-Class-Acc: {0: '99.87%', 1: '99.80%', 2: '99.97%'}, Val Loss: 0.136924183, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.78%', 1: '97.98%', 2: '85.10%'}, LR: 0.000100000\n",
      "Epoch 317/2000, Train Loss: 0.003248830, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.121014002, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.41%', 1: '98.43%', 2: '86.79%'}, LR: 0.000100000\n",
      "Epoch 318/2000, Train Loss: 0.003164265, Train-Class-Acc: {0: '99.90%', 1: '99.87%', 2: '99.97%'}, Val Loss: 0.124902923, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.74%', 1: '98.19%', 2: '85.87%'}, LR: 0.000100000\n",
      "Epoch 319/2000, Train Loss: 0.003047492, Train-Class-Acc: {0: '99.91%', 1: '99.87%', 2: '99.97%'}, Val Loss: 0.123450271, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.47%', 1: '98.40%', 2: '87.48%'}, LR: 0.000100000\n",
      "Epoch 320/2000, Train Loss: 0.003152254, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.123972831, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.68%', 1: '98.26%', 2: '87.01%'}, LR: 0.000100000\n",
      "Epoch 321/2000, Train Loss: 0.003034042, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.98%'}, Val Loss: 0.130077717, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.72%', 1: '98.24%', 2: '85.85%'}, LR: 0.000100000\n",
      "Epoch 322/2000, Train Loss: 0.003062460, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.98%'}, Val Loss: 0.127372991, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.74%', 1: '98.23%', 2: '86.35%'}, LR: 0.000100000\n",
      "Epoch 323/2000, Train Loss: 0.003038482, Train-Class-Acc: {0: '99.90%', 1: '99.87%', 2: '99.97%'}, Val Loss: 0.134448785, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.77%', 1: '98.01%', 2: '85.74%'}, LR: 0.000100000\n",
      "Epoch 324/2000, Train Loss: 0.002998881, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.124121250, Val Accuracy: 97.85%, Val-Class-Acc: {0: '99.72%', 1: '98.10%', 2: '87.97%'}, LR: 0.000100000\n",
      "Epoch 325/2000, Train Loss: 0.002979269, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.129209442, Val Accuracy: 97.80%, Val-Class-Acc: {0: '99.68%', 1: '98.37%', 2: '86.85%'}, LR: 0.000100000\n",
      "Epoch 326/2000, Train Loss: 0.007311722, Train-Class-Acc: {0: '99.77%', 1: '99.65%', 2: '99.94%'}, Val Loss: 0.123554166, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.28%', 1: '97.61%', 2: '89.63%'}, LR: 0.000100000\n",
      "Epoch 327/2000, Train Loss: 0.066821119, Train-Class-Acc: {0: '98.96%', 1: '98.15%', 2: '97.17%'}, Val Loss: 0.088129270, Val Accuracy: 97.79%, Val-Class-Acc: {0: '99.67%', 1: '98.10%', 2: '87.65%'}, LR: 0.000100000\n",
      "Epoch 328/2000, Train Loss: 0.004962875, Train-Class-Acc: {0: '99.87%', 1: '99.78%', 2: '99.93%'}, Val Loss: 0.103520352, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.77%', 1: '97.71%', 2: '84.12%'}, LR: 0.000100000\n",
      "Epoch 329/2000, Train Loss: 0.003801746, Train-Class-Acc: {0: '99.90%', 1: '99.84%', 2: '99.96%'}, Val Loss: 0.093354500, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.63%', 1: '98.38%', 2: '86.71%'}, LR: 0.000100000\n",
      "Epoch 330/2000, Train Loss: 0.003466093, Train-Class-Acc: {0: '99.91%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.097380733, Val Accuracy: 97.74%, Val-Class-Acc: {0: '99.72%', 1: '98.41%', 2: '85.92%'}, LR: 0.000100000\n",
      "Epoch 331/2000, Train Loss: 0.003485154, Train-Class-Acc: {0: '99.90%', 1: '99.85%', 2: '99.97%'}, Val Loss: 0.106785489, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.78%', 1: '98.12%', 2: '84.61%'}, LR: 0.000100000\n",
      "Epoch 332/2000, Train Loss: 0.003270331, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.105049173, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.77%', 1: '98.25%', 2: '85.12%'}, LR: 0.000100000\n",
      "Epoch 333/2000, Train Loss: 0.003121742, Train-Class-Acc: {0: '99.91%', 1: '99.87%', 2: '99.98%'}, Val Loss: 0.110127347, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.76%', 1: '98.25%', 2: '84.60%'}, LR: 0.000100000\n",
      "Epoch 334/2000, Train Loss: 0.003085491, Train-Class-Acc: {0: '99.91%', 1: '99.87%', 2: '99.98%'}, Val Loss: 0.106378676, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.74%', 1: '98.33%', 2: '85.04%'}, LR: 0.000100000\n",
      "Epoch 335/2000, Train Loss: 0.003042101, Train-Class-Acc: {0: '99.91%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.111606156, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.75%', 1: '98.33%', 2: '84.72%'}, LR: 0.000100000\n",
      "Epoch 336/2000, Train Loss: 0.002967988, Train-Class-Acc: {0: '99.91%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.108789658, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.75%', 1: '98.30%', 2: '85.61%'}, LR: 0.000100000\n",
      "Epoch 337/2000, Train Loss: 0.003105887, Train-Class-Acc: {0: '99.91%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.109456085, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.75%', 1: '98.19%', 2: '86.15%'}, LR: 0.000100000\n",
      "Epoch 338/2000, Train Loss: 0.002945605, Train-Class-Acc: {0: '99.91%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.115498472, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.78%', 1: '98.08%', 2: '85.23%'}, LR: 0.000100000\n",
      "Epoch 339/2000, Train Loss: 0.002915317, Train-Class-Acc: {0: '99.91%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.115696581, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.75%', 1: '98.29%', 2: '84.78%'}, LR: 0.000100000\n",
      "Epoch 340/2000, Train Loss: 0.002930305, Train-Class-Acc: {0: '99.91%', 1: '99.87%', 2: '99.98%'}, Val Loss: 0.111347087, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.67%', 1: '98.60%', 2: '85.95%'}, LR: 0.000100000\n",
      "Epoch 341/2000, Train Loss: 0.005121152, Train-Class-Acc: {0: '99.82%', 1: '99.75%', 2: '99.96%'}, Val Loss: 0.129941480, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.93%', 1: '97.37%', 2: '84.34%'}, LR: 0.000100000\n",
      "Epoch 342/2000, Train Loss: 0.003555555, Train-Class-Acc: {0: '99.88%', 1: '99.83%', 2: '99.97%'}, Val Loss: 0.120872737, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.75%', 1: '98.21%', 2: '85.36%'}, LR: 0.000100000\n",
      "Epoch 343/2000, Train Loss: 0.003183006, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.117543668, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.79%', 1: '98.04%', 2: '85.37%'}, LR: 0.000100000\n",
      "Epoch 344/2000, Train Loss: 0.002829697, Train-Class-Acc: {0: '99.92%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.112407183, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.72%', 1: '98.36%', 2: '86.43%'}, LR: 0.000100000\n",
      "Epoch 345/2000, Train Loss: 0.002846046, Train-Class-Acc: {0: '99.91%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.114271989, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.72%', 1: '98.31%', 2: '86.34%'}, LR: 0.000100000\n",
      "Epoch 346/2000, Train Loss: 0.003249374, Train-Class-Acc: {0: '99.89%', 1: '99.85%', 2: '99.97%'}, Val Loss: 0.116243139, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.70%', 1: '98.45%', 2: '85.87%'}, LR: 0.000100000\n",
      "Epoch 347/2000, Train Loss: 0.002783177, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.124130268, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.73%', 1: '98.23%', 2: '84.93%'}, LR: 0.000100000\n",
      "Epoch 348/2000, Train Loss: 0.002778071, Train-Class-Acc: {0: '99.92%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.117185505, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.74%', 1: '98.32%', 2: '85.87%'}, LR: 0.000100000\n",
      "Epoch 349/2000, Train Loss: 0.002763318, Train-Class-Acc: {0: '99.92%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.112181421, Val Accuracy: 97.86%, Val-Class-Acc: {0: '99.67%', 1: '98.51%', 2: '86.97%'}, LR: 0.000100000\n",
      "Epoch 350/2000, Train Loss: 0.002864471, Train-Class-Acc: {0: '99.91%', 1: '99.87%', 2: '99.98%'}, Val Loss: 0.141018906, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.85%', 1: '97.37%', 2: '84.68%'}, LR: 0.000100000\n",
      "Epoch 351/2000, Train Loss: 0.003050844, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.98%'}, Val Loss: 0.118606950, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.71%', 1: '98.37%', 2: '86.27%'}, LR: 0.000100000\n",
      "Epoch 352/2000, Train Loss: 0.002794705, Train-Class-Acc: {0: '99.91%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.117265765, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.75%', 1: '98.26%', 2: '86.55%'}, LR: 0.000100000\n",
      "Epoch 353/2000, Train Loss: 0.002599845, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.122757602, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.72%', 1: '98.43%', 2: '86.07%'}, LR: 0.000100000\n",
      "Epoch 354/2000, Train Loss: 0.002615826, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.122212708, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.73%', 1: '98.40%', 2: '86.01%'}, LR: 0.000100000\n",
      "Epoch 355/2000, Train Loss: 0.003079991, Train-Class-Acc: {0: '99.90%', 1: '99.85%', 2: '99.98%'}, Val Loss: 0.115206168, Val Accuracy: 97.84%, Val-Class-Acc: {0: '99.67%', 1: '98.38%', 2: '87.16%'}, LR: 0.000100000\n",
      "Epoch 356/2000, Train Loss: 0.066049158, Train-Class-Acc: {0: '98.98%', 1: '98.23%', 2: '98.24%'}, Val Loss: 0.178107006, Val Accuracy: 96.23%, Val-Class-Acc: {0: '99.62%', 1: '97.20%', 2: '76.58%'}, LR: 0.000100000\n",
      "Epoch 357/2000, Train Loss: 0.009542335, Train-Class-Acc: {0: '99.73%', 1: '99.51%', 2: '99.74%'}, Val Loss: 0.100837796, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.57%', 1: '98.05%', 2: '86.20%'}, LR: 0.000100000\n",
      "Epoch 358/2000, Train Loss: 0.004210109, Train-Class-Acc: {0: '99.89%', 1: '99.84%', 2: '99.97%'}, Val Loss: 0.096398501, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.72%', 1: '98.06%', 2: '87.00%'}, LR: 0.000100000\n",
      "Epoch 359/2000, Train Loss: 0.003342334, Train-Class-Acc: {0: '99.92%', 1: '99.88%', 2: '99.97%'}, Val Loss: 0.100660833, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.73%', 1: '98.14%', 2: '86.88%'}, LR: 0.000100000\n",
      "Epoch 360/2000, Train Loss: 0.003081655, Train-Class-Acc: {0: '99.92%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.100420697, Val Accuracy: 97.79%, Val-Class-Acc: {0: '99.76%', 1: '98.15%', 2: '87.04%'}, LR: 0.000100000\n",
      "Epoch 361/2000, Train Loss: 0.002941118, Train-Class-Acc: {0: '99.93%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.106838183, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.69%', 1: '98.42%', 2: '86.32%'}, LR: 0.000100000\n",
      "Epoch 362/2000, Train Loss: 0.002841115, Train-Class-Acc: {0: '99.93%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.107504090, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.74%', 1: '98.27%', 2: '86.47%'}, LR: 0.000100000\n",
      "Epoch 363/2000, Train Loss: 0.002775338, Train-Class-Acc: {0: '99.93%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.112319863, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.76%', 1: '98.19%', 2: '86.14%'}, LR: 0.000100000\n",
      "Epoch 364/2000, Train Loss: 0.002771138, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.115958223, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.78%', 1: '98.15%', 2: '85.83%'}, LR: 0.000100000\n",
      "Epoch 365/2000, Train Loss: 0.002719916, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.117937160, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.78%', 1: '98.09%', 2: '85.87%'}, LR: 0.000100000\n",
      "Epoch 366/2000, Train Loss: 0.002694083, Train-Class-Acc: {0: '99.93%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.111349654, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.77%', 1: '98.09%', 2: '86.34%'}, LR: 0.000100000\n",
      "Epoch 367/2000, Train Loss: 0.002661943, Train-Class-Acc: {0: '99.92%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.111680086, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.74%', 1: '98.35%', 2: '86.28%'}, LR: 0.000100000\n",
      "Epoch 368/2000, Train Loss: 0.002673781, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.116016410, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.76%', 1: '98.23%', 2: '86.06%'}, LR: 0.000100000\n",
      "Epoch 369/2000, Train Loss: 0.002626418, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.124215265, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.81%', 1: '97.89%', 2: '85.46%'}, LR: 0.000100000\n",
      "Epoch 370/2000, Train Loss: 0.002693319, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.121415912, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.78%', 1: '97.98%', 2: '85.93%'}, LR: 0.000100000\n",
      "Epoch 371/2000, Train Loss: 0.002560998, Train-Class-Acc: {0: '99.93%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.110944893, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.71%', 1: '98.35%', 2: '86.54%'}, LR: 0.000100000\n",
      "Epoch 372/2000, Train Loss: 0.002635202, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.120981790, Val Accuracy: 97.72%, Val-Class-Acc: {0: '99.77%', 1: '98.27%', 2: '86.03%'}, LR: 0.000100000\n",
      "Epoch 373/2000, Train Loss: 0.002539051, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.122804047, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.77%', 1: '98.19%', 2: '86.07%'}, LR: 0.000100000\n",
      "Epoch 374/2000, Train Loss: 0.002645702, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.130273747, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.80%', 1: '97.97%', 2: '85.55%'}, LR: 0.000100000\n",
      "Epoch 375/2000, Train Loss: 0.002553853, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.124033957, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.75%', 1: '98.25%', 2: '86.02%'}, LR: 0.000100000\n",
      "Epoch 376/2000, Train Loss: 0.002448730, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.124479850, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.77%', 1: '98.17%', 2: '86.03%'}, LR: 0.000100000\n",
      "Epoch 377/2000, Train Loss: 0.002607939, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.131174665, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.81%', 1: '97.73%', 2: '85.43%'}, LR: 0.000100000\n",
      "Epoch 378/2000, Train Loss: 0.016943898, Train-Class-Acc: {0: '99.49%', 1: '99.36%', 2: '99.81%'}, Val Loss: 0.123627174, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.61%', 1: '97.34%', 2: '87.26%'}, LR: 0.000100000\n",
      "Epoch 379/2000, Train Loss: 0.005342662, Train-Class-Acc: {0: '99.83%', 1: '99.73%', 2: '99.94%'}, Val Loss: 0.122939233, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.77%', 1: '98.05%', 2: '85.59%'}, LR: 0.000100000\n",
      "Epoch 380/2000, Train Loss: 0.002730741, Train-Class-Acc: {0: '99.93%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.118723090, Val Accuracy: 97.72%, Val-Class-Acc: {0: '99.77%', 1: '98.18%', 2: '86.24%'}, LR: 0.000100000\n",
      "Epoch 381/2000, Train Loss: 0.002599508, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.119863444, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.76%', 1: '98.34%', 2: '86.06%'}, LR: 0.000100000\n",
      "Epoch 382/2000, Train Loss: 0.002540346, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.121881177, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.72%', 1: '98.40%', 2: '86.24%'}, LR: 0.000100000\n",
      "Epoch 383/2000, Train Loss: 0.002729259, Train-Class-Acc: {0: '99.92%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.125371724, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.78%', 1: '98.23%', 2: '85.64%'}, LR: 0.000100000\n",
      "Epoch 384/2000, Train Loss: 0.002630273, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.127678825, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.78%', 1: '97.99%', 2: '85.82%'}, LR: 0.000100000\n",
      "Epoch 385/2000, Train Loss: 0.002528919, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.126374198, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.76%', 1: '98.24%', 2: '86.03%'}, LR: 0.000100000\n",
      "Epoch 386/2000, Train Loss: 0.002394766, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.98%'}, Val Loss: 0.124702521, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.77%', 1: '98.14%', 2: '86.20%'}, LR: 0.000100000\n",
      "Epoch 387/2000, Train Loss: 0.002392435, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.98%'}, Val Loss: 0.126242986, Val Accuracy: 97.72%, Val-Class-Acc: {0: '99.73%', 1: '98.28%', 2: '86.13%'}, LR: 0.000100000\n",
      "Epoch 388/2000, Train Loss: 0.002423106, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.131171055, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.74%', 1: '98.39%', 2: '85.66%'}, LR: 0.000100000\n",
      "Epoch 389/2000, Train Loss: 0.002377440, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.132474926, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.77%', 1: '98.20%', 2: '85.92%'}, LR: 0.000100000\n",
      "Epoch 390/2000, Train Loss: 0.002307223, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.130325232, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.77%', 1: '98.18%', 2: '86.00%'}, LR: 0.000100000\n",
      "Epoch 391/2000, Train Loss: 0.002483239, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.99%'}, Val Loss: 0.127624750, Val Accuracy: 97.74%, Val-Class-Acc: {0: '99.75%', 1: '98.27%', 2: '86.27%'}, LR: 0.000100000\n",
      "Epoch 392/2000, Train Loss: 0.002598444, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.142387105, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.85%', 1: '97.37%', 2: '85.66%'}, LR: 0.000100000\n",
      "Epoch 393/2000, Train Loss: 0.058842963, Train-Class-Acc: {0: '98.85%', 1: '98.17%', 2: '98.59%'}, Val Loss: 0.134837036, Val Accuracy: 96.84%, Val-Class-Acc: {0: '99.60%', 1: '96.98%', 2: '83.03%'}, LR: 0.000100000\n",
      "Epoch 394/2000, Train Loss: 0.006445413, Train-Class-Acc: {0: '99.82%', 1: '99.67%', 2: '99.92%'}, Val Loss: 0.124814334, Val Accuracy: 97.35%, Val-Class-Acc: {0: '99.52%', 1: '98.01%', 2: '84.61%'}, LR: 0.000100000\n",
      "Epoch 395/2000, Train Loss: 0.003838396, Train-Class-Acc: {0: '99.90%', 1: '99.85%', 2: '99.98%'}, Val Loss: 0.123434149, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.59%', 1: '98.20%', 2: '84.92%'}, LR: 0.000100000\n",
      "Epoch 396/2000, Train Loss: 0.003247648, Train-Class-Acc: {0: '99.92%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.126000229, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.79%', 1: '98.00%', 2: '85.00%'}, LR: 0.000100000\n",
      "Epoch 397/2000, Train Loss: 0.002911310, Train-Class-Acc: {0: '99.93%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.123428339, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.72%', 1: '97.91%', 2: '85.42%'}, LR: 0.000100000\n",
      "Epoch 398/2000, Train Loss: 0.002741177, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.122599941, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.74%', 1: '97.95%', 2: '85.64%'}, LR: 0.000100000\n",
      "Epoch 399/2000, Train Loss: 0.002665337, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.121818516, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.74%', 1: '97.98%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 400/2000, Train Loss: 0.002551231, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.98%'}, Val Loss: 0.126157411, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.74%', 1: '98.09%', 2: '85.67%'}, LR: 0.000100000\n",
      "Epoch 401/2000, Train Loss: 0.002480806, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.129023791, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.77%', 1: '98.18%', 2: '85.22%'}, LR: 0.000100000\n",
      "Epoch 402/2000, Train Loss: 0.002440253, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.126252488, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.77%', 1: '98.08%', 2: '85.64%'}, LR: 0.000100000\n",
      "Epoch 403/2000, Train Loss: 0.002464599, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.98%'}, Val Loss: 0.131062105, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.78%', 1: '98.20%', 2: '85.26%'}, LR: 0.000100000\n",
      "Epoch 404/2000, Train Loss: 0.002322144, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.133522452, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.78%', 1: '98.11%', 2: '85.23%'}, LR: 0.000100000\n",
      "Epoch 405/2000, Train Loss: 0.002362735, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.132482257, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.77%', 1: '98.19%', 2: '85.17%'}, LR: 0.000100000\n",
      "Epoch 406/2000, Train Loss: 0.002288689, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.98%'}, Val Loss: 0.134450346, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.76%', 1: '98.18%', 2: '85.22%'}, LR: 0.000100000\n",
      "Epoch 407/2000, Train Loss: 0.002298724, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.131258184, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.75%', 1: '98.14%', 2: '85.47%'}, LR: 0.000100000\n",
      "Epoch 408/2000, Train Loss: 0.002289780, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.134597938, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.80%', 1: '98.02%', 2: '85.38%'}, LR: 0.000100000\n",
      "Epoch 409/2000, Train Loss: 0.002240182, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.98%'}, Val Loss: 0.130491071, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.67%', 1: '98.39%', 2: '85.50%'}, LR: 0.000100000\n",
      "Epoch 410/2000, Train Loss: 0.002273935, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.98%'}, Val Loss: 0.139116379, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.79%', 1: '98.08%', 2: '85.15%'}, LR: 0.000100000\n",
      "Epoch 411/2000, Train Loss: 0.002356500, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.130273401, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.58%', 1: '98.40%', 2: '85.66%'}, LR: 0.000100000\n",
      "Epoch 412/2000, Train Loss: 0.002598847, Train-Class-Acc: {0: '99.92%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.139438142, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.80%', 1: '97.83%', 2: '85.35%'}, LR: 0.000100000\n",
      "Epoch 413/2000, Train Loss: 0.002540283, Train-Class-Acc: {0: '99.92%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.139328832, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.73%', 1: '98.27%', 2: '85.07%'}, LR: 0.000100000\n",
      "Epoch 414/2000, Train Loss: 0.002181879, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.134002183, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.73%', 1: '98.44%', 2: '85.46%'}, LR: 0.000100000\n",
      "Epoch 415/2000, Train Loss: 0.002186740, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.134074862, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.77%', 1: '98.23%', 2: '85.56%'}, LR: 0.000100000\n",
      "Epoch 416/2000, Train Loss: 0.002179626, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.98%'}, Val Loss: 0.142674216, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.78%', 1: '98.07%', 2: '85.16%'}, LR: 0.000100000\n",
      "Epoch 417/2000, Train Loss: 0.002246850, Train-Class-Acc: {0: '99.94%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.136956254, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.77%', 1: '98.25%', 2: '85.45%'}, LR: 0.000100000\n",
      "Epoch 418/2000, Train Loss: 0.002158869, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.132869538, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.75%', 1: '98.30%', 2: '85.68%'}, LR: 0.000100000\n",
      "Epoch 419/2000, Train Loss: 0.002325174, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.137999944, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.78%', 1: '98.03%', 2: '85.55%'}, LR: 0.000100000\n",
      "Epoch 420/2000, Train Loss: 0.002122990, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.134969472, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.65%', 1: '98.50%', 2: '85.67%'}, LR: 0.000100000\n",
      "Epoch 421/2000, Train Loss: 0.002170055, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.139314015, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.77%', 1: '98.33%', 2: '85.52%'}, LR: 0.000100000\n",
      "Epoch 422/2000, Train Loss: 0.002097012, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.144243810, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.78%', 1: '98.11%', 2: '85.21%'}, LR: 0.000100000\n",
      "Epoch 423/2000, Train Loss: 0.119753493, Train-Class-Acc: {0: '98.38%', 1: '97.14%', 2: '96.98%'}, Val Loss: 0.238191924, Val Accuracy: 95.05%, Val-Class-Acc: {0: '97.78%', 1: '98.50%', 2: '70.33%'}, LR: 0.000100000\n",
      "Epoch 424/2000, Train Loss: 0.036614738, Train-Class-Acc: {0: '99.10%', 1: '98.36%', 2: '97.62%'}, Val Loss: 0.102507159, Val Accuracy: 96.95%, Val-Class-Acc: {0: '99.75%', 1: '97.67%', 2: '81.04%'}, LR: 0.000100000\n",
      "Epoch 425/2000, Train Loss: 0.008918865, Train-Class-Acc: {0: '99.73%', 1: '99.65%', 2: '99.87%'}, Val Loss: 0.099839917, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.72%', 1: '98.12%', 2: '84.34%'}, LR: 0.000100000\n",
      "Epoch 426/2000, Train Loss: 0.005612487, Train-Class-Acc: {0: '99.82%', 1: '99.79%', 2: '99.95%'}, Val Loss: 0.097547198, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.61%', 1: '98.15%', 2: '86.63%'}, LR: 0.000100000\n",
      "Epoch 427/2000, Train Loss: 0.004359716, Train-Class-Acc: {0: '99.87%', 1: '99.83%', 2: '99.97%'}, Val Loss: 0.107129806, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.69%', 1: '97.88%', 2: '84.58%'}, LR: 0.000100000\n",
      "Epoch 428/2000, Train Loss: 0.003405110, Train-Class-Acc: {0: '99.91%', 1: '99.87%', 2: '99.97%'}, Val Loss: 0.113624473, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.72%', 1: '97.75%', 2: '85.37%'}, LR: 0.000100000\n",
      "Epoch 429/2000, Train Loss: 0.002963407, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.97%'}, Val Loss: 0.113492440, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.77%', 1: '97.69%', 2: '85.53%'}, LR: 0.000100000\n",
      "Epoch 430/2000, Train Loss: 0.002814007, Train-Class-Acc: {0: '99.93%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.110943254, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.68%', 1: '97.89%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 431/2000, Train Loss: 0.002508656, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.98%'}, Val Loss: 0.116242703, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.78%', 1: '97.68%', 2: '85.79%'}, LR: 0.000100000\n",
      "Epoch 432/2000, Train Loss: 0.002412155, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.116497249, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.76%', 1: '97.76%', 2: '85.88%'}, LR: 0.000100000\n",
      "Epoch 433/2000, Train Loss: 0.002380183, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.117015767, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.77%', 1: '97.75%', 2: '85.96%'}, LR: 0.000100000\n",
      "Epoch 434/2000, Train Loss: 0.002342024, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.118502612, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.77%', 1: '97.86%', 2: '85.90%'}, LR: 0.000100000\n",
      "Epoch 435/2000, Train Loss: 0.002352003, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.124604038, Val Accuracy: 97.43%, Val-Class-Acc: {0: '99.80%', 1: '97.55%', 2: '85.57%'}, LR: 0.000100000\n",
      "Epoch 436/2000, Train Loss: 0.002277517, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.120849002, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.77%', 1: '97.85%', 2: '85.76%'}, LR: 0.000100000\n",
      "Epoch 437/2000, Train Loss: 0.002257266, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.122690899, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.77%', 1: '97.88%', 2: '85.80%'}, LR: 0.000100000\n",
      "Epoch 438/2000, Train Loss: 0.002229055, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.125623973, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.79%', 1: '97.74%', 2: '85.67%'}, LR: 0.000100000\n",
      "Epoch 439/2000, Train Loss: 0.002320988, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.129608535, Val Accuracy: 97.41%, Val-Class-Acc: {0: '99.82%', 1: '97.46%', 2: '85.55%'}, LR: 0.000100000\n",
      "Epoch 440/2000, Train Loss: 0.002238292, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.128433652, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.77%', 1: '97.96%', 2: '85.49%'}, LR: 0.000100000\n",
      "Epoch 441/2000, Train Loss: 0.002132025, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.126083441, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.76%', 1: '98.03%', 2: '85.75%'}, LR: 0.000100000\n",
      "Epoch 442/2000, Train Loss: 0.003967758, Train-Class-Acc: {0: '99.86%', 1: '99.80%', 2: '99.97%'}, Val Loss: 0.119939892, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.61%', 1: '98.19%', 2: '86.13%'}, LR: 0.000100000\n",
      "Epoch 443/2000, Train Loss: 0.002583627, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.127097032, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.79%', 1: '97.65%', 2: '85.90%'}, LR: 0.000100000\n",
      "Epoch 444/2000, Train Loss: 0.002127895, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.127162763, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.78%', 1: '97.96%', 2: '85.66%'}, LR: 0.000100000\n",
      "Epoch 445/2000, Train Loss: 0.002067958, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.129690699, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.77%', 1: '98.16%', 2: '85.53%'}, LR: 0.000100000\n",
      "Epoch 446/2000, Train Loss: 0.002091106, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.132238494, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.78%', 1: '97.96%', 2: '85.47%'}, LR: 0.000100000\n",
      "Epoch 447/2000, Train Loss: 0.002011025, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.126892303, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.76%', 1: '98.13%', 2: '85.90%'}, LR: 0.000100000\n",
      "Epoch 448/2000, Train Loss: 0.002089443, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.132173474, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.78%', 1: '97.95%', 2: '85.52%'}, LR: 0.000100000\n",
      "Epoch 449/2000, Train Loss: 0.001996235, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.129064050, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.77%', 1: '98.17%', 2: '85.84%'}, LR: 0.000100000\n",
      "Epoch 450/2000, Train Loss: 0.002187848, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.126025815, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.65%', 1: '98.36%', 2: '85.94%'}, LR: 0.000100000\n",
      "Epoch 451/2000, Train Loss: 0.002200961, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.132923965, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.78%', 1: '98.13%', 2: '85.64%'}, LR: 0.000100000\n",
      "Epoch 452/2000, Train Loss: 0.001986725, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.132061490, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.79%', 1: '97.94%', 2: '85.73%'}, LR: 0.000100000\n",
      "Epoch 453/2000, Train Loss: 0.001936584, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.133809255, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.78%', 1: '98.09%', 2: '85.63%'}, LR: 0.000100000\n",
      "Epoch 454/2000, Train Loss: 0.001954672, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.129470022, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.78%', 1: '98.06%', 2: '86.01%'}, LR: 0.000100000\n",
      "Epoch 455/2000, Train Loss: 0.001954080, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.131419859, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.77%', 1: '98.16%', 2: '85.84%'}, LR: 0.000100000\n",
      "Epoch 456/2000, Train Loss: 0.023077154, Train-Class-Acc: {0: '99.50%', 1: '99.32%', 2: '99.72%'}, Val Loss: 0.336853902, Val Accuracy: 95.21%, Val-Class-Acc: {0: '99.98%', 1: '95.28%', 2: '71.87%'}, LR: 0.000100000\n",
      "Epoch 457/2000, Train Loss: 0.022191528, Train-Class-Acc: {0: '99.37%', 1: '99.13%', 2: '99.37%'}, Val Loss: 0.120577863, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.66%', 1: '97.93%', 2: '85.07%'}, LR: 0.000100000\n",
      "Epoch 458/2000, Train Loss: 0.003047606, Train-Class-Acc: {0: '99.92%', 1: '99.87%', 2: '99.97%'}, Val Loss: 0.118336288, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.78%', 1: '97.94%', 2: '86.07%'}, LR: 0.000100000\n",
      "Epoch 459/2000, Train Loss: 0.002353012, Train-Class-Acc: {0: '99.95%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.117305650, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.73%', 1: '98.27%', 2: '85.98%'}, LR: 0.000100000\n",
      "Epoch 460/2000, Train Loss: 0.002210670, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.116711968, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.69%', 1: '98.42%', 2: '86.11%'}, LR: 0.000100000\n",
      "Epoch 461/2000, Train Loss: 0.002108508, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.116955987, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.73%', 1: '98.15%', 2: '86.27%'}, LR: 0.000100000\n",
      "Epoch 462/2000, Train Loss: 0.002080941, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.120775152, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.78%', 1: '98.16%', 2: '86.05%'}, LR: 0.000100000\n",
      "Epoch 463/2000, Train Loss: 0.002021591, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.123471170, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.79%', 1: '98.01%', 2: '85.94%'}, LR: 0.000100000\n",
      "Epoch 464/2000, Train Loss: 0.002026526, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.121572169, Val Accuracy: 97.72%, Val-Class-Acc: {0: '99.70%', 1: '98.39%', 2: '85.93%'}, LR: 0.000100000\n",
      "Epoch 465/2000, Train Loss: 0.001991502, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.127834923, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.78%', 1: '98.12%', 2: '85.59%'}, LR: 0.000100000\n",
      "Epoch 466/2000, Train Loss: 0.001991638, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.125427036, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.78%', 1: '98.08%', 2: '85.83%'}, LR: 0.000100000\n",
      "Epoch 467/2000, Train Loss: 0.001905747, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.125645711, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.78%', 1: '98.25%', 2: '85.79%'}, LR: 0.000100000\n",
      "Epoch 468/2000, Train Loss: 0.001924544, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.122877586, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.78%', 1: '98.16%', 2: '86.00%'}, LR: 0.000100000\n",
      "Epoch 469/2000, Train Loss: 0.001866483, Train-Class-Acc: {0: '99.95%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.123342518, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.78%', 1: '98.24%', 2: '86.18%'}, LR: 0.000100000\n",
      "Epoch 470/2000, Train Loss: 0.001872887, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.125724757, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.74%', 1: '98.27%', 2: '85.99%'}, LR: 0.000100000\n",
      "Epoch 471/2000, Train Loss: 0.001874355, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.128717187, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.78%', 1: '98.13%', 2: '85.77%'}, LR: 0.000100000\n",
      "Epoch 472/2000, Train Loss: 0.001827871, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.128850087, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.78%', 1: '98.19%', 2: '85.93%'}, LR: 0.000100000\n",
      "Epoch 473/2000, Train Loss: 0.001881375, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.125495983, Val Accuracy: 97.74%, Val-Class-Acc: {0: '99.76%', 1: '98.31%', 2: '86.06%'}, LR: 0.000100000\n",
      "Epoch 474/2000, Train Loss: 0.001967129, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.131168870, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.78%', 1: '98.21%', 2: '85.73%'}, LR: 0.000100000\n",
      "Epoch 475/2000, Train Loss: 0.001982176, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.137459190, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.83%', 1: '97.62%', 2: '85.52%'}, LR: 0.000100000\n",
      "Epoch 476/2000, Train Loss: 0.001881178, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.131665780, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.78%', 1: '98.08%', 2: '85.85%'}, LR: 0.000100000\n",
      "Epoch 477/2000, Train Loss: 0.001954305, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.127896406, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.72%', 1: '98.25%', 2: '86.20%'}, LR: 0.000100000\n",
      "Epoch 478/2000, Train Loss: 0.001891071, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.128376782, Val Accuracy: 97.72%, Val-Class-Acc: {0: '99.67%', 1: '98.35%', 2: '86.22%'}, LR: 0.000100000\n",
      "Epoch 479/2000, Train Loss: 0.001794726, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.134338354, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.80%', 1: '97.96%', 2: '85.87%'}, LR: 0.000100000\n",
      "Epoch 480/2000, Train Loss: 0.002516037, Train-Class-Acc: {0: '99.92%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.131291585, Val Accuracy: 97.72%, Val-Class-Acc: {0: '99.70%', 1: '98.34%', 2: '86.04%'}, LR: 0.000100000\n",
      "Epoch 481/2000, Train Loss: 0.001759655, Train-Class-Acc: {0: '99.95%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.138382237, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.76%', 1: '98.23%', 2: '85.68%'}, LR: 0.000100000\n",
      "Epoch 482/2000, Train Loss: 0.043168165, Train-Class-Acc: {0: '99.16%', 1: '98.68%', 2: '98.92%'}, Val Loss: 0.158322315, Val Accuracy: 96.52%, Val-Class-Acc: {0: '99.94%', 1: '96.18%', 2: '81.17%'}, LR: 0.000100000\n",
      "Epoch 483/2000, Train Loss: 0.005227550, Train-Class-Acc: {0: '99.86%', 1: '99.73%', 2: '99.94%'}, Val Loss: 0.111825732, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.55%', 1: '98.30%', 2: '85.97%'}, LR: 0.000100000\n",
      "Epoch 484/2000, Train Loss: 0.002389432, Train-Class-Acc: {0: '99.95%', 1: '99.91%', 2: '99.98%'}, Val Loss: 0.109706859, Val Accuracy: 97.74%, Val-Class-Acc: {0: '99.67%', 1: '98.29%', 2: '86.53%'}, LR: 0.000100000\n",
      "Epoch 485/2000, Train Loss: 0.002089437, Train-Class-Acc: {0: '99.96%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.111118566, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.69%', 1: '98.32%', 2: '86.41%'}, LR: 0.000100000\n",
      "Epoch 486/2000, Train Loss: 0.002048303, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.109232944, Val Accuracy: 97.77%, Val-Class-Acc: {0: '99.67%', 1: '98.33%', 2: '86.70%'}, LR: 0.000100000\n",
      "Epoch 487/2000, Train Loss: 0.001930360, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.112756415, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.77%', 1: '98.27%', 2: '86.32%'}, LR: 0.000100000\n",
      "Epoch 488/2000, Train Loss: 0.001911782, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.112724530, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.78%', 1: '98.18%', 2: '86.37%'}, LR: 0.000100000\n",
      "Epoch 489/2000, Train Loss: 0.001822195, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.116738699, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.76%', 1: '98.33%', 2: '86.19%'}, LR: 0.000100000\n",
      "Epoch 490/2000, Train Loss: 0.001824348, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.117838693, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.77%', 1: '98.31%', 2: '86.10%'}, LR: 0.000100000\n",
      "Epoch 491/2000, Train Loss: 0.001763008, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.119545494, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.76%', 1: '98.31%', 2: '86.18%'}, LR: 0.000100000\n",
      "Epoch 492/2000, Train Loss: 0.001774804, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.118981025, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.66%', 1: '98.38%', 2: '86.23%'}, LR: 0.000100000\n",
      "Epoch 493/2000, Train Loss: 0.001783615, Train-Class-Acc: {0: '99.96%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.119495090, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.72%', 1: '98.35%', 2: '86.30%'}, LR: 0.000100000\n",
      "Epoch 494/2000, Train Loss: 0.001708472, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.124505818, Val Accuracy: 97.72%, Val-Class-Acc: {0: '99.78%', 1: '98.24%', 2: '85.98%'}, LR: 0.000100000\n",
      "Epoch 495/2000, Train Loss: 0.001697095, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.123575074, Val Accuracy: 97.72%, Val-Class-Acc: {0: '99.77%', 1: '98.26%', 2: '85.99%'}, LR: 0.000100000\n",
      "Epoch 496/2000, Train Loss: 0.001712528, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.121327163, Val Accuracy: 97.74%, Val-Class-Acc: {0: '99.78%', 1: '98.23%', 2: '86.29%'}, LR: 0.000100000\n",
      "Epoch 497/2000, Train Loss: 0.001642315, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.123781422, Val Accuracy: 97.73%, Val-Class-Acc: {0: '99.76%', 1: '98.25%', 2: '86.22%'}, LR: 0.000100000\n",
      "Epoch 498/2000, Train Loss: 0.001670798, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.126636016, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.77%', 1: '98.22%', 2: '85.98%'}, LR: 0.000100000\n",
      "Epoch 499/2000, Train Loss: 0.001731653, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.124738980, Val Accuracy: 97.76%, Val-Class-Acc: {0: '99.68%', 1: '98.39%', 2: '86.35%'}, LR: 0.000100000\n",
      "Epoch 500/2000, Train Loss: 0.002386623, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.122171070, Val Accuracy: 97.78%, Val-Class-Acc: {0: '99.35%', 1: '98.46%', 2: '87.85%'}, LR: 0.000100000\n",
      "Epoch 501/2000, Train Loss: 0.001863670, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.125783566, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.69%', 1: '98.38%', 2: '86.21%'}, LR: 0.000100000\n",
      "Epoch 502/2000, Train Loss: 0.002150482, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.126091349, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.79%', 1: '98.03%', 2: '86.33%'}, LR: 0.000100000\n",
      "Epoch 503/2000, Train Loss: 0.001613932, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.129615909, Val Accuracy: 97.75%, Val-Class-Acc: {0: '99.74%', 1: '98.35%', 2: '86.12%'}, LR: 0.000100000\n",
      "Epoch 504/2000, Train Loss: 0.001707756, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.127769951, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.79%', 1: '98.09%', 2: '86.24%'}, LR: 0.000100000\n",
      "Epoch 505/2000, Train Loss: 0.001651169, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.136545778, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.83%', 1: '97.65%', 2: '85.90%'}, LR: 0.000100000\n",
      "Epoch 506/2000, Train Loss: 0.073346659, Train-Class-Acc: {0: '98.88%', 1: '97.91%', 2: '97.87%'}, Val Loss: 0.123038716, Val Accuracy: 96.86%, Val-Class-Acc: {0: '98.77%', 1: '97.81%', 2: '84.44%'}, LR: 0.000100000\n",
      "Epoch 507/2000, Train Loss: 0.011338325, Train-Class-Acc: {0: '99.58%', 1: '99.50%', 2: '99.83%'}, Val Loss: 0.100236844, Val Accuracy: 97.41%, Val-Class-Acc: {0: '99.55%', 1: '97.77%', 2: '85.92%'}, LR: 0.000100000\n",
      "Epoch 508/2000, Train Loss: 0.003346764, Train-Class-Acc: {0: '99.93%', 1: '99.88%', 2: '99.96%'}, Val Loss: 0.104884207, Val Accuracy: 97.47%, Val-Class-Acc: {0: '99.74%', 1: '97.49%', 2: '86.47%'}, LR: 0.000100000\n",
      "Epoch 509/2000, Train Loss: 0.002366292, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.98%'}, Val Loss: 0.106418577, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.72%', 1: '97.55%', 2: '86.91%'}, LR: 0.000100000\n",
      "Epoch 510/2000, Train Loss: 0.002111191, Train-Class-Acc: {0: '99.96%', 1: '99.93%', 2: '99.98%'}, Val Loss: 0.107883584, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.70%', 1: '97.87%', 2: '86.49%'}, LR: 0.000100000\n",
      "Epoch 511/2000, Train Loss: 0.002018751, Train-Class-Acc: {0: '99.96%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.110732697, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.69%', 1: '98.05%', 2: '86.32%'}, LR: 0.000100000\n",
      "Epoch 512/2000, Train Loss: 0.001987582, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.114813156, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.79%', 1: '97.83%', 2: '85.94%'}, LR: 0.000100000\n",
      "Epoch 513/2000, Train Loss: 0.001836885, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.115739369, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.77%', 1: '97.91%', 2: '85.93%'}, LR: 0.000100000\n",
      "Epoch 514/2000, Train Loss: 0.001786327, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.117446938, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.78%', 1: '97.83%', 2: '85.90%'}, LR: 0.000100000\n",
      "Epoch 515/2000, Train Loss: 0.001733741, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.121719134, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.79%', 1: '97.91%', 2: '85.56%'}, LR: 0.000100000\n",
      "Epoch 516/2000, Train Loss: 0.001765035, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.122210061, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.77%', 1: '98.12%', 2: '85.64%'}, LR: 0.000100000\n",
      "Epoch 517/2000, Train Loss: 0.001701979, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.120429765, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.76%', 1: '98.04%', 2: '85.97%'}, LR: 0.000100000\n",
      "Epoch 518/2000, Train Loss: 0.001630423, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.120213114, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.77%', 1: '98.05%', 2: '85.98%'}, LR: 0.000100000\n",
      "Epoch 519/2000, Train Loss: 0.001635653, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.121912120, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.72%', 1: '98.23%', 2: '86.09%'}, LR: 0.000100000\n",
      "Epoch 520/2000, Train Loss: 0.001629581, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.123090438, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.77%', 1: '98.08%', 2: '85.93%'}, LR: 0.000100000\n",
      "Epoch 521/2000, Train Loss: 0.001616026, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.126882787, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.77%', 1: '98.07%', 2: '85.61%'}, LR: 0.000100000\n",
      "Epoch 522/2000, Train Loss: 0.001624807, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.125161538, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.78%', 1: '98.00%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 523/2000, Train Loss: 0.001628268, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.128322347, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.80%', 1: '97.95%', 2: '85.60%'}, LR: 0.000100000\n",
      "Epoch 524/2000, Train Loss: 0.001615448, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.127632876, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.73%', 1: '98.29%', 2: '85.85%'}, LR: 0.000100000\n",
      "Epoch 525/2000, Train Loss: 0.001669345, Train-Class-Acc: {0: '99.96%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.128199751, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.78%', 1: '98.13%', 2: '85.71%'}, LR: 0.000100000\n",
      "Epoch 526/2000, Train Loss: 0.001675887, Train-Class-Acc: {0: '99.95%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.132237689, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.83%', 1: '97.53%', 2: '85.70%'}, LR: 0.000100000\n",
      "Epoch 527/2000, Train Loss: 0.001595351, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.130255454, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.79%', 1: '98.01%', 2: '85.73%'}, LR: 0.000100000\n",
      "Epoch 528/2000, Train Loss: 0.001594329, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.130680013, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.77%', 1: '98.13%', 2: '85.80%'}, LR: 0.000100000\n",
      "Epoch 529/2000, Train Loss: 0.001556938, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.126601172, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.78%', 1: '97.97%', 2: '86.17%'}, LR: 0.000100000\n",
      "Epoch 530/2000, Train Loss: 0.001527335, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.133093519, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.79%', 1: '97.91%', 2: '85.79%'}, LR: 0.000100000\n",
      "Epoch 531/2000, Train Loss: 0.001549924, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.130391023, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.77%', 1: '98.17%', 2: '85.97%'}, LR: 0.000100000\n",
      "Epoch 532/2000, Train Loss: 0.001511745, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.128749152, Val Accuracy: 97.72%, Val-Class-Acc: {0: '99.68%', 1: '98.39%', 2: '86.06%'}, LR: 0.000100000\n",
      "Epoch 533/2000, Train Loss: 0.001578842, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.131046566, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.80%', 1: '97.98%', 2: '86.04%'}, LR: 0.000100000\n",
      "Epoch 534/2000, Train Loss: 0.001524719, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.128818148, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.77%', 1: '98.19%', 2: '86.09%'}, LR: 0.000100000\n",
      "Epoch 535/2000, Train Loss: 0.001464138, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.134910897, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.78%', 1: '98.08%', 2: '85.75%'}, LR: 0.000100000\n",
      "Epoch 536/2000, Train Loss: 0.001620814, Train-Class-Acc: {0: '99.96%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.138541056, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.84%', 1: '97.72%', 2: '85.78%'}, LR: 0.000100000\n",
      "Epoch 537/2000, Train Loss: 0.024444817, Train-Class-Acc: {0: '99.46%', 1: '99.23%', 2: '99.78%'}, Val Loss: 0.145479174, Val Accuracy: 97.47%, Val-Class-Acc: {0: '99.08%', 1: '98.32%', 2: '86.82%'}, LR: 0.000100000\n",
      "Epoch 538/2000, Train Loss: 0.005119915, Train-Class-Acc: {0: '99.83%', 1: '99.75%', 2: '99.94%'}, Val Loss: 0.128555391, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.60%', 1: '97.95%', 2: '86.09%'}, LR: 0.000100000\n",
      "Epoch 539/2000, Train Loss: 0.001940641, Train-Class-Acc: {0: '99.96%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.133484864, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.70%', 1: '97.94%', 2: '85.76%'}, LR: 0.000100000\n",
      "Epoch 540/2000, Train Loss: 0.001690156, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.133657046, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.72%', 1: '98.01%', 2: '85.77%'}, LR: 0.000100000\n",
      "Epoch 541/2000, Train Loss: 0.001627809, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.134937197, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.71%', 1: '98.09%', 2: '85.91%'}, LR: 0.000100000\n",
      "Epoch 542/2000, Train Loss: 0.001590166, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.137594308, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.78%', 1: '98.07%', 2: '85.57%'}, LR: 0.000100000\n",
      "Epoch 543/2000, Train Loss: 0.001542665, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.133904320, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.69%', 1: '98.31%', 2: '85.92%'}, LR: 0.000100000\n",
      "Epoch 544/2000, Train Loss: 0.001532095, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.137527805, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.79%', 1: '98.03%', 2: '85.76%'}, LR: 0.000100000\n",
      "Epoch 545/2000, Train Loss: 0.001481770, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.138922336, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.78%', 1: '98.07%', 2: '85.72%'}, LR: 0.000100000\n",
      "Epoch 546/2000, Train Loss: 0.001447746, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.139028731, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.77%', 1: '98.11%', 2: '85.71%'}, LR: 0.000100000\n",
      "Epoch 547/2000, Train Loss: 0.001445861, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.136962976, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.78%', 1: '98.10%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 548/2000, Train Loss: 0.001557916, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.138483303, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.82%', 1: '97.89%', 2: '85.83%'}, LR: 0.000100000\n",
      "Epoch 549/2000, Train Loss: 0.001448148, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.140631487, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.75%', 1: '98.28%', 2: '85.66%'}, LR: 0.000100000\n",
      "Epoch 550/2000, Train Loss: 0.001645184, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.168242825, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.92%', 1: '96.56%', 2: '84.35%'}, LR: 0.000100000\n",
      "Epoch 551/2000, Train Loss: 0.006059574, Train-Class-Acc: {0: '99.80%', 1: '99.72%', 2: '99.96%'}, Val Loss: 0.130746937, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.56%', 1: '98.33%', 2: '86.18%'}, LR: 0.000100000\n",
      "Epoch 552/2000, Train Loss: 0.001602743, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.138595646, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.75%', 1: '98.16%', 2: '85.81%'}, LR: 0.000100000\n",
      "Epoch 553/2000, Train Loss: 0.001455292, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.137002795, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.77%', 1: '98.14%', 2: '85.91%'}, LR: 0.000100000\n",
      "Epoch 554/2000, Train Loss: 0.001520434, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.132609788, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.58%', 1: '98.44%', 2: '86.15%'}, LR: 0.000100000\n",
      "Epoch 555/2000, Train Loss: 0.001538137, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.142398813, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.79%', 1: '98.26%', 2: '85.54%'}, LR: 0.000100000\n",
      "Epoch 556/2000, Train Loss: 0.001468335, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.144803303, Val Accuracy: 97.68%, Val-Class-Acc: {0: '99.76%', 1: '98.27%', 2: '85.69%'}, LR: 0.000100000\n",
      "Epoch 557/2000, Train Loss: 0.001535750, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.138889828, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.77%', 1: '98.20%', 2: '85.93%'}, LR: 0.000100000\n",
      "Epoch 558/2000, Train Loss: 0.001514550, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.138721020, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.80%', 1: '98.01%', 2: '86.04%'}, LR: 0.000100000\n",
      "Epoch 559/2000, Train Loss: 0.001567500, Train-Class-Acc: {0: '99.96%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.138510307, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.81%', 1: '97.97%', 2: '86.03%'}, LR: 0.000100000\n",
      "Epoch 560/2000, Train Loss: 0.001333780, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.140792364, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.76%', 1: '98.24%', 2: '85.95%'}, LR: 0.000100000\n",
      "Epoch 561/2000, Train Loss: 0.001341586, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.137699082, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.73%', 1: '98.22%', 2: '86.18%'}, LR: 0.000100000\n",
      "Epoch 562/2000, Train Loss: 0.055836156, Train-Class-Acc: {0: '99.25%', 1: '98.82%', 2: '98.59%'}, Val Loss: 0.187779585, Val Accuracy: 96.17%, Val-Class-Acc: {0: '97.54%', 1: '98.18%', 2: '82.86%'}, LR: 0.000100000\n",
      "Epoch 563/2000, Train Loss: 0.031761679, Train-Class-Acc: {0: '99.17%', 1: '98.56%', 2: '98.66%'}, Val Loss: 0.102585781, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.46%', 1: '97.98%', 2: '84.48%'}, LR: 0.000100000\n",
      "Epoch 564/2000, Train Loss: 0.004592287, Train-Class-Acc: {0: '99.87%', 1: '99.83%', 2: '99.94%'}, Val Loss: 0.112359996, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.72%', 1: '97.85%', 2: '83.94%'}, LR: 0.000100000\n",
      "Epoch 565/2000, Train Loss: 0.002464035, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.98%'}, Val Loss: 0.107464255, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.65%', 1: '98.11%', 2: '85.58%'}, LR: 0.000100000\n",
      "Epoch 566/2000, Train Loss: 0.001897490, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.98%'}, Val Loss: 0.107031362, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.68%', 1: '98.06%', 2: '86.02%'}, LR: 0.000100000\n",
      "Epoch 567/2000, Train Loss: 0.001713035, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.110330324, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.68%', 1: '98.19%', 2: '85.54%'}, LR: 0.000100000\n",
      "Epoch 568/2000, Train Loss: 0.001621125, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.109988523, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.74%', 1: '97.92%', 2: '85.92%'}, LR: 0.000100000\n",
      "Epoch 569/2000, Train Loss: 0.001605758, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.113429035, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.76%', 1: '98.19%', 2: '85.08%'}, LR: 0.000100000\n",
      "Epoch 570/2000, Train Loss: 0.001537011, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.112953144, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.79%', 1: '98.00%', 2: '85.35%'}, LR: 0.000100000\n",
      "Epoch 571/2000, Train Loss: 0.001470578, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.116174222, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.81%', 1: '97.72%', 2: '85.13%'}, LR: 0.000100000\n",
      "Epoch 572/2000, Train Loss: 0.001641038, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.116779947, Val Accuracy: 97.70%, Val-Class-Acc: {0: '99.77%', 1: '98.20%', 2: '85.98%'}, LR: 0.000100000\n",
      "Epoch 573/2000, Train Loss: 0.001456667, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.114660954, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.71%', 1: '98.12%', 2: '86.34%'}, LR: 0.000100000\n",
      "Epoch 574/2000, Train Loss: 0.001464332, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.116941293, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.80%', 1: '98.03%', 2: '86.10%'}, LR: 0.000100000\n",
      "Epoch 575/2000, Train Loss: 0.001405110, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.117067971, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.77%', 1: '98.10%', 2: '86.22%'}, LR: 0.000100000\n",
      "Epoch 576/2000, Train Loss: 0.001407463, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.118835555, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.63%', 1: '98.25%', 2: '86.29%'}, LR: 0.000100000\n",
      "Epoch 577/2000, Train Loss: 0.001708730, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.119604047, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.76%', 1: '98.09%', 2: '86.22%'}, LR: 0.000100000\n",
      "Epoch 578/2000, Train Loss: 0.001448578, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.123137859, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.77%', 1: '98.20%', 2: '85.98%'}, LR: 0.000100000\n",
      "Epoch 579/2000, Train Loss: 0.001322609, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.122614258, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.80%', 1: '97.95%', 2: '86.07%'}, LR: 0.000100000\n",
      "Epoch 580/2000, Train Loss: 0.001345779, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.123844925, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.78%', 1: '98.10%', 2: '86.05%'}, LR: 0.000100000\n",
      "Epoch 581/2000, Train Loss: 0.001365276, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.125201584, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.82%', 1: '97.87%', 2: '86.02%'}, LR: 0.000100000\n",
      "Epoch 582/2000, Train Loss: 0.001377280, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.123029170, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.66%', 1: '98.20%', 2: '86.30%'}, LR: 0.000100000\n",
      "Epoch 583/2000, Train Loss: 0.001433497, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.124738137, Val Accuracy: 97.69%, Val-Class-Acc: {0: '99.78%', 1: '98.13%', 2: '86.19%'}, LR: 0.000100000\n",
      "Epoch 584/2000, Train Loss: 0.001298241, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.126086803, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.75%', 1: '98.22%', 2: '86.14%'}, LR: 0.000100000\n",
      "Epoch 585/2000, Train Loss: 0.001269293, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.127162828, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.78%', 1: '98.05%', 2: '86.16%'}, LR: 0.000100000\n",
      "Epoch 586/2000, Train Loss: 0.001284551, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.128927900, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.81%', 1: '97.92%', 2: '85.96%'}, LR: 0.000100000\n",
      "Epoch 587/2000, Train Loss: 0.001262966, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.130126884, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.79%', 1: '98.09%', 2: '86.03%'}, LR: 0.000100000\n",
      "Epoch 588/2000, Train Loss: 0.001224109, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.126736993, Val Accuracy: 97.71%, Val-Class-Acc: {0: '99.75%', 1: '98.18%', 2: '86.27%'}, LR: 0.000100000\n",
      "Epoch 589/2000, Train Loss: 0.001205077, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.130741627, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.78%', 1: '98.09%', 2: '85.99%'}, LR: 0.000100000\n",
      "Epoch 590/2000, Train Loss: 0.002478474, Train-Class-Acc: {0: '99.92%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.208125193, Val Accuracy: 96.42%, Val-Class-Acc: {0: '99.98%', 1: '95.42%', 2: '82.59%'}, LR: 0.000100000\n",
      "Epoch 591/2000, Train Loss: 0.069617377, Train-Class-Acc: {0: '98.79%', 1: '97.96%', 2: '97.92%'}, Val Loss: 0.124240817, Val Accuracy: 96.86%, Val-Class-Acc: {0: '99.56%', 1: '97.77%', 2: '80.74%'}, LR: 0.000100000\n",
      "Epoch 592/2000, Train Loss: 0.004942858, Train-Class-Acc: {0: '99.87%', 1: '99.81%', 2: '99.96%'}, Val Loss: 0.113851258, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.62%', 1: '97.67%', 2: '84.08%'}, LR: 0.000100000\n",
      "Epoch 593/2000, Train Loss: 0.002391961, Train-Class-Acc: {0: '99.96%', 1: '99.92%', 2: '99.98%'}, Val Loss: 0.115410402, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.76%', 1: '97.79%', 2: '84.18%'}, LR: 0.000100000\n",
      "Epoch 594/2000, Train Loss: 0.001877396, Train-Class-Acc: {0: '99.97%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.111922027, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.72%', 1: '97.96%', 2: '84.72%'}, LR: 0.000100000\n",
      "Epoch 595/2000, Train Loss: 0.001648574, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.110084430, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.69%', 1: '98.09%', 2: '86.32%'}, LR: 0.000100000\n",
      "Epoch 596/2000, Train Loss: 0.001525680, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.111724535, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.72%', 1: '98.00%', 2: '86.25%'}, LR: 0.000100000\n",
      "Epoch 597/2000, Train Loss: 0.001521418, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.113506554, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.66%', 1: '98.23%', 2: '86.17%'}, LR: 0.000100000\n",
      "Epoch 598/2000, Train Loss: 0.001443648, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.116658376, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.73%', 1: '98.10%', 2: '85.73%'}, LR: 0.000100000\n",
      "Epoch 599/2000, Train Loss: 0.001400601, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.117006483, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.71%', 1: '98.14%', 2: '85.80%'}, LR: 0.000100000\n",
      "Epoch 600/2000, Train Loss: 0.001365948, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.117861965, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.80%', 1: '97.83%', 2: '85.83%'}, LR: 0.000100000\n",
      "Epoch 601/2000, Train Loss: 0.001363945, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.118257095, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.75%', 1: '97.93%', 2: '86.19%'}, LR: 0.000100000\n",
      "Epoch 602/2000, Train Loss: 0.001300266, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.119443205, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.77%', 1: '97.90%', 2: '85.82%'}, LR: 0.000100000\n",
      "Epoch 603/2000, Train Loss: 0.001309576, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.120332214, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.73%', 1: '98.10%', 2: '85.86%'}, LR: 0.000100000\n",
      "Epoch 604/2000, Train Loss: 0.001371616, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.123010717, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.81%', 1: '97.85%', 2: '85.72%'}, LR: 0.000100000\n",
      "Epoch 605/2000, Train Loss: 0.001288677, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.121839418, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.79%', 1: '97.92%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 606/2000, Train Loss: 0.001295849, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.121052978, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.75%', 1: '97.89%', 2: '86.01%'}, LR: 0.000100000\n",
      "Epoch 607/2000, Train Loss: 0.001283137, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.125544299, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.78%', 1: '98.02%', 2: '85.80%'}, LR: 0.000100000\n",
      "Epoch 608/2000, Train Loss: 0.001261173, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.126102116, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.82%', 1: '97.78%', 2: '85.83%'}, LR: 0.000100000\n",
      "Epoch 609/2000, Train Loss: 0.001242906, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.127351615, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.80%', 1: '97.94%', 2: '85.78%'}, LR: 0.000100000\n",
      "Epoch 610/2000, Train Loss: 0.001286428, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.130075180, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.82%', 1: '97.64%', 2: '85.72%'}, LR: 0.000100000\n",
      "Epoch 611/2000, Train Loss: 0.001296146, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.129164460, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.78%', 1: '98.03%', 2: '85.78%'}, LR: 0.000100000\n",
      "Epoch 612/2000, Train Loss: 0.001244655, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.128454416, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.75%', 1: '98.08%', 2: '85.91%'}, LR: 0.000100000\n",
      "Epoch 613/2000, Train Loss: 0.007367165, Train-Class-Acc: {0: '99.80%', 1: '99.71%', 2: '99.95%'}, Val Loss: 0.147598520, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.05%', 1: '98.51%', 2: '83.57%'}, LR: 0.000100000\n",
      "Epoch 614/2000, Train Loss: 0.002183424, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.98%'}, Val Loss: 0.142495562, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.83%', 1: '97.63%', 2: '84.20%'}, LR: 0.000100000\n",
      "Epoch 615/2000, Train Loss: 0.001285562, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.139703019, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.76%', 1: '97.97%', 2: '84.23%'}, LR: 0.000100000\n",
      "Epoch 616/2000, Train Loss: 0.001218974, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.135206140, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.73%', 1: '97.95%', 2: '84.76%'}, LR: 0.000100000\n",
      "Epoch 617/2000, Train Loss: 0.001221976, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.137149747, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.75%', 1: '97.99%', 2: '84.55%'}, LR: 0.000100000\n",
      "Epoch 618/2000, Train Loss: 0.001247357, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.137091429, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.72%', 1: '98.19%', 2: '85.00%'}, LR: 0.000100000\n",
      "Epoch 619/2000, Train Loss: 0.001205991, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.136575576, Val Accuracy: 97.47%, Val-Class-Acc: {0: '99.77%', 1: '97.99%', 2: '84.67%'}, LR: 0.000100000\n",
      "Epoch 620/2000, Train Loss: 0.001186900, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.132778778, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.72%', 1: '98.02%', 2: '85.90%'}, LR: 0.000100000\n",
      "Epoch 621/2000, Train Loss: 0.001181998, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.145399699, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.85%', 1: '97.53%', 2: '84.24%'}, LR: 0.000100000\n",
      "Epoch 622/2000, Train Loss: 0.001230238, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.134716524, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.74%', 1: '98.00%', 2: '85.87%'}, LR: 0.000100000\n",
      "Epoch 623/2000, Train Loss: 0.017720872, Train-Class-Acc: {0: '99.71%', 1: '99.50%', 2: '99.65%'}, Val Loss: 0.188438718, Val Accuracy: 96.62%, Val-Class-Acc: {0: '99.15%', 1: '98.57%', 2: '77.91%'}, LR: 0.000100000\n",
      "Epoch 624/2000, Train Loss: 0.015142869, Train-Class-Acc: {0: '99.54%', 1: '99.38%', 2: '99.66%'}, Val Loss: 0.124735681, Val Accuracy: 97.35%, Val-Class-Acc: {0: '99.69%', 1: '97.78%', 2: '84.53%'}, LR: 0.000100000\n",
      "Epoch 625/2000, Train Loss: 0.001948281, Train-Class-Acc: {0: '99.96%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.123758439, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.78%', 1: '97.83%', 2: '85.45%'}, LR: 0.000100000\n",
      "Epoch 626/2000, Train Loss: 0.001475123, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.123421497, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.74%', 1: '98.04%', 2: '85.62%'}, LR: 0.000100000\n",
      "Epoch 627/2000, Train Loss: 0.001349556, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.122568937, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.69%', 1: '98.17%', 2: '85.91%'}, LR: 0.000100000\n",
      "Epoch 628/2000, Train Loss: 0.001328680, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.124350585, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.81%', 1: '97.86%', 2: '85.87%'}, LR: 0.000100000\n",
      "Epoch 629/2000, Train Loss: 0.001297922, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.127550451, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.79%', 1: '98.02%', 2: '85.46%'}, LR: 0.000100000\n",
      "Epoch 630/2000, Train Loss: 0.001301849, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.125335884, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.72%', 1: '98.15%', 2: '85.76%'}, LR: 0.000100000\n",
      "Epoch 631/2000, Train Loss: 0.001285096, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.126012684, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.68%', 1: '98.26%', 2: '85.78%'}, LR: 0.000100000\n",
      "Epoch 632/2000, Train Loss: 0.001204455, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.127199405, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.79%', 1: '98.01%', 2: '85.75%'}, LR: 0.000100000\n",
      "Epoch 633/2000, Train Loss: 0.001188580, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.125764084, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.75%', 1: '98.07%', 2: '85.98%'}, LR: 0.000100000\n",
      "Epoch 634/2000, Train Loss: 0.001183802, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.129848394, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.81%', 1: '97.90%', 2: '85.58%'}, LR: 0.000100000\n",
      "Epoch 635/2000, Train Loss: 0.001276768, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.129170049, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.83%', 1: '97.76%', 2: '85.83%'}, LR: 0.000100000\n",
      "Epoch 636/2000, Train Loss: 0.001378087, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.129516497, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.59%', 1: '98.30%', 2: '85.93%'}, LR: 0.000100000\n",
      "Epoch 637/2000, Train Loss: 0.001261478, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.130673761, Val Accuracy: 97.63%, Val-Class-Acc: {0: '99.77%', 1: '98.09%', 2: '85.78%'}, LR: 0.000100000\n",
      "Epoch 638/2000, Train Loss: 0.001110882, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.127187449, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.73%', 1: '98.13%', 2: '86.00%'}, LR: 0.000100000\n",
      "Epoch 639/2000, Train Loss: 0.001210851, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.137757915, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.81%', 1: '97.85%', 2: '85.34%'}, LR: 0.000100000\n",
      "Epoch 640/2000, Train Loss: 0.001176060, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.126947528, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.67%', 1: '98.15%', 2: '86.22%'}, LR: 0.000100000\n",
      "Epoch 641/2000, Train Loss: 0.001118201, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.129391471, Val Accuracy: 97.62%, Val-Class-Acc: {0: '99.80%', 1: '97.94%', 2: '86.05%'}, LR: 0.000100000\n",
      "Epoch 642/2000, Train Loss: 0.001350058, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.140588480, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.84%', 1: '97.61%', 2: '85.42%'}, LR: 0.000100000\n",
      "Epoch 643/2000, Train Loss: 0.001153623, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.132651051, Val Accuracy: 97.66%, Val-Class-Acc: {0: '99.69%', 1: '98.19%', 2: '86.08%'}, LR: 0.000100000\n",
      "Epoch 644/2000, Train Loss: 0.001185238, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.130968712, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.74%', 1: '98.05%', 2: '86.15%'}, LR: 0.000100000\n",
      "Epoch 645/2000, Train Loss: 0.001183681, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.133186897, Val Accuracy: 97.67%, Val-Class-Acc: {0: '99.78%', 1: '98.16%', 2: '85.83%'}, LR: 0.000100000\n",
      "Epoch 646/2000, Train Loss: 0.001045146, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.137833370, Val Accuracy: 97.65%, Val-Class-Acc: {0: '99.76%', 1: '98.18%', 2: '85.63%'}, LR: 0.000100000\n",
      "Epoch 647/2000, Train Loss: 0.001303707, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.133770418, Val Accuracy: 97.64%, Val-Class-Acc: {0: '99.64%', 1: '98.22%', 2: '86.06%'}, LR: 0.000100000\n",
      "Epoch 648/2000, Train Loss: 0.043660820, Train-Class-Acc: {0: '99.12%', 1: '98.56%', 2: '98.89%'}, Val Loss: 0.141298043, Val Accuracy: 96.49%, Val-Class-Acc: {0: '99.78%', 1: '96.51%', 2: '80.53%'}, LR: 0.000100000\n",
      "Epoch 649/2000, Train Loss: 0.008830046, Train-Class-Acc: {0: '99.68%', 1: '99.61%', 2: '99.88%'}, Val Loss: 0.134411487, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.83%', 1: '97.24%', 2: '83.84%'}, LR: 0.000100000\n",
      "Epoch 650/2000, Train Loss: 0.002362355, Train-Class-Acc: {0: '99.95%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.126290450, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.73%', 1: '97.44%', 2: '85.17%'}, LR: 0.000100000\n",
      "Epoch 651/2000, Train Loss: 0.001567113, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.124548847, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.70%', 1: '97.52%', 2: '85.72%'}, LR: 0.000100000\n",
      "Epoch 652/2000, Train Loss: 0.001327804, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.124898749, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.71%', 1: '97.58%', 2: '85.83%'}, LR: 0.000100000\n",
      "Epoch 653/2000, Train Loss: 0.001272311, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.124820659, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.75%', 1: '97.52%', 2: '86.73%'}, LR: 0.000100000\n",
      "Epoch 654/2000, Train Loss: 0.001215269, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.128045956, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.71%', 1: '97.84%', 2: '86.23%'}, LR: 0.000100000\n",
      "Epoch 655/2000, Train Loss: 0.001168773, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.129762826, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.74%', 1: '97.77%', 2: '86.31%'}, LR: 0.000100000\n",
      "Epoch 656/2000, Train Loss: 0.001140212, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.129178514, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.72%', 1: '97.83%', 2: '86.42%'}, LR: 0.000100000\n",
      "Epoch 657/2000, Train Loss: 0.001143152, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.131865818, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.78%', 1: '97.73%', 2: '86.23%'}, LR: 0.000100000\n",
      "Epoch 658/2000, Train Loss: 0.001147507, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.131970301, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.79%', 1: '97.65%', 2: '86.37%'}, LR: 0.000100000\n",
      "Epoch 659/2000, Train Loss: 0.001217146, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.129963685, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.62%', 1: '97.87%', 2: '86.79%'}, LR: 0.000100000\n",
      "Epoch 660/2000, Train Loss: 0.001217835, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.132356932, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.78%', 1: '97.78%', 2: '86.18%'}, LR: 0.000100000\n",
      "Epoch 661/2000, Train Loss: 0.001099952, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.136153231, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.79%', 1: '97.75%', 2: '86.08%'}, LR: 0.000100000\n",
      "Epoch 662/2000, Train Loss: 0.001044650, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.136052844, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.78%', 1: '97.81%', 2: '86.06%'}, LR: 0.000100000\n",
      "Epoch 663/2000, Train Loss: 0.001157020, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.137363454, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.81%', 1: '97.58%', 2: '86.15%'}, LR: 0.000100000\n",
      "Epoch 664/2000, Train Loss: 0.001236362, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.135303891, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.78%', 1: '97.88%', 2: '86.02%'}, LR: 0.000100000\n",
      "Epoch 665/2000, Train Loss: 0.001054667, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.137355867, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.72%', 1: '97.98%', 2: '86.03%'}, LR: 0.000100000\n",
      "Epoch 666/2000, Train Loss: 0.001063644, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.140056830, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.78%', 1: '97.84%', 2: '85.69%'}, LR: 0.000100000\n",
      "Epoch 667/2000, Train Loss: 0.001090875, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.136807883, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.79%', 1: '97.73%', 2: '86.28%'}, LR: 0.000100000\n",
      "Epoch 668/2000, Train Loss: 0.001160621, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.138582972, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.71%', 1: '97.97%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 669/2000, Train Loss: 0.001029183, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.139241863, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.80%', 1: '97.64%', 2: '86.09%'}, LR: 0.000100000\n",
      "Epoch 670/2000, Train Loss: 0.001118109, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.137502104, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.81%', 1: '97.62%', 2: '86.18%'}, LR: 0.000100000\n",
      "Epoch 671/2000, Train Loss: 0.001113550, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.141235661, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.83%', 1: '97.51%', 2: '85.79%'}, LR: 0.000100000\n",
      "Epoch 672/2000, Train Loss: 0.035383247, Train-Class-Acc: {0: '99.22%', 1: '98.91%', 2: '99.26%'}, Val Loss: 0.118247217, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.68%', 1: '96.57%', 2: '87.52%'}, LR: 0.000100000\n",
      "Epoch 673/2000, Train Loss: 0.005300182, Train-Class-Acc: {0: '99.85%', 1: '99.74%', 2: '99.90%'}, Val Loss: 0.111097693, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.62%', 1: '97.88%', 2: '86.59%'}, LR: 0.000100000\n",
      "Epoch 674/2000, Train Loss: 0.001558708, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.115318628, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.72%', 1: '97.83%', 2: '86.64%'}, LR: 0.000100000\n",
      "Epoch 675/2000, Train Loss: 0.001331809, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.119442534, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.75%', 1: '97.87%', 2: '86.27%'}, LR: 0.000100000\n",
      "Epoch 676/2000, Train Loss: 0.001222478, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.119648022, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.78%', 1: '97.75%', 2: '86.62%'}, LR: 0.000100000\n",
      "Epoch 677/2000, Train Loss: 0.001166364, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.121656905, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.78%', 1: '97.74%', 2: '86.57%'}, LR: 0.000100000\n",
      "Epoch 678/2000, Train Loss: 0.001114194, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.124930961, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.80%', 1: '97.62%', 2: '86.23%'}, LR: 0.000100000\n",
      "Epoch 679/2000, Train Loss: 0.001149738, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.125316158, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.79%', 1: '97.82%', 2: '86.07%'}, LR: 0.000100000\n",
      "Epoch 680/2000, Train Loss: 0.001084572, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.126570348, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.78%', 1: '97.86%', 2: '85.95%'}, LR: 0.000100000\n",
      "Epoch 681/2000, Train Loss: 0.001080269, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.128019691, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.78%', 1: '97.88%', 2: '85.95%'}, LR: 0.000100000\n",
      "Epoch 682/2000, Train Loss: 0.001032350, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.130544971, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.78%', 1: '97.83%', 2: '85.81%'}, LR: 0.000100000\n",
      "Epoch 683/2000, Train Loss: 0.001075021, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.132784201, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.79%', 1: '97.80%', 2: '85.61%'}, LR: 0.000100000\n",
      "Epoch 684/2000, Train Loss: 0.001018086, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.133497761, Val Accuracy: 97.47%, Val-Class-Acc: {0: '99.80%', 1: '97.58%', 2: '85.80%'}, LR: 0.000100000\n",
      "Epoch 685/2000, Train Loss: 0.000995568, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.133399026, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.78%', 1: '97.86%', 2: '85.81%'}, LR: 0.000100000\n",
      "Epoch 686/2000, Train Loss: 0.001034007, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.132705147, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.78%', 1: '97.89%', 2: '85.91%'}, LR: 0.000100000\n",
      "Epoch 687/2000, Train Loss: 0.000971908, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.135919354, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.79%', 1: '97.81%', 2: '85.61%'}, LR: 0.000100000\n",
      "Epoch 688/2000, Train Loss: 0.000950037, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.136956001, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.81%', 1: '97.69%', 2: '85.71%'}, LR: 0.000100000\n",
      "Epoch 689/2000, Train Loss: 0.001003811, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.136297824, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.82%', 1: '97.60%', 2: '85.81%'}, LR: 0.000100000\n",
      "Epoch 690/2000, Train Loss: 0.001061384, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.137403132, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.77%', 1: '97.96%', 2: '85.73%'}, LR: 0.000100000\n",
      "Epoch 691/2000, Train Loss: 0.020909836, Train-Class-Acc: {0: '99.61%', 1: '99.40%', 2: '99.74%'}, Val Loss: 0.146518778, Val Accuracy: 96.90%, Val-Class-Acc: {0: '97.89%', 1: '97.70%', 2: '89.49%'}, LR: 0.000100000\n",
      "Epoch 692/2000, Train Loss: 0.025491225, Train-Class-Acc: {0: '99.13%', 1: '98.81%', 2: '99.62%'}, Val Loss: 0.152266101, Val Accuracy: 96.94%, Val-Class-Acc: {0: '99.61%', 1: '97.75%', 2: '81.31%'}, LR: 0.000100000\n",
      "Epoch 693/2000, Train Loss: 0.003438200, Train-Class-Acc: {0: '99.91%', 1: '99.86%', 2: '99.93%'}, Val Loss: 0.123978484, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.74%', 1: '97.34%', 2: '86.73%'}, LR: 0.000100000\n",
      "Epoch 694/2000, Train Loss: 0.001530315, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.129857859, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.75%', 1: '97.66%', 2: '86.06%'}, LR: 0.000100000\n",
      "Epoch 695/2000, Train Loss: 0.001318464, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.131548560, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.78%', 1: '97.82%', 2: '85.86%'}, LR: 0.000100000\n",
      "Epoch 696/2000, Train Loss: 0.001224496, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.132860494, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.77%', 1: '97.83%', 2: '85.83%'}, LR: 0.000100000\n",
      "Epoch 697/2000, Train Loss: 0.001131512, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.133355057, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.72%', 1: '97.90%', 2: '85.87%'}, LR: 0.000100000\n",
      "Epoch 698/2000, Train Loss: 0.001071994, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.131917512, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.73%', 1: '97.90%', 2: '86.14%'}, LR: 0.000100000\n",
      "Epoch 699/2000, Train Loss: 0.001056665, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.137433388, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.76%', 1: '97.88%', 2: '85.45%'}, LR: 0.000100000\n",
      "Epoch 700/2000, Train Loss: 0.001035987, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.137047458, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.78%', 1: '97.79%', 2: '85.60%'}, LR: 0.000100000\n",
      "Epoch 701/2000, Train Loss: 0.001005982, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.136710046, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.79%', 1: '97.78%', 2: '85.72%'}, LR: 0.000100000\n",
      "Epoch 702/2000, Train Loss: 0.001067443, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.138407598, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.79%', 1: '97.81%', 2: '85.61%'}, LR: 0.000100000\n",
      "Epoch 703/2000, Train Loss: 0.001001916, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.141346016, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.79%', 1: '97.82%', 2: '85.37%'}, LR: 0.000100000\n",
      "Epoch 704/2000, Train Loss: 0.001081563, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '100.00%'}, Val Loss: 0.137874182, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.78%', 1: '97.85%', 2: '85.79%'}, LR: 0.000100000\n",
      "Epoch 705/2000, Train Loss: 0.000992015, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.142863092, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.77%', 1: '97.78%', 2: '85.54%'}, LR: 0.000100000\n",
      "Epoch 706/2000, Train Loss: 0.001042681, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.143246520, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.82%', 1: '97.50%', 2: '85.52%'}, LR: 0.000100000\n",
      "Epoch 707/2000, Train Loss: 0.001008118, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.141058236, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.79%', 1: '97.80%', 2: '85.87%'}, LR: 0.000100000\n",
      "Epoch 708/2000, Train Loss: 0.000972544, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.144628198, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.76%', 1: '97.95%', 2: '85.55%'}, LR: 0.000100000\n",
      "Epoch 709/2000, Train Loss: 0.001146097, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.143040121, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.83%', 1: '97.58%', 2: '85.79%'}, LR: 0.000100000\n",
      "Epoch 710/2000, Train Loss: 0.001167031, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.145079286, Val Accuracy: 97.43%, Val-Class-Acc: {0: '99.83%', 1: '97.47%', 2: '85.72%'}, LR: 0.000100000\n",
      "Epoch 711/2000, Train Loss: 0.003755764, Train-Class-Acc: {0: '99.88%', 1: '99.83%', 2: '99.98%'}, Val Loss: 0.161142255, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.40%', 1: '98.09%', 2: '85.39%'}, LR: 0.000100000\n",
      "Epoch 712/2000, Train Loss: 0.002205250, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.99%'}, Val Loss: 0.143422307, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.72%', 1: '97.91%', 2: '86.14%'}, LR: 0.000100000\n",
      "Epoch 713/2000, Train Loss: 0.001018609, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.144502959, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.78%', 1: '97.88%', 2: '85.62%'}, LR: 0.000100000\n",
      "Epoch 714/2000, Train Loss: 0.000951843, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.141897525, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.70%', 1: '97.97%', 2: '86.01%'}, LR: 0.000100000\n",
      "Epoch 715/2000, Train Loss: 0.000980592, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.144641120, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.82%', 1: '97.67%', 2: '85.56%'}, LR: 0.000100000\n",
      "Epoch 716/2000, Train Loss: 0.000927600, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.148257406, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.80%', 1: '97.84%', 2: '85.22%'}, LR: 0.000100000\n",
      "Epoch 717/2000, Train Loss: 0.000922554, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.149475529, Val Accuracy: 97.35%, Val-Class-Acc: {0: '99.85%', 1: '97.30%', 2: '85.44%'}, LR: 0.000100000\n",
      "Epoch 718/2000, Train Loss: 0.001846930, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.144602098, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.72%', 1: '97.90%', 2: '85.83%'}, LR: 0.000100000\n",
      "Epoch 719/2000, Train Loss: 0.000932871, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.144730888, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.76%', 1: '97.94%', 2: '85.80%'}, LR: 0.000100000\n",
      "Epoch 720/2000, Train Loss: 0.000856253, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.147144499, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.78%', 1: '97.83%', 2: '85.71%'}, LR: 0.000100000\n",
      "Epoch 721/2000, Train Loss: 0.000930345, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.142753369, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.74%', 1: '97.92%', 2: '86.24%'}, LR: 0.000100000\n",
      "Epoch 722/2000, Train Loss: 0.000919962, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.145962307, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.75%', 1: '97.96%', 2: '85.98%'}, LR: 0.000100000\n",
      "Epoch 723/2000, Train Loss: 0.000908258, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.149314852, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.80%', 1: '97.83%', 2: '85.72%'}, LR: 0.000100000\n",
      "Epoch 724/2000, Train Loss: 0.000899234, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.147708057, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.80%', 1: '97.68%', 2: '85.94%'}, LR: 0.000100000\n",
      "Epoch 725/2000, Train Loss: 0.000841392, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.147171223, Val Accuracy: 97.59%, Val-Class-Acc: {0: '99.78%', 1: '97.87%', 2: '86.05%'}, LR: 0.000100000\n",
      "Epoch 726/2000, Train Loss: 0.000881827, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.147520749, Val Accuracy: 97.61%, Val-Class-Acc: {0: '99.69%', 1: '97.97%', 2: '86.31%'}, LR: 0.000100000\n",
      "Epoch 727/2000, Train Loss: 0.001028870, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.156932272, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.86%', 1: '97.15%', 2: '85.13%'}, LR: 0.000100000\n",
      "Epoch 728/2000, Train Loss: 0.140146214, Train-Class-Acc: {0: '97.68%', 1: '95.80%', 2: '95.55%'}, Val Loss: 0.120496134, Val Accuracy: 96.66%, Val-Class-Acc: {0: '99.61%', 1: '97.42%', 2: '79.86%'}, LR: 0.000100000\n",
      "Epoch 729/2000, Train Loss: 0.009347791, Train-Class-Acc: {0: '99.70%', 1: '99.63%', 2: '99.83%'}, Val Loss: 0.118347411, Val Accuracy: 96.97%, Val-Class-Acc: {0: '99.75%', 1: '97.81%', 2: '80.66%'}, LR: 0.000100000\n",
      "Epoch 730/2000, Train Loss: 0.004601162, Train-Class-Acc: {0: '99.86%', 1: '99.84%', 2: '99.97%'}, Val Loss: 0.116937522, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.50%', 1: '97.59%', 2: '83.55%'}, LR: 0.000100000\n",
      "Epoch 731/2000, Train Loss: 0.002867622, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.97%'}, Val Loss: 0.119490209, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.62%', 1: '97.51%', 2: '84.94%'}, LR: 0.000100000\n",
      "Epoch 732/2000, Train Loss: 0.001908731, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.117185319, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.53%', 1: '97.56%', 2: '85.28%'}, LR: 0.000100000\n",
      "Epoch 733/2000, Train Loss: 0.001602421, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.123635988, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.74%', 1: '97.75%', 2: '84.29%'}, LR: 0.000100000\n",
      "Epoch 734/2000, Train Loss: 0.001358700, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.121974522, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.77%', 1: '97.76%', 2: '84.51%'}, LR: 0.000100000\n",
      "Epoch 735/2000, Train Loss: 0.001284231, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.119548141, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.71%', 1: '97.74%', 2: '84.91%'}, LR: 0.000100000\n",
      "Epoch 736/2000, Train Loss: 0.001158112, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.119849206, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.72%', 1: '97.70%', 2: '84.90%'}, LR: 0.000100000\n",
      "Epoch 737/2000, Train Loss: 0.001109450, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.121582305, Val Accuracy: 97.41%, Val-Class-Acc: {0: '99.72%', 1: '97.77%', 2: '85.02%'}, LR: 0.000100000\n",
      "Epoch 738/2000, Train Loss: 0.001124696, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.120725707, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.74%', 1: '97.50%', 2: '86.29%'}, LR: 0.000100000\n",
      "Epoch 739/2000, Train Loss: 0.001041808, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.121994792, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.81%', 1: '97.60%', 2: '85.94%'}, LR: 0.000100000\n",
      "Epoch 740/2000, Train Loss: 0.001012113, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.123829230, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.80%', 1: '97.70%', 2: '85.74%'}, LR: 0.000100000\n",
      "Epoch 741/2000, Train Loss: 0.001001224, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.123821369, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.71%', 1: '97.86%', 2: '85.85%'}, LR: 0.000100000\n",
      "Epoch 742/2000, Train Loss: 0.000954532, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.124565209, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.81%', 1: '97.62%', 2: '85.94%'}, LR: 0.000100000\n",
      "Epoch 743/2000, Train Loss: 0.000949877, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.126489001, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.80%', 1: '97.71%', 2: '85.81%'}, LR: 0.000100000\n",
      "Epoch 744/2000, Train Loss: 0.000941576, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.127278968, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.79%', 1: '97.70%', 2: '85.81%'}, LR: 0.000100000\n",
      "Epoch 745/2000, Train Loss: 0.000974963, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.127825521, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.80%', 1: '97.62%', 2: '85.99%'}, LR: 0.000100000\n",
      "Epoch 746/2000, Train Loss: 0.000918783, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.129685210, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.80%', 1: '97.65%', 2: '85.78%'}, LR: 0.000100000\n",
      "Epoch 747/2000, Train Loss: 0.000955393, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.128989998, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.74%', 1: '97.83%', 2: '85.83%'}, LR: 0.000100000\n",
      "Epoch 748/2000, Train Loss: 0.000901268, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.129278651, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.68%', 1: '97.96%', 2: '86.04%'}, LR: 0.000100000\n",
      "Epoch 749/2000, Train Loss: 0.000948775, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.133477442, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.80%', 1: '97.64%', 2: '85.38%'}, LR: 0.000100000\n",
      "Epoch 750/2000, Train Loss: 0.000884990, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.130513882, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.81%', 1: '97.67%', 2: '86.00%'}, LR: 0.000100000\n",
      "Epoch 751/2000, Train Loss: 0.000908928, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.134632471, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.82%', 1: '97.63%', 2: '85.32%'}, LR: 0.000100000\n",
      "Epoch 752/2000, Train Loss: 0.000886356, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.132914038, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.80%', 1: '97.66%', 2: '85.72%'}, LR: 0.000100000\n",
      "Epoch 753/2000, Train Loss: 0.000997191, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.132442871, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.74%', 1: '97.83%', 2: '86.07%'}, LR: 0.000100000\n",
      "Epoch 754/2000, Train Loss: 0.001009408, Train-Class-Acc: {0: '99.97%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.132818584, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.76%', 1: '97.85%', 2: '86.01%'}, LR: 0.000100000\n",
      "Epoch 755/2000, Train Loss: 0.000879173, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.132813742, Val Accuracy: 97.58%, Val-Class-Acc: {0: '99.76%', 1: '97.84%', 2: '86.14%'}, LR: 0.000100000\n",
      "Epoch 756/2000, Train Loss: 0.014361898, Train-Class-Acc: {0: '99.65%', 1: '99.69%', 2: '99.87%'}, Val Loss: 0.362732639, Val Accuracy: 94.75%, Val-Class-Acc: {0: '99.97%', 1: '93.69%', 2: '73.09%'}, LR: 0.000100000\n",
      "Epoch 757/2000, Train Loss: 0.025190924, Train-Class-Acc: {0: '99.40%', 1: '98.93%', 2: '99.44%'}, Val Loss: 0.129736252, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.45%', 1: '97.65%', 2: '85.19%'}, LR: 0.000100000\n",
      "Epoch 758/2000, Train Loss: 0.002085905, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.98%'}, Val Loss: 0.132484899, Val Accuracy: 97.35%, Val-Class-Acc: {0: '99.69%', 1: '97.44%', 2: '85.69%'}, LR: 0.000100000\n",
      "Epoch 759/2000, Train Loss: 0.001290631, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.135925847, Val Accuracy: 97.36%, Val-Class-Acc: {0: '99.78%', 1: '97.44%', 2: '85.36%'}, LR: 0.000100000\n",
      "Epoch 760/2000, Train Loss: 0.001075222, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.132626379, Val Accuracy: 97.39%, Val-Class-Acc: {0: '99.71%', 1: '97.56%', 2: '85.53%'}, LR: 0.000100000\n",
      "Epoch 761/2000, Train Loss: 0.001034032, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.135321678, Val Accuracy: 97.39%, Val-Class-Acc: {0: '99.78%', 1: '97.53%', 2: '85.40%'}, LR: 0.000100000\n",
      "Epoch 762/2000, Train Loss: 0.000984665, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.133765490, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.78%', 1: '97.52%', 2: '86.47%'}, LR: 0.000100000\n",
      "Epoch 763/2000, Train Loss: 0.000945124, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.135052320, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.80%', 1: '97.46%', 2: '86.36%'}, LR: 0.000100000\n",
      "Epoch 764/2000, Train Loss: 0.000958256, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.136572323, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.77%', 1: '97.68%', 2: '86.04%'}, LR: 0.000100000\n",
      "Epoch 765/2000, Train Loss: 0.000964273, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.138344788, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.77%', 1: '97.78%', 2: '85.75%'}, LR: 0.000100000\n",
      "Epoch 766/2000, Train Loss: 0.000990535, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.139035659, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.78%', 1: '97.68%', 2: '85.79%'}, LR: 0.000100000\n",
      "Epoch 767/2000, Train Loss: 0.000929416, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.139381082, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.81%', 1: '97.63%', 2: '85.79%'}, LR: 0.000100000\n",
      "Epoch 768/2000, Train Loss: 0.000912983, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.146089175, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.86%', 1: '97.24%', 2: '84.09%'}, LR: 0.000100000\n",
      "Epoch 769/2000, Train Loss: 0.001039516, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.138899081, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.82%', 1: '97.50%', 2: '86.05%'}, LR: 0.000100000\n",
      "Epoch 770/2000, Train Loss: 0.000877499, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.138686973, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.79%', 1: '97.72%', 2: '86.15%'}, LR: 0.000100000\n",
      "Epoch 771/2000, Train Loss: 0.000823410, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.141061307, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.76%', 1: '97.77%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 772/2000, Train Loss: 0.000979623, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.142864514, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.82%', 1: '97.56%', 2: '85.74%'}, LR: 0.000100000\n",
      "Epoch 773/2000, Train Loss: 0.001148749, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.143390669, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.79%', 1: '97.76%', 2: '85.60%'}, LR: 0.000100000\n",
      "Epoch 774/2000, Train Loss: 0.001333588, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.141904790, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.83%', 1: '97.54%', 2: '85.60%'}, LR: 0.000100000\n",
      "Epoch 775/2000, Train Loss: 0.023897362, Train-Class-Acc: {0: '99.32%', 1: '99.11%', 2: '99.70%'}, Val Loss: 0.141314001, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.55%', 1: '97.36%', 2: '85.22%'}, LR: 0.000100000\n",
      "Epoch 776/2000, Train Loss: 0.003192914, Train-Class-Acc: {0: '99.90%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.134900346, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.62%', 1: '97.69%', 2: '85.45%'}, LR: 0.000100000\n",
      "Epoch 777/2000, Train Loss: 0.001193605, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.135420598, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.70%', 1: '97.76%', 2: '85.47%'}, LR: 0.000100000\n",
      "Epoch 778/2000, Train Loss: 0.001008491, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.137019336, Val Accuracy: 97.43%, Val-Class-Acc: {0: '99.78%', 1: '97.59%', 2: '85.52%'}, LR: 0.000100000\n",
      "Epoch 779/2000, Train Loss: 0.000948666, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.135552560, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.72%', 1: '97.70%', 2: '85.77%'}, LR: 0.000100000\n",
      "Epoch 780/2000, Train Loss: 0.000921354, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.138721293, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.81%', 1: '97.48%', 2: '85.64%'}, LR: 0.000100000\n",
      "Epoch 781/2000, Train Loss: 0.000960889, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.140037700, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.82%', 1: '97.50%', 2: '85.42%'}, LR: 0.000100000\n",
      "Epoch 782/2000, Train Loss: 0.000909744, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.137167938, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.73%', 1: '97.79%', 2: '85.87%'}, LR: 0.000100000\n",
      "Epoch 783/2000, Train Loss: 0.000862684, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.138094764, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.72%', 1: '97.86%', 2: '85.72%'}, LR: 0.000100000\n",
      "Epoch 784/2000, Train Loss: 0.000894370, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.142723477, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.76%', 1: '97.82%', 2: '85.35%'}, LR: 0.000100000\n",
      "Epoch 785/2000, Train Loss: 0.001177834, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.143336926, Val Accuracy: 97.43%, Val-Class-Acc: {0: '99.80%', 1: '97.62%', 2: '85.39%'}, LR: 0.000100000\n",
      "Epoch 786/2000, Train Loss: 0.000851022, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.142545913, Val Accuracy: 97.47%, Val-Class-Acc: {0: '99.79%', 1: '97.67%', 2: '85.61%'}, LR: 0.000100000\n",
      "Epoch 787/2000, Train Loss: 0.000911260, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.141003157, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.70%', 1: '97.90%', 2: '86.03%'}, LR: 0.000100000\n",
      "Epoch 788/2000, Train Loss: 0.000838235, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.140611806, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.76%', 1: '97.88%', 2: '85.90%'}, LR: 0.000100000\n",
      "Epoch 789/2000, Train Loss: 0.001146130, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.143441667, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.75%', 1: '97.92%', 2: '85.57%'}, LR: 0.000100000\n",
      "Epoch 790/2000, Train Loss: 0.001166727, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.145541330, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.79%', 1: '97.73%', 2: '85.11%'}, LR: 0.000100000\n",
      "Epoch 791/2000, Train Loss: 0.000817721, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.143476162, Val Accuracy: 97.57%, Val-Class-Acc: {0: '99.69%', 1: '97.97%', 2: '85.99%'}, LR: 0.000100000\n",
      "Epoch 792/2000, Train Loss: 0.000827346, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.142732998, Val Accuracy: 97.56%, Val-Class-Acc: {0: '99.77%', 1: '97.87%', 2: '85.88%'}, LR: 0.000100000\n",
      "Epoch 793/2000, Train Loss: 0.018222616, Train-Class-Acc: {0: '99.67%', 1: '99.56%', 2: '99.61%'}, Val Loss: 0.241936533, Val Accuracy: 95.35%, Val-Class-Acc: {0: '99.78%', 1: '94.98%', 2: '75.15%'}, LR: 0.000100000\n",
      "Epoch 794/2000, Train Loss: 0.024593574, Train-Class-Acc: {0: '99.30%', 1: '98.88%', 2: '99.28%'}, Val Loss: 0.112386733, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.70%', 1: '97.68%', 2: '84.44%'}, LR: 0.000100000\n",
      "Epoch 795/2000, Train Loss: 0.002770584, Train-Class-Acc: {0: '99.92%', 1: '99.89%', 2: '99.96%'}, Val Loss: 0.121528281, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.75%', 1: '97.91%', 2: '84.68%'}, LR: 0.000100000\n",
      "Epoch 796/2000, Train Loss: 0.001255306, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.121922102, Val Accuracy: 97.43%, Val-Class-Acc: {0: '99.76%', 1: '97.75%', 2: '85.09%'}, LR: 0.000100000\n",
      "Epoch 797/2000, Train Loss: 0.001048299, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.123599062, Val Accuracy: 97.39%, Val-Class-Acc: {0: '99.71%', 1: '97.92%', 2: '84.47%'}, LR: 0.000100000\n",
      "Epoch 798/2000, Train Loss: 0.000931301, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.127819427, Val Accuracy: 97.39%, Val-Class-Acc: {0: '99.79%', 1: '97.83%', 2: '84.35%'}, LR: 0.000100000\n",
      "Epoch 799/2000, Train Loss: 0.000885184, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.124492722, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.71%', 1: '97.81%', 2: '85.06%'}, LR: 0.000100000\n",
      "Epoch 800/2000, Train Loss: 0.000927172, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.130088176, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.79%', 1: '97.85%', 2: '84.06%'}, LR: 0.000100000\n",
      "Epoch 801/2000, Train Loss: 0.000883833, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.129379647, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.75%', 1: '97.82%', 2: '84.67%'}, LR: 0.000100000\n",
      "Epoch 802/2000, Train Loss: 0.000850606, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.129294407, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.79%', 1: '97.64%', 2: '85.24%'}, LR: 0.000100000\n",
      "Epoch 803/2000, Train Loss: 0.000839126, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.131504365, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.71%', 1: '97.88%', 2: '84.81%'}, LR: 0.000100000\n",
      "Epoch 804/2000, Train Loss: 0.000817322, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.135571387, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.82%', 1: '97.55%', 2: '84.26%'}, LR: 0.000100000\n",
      "Epoch 805/2000, Train Loss: 0.000903740, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.132656936, Val Accuracy: 97.43%, Val-Class-Acc: {0: '99.78%', 1: '97.74%', 2: '85.04%'}, LR: 0.000100000\n",
      "Epoch 806/2000, Train Loss: 0.000926831, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.133732468, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.81%', 1: '97.62%', 2: '85.74%'}, LR: 0.000100000\n",
      "Epoch 807/2000, Train Loss: 0.000785984, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.135221389, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.79%', 1: '97.73%', 2: '85.67%'}, LR: 0.000100000\n",
      "Epoch 808/2000, Train Loss: 0.001091975, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.140785981, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.85%', 1: '97.36%', 2: '84.40%'}, LR: 0.000100000\n",
      "Epoch 809/2000, Train Loss: 0.001104054, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.135221155, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.74%', 1: '97.88%', 2: '85.84%'}, LR: 0.000100000\n",
      "Epoch 810/2000, Train Loss: 0.000833815, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.138583797, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.77%', 1: '97.80%', 2: '85.31%'}, LR: 0.000100000\n",
      "Epoch 811/2000, Train Loss: 0.000842767, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.137231614, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.49%', 1: '98.03%', 2: '86.11%'}, LR: 0.000100000\n",
      "Epoch 812/2000, Train Loss: 0.000907150, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.139382042, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.79%', 1: '97.70%', 2: '85.63%'}, LR: 0.000100000\n",
      "Epoch 813/2000, Train Loss: 0.000861655, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.145911513, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.85%', 1: '97.27%', 2: '84.37%'}, LR: 0.000100000\n",
      "Epoch 814/2000, Train Loss: 0.000824002, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.139649883, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.77%', 1: '97.80%', 2: '85.55%'}, LR: 0.000100000\n",
      "Epoch 815/2000, Train Loss: 0.065282284, Train-Class-Acc: {0: '98.89%', 1: '97.97%', 2: '97.67%'}, Val Loss: 0.127652252, Val Accuracy: 96.84%, Val-Class-Acc: {0: '99.26%', 1: '97.80%', 2: '81.97%'}, LR: 0.000100000\n",
      "Epoch 816/2000, Train Loss: 0.007569083, Train-Class-Acc: {0: '99.75%', 1: '99.68%', 2: '99.88%'}, Val Loss: 0.129933255, Val Accuracy: 96.77%, Val-Class-Acc: {0: '99.71%', 1: '96.30%', 2: '84.09%'}, LR: 0.000100000\n",
      "Epoch 817/2000, Train Loss: 0.002304792, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.130256041, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.77%', 1: '97.63%', 2: '83.36%'}, LR: 0.000100000\n",
      "Epoch 818/2000, Train Loss: 0.001398647, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.130357542, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.79%', 1: '97.39%', 2: '83.66%'}, LR: 0.000100000\n",
      "Epoch 819/2000, Train Loss: 0.001131666, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.127438157, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.73%', 1: '97.42%', 2: '84.58%'}, LR: 0.000100000\n",
      "Epoch 820/2000, Train Loss: 0.001036270, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.127151719, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.73%', 1: '97.45%', 2: '84.81%'}, LR: 0.000100000\n",
      "Epoch 821/2000, Train Loss: 0.000963485, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.130716833, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.81%', 1: '97.36%', 2: '84.53%'}, LR: 0.000100000\n",
      "Epoch 822/2000, Train Loss: 0.000953037, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.128861596, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.72%', 1: '97.48%', 2: '85.03%'}, LR: 0.000100000\n",
      "Epoch 823/2000, Train Loss: 0.000886696, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.131324806, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.74%', 1: '97.44%', 2: '84.83%'}, LR: 0.000100000\n",
      "Epoch 824/2000, Train Loss: 0.000904115, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.131465437, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.72%', 1: '97.53%', 2: '84.94%'}, LR: 0.000100000\n",
      "Epoch 825/2000, Train Loss: 0.000839094, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.134383121, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.74%', 1: '97.50%', 2: '84.52%'}, LR: 0.000100000\n",
      "Epoch 826/2000, Train Loss: 0.000842503, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.137279861, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.80%', 1: '97.54%', 2: '84.02%'}, LR: 0.000100000\n",
      "Epoch 827/2000, Train Loss: 0.000858085, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.137230905, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.78%', 1: '97.53%', 2: '84.48%'}, LR: 0.000100000\n",
      "Epoch 828/2000, Train Loss: 0.000983439, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.136062531, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.79%', 1: '97.46%', 2: '84.68%'}, LR: 0.000100000\n",
      "Epoch 829/2000, Train Loss: 0.000894949, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.136977164, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.74%', 1: '97.63%', 2: '84.64%'}, LR: 0.000100000\n",
      "Epoch 830/2000, Train Loss: 0.000796558, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.137957022, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.77%', 1: '97.62%', 2: '84.45%'}, LR: 0.000100000\n",
      "Epoch 831/2000, Train Loss: 0.000866031, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.139057959, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.81%', 1: '97.42%', 2: '84.59%'}, LR: 0.000100000\n",
      "Epoch 832/2000, Train Loss: 0.000811706, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.135467803, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.73%', 1: '97.39%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 833/2000, Train Loss: 0.000796418, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.138126080, Val Accuracy: 97.35%, Val-Class-Acc: {0: '99.68%', 1: '97.72%', 2: '84.80%'}, LR: 0.000100000\n",
      "Epoch 834/2000, Train Loss: 0.001050353, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.136364910, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.67%', 1: '97.63%', 2: '85.11%'}, LR: 0.000100000\n",
      "Epoch 835/2000, Train Loss: 0.000904657, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.141651234, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.70%', 1: '97.77%', 2: '84.52%'}, LR: 0.000100000\n",
      "Epoch 836/2000, Train Loss: 0.000797489, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.149939778, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.85%', 1: '97.33%', 2: '83.40%'}, LR: 0.000100000\n",
      "Epoch 837/2000, Train Loss: 0.000880157, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.144596261, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.82%', 1: '97.56%', 2: '83.92%'}, LR: 0.000100000\n",
      "Epoch 838/2000, Train Loss: 0.000932177, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.145079052, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.84%', 1: '97.41%', 2: '84.07%'}, LR: 0.000100000\n",
      "Epoch 839/2000, Train Loss: 0.000820685, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.145309903, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.75%', 1: '97.79%', 2: '83.95%'}, LR: 0.000100000\n",
      "Epoch 840/2000, Train Loss: 0.000884636, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.146732831, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.84%', 1: '97.28%', 2: '84.19%'}, LR: 0.000100000\n",
      "Epoch 841/2000, Train Loss: 0.000840675, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.152636510, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.85%', 1: '97.17%', 2: '83.90%'}, LR: 0.000100000\n",
      "Epoch 842/2000, Train Loss: 0.037114267, Train-Class-Acc: {0: '99.15%', 1: '98.78%', 2: '99.29%'}, Val Loss: 0.152708435, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.48%', 1: '98.07%', 2: '81.30%'}, LR: 0.000100000\n",
      "Epoch 843/2000, Train Loss: 0.002695655, Train-Class-Acc: {0: '99.92%', 1: '99.90%', 2: '99.98%'}, Val Loss: 0.139273832, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.81%', 1: '97.09%', 2: '84.08%'}, LR: 0.000100000\n",
      "Epoch 844/2000, Train Loss: 0.001199299, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.140896725, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.80%', 1: '97.26%', 2: '84.07%'}, LR: 0.000100000\n",
      "Epoch 845/2000, Train Loss: 0.000965171, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.141533883, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.72%', 1: '97.42%', 2: '84.68%'}, LR: 0.000100000\n",
      "Epoch 846/2000, Train Loss: 0.000861942, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.141132471, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.73%', 1: '97.46%', 2: '84.67%'}, LR: 0.000100000\n",
      "Epoch 847/2000, Train Loss: 0.000846869, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.141724296, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.72%', 1: '97.47%', 2: '84.82%'}, LR: 0.000100000\n",
      "Epoch 848/2000, Train Loss: 0.000838290, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.141015974, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.64%', 1: '97.55%', 2: '84.95%'}, LR: 0.000100000\n",
      "Epoch 849/2000, Train Loss: 0.000789373, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.142521395, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.76%', 1: '97.49%', 2: '84.72%'}, LR: 0.000100000\n",
      "Epoch 850/2000, Train Loss: 0.000788946, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.143773054, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.78%', 1: '97.43%', 2: '84.88%'}, LR: 0.000100000\n",
      "Epoch 851/2000, Train Loss: 0.000785110, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.146447199, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.81%', 1: '97.43%', 2: '84.32%'}, LR: 0.000100000\n",
      "Epoch 852/2000, Train Loss: 0.000760838, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.145287037, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.75%', 1: '97.46%', 2: '84.69%'}, LR: 0.000100000\n",
      "Epoch 853/2000, Train Loss: 0.000740589, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.142841690, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.69%', 1: '97.64%', 2: '84.99%'}, LR: 0.000100000\n",
      "Epoch 854/2000, Train Loss: 0.000737449, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.142949519, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.68%', 1: '97.60%', 2: '85.55%'}, LR: 0.000100000\n",
      "Epoch 855/2000, Train Loss: 0.000727614, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.151448874, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.84%', 1: '97.18%', 2: '84.40%'}, LR: 0.000100000\n",
      "Epoch 856/2000, Train Loss: 0.002828841, Train-Class-Acc: {0: '99.92%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.161449072, Val Accuracy: 97.18%, Val-Class-Acc: {0: '99.04%', 1: '97.75%', 2: '86.35%'}, LR: 0.000100000\n",
      "Epoch 857/2000, Train Loss: 0.123410657, Train-Class-Acc: {0: '97.88%', 1: '95.97%', 2: '94.64%'}, Val Loss: 0.084101162, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.33%', 1: '97.31%', 2: '86.21%'}, LR: 0.000100000\n",
      "Epoch 858/2000, Train Loss: 0.008221616, Train-Class-Acc: {0: '99.75%', 1: '99.73%', 2: '99.81%'}, Val Loss: 0.106137516, Val Accuracy: 96.89%, Val-Class-Acc: {0: '99.80%', 1: '96.88%', 2: '82.86%'}, LR: 0.000100000\n",
      "Epoch 859/2000, Train Loss: 0.003450879, Train-Class-Acc: {0: '99.91%', 1: '99.90%', 2: '99.97%'}, Val Loss: 0.118302079, Val Accuracy: 96.78%, Val-Class-Acc: {0: '99.77%', 1: '96.86%', 2: '82.03%'}, LR: 0.000100000\n",
      "Epoch 860/2000, Train Loss: 0.002328414, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.124068109, Val Accuracy: 96.82%, Val-Class-Acc: {0: '99.78%', 1: '96.81%', 2: '82.56%'}, LR: 0.000100000\n",
      "Epoch 861/2000, Train Loss: 0.001693267, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.120255227, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.82%', 1: '97.07%', 2: '84.71%'}, LR: 0.000100000\n",
      "Epoch 862/2000, Train Loss: 0.001360632, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.121569283, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.71%', 1: '97.52%', 2: '83.92%'}, LR: 0.000100000\n",
      "Epoch 863/2000, Train Loss: 0.001215984, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.125760928, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.75%', 1: '97.62%', 2: '83.31%'}, LR: 0.000100000\n",
      "Epoch 864/2000, Train Loss: 0.001068012, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.126488098, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.77%', 1: '97.47%', 2: '83.89%'}, LR: 0.000100000\n",
      "Epoch 865/2000, Train Loss: 0.000991622, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.126107133, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.73%', 1: '97.46%', 2: '84.41%'}, LR: 0.000100000\n",
      "Epoch 866/2000, Train Loss: 0.000963249, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.126513579, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.73%', 1: '97.47%', 2: '84.51%'}, LR: 0.000100000\n",
      "Epoch 867/2000, Train Loss: 0.000928652, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.128712289, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.74%', 1: '97.54%', 2: '84.13%'}, LR: 0.000100000\n",
      "Epoch 868/2000, Train Loss: 0.000892692, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.128896469, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.76%', 1: '97.49%', 2: '84.37%'}, LR: 0.000100000\n",
      "Epoch 869/2000, Train Loss: 0.000896568, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.129179703, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.71%', 1: '97.57%', 2: '84.34%'}, LR: 0.000100000\n",
      "Epoch 870/2000, Train Loss: 0.000905305, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.133408094, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.84%', 1: '97.23%', 2: '84.21%'}, LR: 0.000100000\n",
      "Epoch 871/2000, Train Loss: 0.001229197, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.130987629, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.75%', 1: '97.41%', 2: '84.78%'}, LR: 0.000100000\n",
      "Epoch 872/2000, Train Loss: 0.001083330, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.131464728, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.71%', 1: '97.57%', 2: '84.47%'}, LR: 0.000100000\n",
      "Epoch 873/2000, Train Loss: 0.000982829, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.129279276, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.57%', 1: '97.58%', 2: '85.69%'}, LR: 0.000100000\n",
      "Epoch 874/2000, Train Loss: 0.002856507, Train-Class-Acc: {0: '99.90%', 1: '99.87%', 2: '99.98%'}, Val Loss: 0.146900955, Val Accuracy: 96.96%, Val-Class-Acc: {0: '99.85%', 1: '97.09%', 2: '82.57%'}, LR: 0.000100000\n",
      "Epoch 875/2000, Train Loss: 0.001067247, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.130786550, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.74%', 1: '97.44%', 2: '84.91%'}, LR: 0.000100000\n",
      "Epoch 876/2000, Train Loss: 0.000839745, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.130957016, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.75%', 1: '97.46%', 2: '84.85%'}, LR: 0.000100000\n",
      "Epoch 877/2000, Train Loss: 0.000795763, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.133137350, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.71%', 1: '97.58%', 2: '84.40%'}, LR: 0.000100000\n",
      "Epoch 878/2000, Train Loss: 0.000799001, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.130474212, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.72%', 1: '97.46%', 2: '85.38%'}, LR: 0.000100000\n",
      "Epoch 879/2000, Train Loss: 0.000766540, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.132427852, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.70%', 1: '97.60%', 2: '84.95%'}, LR: 0.000100000\n",
      "Epoch 880/2000, Train Loss: 0.000845050, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.136733596, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.80%', 1: '97.46%', 2: '84.30%'}, LR: 0.000100000\n",
      "Epoch 881/2000, Train Loss: 0.000801963, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.132758367, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.69%', 1: '97.51%', 2: '86.16%'}, LR: 0.000100000\n",
      "Epoch 882/2000, Train Loss: 0.000877832, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.143803194, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.83%', 1: '97.25%', 2: '83.63%'}, LR: 0.000100000\n",
      "Epoch 883/2000, Train Loss: 0.000887411, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.141771779, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.82%', 1: '97.46%', 2: '83.78%'}, LR: 0.000100000\n",
      "Epoch 884/2000, Train Loss: 0.000751546, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.135989501, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.73%', 1: '97.58%', 2: '84.69%'}, LR: 0.000100000\n",
      "Epoch 885/2000, Train Loss: 0.000737827, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.136356842, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.76%', 1: '97.46%', 2: '85.03%'}, LR: 0.000100000\n",
      "Epoch 886/2000, Train Loss: 0.000707360, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.137871095, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.73%', 1: '97.65%', 2: '85.16%'}, LR: 0.000100000\n",
      "Epoch 887/2000, Train Loss: 0.000723434, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.143877873, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.82%', 1: '97.37%', 2: '83.99%'}, LR: 0.000100000\n",
      "Epoch 888/2000, Train Loss: 0.000739152, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.137635744, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.79%', 1: '97.41%', 2: '85.80%'}, LR: 0.000100000\n",
      "Epoch 889/2000, Train Loss: 0.000768480, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.140667099, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.82%', 1: '97.38%', 2: '84.63%'}, LR: 0.000100000\n",
      "Epoch 890/2000, Train Loss: 0.000722953, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.143330937, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.81%', 1: '97.35%', 2: '84.74%'}, LR: 0.000100000\n",
      "Epoch 891/2000, Train Loss: 0.108417474, Train-Class-Acc: {0: '97.99%', 1: '96.74%', 2: '96.13%'}, Val Loss: 0.137166560, Val Accuracy: 95.61%, Val-Class-Acc: {0: '99.50%', 1: '95.54%', 2: '77.03%'}, LR: 0.000100000\n",
      "Epoch 892/2000, Train Loss: 0.017348731, Train-Class-Acc: {0: '99.51%', 1: '99.25%', 2: '99.56%'}, Val Loss: 0.116192324, Val Accuracy: 96.67%, Val-Class-Acc: {0: '99.60%', 1: '96.24%', 2: '83.92%'}, LR: 0.000100000\n",
      "Epoch 893/2000, Train Loss: 0.003745805, Train-Class-Acc: {0: '99.89%', 1: '99.89%', 2: '99.98%'}, Val Loss: 0.122157509, Val Accuracy: 96.70%, Val-Class-Acc: {0: '99.74%', 1: '96.26%', 2: '83.43%'}, LR: 0.000100000\n",
      "Epoch 894/2000, Train Loss: 0.002477143, Train-Class-Acc: {0: '99.93%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.123782308, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.72%', 1: '96.74%', 2: '84.03%'}, LR: 0.000100000\n",
      "Epoch 895/2000, Train Loss: 0.001627111, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.124880088, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.78%', 1: '97.22%', 2: '84.20%'}, LR: 0.000100000\n",
      "Epoch 896/2000, Train Loss: 0.001288632, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.126850489, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.75%', 1: '97.35%', 2: '83.75%'}, LR: 0.000100000\n",
      "Epoch 897/2000, Train Loss: 0.001135411, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.125480436, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.70%', 1: '97.32%', 2: '85.03%'}, LR: 0.000100000\n",
      "Epoch 898/2000, Train Loss: 0.001043385, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.125482203, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.72%', 1: '97.35%', 2: '85.28%'}, LR: 0.000100000\n",
      "Epoch 899/2000, Train Loss: 0.000954814, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.129153086, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.72%', 1: '97.37%', 2: '84.69%'}, LR: 0.000100000\n",
      "Epoch 900/2000, Train Loss: 0.000989525, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.128559281, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.70%', 1: '97.40%', 2: '84.81%'}, LR: 0.000100000\n",
      "Epoch 901/2000, Train Loss: 0.001090949, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.135271846, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.80%', 1: '97.14%', 2: '84.26%'}, LR: 0.000100000\n",
      "Epoch 902/2000, Train Loss: 0.000932385, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.132548372, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.71%', 1: '97.38%', 2: '84.51%'}, LR: 0.000100000\n",
      "Epoch 903/2000, Train Loss: 0.000848050, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.132158800, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.71%', 1: '97.35%', 2: '84.89%'}, LR: 0.000100000\n",
      "Epoch 904/2000, Train Loss: 0.000853810, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.132119409, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.65%', 1: '97.45%', 2: '85.19%'}, LR: 0.000100000\n",
      "Epoch 905/2000, Train Loss: 0.001923135, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.138832729, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.82%', 1: '97.21%', 2: '83.89%'}, LR: 0.000100000\n",
      "Epoch 906/2000, Train Loss: 0.000837279, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.137326941, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.78%', 1: '97.25%', 2: '84.33%'}, LR: 0.000100000\n",
      "Epoch 907/2000, Train Loss: 0.000924757, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.140186790, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.77%', 1: '97.47%', 2: '83.72%'}, LR: 0.000100000\n",
      "Epoch 908/2000, Train Loss: 0.000794318, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.137829034, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.71%', 1: '97.45%', 2: '84.40%'}, LR: 0.000100000\n",
      "Epoch 909/2000, Train Loss: 0.000766128, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.136846281, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.69%', 1: '97.38%', 2: '84.85%'}, LR: 0.000100000\n",
      "Epoch 910/2000, Train Loss: 0.000823734, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.140640493, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.79%', 1: '97.39%', 2: '84.18%'}, LR: 0.000100000\n",
      "Epoch 911/2000, Train Loss: 0.000741734, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.140297028, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.76%', 1: '97.42%', 2: '84.28%'}, LR: 0.000100000\n",
      "Epoch 912/2000, Train Loss: 0.000961967, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.136979226, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.62%', 1: '97.48%', 2: '84.94%'}, LR: 0.000100000\n",
      "Epoch 913/2000, Train Loss: 0.000798368, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.141239180, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.69%', 1: '97.55%', 2: '84.21%'}, LR: 0.000100000\n",
      "Epoch 914/2000, Train Loss: 0.000904514, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.144325277, Val Accuracy: 97.18%, Val-Class-Acc: {0: '99.80%', 1: '97.32%', 2: '84.07%'}, LR: 0.000100000\n",
      "Epoch 915/2000, Train Loss: 0.000778106, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.138669146, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.64%', 1: '97.47%', 2: '85.23%'}, LR: 0.000100000\n",
      "Epoch 916/2000, Train Loss: 0.006361307, Train-Class-Acc: {0: '99.81%', 1: '99.79%', 2: '99.96%'}, Val Loss: 0.142861559, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.65%', 1: '97.70%', 2: '84.16%'}, LR: 0.000100000\n",
      "Epoch 917/2000, Train Loss: 0.001231960, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.141699379, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.79%', 1: '97.39%', 2: '84.13%'}, LR: 0.000100000\n",
      "Epoch 918/2000, Train Loss: 0.000771292, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.139023185, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.73%', 1: '97.48%', 2: '84.64%'}, LR: 0.000100000\n",
      "Epoch 919/2000, Train Loss: 0.000900266, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.139743798, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.81%', 1: '97.18%', 2: '85.31%'}, LR: 0.000100000\n",
      "Epoch 920/2000, Train Loss: 0.000861257, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.140573509, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.71%', 1: '97.58%', 2: '84.42%'}, LR: 0.000100000\n",
      "Epoch 921/2000, Train Loss: 0.000726568, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.141098164, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.70%', 1: '97.39%', 2: '84.90%'}, LR: 0.000100000\n",
      "Epoch 922/2000, Train Loss: 0.000711791, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.144620469, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.77%', 1: '97.50%', 2: '84.14%'}, LR: 0.000100000\n",
      "Epoch 923/2000, Train Loss: 0.000745582, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.144149503, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.81%', 1: '97.37%', 2: '84.32%'}, LR: 0.000100000\n",
      "Epoch 924/2000, Train Loss: 0.000696478, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.142948862, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.78%', 1: '97.49%', 2: '84.49%'}, LR: 0.000100000\n",
      "Epoch 925/2000, Train Loss: 0.000691952, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.142762642, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.72%', 1: '97.62%', 2: '84.45%'}, LR: 0.000100000\n",
      "Epoch 926/2000, Train Loss: 0.000705446, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.146037257, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.79%', 1: '97.49%', 2: '84.17%'}, LR: 0.000100000\n",
      "Epoch 927/2000, Train Loss: 0.000668630, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.146230110, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.76%', 1: '97.60%', 2: '84.22%'}, LR: 0.000100000\n",
      "Epoch 928/2000, Train Loss: 0.000947834, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '100.00%'}, Val Loss: 0.145617606, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.73%', 1: '97.46%', 2: '84.62%'}, LR: 0.000100000\n",
      "Epoch 929/2000, Train Loss: 0.000807057, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.147971485, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.79%', 1: '97.48%', 2: '84.37%'}, LR: 0.000100000\n",
      "Epoch 930/2000, Train Loss: 0.000793640, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.148119266, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.83%', 1: '97.26%', 2: '84.64%'}, LR: 0.000100000\n",
      "Epoch 931/2000, Train Loss: 0.073442821, Train-Class-Acc: {0: '98.87%', 1: '98.27%', 2: '98.04%'}, Val Loss: 0.222886486, Val Accuracy: 93.86%, Val-Class-Acc: {0: '99.89%', 1: '90.17%', 2: '77.00%'}, LR: 0.000100000\n",
      "Epoch 932/2000, Train Loss: 0.036272638, Train-Class-Acc: {0: '99.06%', 1: '98.15%', 2: '98.48%'}, Val Loss: 0.121696947, Val Accuracy: 96.91%, Val-Class-Acc: {0: '99.58%', 1: '97.77%', 2: '81.12%'}, LR: 0.000100000\n",
      "Epoch 933/2000, Train Loss: 0.007043988, Train-Class-Acc: {0: '99.79%', 1: '99.72%', 2: '99.90%'}, Val Loss: 0.114907824, Val Accuracy: 96.74%, Val-Class-Acc: {0: '99.70%', 1: '96.52%', 2: '83.17%'}, LR: 0.000100000\n",
      "Epoch 934/2000, Train Loss: 0.002544065, Train-Class-Acc: {0: '99.94%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.109315765, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.67%', 1: '97.17%', 2: '84.67%'}, LR: 0.000100000\n",
      "Epoch 935/2000, Train Loss: 0.001767597, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.112147733, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.69%', 1: '97.40%', 2: '84.78%'}, LR: 0.000100000\n",
      "Epoch 936/2000, Train Loss: 0.001217448, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.122359346, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.84%', 1: '97.09%', 2: '84.38%'}, LR: 0.000100000\n",
      "Epoch 937/2000, Train Loss: 0.001104243, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.119781160, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.76%', 1: '97.42%', 2: '84.89%'}, LR: 0.000100000\n",
      "Epoch 938/2000, Train Loss: 0.000957038, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.123713388, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.79%', 1: '97.39%', 2: '84.72%'}, LR: 0.000100000\n",
      "Epoch 939/2000, Train Loss: 0.000936573, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.124589025, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.80%', 1: '97.31%', 2: '85.07%'}, LR: 0.000100000\n",
      "Epoch 940/2000, Train Loss: 0.000882368, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.125206060, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.70%', 1: '97.54%', 2: '84.87%'}, LR: 0.000100000\n",
      "Epoch 941/2000, Train Loss: 0.000841385, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.127584833, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.78%', 1: '97.37%', 2: '84.99%'}, LR: 0.000100000\n",
      "Epoch 942/2000, Train Loss: 0.000832660, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.130807488, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.83%', 1: '97.31%', 2: '84.91%'}, LR: 0.000100000\n",
      "Epoch 943/2000, Train Loss: 0.001261075, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.130092840, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.73%', 1: '97.51%', 2: '84.86%'}, LR: 0.000100000\n",
      "Epoch 944/2000, Train Loss: 0.000775193, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.130640253, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.69%', 1: '97.64%', 2: '84.80%'}, LR: 0.000100000\n",
      "Epoch 945/2000, Train Loss: 0.000754689, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.132355858, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.70%', 1: '97.65%', 2: '84.51%'}, LR: 0.000100000\n",
      "Epoch 946/2000, Train Loss: 0.000878515, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.133584118, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.72%', 1: '97.56%', 2: '84.78%'}, LR: 0.000100000\n",
      "Epoch 947/2000, Train Loss: 0.000795345, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.133949639, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.64%', 1: '97.69%', 2: '84.81%'}, LR: 0.000100000\n",
      "Epoch 948/2000, Train Loss: 0.000879679, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.134940206, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.72%', 1: '97.55%', 2: '84.84%'}, LR: 0.000100000\n",
      "Epoch 949/2000, Train Loss: 0.001095035, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.137479307, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.79%', 1: '97.39%', 2: '84.95%'}, LR: 0.000100000\n",
      "Epoch 950/2000, Train Loss: 0.000722545, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.138328546, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.81%', 1: '97.41%', 2: '84.74%'}, LR: 0.000100000\n",
      "Epoch 951/2000, Train Loss: 0.001135534, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.132174299, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.14%', 1: '97.74%', 2: '87.86%'}, LR: 0.000100000\n",
      "Epoch 952/2000, Train Loss: 0.046797773, Train-Class-Acc: {0: '98.83%', 1: '98.37%', 2: '99.04%'}, Val Loss: 0.124093882, Val Accuracy: 96.77%, Val-Class-Acc: {0: '98.76%', 1: '97.18%', 2: '85.78%'}, LR: 0.000100000\n",
      "Epoch 953/2000, Train Loss: 0.006177786, Train-Class-Acc: {0: '99.83%', 1: '99.73%', 2: '99.94%'}, Val Loss: 0.118803977, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.77%', 1: '97.12%', 2: '85.53%'}, LR: 0.000100000\n",
      "Epoch 954/2000, Train Loss: 0.001482506, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.120590428, Val Accuracy: 97.35%, Val-Class-Acc: {0: '99.78%', 1: '97.43%', 2: '85.29%'}, LR: 0.000100000\n",
      "Epoch 955/2000, Train Loss: 0.001069484, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.124886794, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.79%', 1: '97.33%', 2: '85.53%'}, LR: 0.000100000\n",
      "Epoch 956/2000, Train Loss: 0.000925120, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.126044815, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.78%', 1: '97.50%', 2: '85.27%'}, LR: 0.000100000\n",
      "Epoch 957/2000, Train Loss: 0.000904957, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.128882841, Val Accuracy: 97.36%, Val-Class-Acc: {0: '99.83%', 1: '97.37%', 2: '85.31%'}, LR: 0.000100000\n",
      "Epoch 958/2000, Train Loss: 0.000875090, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.127841219, Val Accuracy: 97.41%, Val-Class-Acc: {0: '99.79%', 1: '97.40%', 2: '85.94%'}, LR: 0.000100000\n",
      "Epoch 959/2000, Train Loss: 0.000825757, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.126062232, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.70%', 1: '97.63%', 2: '85.97%'}, LR: 0.000100000\n",
      "Epoch 960/2000, Train Loss: 0.000793224, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.126975213, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.70%', 1: '97.68%', 2: '85.80%'}, LR: 0.000100000\n",
      "Epoch 961/2000, Train Loss: 0.000758154, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.131718495, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.83%', 1: '97.31%', 2: '85.72%'}, LR: 0.000100000\n",
      "Epoch 962/2000, Train Loss: 0.000818592, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.129012938, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.75%', 1: '97.55%', 2: '85.96%'}, LR: 0.000100000\n",
      "Epoch 963/2000, Train Loss: 0.000721291, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.131991642, Val Accuracy: 97.43%, Val-Class-Acc: {0: '99.79%', 1: '97.55%', 2: '85.62%'}, LR: 0.000100000\n",
      "Epoch 964/2000, Train Loss: 0.000717079, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.131327016, Val Accuracy: 97.43%, Val-Class-Acc: {0: '99.76%', 1: '97.59%', 2: '85.61%'}, LR: 0.000100000\n",
      "Epoch 965/2000, Train Loss: 0.000721203, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.131769847, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.78%', 1: '97.53%', 2: '85.91%'}, LR: 0.000100000\n",
      "Epoch 966/2000, Train Loss: 0.000704485, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.133312988, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.75%', 1: '97.59%', 2: '85.80%'}, LR: 0.000100000\n",
      "Epoch 967/2000, Train Loss: 0.000829758, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.137259095, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.80%', 1: '97.48%', 2: '85.37%'}, LR: 0.000100000\n",
      "Epoch 968/2000, Train Loss: 0.033150489, Train-Class-Acc: {0: '99.28%', 1: '99.03%', 2: '99.06%'}, Val Loss: 0.120198403, Val Accuracy: 96.54%, Val-Class-Acc: {0: '99.09%', 1: '95.06%', 2: '89.13%'}, LR: 0.000100000\n",
      "Epoch 969/2000, Train Loss: 0.017045966, Train-Class-Acc: {0: '99.48%', 1: '99.16%', 2: '99.55%'}, Val Loss: 0.121574102, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.62%', 1: '97.67%', 2: '83.47%'}, LR: 0.000100000\n",
      "Epoch 970/2000, Train Loss: 0.002365447, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.115191042, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.79%', 1: '97.46%', 2: '85.11%'}, LR: 0.000100000\n",
      "Epoch 971/2000, Train Loss: 0.001233676, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.118553955, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.78%', 1: '97.48%', 2: '85.09%'}, LR: 0.000100000\n",
      "Epoch 972/2000, Train Loss: 0.001005902, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.119120231, Val Accuracy: 97.36%, Val-Class-Acc: {0: '99.75%', 1: '97.48%', 2: '85.42%'}, LR: 0.000100000\n",
      "Epoch 973/2000, Train Loss: 0.000882700, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.120642565, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.77%', 1: '97.36%', 2: '85.75%'}, LR: 0.000100000\n",
      "Epoch 974/2000, Train Loss: 0.000849760, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.123827253, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.80%', 1: '97.36%', 2: '85.40%'}, LR: 0.000100000\n",
      "Epoch 975/2000, Train Loss: 0.000806396, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.126818728, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.80%', 1: '97.45%', 2: '84.91%'}, LR: 0.000100000\n",
      "Epoch 976/2000, Train Loss: 0.000801996, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.124039438, Val Accuracy: 97.39%, Val-Class-Acc: {0: '99.72%', 1: '97.49%', 2: '85.80%'}, LR: 0.000100000\n",
      "Epoch 977/2000, Train Loss: 0.000786639, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.125630455, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.76%', 1: '97.51%', 2: '85.35%'}, LR: 0.000100000\n",
      "Epoch 978/2000, Train Loss: 0.000748610, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.125421182, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.77%', 1: '97.39%', 2: '85.99%'}, LR: 0.000100000\n",
      "Epoch 979/2000, Train Loss: 0.000737265, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.127773440, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.74%', 1: '97.55%', 2: '84.95%'}, LR: 0.000100000\n",
      "Epoch 980/2000, Train Loss: 0.000710082, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.130952173, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.78%', 1: '97.54%', 2: '84.59%'}, LR: 0.000100000\n",
      "Epoch 981/2000, Train Loss: 0.000727518, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.129581467, Val Accuracy: 97.36%, Val-Class-Acc: {0: '99.79%', 1: '97.45%', 2: '85.26%'}, LR: 0.000100000\n",
      "Epoch 982/2000, Train Loss: 0.000711734, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.128597605, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.75%', 1: '97.53%', 2: '85.61%'}, LR: 0.000100000\n",
      "Epoch 983/2000, Train Loss: 0.000917706, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.129887430, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.78%', 1: '97.45%', 2: '85.57%'}, LR: 0.000100000\n",
      "Epoch 984/2000, Train Loss: 0.000718413, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.131671362, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.71%', 1: '97.61%', 2: '85.25%'}, LR: 0.000100000\n",
      "Epoch 985/2000, Train Loss: 0.000811907, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.135290076, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.84%', 1: '97.26%', 2: '84.94%'}, LR: 0.000100000\n",
      "Epoch 986/2000, Train Loss: 0.012559540, Train-Class-Acc: {0: '99.66%', 1: '99.60%', 2: '99.94%'}, Val Loss: 0.130362343, Val Accuracy: 97.35%, Val-Class-Acc: {0: '99.37%', 1: '97.87%', 2: '85.86%'}, LR: 0.000100000\n",
      "Epoch 987/2000, Train Loss: 0.001994547, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.126065586, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.60%', 1: '97.56%', 2: '87.10%'}, LR: 0.000100000\n",
      "Epoch 988/2000, Train Loss: 0.001019204, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.129482269, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.68%', 1: '97.61%', 2: '85.47%'}, LR: 0.000100000\n",
      "Epoch 989/2000, Train Loss: 0.000795937, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.129566593, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.66%', 1: '97.59%', 2: '86.01%'}, LR: 0.000100000\n",
      "Epoch 990/2000, Train Loss: 0.000736317, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.136208989, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.82%', 1: '97.45%', 2: '84.57%'}, LR: 0.000100000\n",
      "Epoch 991/2000, Train Loss: 0.000703103, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.132726484, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.72%', 1: '97.60%', 2: '85.51%'}, LR: 0.000100000\n",
      "Epoch 992/2000, Train Loss: 0.000683411, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.134154019, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.75%', 1: '97.56%', 2: '85.30%'}, LR: 0.000100000\n",
      "Epoch 993/2000, Train Loss: 0.000669255, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.134146161, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.76%', 1: '97.51%', 2: '85.33%'}, LR: 0.000100000\n",
      "Epoch 994/2000, Train Loss: 0.000799710, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.132432645, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.64%', 1: '97.63%', 2: '87.04%'}, LR: 0.000100000\n",
      "Epoch 995/2000, Train Loss: 0.001258296, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '100.00%'}, Val Loss: 0.134537542, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.72%', 1: '97.57%', 2: '86.17%'}, LR: 0.000100000\n",
      "Epoch 996/2000, Train Loss: 0.000778164, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.138022489, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.78%', 1: '97.51%', 2: '84.92%'}, LR: 0.000100000\n",
      "Epoch 997/2000, Train Loss: 0.000704897, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.134769202, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.71%', 1: '97.61%', 2: '86.39%'}, LR: 0.000100000\n",
      "Epoch 998/2000, Train Loss: 0.000677311, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.139140808, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.73%', 1: '97.68%', 2: '84.60%'}, LR: 0.000100000\n",
      "Epoch 999/2000, Train Loss: 0.000665658, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.138096610, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.83%', 1: '97.44%', 2: '85.92%'}, LR: 0.000100000\n",
      "Epoch 1000/2000, Train Loss: 0.000635201, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.140073163, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.76%', 1: '97.66%', 2: '84.88%'}, LR: 0.000100000\n",
      "Epoch 1001/2000, Train Loss: 0.000632492, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.143172526, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.84%', 1: '97.28%', 2: '84.90%'}, LR: 0.000100000\n",
      "Epoch 1002/2000, Train Loss: 0.000625424, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.142670884, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.77%', 1: '97.52%', 2: '84.78%'}, LR: 0.000100000\n",
      "Epoch 1003/2000, Train Loss: 0.038068469, Train-Class-Acc: {0: '99.14%', 1: '98.78%', 2: '99.44%'}, Val Loss: 0.121969127, Val Accuracy: 96.94%, Val-Class-Acc: {0: '99.26%', 1: '96.64%', 2: '86.68%'}, LR: 0.000100000\n",
      "Epoch 1004/2000, Train Loss: 0.008564190, Train-Class-Acc: {0: '99.74%', 1: '99.64%', 2: '99.88%'}, Val Loss: 0.134938662, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.71%', 1: '97.17%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 1005/2000, Train Loss: 0.001558259, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.98%'}, Val Loss: 0.134570875, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.79%', 1: '97.29%', 2: '84.62%'}, LR: 0.000100000\n",
      "Epoch 1006/2000, Train Loss: 0.000992919, Train-Class-Acc: {0: '99.99%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.134794868, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.82%', 1: '96.88%', 2: '86.17%'}, LR: 0.000100000\n",
      "Epoch 1007/2000, Train Loss: 0.000937047, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.134910208, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.77%', 1: '97.22%', 2: '85.70%'}, LR: 0.000100000\n",
      "Epoch 1008/2000, Train Loss: 0.000800115, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.135764464, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.80%', 1: '97.17%', 2: '85.95%'}, LR: 0.000100000\n",
      "Epoch 1009/2000, Train Loss: 0.000764767, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.135995739, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.75%', 1: '97.23%', 2: '86.96%'}, LR: 0.000100000\n",
      "Epoch 1010/2000, Train Loss: 0.000721803, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.135961977, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.69%', 1: '97.24%', 2: '87.53%'}, LR: 0.000100000\n",
      "Epoch 1011/2000, Train Loss: 0.000734440, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.136660023, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.72%', 1: '97.38%', 2: '86.95%'}, LR: 0.000100000\n",
      "Epoch 1012/2000, Train Loss: 0.000680833, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.138445846, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.77%', 1: '97.35%', 2: '86.71%'}, LR: 0.000100000\n",
      "Epoch 1013/2000, Train Loss: 0.000662070, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.139342476, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.76%', 1: '97.39%', 2: '86.49%'}, LR: 0.000100000\n",
      "Epoch 1014/2000, Train Loss: 0.000672111, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.140418617, Val Accuracy: 97.47%, Val-Class-Acc: {0: '99.80%', 1: '97.33%', 2: '86.67%'}, LR: 0.000100000\n",
      "Epoch 1015/2000, Train Loss: 0.000632389, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.140930072, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.77%', 1: '97.40%', 2: '86.84%'}, LR: 0.000100000\n",
      "Epoch 1016/2000, Train Loss: 0.000636546, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.138132157, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.73%', 1: '97.43%', 2: '86.93%'}, LR: 0.000100000\n",
      "Epoch 1017/2000, Train Loss: 0.000860058, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.146970783, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.83%', 1: '97.28%', 2: '84.73%'}, LR: 0.000100000\n",
      "Epoch 1018/2000, Train Loss: 0.000757958, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.143191304, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.80%', 1: '97.37%', 2: '86.47%'}, LR: 0.000100000\n",
      "Epoch 1019/2000, Train Loss: 0.000681713, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.141936792, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.70%', 1: '97.59%', 2: '86.55%'}, LR: 0.000100000\n",
      "Epoch 1020/2000, Train Loss: 0.000755995, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.141354833, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.71%', 1: '97.52%', 2: '86.97%'}, LR: 0.000100000\n",
      "Epoch 1021/2000, Train Loss: 0.000800540, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.143895276, Val Accuracy: 97.51%, Val-Class-Acc: {0: '99.80%', 1: '97.38%', 2: '86.84%'}, LR: 0.000100000\n",
      "Epoch 1022/2000, Train Loss: 0.000588668, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.145727711, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.78%', 1: '97.52%', 2: '86.18%'}, LR: 0.000100000\n",
      "Epoch 1023/2000, Train Loss: 0.000609307, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.142902837, Val Accuracy: 97.53%, Val-Class-Acc: {0: '99.72%', 1: '97.60%', 2: '86.72%'}, LR: 0.000100000\n",
      "Epoch 1024/2000, Train Loss: 0.000663242, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.150172265, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.86%', 1: '97.19%', 2: '85.28%'}, LR: 0.000100000\n",
      "Epoch 1025/2000, Train Loss: 0.000688367, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.145615465, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.63%', 1: '97.66%', 2: '86.70%'}, LR: 0.000100000\n",
      "Epoch 1026/2000, Train Loss: 0.095360367, Train-Class-Acc: {0: '98.40%', 1: '97.56%', 2: '96.71%'}, Val Loss: 0.215221062, Val Accuracy: 93.79%, Val-Class-Acc: {0: '99.82%', 1: '93.05%', 2: '67.04%'}, LR: 0.000100000\n",
      "Epoch 1027/2000, Train Loss: 0.028196812, Train-Class-Acc: {0: '99.34%', 1: '98.55%', 2: '98.74%'}, Val Loss: 0.114087279, Val Accuracy: 96.85%, Val-Class-Acc: {0: '99.60%', 1: '97.29%', 2: '82.03%'}, LR: 0.000100000\n",
      "Epoch 1028/2000, Train Loss: 0.005530668, Train-Class-Acc: {0: '99.86%', 1: '99.81%', 2: '99.93%'}, Val Loss: 0.113193991, Val Accuracy: 96.91%, Val-Class-Acc: {0: '99.81%', 1: '96.99%', 2: '82.65%'}, LR: 0.000100000\n",
      "Epoch 1029/2000, Train Loss: 0.002824258, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.116211942, Val Accuracy: 96.83%, Val-Class-Acc: {0: '99.79%', 1: '96.62%', 2: '83.20%'}, LR: 0.000100000\n",
      "Epoch 1030/2000, Train Loss: 0.001890694, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '100.00%'}, Val Loss: 0.108151374, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.70%', 1: '96.95%', 2: '85.29%'}, LR: 0.000100000\n",
      "Epoch 1031/2000, Train Loss: 0.001423883, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.110463673, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.71%', 1: '97.41%', 2: '84.75%'}, LR: 0.000100000\n",
      "Epoch 1032/2000, Train Loss: 0.001100893, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.115113642, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.77%', 1: '97.37%', 2: '84.47%'}, LR: 0.000100000\n",
      "Epoch 1033/2000, Train Loss: 0.000970974, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.115941985, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.77%', 1: '97.58%', 2: '83.98%'}, LR: 0.000100000\n",
      "Epoch 1034/2000, Train Loss: 0.000877294, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.117947854, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.79%', 1: '97.50%', 2: '84.17%'}, LR: 0.000100000\n",
      "Epoch 1035/2000, Train Loss: 0.000894325, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.116257581, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.74%', 1: '97.61%', 2: '84.51%'}, LR: 0.000100000\n",
      "Epoch 1036/2000, Train Loss: 0.000825642, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.116792030, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.73%', 1: '97.59%', 2: '84.68%'}, LR: 0.000100000\n",
      "Epoch 1037/2000, Train Loss: 0.000762265, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.118258586, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.70%', 1: '97.75%', 2: '84.44%'}, LR: 0.000100000\n",
      "Epoch 1038/2000, Train Loss: 0.000750462, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.121475430, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.78%', 1: '97.54%', 2: '84.32%'}, LR: 0.000100000\n",
      "Epoch 1039/2000, Train Loss: 0.000730258, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.120487381, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.73%', 1: '97.62%', 2: '84.66%'}, LR: 0.000100000\n",
      "Epoch 1040/2000, Train Loss: 0.000692193, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.122886063, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.77%', 1: '97.59%', 2: '84.39%'}, LR: 0.000100000\n",
      "Epoch 1041/2000, Train Loss: 0.000666554, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '99.99%'}, Val Loss: 0.122031678, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.74%', 1: '97.61%', 2: '84.71%'}, LR: 0.000100000\n",
      "Epoch 1042/2000, Train Loss: 0.000969066, Train-Class-Acc: {0: '99.97%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.123030280, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.72%', 1: '97.52%', 2: '84.94%'}, LR: 0.000100000\n",
      "Epoch 1043/2000, Train Loss: 0.000680070, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.125837070, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.79%', 1: '97.52%', 2: '84.41%'}, LR: 0.000100000\n",
      "Epoch 1044/2000, Train Loss: 0.000665937, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.131718531, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.85%', 1: '97.34%', 2: '83.89%'}, LR: 0.000100000\n",
      "Epoch 1045/2000, Train Loss: 0.000683815, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.127333076, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.74%', 1: '97.63%', 2: '84.34%'}, LR: 0.000100000\n",
      "Epoch 1046/2000, Train Loss: 0.000724253, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.130760305, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.81%', 1: '97.59%', 2: '83.95%'}, LR: 0.000100000\n",
      "Epoch 1047/2000, Train Loss: 0.000828597, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.151080028, Val Accuracy: 96.96%, Val-Class-Acc: {0: '99.88%', 1: '96.94%', 2: '82.92%'}, LR: 0.000100000\n",
      "Epoch 1048/2000, Train Loss: 0.008397317, Train-Class-Acc: {0: '99.75%', 1: '99.67%', 2: '99.95%'}, Val Loss: 0.128843370, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.02%', 1: '97.86%', 2: '86.23%'}, LR: 0.000100000\n",
      "Epoch 1049/2000, Train Loss: 0.003630858, Train-Class-Acc: {0: '99.86%', 1: '99.83%', 2: '99.98%'}, Val Loss: 0.123138246, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.60%', 1: '97.71%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 1050/2000, Train Loss: 0.001533474, Train-Class-Acc: {0: '99.95%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.120556294, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.65%', 1: '97.54%', 2: '86.90%'}, LR: 0.000100000\n",
      "Epoch 1051/2000, Train Loss: 0.000782168, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.121416500, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.66%', 1: '97.57%', 2: '86.68%'}, LR: 0.000100000\n",
      "Epoch 1052/2000, Train Loss: 0.000680434, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.127475339, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.76%', 1: '97.61%', 2: '84.94%'}, LR: 0.000100000\n",
      "Epoch 1053/2000, Train Loss: 0.000652404, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.127694092, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.81%', 1: '97.46%', 2: '85.21%'}, LR: 0.000100000\n",
      "Epoch 1054/2000, Train Loss: 0.000630066, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.128080827, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.76%', 1: '97.62%', 2: '85.28%'}, LR: 0.000100000\n",
      "Epoch 1055/2000, Train Loss: 0.000621418, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.129171044, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.79%', 1: '97.50%', 2: '85.67%'}, LR: 0.000100000\n",
      "Epoch 1056/2000, Train Loss: 0.000623611, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.129111793, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.73%', 1: '97.56%', 2: '86.11%'}, LR: 0.000100000\n",
      "Epoch 1057/2000, Train Loss: 0.000616568, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.129879755, Val Accuracy: 97.43%, Val-Class-Acc: {0: '99.74%', 1: '97.56%', 2: '85.78%'}, LR: 0.000100000\n",
      "Epoch 1058/2000, Train Loss: 0.000640319, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.133156598, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.78%', 1: '97.51%', 2: '84.95%'}, LR: 0.000100000\n",
      "Epoch 1059/2000, Train Loss: 0.000890074, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.128851314, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.66%', 1: '97.58%', 2: '86.74%'}, LR: 0.000100000\n",
      "Epoch 1060/2000, Train Loss: 0.000629945, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.130731190, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.67%', 1: '97.56%', 2: '86.84%'}, LR: 0.000100000\n",
      "Epoch 1061/2000, Train Loss: 0.000627300, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.130594463, Val Accuracy: 97.50%, Val-Class-Acc: {0: '99.70%', 1: '97.59%', 2: '86.53%'}, LR: 0.000100000\n",
      "Epoch 1062/2000, Train Loss: 0.000649532, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.139198819, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.84%', 1: '97.29%', 2: '84.55%'}, LR: 0.000100000\n",
      "Epoch 1063/2000, Train Loss: 0.000616630, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.139496003, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.79%', 1: '97.57%', 2: '84.37%'}, LR: 0.000100000\n",
      "Epoch 1064/2000, Train Loss: 0.000568596, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.139541886, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.82%', 1: '97.42%', 2: '84.67%'}, LR: 0.000100000\n",
      "Epoch 1065/2000, Train Loss: 0.000566539, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.138275791, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.80%', 1: '97.50%', 2: '84.84%'}, LR: 0.000100000\n",
      "Epoch 1066/2000, Train Loss: 0.001429049, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.145101395, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.84%', 1: '97.12%', 2: '84.44%'}, LR: 0.000100000\n",
      "Epoch 1067/2000, Train Loss: 0.014686149, Train-Class-Acc: {0: '99.62%', 1: '99.58%', 2: '99.91%'}, Val Loss: 0.153750180, Val Accuracy: 96.74%, Val-Class-Acc: {0: '98.54%', 1: '97.81%', 2: '84.44%'}, LR: 0.000100000\n",
      "Epoch 1068/2000, Train Loss: 0.006779722, Train-Class-Acc: {0: '99.77%', 1: '99.67%', 2: '99.93%'}, Val Loss: 0.116078958, Val Accuracy: 97.60%, Val-Class-Acc: {0: '99.67%', 1: '97.21%', 2: '88.90%'}, LR: 0.000100000\n",
      "Epoch 1069/2000, Train Loss: 0.001064566, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.121810084, Val Accuracy: 97.41%, Val-Class-Acc: {0: '99.76%', 1: '97.32%', 2: '86.32%'}, LR: 0.000100000\n",
      "Epoch 1070/2000, Train Loss: 0.000778794, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.124113047, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.76%', 1: '97.39%', 2: '86.44%'}, LR: 0.000100000\n",
      "Epoch 1071/2000, Train Loss: 0.000662670, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.128917249, Val Accuracy: 97.39%, Val-Class-Acc: {0: '99.78%', 1: '97.38%', 2: '85.88%'}, LR: 0.000100000\n",
      "Epoch 1072/2000, Train Loss: 0.000657846, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.130018957, Val Accuracy: 97.41%, Val-Class-Acc: {0: '99.74%', 1: '97.44%', 2: '85.99%'}, LR: 0.000100000\n",
      "Epoch 1073/2000, Train Loss: 0.000616693, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.131791691, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.77%', 1: '97.48%', 2: '85.71%'}, LR: 0.000100000\n",
      "Epoch 1074/2000, Train Loss: 0.000608379, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.136481445, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.80%', 1: '97.45%', 2: '84.79%'}, LR: 0.000100000\n",
      "Epoch 1075/2000, Train Loss: 0.000588352, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.134228919, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.76%', 1: '97.49%', 2: '85.45%'}, LR: 0.000100000\n",
      "Epoch 1076/2000, Train Loss: 0.000594318, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.136883321, Val Accuracy: 97.36%, Val-Class-Acc: {0: '99.79%', 1: '97.43%', 2: '85.37%'}, LR: 0.000100000\n",
      "Epoch 1077/2000, Train Loss: 0.000563871, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.140916358, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.82%', 1: '97.55%', 2: '84.46%'}, LR: 0.000100000\n",
      "Epoch 1078/2000, Train Loss: 0.000763085, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.139395292, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.84%', 1: '97.22%', 2: '86.00%'}, LR: 0.000100000\n",
      "Epoch 1079/2000, Train Loss: 0.000996428, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '100.00%'}, Val Loss: 0.139764028, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.84%', 1: '97.38%', 2: '85.70%'}, LR: 0.000100000\n",
      "Epoch 1080/2000, Train Loss: 0.000561127, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.134893325, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.75%', 1: '97.43%', 2: '86.73%'}, LR: 0.000100000\n",
      "Epoch 1081/2000, Train Loss: 0.000589485, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.144423663, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.82%', 1: '97.45%', 2: '84.31%'}, LR: 0.000100000\n",
      "Epoch 1082/2000, Train Loss: 0.012958189, Train-Class-Acc: {0: '99.66%', 1: '99.68%', 2: '99.93%'}, Val Loss: 0.323807985, Val Accuracy: 95.11%, Val-Class-Acc: {0: '99.96%', 1: '94.23%', 2: '74.61%'}, LR: 0.000100000\n",
      "Epoch 1083/2000, Train Loss: 0.015590709, Train-Class-Acc: {0: '99.58%', 1: '99.28%', 2: '99.61%'}, Val Loss: 0.116913616, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.67%', 1: '97.49%', 2: '85.88%'}, LR: 0.000100000\n",
      "Epoch 1084/2000, Train Loss: 0.001542675, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.97%'}, Val Loss: 0.113818138, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.79%', 1: '97.65%', 2: '85.82%'}, LR: 0.000100000\n",
      "Epoch 1085/2000, Train Loss: 0.000846857, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.121947277, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.72%', 1: '97.85%', 2: '85.36%'}, LR: 0.000100000\n",
      "Epoch 1086/2000, Train Loss: 0.000726072, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.121990008, Val Accuracy: 97.47%, Val-Class-Acc: {0: '99.80%', 1: '97.53%', 2: '85.95%'}, LR: 0.000100000\n",
      "Epoch 1087/2000, Train Loss: 0.000786639, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.142734952, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.88%', 1: '96.94%', 2: '84.65%'}, LR: 0.000100000\n",
      "Epoch 1088/2000, Train Loss: 0.002800554, Train-Class-Acc: {0: '99.90%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.127825213, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.83%', 1: '97.46%', 2: '85.61%'}, LR: 0.000100000\n",
      "Epoch 1089/2000, Train Loss: 0.000723434, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.129361682, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.79%', 1: '97.64%', 2: '85.56%'}, LR: 0.000100000\n",
      "Epoch 1090/2000, Train Loss: 0.000644830, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.128805006, Val Accuracy: 97.47%, Val-Class-Acc: {0: '99.78%', 1: '97.62%', 2: '85.77%'}, LR: 0.000100000\n",
      "Epoch 1091/2000, Train Loss: 0.000625346, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.132877238, Val Accuracy: 97.43%, Val-Class-Acc: {0: '99.79%', 1: '97.58%', 2: '85.48%'}, LR: 0.000100000\n",
      "Epoch 1092/2000, Train Loss: 0.000585893, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.133801036, Val Accuracy: 97.41%, Val-Class-Acc: {0: '99.78%', 1: '97.54%', 2: '85.54%'}, LR: 0.000100000\n",
      "Epoch 1093/2000, Train Loss: 0.000583502, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.137770632, Val Accuracy: 97.36%, Val-Class-Acc: {0: '99.78%', 1: '97.65%', 2: '84.66%'}, LR: 0.000100000\n",
      "Epoch 1094/2000, Train Loss: 0.000614401, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.136992082, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.81%', 1: '97.52%', 2: '85.23%'}, LR: 0.000100000\n",
      "Epoch 1095/2000, Train Loss: 0.000568760, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.133233784, Val Accuracy: 97.47%, Val-Class-Acc: {0: '99.78%', 1: '97.50%', 2: '86.21%'}, LR: 0.000100000\n",
      "Epoch 1096/2000, Train Loss: 0.000562630, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.134995656, Val Accuracy: 97.48%, Val-Class-Acc: {0: '99.77%', 1: '97.60%', 2: '85.98%'}, LR: 0.000100000\n",
      "Epoch 1097/2000, Train Loss: 0.000548818, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.135164832, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.81%', 1: '97.48%', 2: '86.04%'}, LR: 0.000100000\n",
      "Epoch 1098/2000, Train Loss: 0.000546991, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.133052853, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.72%', 1: '97.53%', 2: '87.07%'}, LR: 0.000100000\n",
      "Epoch 1099/2000, Train Loss: 0.000574746, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.146118169, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.81%', 1: '97.49%', 2: '84.26%'}, LR: 0.000100000\n",
      "Epoch 1100/2000, Train Loss: 0.000536206, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.136743487, Val Accuracy: 97.49%, Val-Class-Acc: {0: '99.80%', 1: '97.42%', 2: '86.55%'}, LR: 0.000100000\n",
      "Epoch 1101/2000, Train Loss: 0.000673936, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.139293875, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.82%', 1: '97.37%', 2: '86.00%'}, LR: 0.000100000\n",
      "Epoch 1102/2000, Train Loss: 0.000554154, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.135980037, Val Accuracy: 97.55%, Val-Class-Acc: {0: '99.66%', 1: '97.63%', 2: '87.11%'}, LR: 0.000100000\n",
      "Epoch 1103/2000, Train Loss: 0.000556484, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.140859027, Val Accuracy: 97.46%, Val-Class-Acc: {0: '99.77%', 1: '97.69%', 2: '85.45%'}, LR: 0.000100000\n",
      "Epoch 1104/2000, Train Loss: 0.000739797, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.139530280, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.64%', 1: '97.66%', 2: '86.98%'}, LR: 0.000100000\n",
      "Epoch 1105/2000, Train Loss: 0.000889675, Train-Class-Acc: {0: '99.97%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.143447007, Val Accuracy: 97.47%, Val-Class-Acc: {0: '99.77%', 1: '97.66%', 2: '85.71%'}, LR: 0.000100000\n",
      "Epoch 1106/2000, Train Loss: 0.000562654, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.145670310, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.81%', 1: '97.55%', 2: '85.26%'}, LR: 0.000100000\n",
      "Epoch 1107/2000, Train Loss: 0.057272288, Train-Class-Acc: {0: '98.89%', 1: '98.31%', 2: '98.20%'}, Val Loss: 0.141690943, Val Accuracy: 96.26%, Val-Class-Acc: {0: '99.68%', 1: '95.79%', 2: '81.29%'}, LR: 0.000100000\n",
      "Epoch 1108/2000, Train Loss: 0.009227436, Train-Class-Acc: {0: '99.76%', 1: '99.61%', 2: '99.83%'}, Val Loss: 0.149062145, Val Accuracy: 96.39%, Val-Class-Acc: {0: '99.54%', 1: '96.75%', 2: '79.97%'}, LR: 0.000100000\n",
      "Epoch 1109/2000, Train Loss: 0.002171774, Train-Class-Acc: {0: '99.95%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.140738758, Val Accuracy: 96.95%, Val-Class-Acc: {0: '99.72%', 1: '97.50%', 2: '81.78%'}, LR: 0.000100000\n",
      "Epoch 1110/2000, Train Loss: 0.001237580, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '100.00%'}, Val Loss: 0.141168526, Val Accuracy: 96.97%, Val-Class-Acc: {0: '99.69%', 1: '97.33%', 2: '82.58%'}, LR: 0.000100000\n",
      "Epoch 1111/2000, Train Loss: 0.000909627, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.144394577, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.77%', 1: '97.39%', 2: '82.38%'}, LR: 0.000100000\n",
      "Epoch 1112/2000, Train Loss: 0.000793855, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.147552839, Val Accuracy: 96.97%, Val-Class-Acc: {0: '99.82%', 1: '97.16%', 2: '82.60%'}, LR: 0.000100000\n",
      "Epoch 1113/2000, Train Loss: 0.000775688, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.147044116, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.72%', 1: '97.63%', 2: '82.52%'}, LR: 0.000100000\n",
      "Epoch 1114/2000, Train Loss: 0.000658476, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '99.99%'}, Val Loss: 0.149879066, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.81%', 1: '97.44%', 2: '82.46%'}, LR: 0.000100000\n",
      "Epoch 1115/2000, Train Loss: 0.000651085, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.149309978, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.82%', 1: '97.34%', 2: '82.85%'}, LR: 0.000100000\n",
      "Epoch 1116/2000, Train Loss: 0.000609515, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.148418623, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.73%', 1: '97.40%', 2: '83.18%'}, LR: 0.000100000\n",
      "Epoch 1117/2000, Train Loss: 0.000588286, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151105369, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.79%', 1: '97.35%', 2: '83.09%'}, LR: 0.000100000\n",
      "Epoch 1118/2000, Train Loss: 0.000570677, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.148810304, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.74%', 1: '97.37%', 2: '83.43%'}, LR: 0.000100000\n",
      "Epoch 1119/2000, Train Loss: 0.000583146, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '99.99%'}, Val Loss: 0.150335917, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.78%', 1: '97.34%', 2: '83.38%'}, LR: 0.000100000\n",
      "Epoch 1120/2000, Train Loss: 0.000559430, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152396213, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.79%', 1: '97.38%', 2: '83.20%'}, LR: 0.000100000\n",
      "Epoch 1121/2000, Train Loss: 0.000548230, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153333579, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.79%', 1: '97.43%', 2: '83.15%'}, LR: 0.000100000\n",
      "Epoch 1122/2000, Train Loss: 0.000588932, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.150073806, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.72%', 1: '97.45%', 2: '83.54%'}, LR: 0.000100000\n",
      "Epoch 1123/2000, Train Loss: 0.000548861, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153720383, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.79%', 1: '97.28%', 2: '83.50%'}, LR: 0.000100000\n",
      "Epoch 1124/2000, Train Loss: 0.000610467, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.160737632, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.84%', 1: '97.05%', 2: '83.17%'}, LR: 0.000100000\n",
      "Epoch 1125/2000, Train Loss: 0.009880323, Train-Class-Acc: {0: '99.72%', 1: '99.69%', 2: '99.95%'}, Val Loss: 0.146487686, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.79%', 1: '96.72%', 2: '85.01%'}, LR: 0.000100000\n",
      "Epoch 1126/2000, Train Loss: 0.001823778, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.143726470, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.72%', 1: '97.22%', 2: '84.73%'}, LR: 0.000100000\n",
      "Epoch 1127/2000, Train Loss: 0.000657739, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.149564587, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.73%', 1: '97.48%', 2: '83.48%'}, LR: 0.000100000\n",
      "Epoch 1128/2000, Train Loss: 0.000594050, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152436550, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.75%', 1: '97.43%', 2: '83.49%'}, LR: 0.000100000\n",
      "Epoch 1129/2000, Train Loss: 0.000569094, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155711296, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.81%', 1: '97.46%', 2: '83.08%'}, LR: 0.000100000\n",
      "Epoch 1130/2000, Train Loss: 0.000544253, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152439189, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.72%', 1: '97.55%', 2: '83.75%'}, LR: 0.000100000\n",
      "Epoch 1131/2000, Train Loss: 0.000554056, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154765281, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.79%', 1: '97.47%', 2: '83.34%'}, LR: 0.000100000\n",
      "Epoch 1132/2000, Train Loss: 0.000521433, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155282609, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.78%', 1: '97.35%', 2: '83.89%'}, LR: 0.000100000\n",
      "Epoch 1133/2000, Train Loss: 0.000601377, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.154274119, Val Accuracy: 97.18%, Val-Class-Acc: {0: '99.69%', 1: '97.59%', 2: '83.65%'}, LR: 0.000100000\n",
      "Epoch 1134/2000, Train Loss: 0.000862062, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.152861244, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.39%', 1: '97.67%', 2: '84.44%'}, LR: 0.000100000\n",
      "Epoch 1135/2000, Train Loss: 0.005164403, Train-Class-Acc: {0: '99.85%', 1: '99.83%', 2: '99.98%'}, Val Loss: 0.146041161, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.74%', 1: '97.24%', 2: '84.37%'}, LR: 0.000100000\n",
      "Epoch 1136/2000, Train Loss: 0.000739334, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.145947563, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.56%', 1: '97.50%', 2: '85.24%'}, LR: 0.000100000\n",
      "Epoch 1137/2000, Train Loss: 0.001340725, Train-Class-Acc: {0: '99.95%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.168210864, Val Accuracy: 96.95%, Val-Class-Acc: {0: '99.88%', 1: '96.72%', 2: '83.50%'}, LR: 0.000100000\n",
      "Epoch 1138/2000, Train Loss: 0.001367550, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.151859835, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.70%', 1: '97.51%', 2: '84.53%'}, LR: 0.000100000\n",
      "Epoch 1139/2000, Train Loss: 0.000572550, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156002230, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.79%', 1: '97.46%', 2: '83.82%'}, LR: 0.000100000\n",
      "Epoch 1140/2000, Train Loss: 0.000527610, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154173918, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.75%', 1: '97.57%', 2: '84.19%'}, LR: 0.000100000\n",
      "Epoch 1141/2000, Train Loss: 0.000519682, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155389507, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.78%', 1: '97.46%', 2: '84.25%'}, LR: 0.000100000\n",
      "Epoch 1142/2000, Train Loss: 0.000508624, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158374777, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.81%', 1: '97.39%', 2: '83.98%'}, LR: 0.000100000\n",
      "Epoch 1143/2000, Train Loss: 0.000506452, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158744827, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.81%', 1: '97.41%', 2: '83.93%'}, LR: 0.000100000\n",
      "Epoch 1144/2000, Train Loss: 0.000689663, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.156413493, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.19%', 1: '97.81%', 2: '85.96%'}, LR: 0.000100000\n",
      "Epoch 1145/2000, Train Loss: 0.044216948, Train-Class-Acc: {0: '98.81%', 1: '98.25%', 2: '99.12%'}, Val Loss: 0.151117141, Val Accuracy: 96.77%, Val-Class-Acc: {0: '99.60%', 1: '97.61%', 2: '80.30%'}, LR: 0.000100000\n",
      "Epoch 1146/2000, Train Loss: 0.003978266, Train-Class-Acc: {0: '99.91%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.140273744, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.74%', 1: '97.98%', 2: '82.32%'}, LR: 0.000100000\n",
      "Epoch 1147/2000, Train Loss: 0.001123518, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.141227326, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.80%', 1: '97.53%', 2: '83.27%'}, LR: 0.000100000\n",
      "Epoch 1148/2000, Train Loss: 0.000769076, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.142766521, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.78%', 1: '97.69%', 2: '83.18%'}, LR: 0.000100000\n",
      "Epoch 1149/2000, Train Loss: 0.000678534, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.147133498, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.79%', 1: '97.75%', 2: '82.92%'}, LR: 0.000100000\n",
      "Epoch 1150/2000, Train Loss: 0.000634463, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.145080220, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.78%', 1: '97.67%', 2: '83.53%'}, LR: 0.000100000\n",
      "Epoch 1151/2000, Train Loss: 0.000614669, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.149597882, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.79%', 1: '97.71%', 2: '83.20%'}, LR: 0.000100000\n",
      "Epoch 1152/2000, Train Loss: 0.000587809, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.148010532, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.79%', 1: '97.63%', 2: '83.62%'}, LR: 0.000100000\n",
      "Epoch 1153/2000, Train Loss: 0.000577893, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.149183464, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.77%', 1: '97.76%', 2: '83.50%'}, LR: 0.000100000\n",
      "Epoch 1154/2000, Train Loss: 0.000551188, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.148641456, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.78%', 1: '97.66%', 2: '83.85%'}, LR: 0.000100000\n",
      "Epoch 1155/2000, Train Loss: 0.000540564, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151357695, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.78%', 1: '97.64%', 2: '83.60%'}, LR: 0.000100000\n",
      "Epoch 1156/2000, Train Loss: 0.000537918, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152542398, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.80%', 1: '97.57%', 2: '83.67%'}, LR: 0.000100000\n",
      "Epoch 1157/2000, Train Loss: 0.000533099, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152727546, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.78%', 1: '97.67%', 2: '83.75%'}, LR: 0.000100000\n",
      "Epoch 1158/2000, Train Loss: 0.000514094, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153556139, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.79%', 1: '97.62%', 2: '83.73%'}, LR: 0.000100000\n",
      "Epoch 1159/2000, Train Loss: 0.000508699, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153888531, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.79%', 1: '97.68%', 2: '83.72%'}, LR: 0.000100000\n",
      "Epoch 1160/2000, Train Loss: 0.000516564, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154353325, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.82%', 1: '97.56%', 2: '83.89%'}, LR: 0.000100000\n",
      "Epoch 1161/2000, Train Loss: 0.000509566, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151464064, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.80%', 1: '97.59%', 2: '84.38%'}, LR: 0.000100000\n",
      "Epoch 1162/2000, Train Loss: 0.000514237, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156718577, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.80%', 1: '97.71%', 2: '83.56%'}, LR: 0.000100000\n",
      "Epoch 1163/2000, Train Loss: 0.000496169, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159025349, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.83%', 1: '97.44%', 2: '83.82%'}, LR: 0.000100000\n",
      "Epoch 1164/2000, Train Loss: 0.000492917, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156358921, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.78%', 1: '97.67%', 2: '83.86%'}, LR: 0.000100000\n",
      "Epoch 1165/2000, Train Loss: 0.000537497, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.157740197, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.78%', 1: '97.66%', 2: '83.81%'}, LR: 0.000100000\n",
      "Epoch 1166/2000, Train Loss: 0.000514467, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159285536, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.82%', 1: '97.49%', 2: '83.89%'}, LR: 0.000100000\n",
      "Epoch 1167/2000, Train Loss: 0.048557433, Train-Class-Acc: {0: '99.00%', 1: '98.57%', 2: '98.95%'}, Val Loss: 0.154461936, Val Accuracy: 95.48%, Val-Class-Acc: {0: '99.86%', 1: '93.49%', 2: '80.94%'}, LR: 0.000100000\n",
      "Epoch 1168/2000, Train Loss: 0.012345323, Train-Class-Acc: {0: '99.64%', 1: '99.44%', 2: '99.79%'}, Val Loss: 0.131029766, Val Accuracy: 96.76%, Val-Class-Acc: {0: '99.64%', 1: '96.84%', 2: '82.58%'}, LR: 0.000100000\n",
      "Epoch 1169/2000, Train Loss: 0.002196889, Train-Class-Acc: {0: '99.95%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.126990966, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.79%', 1: '97.21%', 2: '85.50%'}, LR: 0.000100000\n",
      "Epoch 1170/2000, Train Loss: 0.001117951, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.131941737, Val Accuracy: 97.18%, Val-Class-Acc: {0: '99.73%', 1: '97.23%', 2: '84.70%'}, LR: 0.000100000\n",
      "Epoch 1171/2000, Train Loss: 0.000804052, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.135178724, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.75%', 1: '97.30%', 2: '84.47%'}, LR: 0.000100000\n",
      "Epoch 1172/2000, Train Loss: 0.000689131, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.135506897, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.77%', 1: '97.26%', 2: '84.87%'}, LR: 0.000100000\n",
      "Epoch 1173/2000, Train Loss: 0.000632637, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.137381529, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.74%', 1: '97.34%', 2: '84.91%'}, LR: 0.000100000\n",
      "Epoch 1174/2000, Train Loss: 0.000595181, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.142386761, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.81%', 1: '97.21%', 2: '84.59%'}, LR: 0.000100000\n",
      "Epoch 1175/2000, Train Loss: 0.000585019, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.141077949, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.75%', 1: '97.37%', 2: '84.83%'}, LR: 0.000100000\n",
      "Epoch 1176/2000, Train Loss: 0.000562918, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.142012143, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.79%', 1: '97.32%', 2: '84.77%'}, LR: 0.000100000\n",
      "Epoch 1177/2000, Train Loss: 0.000547542, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.142281046, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.75%', 1: '97.42%', 2: '84.84%'}, LR: 0.000100000\n",
      "Epoch 1178/2000, Train Loss: 0.000841113, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.140357773, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.68%', 1: '97.42%', 2: '85.21%'}, LR: 0.000100000\n",
      "Epoch 1179/2000, Train Loss: 0.000545969, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.144109663, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.73%', 1: '97.47%', 2: '84.77%'}, LR: 0.000100000\n",
      "Epoch 1180/2000, Train Loss: 0.000533508, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.144849691, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.74%', 1: '97.40%', 2: '84.90%'}, LR: 0.000100000\n",
      "Epoch 1181/2000, Train Loss: 0.000529441, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.143082428, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.67%', 1: '97.50%', 2: '85.08%'}, LR: 0.000100000\n",
      "Epoch 1182/2000, Train Loss: 0.000525850, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.146665596, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.77%', 1: '97.42%', 2: '84.86%'}, LR: 0.000100000\n",
      "Epoch 1183/2000, Train Loss: 0.000513503, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.148570345, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.81%', 1: '97.34%', 2: '84.84%'}, LR: 0.000100000\n",
      "Epoch 1184/2000, Train Loss: 0.000511884, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.145680855, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.68%', 1: '97.53%', 2: '84.94%'}, LR: 0.000100000\n",
      "Epoch 1185/2000, Train Loss: 0.006167261, Train-Class-Acc: {0: '99.82%', 1: '99.78%', 2: '99.96%'}, Val Loss: 0.143697820, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.30%', 1: '97.58%', 2: '86.83%'}, LR: 0.000100000\n",
      "Epoch 1186/2000, Train Loss: 0.001259445, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.146200994, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.76%', 1: '97.46%', 2: '85.14%'}, LR: 0.000100000\n",
      "Epoch 1187/2000, Train Loss: 0.000574011, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.146950091, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.72%', 1: '97.54%', 2: '85.01%'}, LR: 0.000100000\n",
      "Epoch 1188/2000, Train Loss: 0.000538099, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.146928706, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.73%', 1: '97.57%', 2: '85.03%'}, LR: 0.000100000\n",
      "Epoch 1189/2000, Train Loss: 0.000541136, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153554286, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.84%', 1: '97.25%', 2: '84.66%'}, LR: 0.000100000\n",
      "Epoch 1190/2000, Train Loss: 0.001372101, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.153225971, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.80%', 1: '97.48%', 2: '84.62%'}, LR: 0.000100000\n",
      "Epoch 1191/2000, Train Loss: 0.000586325, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.151720872, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.79%', 1: '97.47%', 2: '84.78%'}, LR: 0.000100000\n",
      "Epoch 1192/2000, Train Loss: 0.000501755, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151562654, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.80%', 1: '97.44%', 2: '84.91%'}, LR: 0.000100000\n",
      "Epoch 1193/2000, Train Loss: 0.001088656, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.164396219, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.87%', 1: '96.81%', 2: '84.53%'}, LR: 0.000100000\n",
      "Epoch 1194/2000, Train Loss: 0.007202879, Train-Class-Acc: {0: '99.76%', 1: '99.70%', 2: '99.94%'}, Val Loss: 0.141818354, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.49%', 1: '97.04%', 2: '87.54%'}, LR: 0.000100000\n",
      "Epoch 1195/2000, Train Loss: 0.001379235, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '100.00%'}, Val Loss: 0.133284239, Val Accuracy: 97.54%, Val-Class-Acc: {0: '99.68%', 1: '97.47%', 2: '87.38%'}, LR: 0.000100000\n",
      "Epoch 1196/2000, Train Loss: 0.000604794, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.144154110, Val Accuracy: 97.41%, Val-Class-Acc: {0: '99.79%', 1: '97.56%', 2: '85.44%'}, LR: 0.000100000\n",
      "Epoch 1197/2000, Train Loss: 0.000546186, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.147004897, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.79%', 1: '97.57%', 2: '85.10%'}, LR: 0.000100000\n",
      "Epoch 1198/2000, Train Loss: 0.000507566, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.147798821, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.77%', 1: '97.59%', 2: '85.31%'}, LR: 0.000100000\n",
      "Epoch 1199/2000, Train Loss: 0.000516090, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151711890, Val Accuracy: 97.36%, Val-Class-Acc: {0: '99.78%', 1: '97.54%', 2: '85.03%'}, LR: 0.000100000\n",
      "Epoch 1200/2000, Train Loss: 0.000491004, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153317069, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.79%', 1: '97.50%', 2: '84.88%'}, LR: 0.000100000\n",
      "Epoch 1201/2000, Train Loss: 0.000505031, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154576451, Val Accuracy: 97.35%, Val-Class-Acc: {0: '99.80%', 1: '97.56%', 2: '84.81%'}, LR: 0.000100000\n",
      "Epoch 1202/2000, Train Loss: 0.000481787, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151465107, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.77%', 1: '97.45%', 2: '85.50%'}, LR: 0.000100000\n",
      "Epoch 1203/2000, Train Loss: 0.000596136, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.155212231, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.79%', 1: '97.49%', 2: '85.02%'}, LR: 0.000100000\n",
      "Epoch 1204/2000, Train Loss: 0.000659603, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.154094795, Val Accuracy: 97.35%, Val-Class-Acc: {0: '99.80%', 1: '97.33%', 2: '85.59%'}, LR: 0.000100000\n",
      "Epoch 1205/2000, Train Loss: 0.000458697, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158965619, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.82%', 1: '97.41%', 2: '84.88%'}, LR: 0.000100000\n",
      "Epoch 1206/2000, Train Loss: 0.000465415, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163403185, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.81%', 1: '97.42%', 2: '84.50%'}, LR: 0.000100000\n",
      "Epoch 1207/2000, Train Loss: 0.004369794, Train-Class-Acc: {0: '99.87%', 1: '99.84%', 2: '99.98%'}, Val Loss: 0.155859088, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.41%', 1: '97.77%', 2: '85.89%'}, LR: 0.000100000\n",
      "Epoch 1208/2000, Train Loss: 0.002532593, Train-Class-Acc: {0: '99.91%', 1: '99.88%', 2: '99.99%'}, Val Loss: 0.153709621, Val Accuracy: 97.41%, Val-Class-Acc: {0: '99.75%', 1: '97.32%', 2: '86.35%'}, LR: 0.000100000\n",
      "Epoch 1209/2000, Train Loss: 0.000623571, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.147125615, Val Accuracy: 97.52%, Val-Class-Acc: {0: '99.61%', 1: '97.62%', 2: '87.07%'}, LR: 0.000100000\n",
      "Epoch 1210/2000, Train Loss: 0.000545373, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155013297, Val Accuracy: 97.39%, Val-Class-Acc: {0: '99.70%', 1: '97.62%', 2: '85.40%'}, LR: 0.000100000\n",
      "Epoch 1211/2000, Train Loss: 0.000506535, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155490260, Val Accuracy: 97.39%, Val-Class-Acc: {0: '99.72%', 1: '97.58%', 2: '85.54%'}, LR: 0.000100000\n",
      "Epoch 1212/2000, Train Loss: 0.000480033, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153883443, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.73%', 1: '97.46%', 2: '85.97%'}, LR: 0.000100000\n",
      "Epoch 1213/2000, Train Loss: 0.000452403, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158282634, Val Accuracy: 97.36%, Val-Class-Acc: {0: '99.77%', 1: '97.45%', 2: '85.40%'}, LR: 0.000100000\n",
      "Epoch 1214/2000, Train Loss: 0.000468612, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164708207, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.81%', 1: '97.36%', 2: '84.76%'}, LR: 0.000100000\n",
      "Epoch 1215/2000, Train Loss: 0.001350181, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.202444535, Val Accuracy: 96.79%, Val-Class-Acc: {0: '99.97%', 1: '96.48%', 2: '82.48%'}, LR: 0.000100000\n",
      "Epoch 1216/2000, Train Loss: 0.006653772, Train-Class-Acc: {0: '99.82%', 1: '99.74%', 2: '99.82%'}, Val Loss: 0.134496704, Val Accuracy: 97.43%, Val-Class-Acc: {0: '99.12%', 1: '96.50%', 2: '92.38%'}, LR: 0.000100000\n",
      "Epoch 1217/2000, Train Loss: 0.002356113, Train-Class-Acc: {0: '99.93%', 1: '99.89%', 2: '99.96%'}, Val Loss: 0.143213451, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.59%', 1: '97.65%', 2: '85.31%'}, LR: 0.000100000\n",
      "Epoch 1218/2000, Train Loss: 0.000629778, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.149413634, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.80%', 1: '97.31%', 2: '85.45%'}, LR: 0.000100000\n",
      "Epoch 1219/2000, Train Loss: 0.000528840, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.146715768, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.67%', 1: '97.59%', 2: '85.48%'}, LR: 0.000100000\n",
      "Epoch 1220/2000, Train Loss: 0.000489613, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153252399, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.76%', 1: '97.53%', 2: '85.04%'}, LR: 0.000100000\n",
      "Epoch 1221/2000, Train Loss: 0.000461686, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158442681, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.79%', 1: '97.43%', 2: '84.45%'}, LR: 0.000100000\n",
      "Epoch 1222/2000, Train Loss: 0.000452200, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153908228, Val Accuracy: 97.36%, Val-Class-Acc: {0: '99.78%', 1: '97.46%', 2: '85.34%'}, LR: 0.000100000\n",
      "Epoch 1223/2000, Train Loss: 0.000465283, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154042127, Val Accuracy: 97.36%, Val-Class-Acc: {0: '99.74%', 1: '97.56%', 2: '85.19%'}, LR: 0.000100000\n",
      "Epoch 1224/2000, Train Loss: 0.000439393, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154529393, Val Accuracy: 97.36%, Val-Class-Acc: {0: '99.67%', 1: '97.64%', 2: '85.30%'}, LR: 0.000100000\n",
      "Epoch 1225/2000, Train Loss: 0.038119462, Train-Class-Acc: {0: '99.25%', 1: '98.76%', 2: '98.92%'}, Val Loss: 0.139770575, Val Accuracy: 96.55%, Val-Class-Acc: {0: '99.17%', 1: '96.17%', 2: '85.12%'}, LR: 0.000100000\n",
      "Epoch 1226/2000, Train Loss: 0.006362513, Train-Class-Acc: {0: '99.83%', 1: '99.73%', 2: '99.91%'}, Val Loss: 0.133291230, Val Accuracy: 96.92%, Val-Class-Acc: {0: '99.68%', 1: '96.81%', 2: '84.00%'}, LR: 0.000100000\n",
      "Epoch 1227/2000, Train Loss: 0.001504316, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.140226630, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.77%', 1: '97.23%', 2: '82.87%'}, LR: 0.000100000\n",
      "Epoch 1228/2000, Train Loss: 0.000838888, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.137215007, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.78%', 1: '97.22%', 2: '83.13%'}, LR: 0.000100000\n",
      "Epoch 1229/2000, Train Loss: 0.000676007, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.140793165, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.79%', 1: '97.39%', 2: '82.87%'}, LR: 0.000100000\n",
      "Epoch 1230/2000, Train Loss: 0.000602224, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.142913836, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.80%', 1: '97.35%', 2: '82.92%'}, LR: 0.000100000\n",
      "Epoch 1231/2000, Train Loss: 0.000564591, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.141417545, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.75%', 1: '97.45%', 2: '83.11%'}, LR: 0.000100000\n",
      "Epoch 1232/2000, Train Loss: 0.000540993, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.140620569, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.75%', 1: '97.39%', 2: '83.30%'}, LR: 0.000100000\n",
      "Epoch 1233/2000, Train Loss: 0.000514479, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.146902756, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.81%', 1: '97.41%', 2: '82.90%'}, LR: 0.000100000\n",
      "Epoch 1234/2000, Train Loss: 0.000493914, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.143909711, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.72%', 1: '97.50%', 2: '83.18%'}, LR: 0.000100000\n",
      "Epoch 1235/2000, Train Loss: 0.000491483, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.147297148, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.79%', 1: '97.41%', 2: '82.96%'}, LR: 0.000100000\n",
      "Epoch 1236/2000, Train Loss: 0.000476448, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.147960443, Val Accuracy: 97.12%, Val-Class-Acc: {0: '99.78%', 1: '97.48%', 2: '83.03%'}, LR: 0.000100000\n",
      "Epoch 1237/2000, Train Loss: 0.000473999, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151012897, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.79%', 1: '97.47%', 2: '82.88%'}, LR: 0.000100000\n",
      "Epoch 1238/2000, Train Loss: 0.000497997, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151043152, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.79%', 1: '97.45%', 2: '83.03%'}, LR: 0.000100000\n",
      "Epoch 1239/2000, Train Loss: 0.000460011, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.147800899, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.73%', 1: '97.49%', 2: '83.59%'}, LR: 0.000100000\n",
      "Epoch 1240/2000, Train Loss: 0.000476633, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152719285, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.79%', 1: '97.39%', 2: '82.95%'}, LR: 0.000100000\n",
      "Epoch 1241/2000, Train Loss: 0.000448318, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.149919454, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.78%', 1: '97.39%', 2: '83.70%'}, LR: 0.000100000\n",
      "Epoch 1242/2000, Train Loss: 0.000475118, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151715430, Val Accuracy: 97.18%, Val-Class-Acc: {0: '99.76%', 1: '97.49%', 2: '83.65%'}, LR: 0.000100000\n",
      "Epoch 1243/2000, Train Loss: 0.000434791, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.157778466, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.79%', 1: '97.47%', 2: '82.78%'}, LR: 0.000100000\n",
      "Epoch 1244/2000, Train Loss: 0.000429892, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.149737159, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.70%', 1: '97.46%', 2: '84.69%'}, LR: 0.000100000\n",
      "Epoch 1245/2000, Train Loss: 0.000442852, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152696961, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.78%', 1: '97.42%', 2: '84.03%'}, LR: 0.000100000\n",
      "Epoch 1246/2000, Train Loss: 0.000575281, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.158719433, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.71%', 1: '97.64%', 2: '83.02%'}, LR: 0.000100000\n",
      "Epoch 1247/2000, Train Loss: 0.016666874, Train-Class-Acc: {0: '99.69%', 1: '99.51%', 2: '99.73%'}, Val Loss: 0.148808340, Val Accuracy: 96.49%, Val-Class-Acc: {0: '99.44%', 1: '94.56%', 2: '88.65%'}, LR: 0.000100000\n",
      "Epoch 1248/2000, Train Loss: 0.005827209, Train-Class-Acc: {0: '99.82%', 1: '99.74%', 2: '99.88%'}, Val Loss: 0.136629372, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.56%', 1: '96.61%', 2: '85.30%'}, LR: 0.000100000\n",
      "Epoch 1249/2000, Train Loss: 0.001008755, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.141812661, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.68%', 1: '96.87%', 2: '85.47%'}, LR: 0.000100000\n",
      "Epoch 1250/2000, Train Loss: 0.000640473, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.146628612, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.78%', 1: '96.97%', 2: '84.18%'}, LR: 0.000100000\n",
      "Epoch 1251/2000, Train Loss: 0.000565868, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.147798981, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.74%', 1: '97.03%', 2: '84.34%'}, LR: 0.000100000\n",
      "Epoch 1252/2000, Train Loss: 0.000517945, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.149835285, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.75%', 1: '97.15%', 2: '84.00%'}, LR: 0.000100000\n",
      "Epoch 1253/2000, Train Loss: 0.000503571, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153359978, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.77%', 1: '97.31%', 2: '83.57%'}, LR: 0.000100000\n",
      "Epoch 1254/2000, Train Loss: 0.000478290, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152025165, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.75%', 1: '97.27%', 2: '84.02%'}, LR: 0.000100000\n",
      "Epoch 1255/2000, Train Loss: 0.000484361, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152552965, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.74%', 1: '97.30%', 2: '84.14%'}, LR: 0.000100000\n",
      "Epoch 1256/2000, Train Loss: 0.000453745, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154670178, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.77%', 1: '97.34%', 2: '83.93%'}, LR: 0.000100000\n",
      "Epoch 1257/2000, Train Loss: 0.000458633, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158795899, Val Accuracy: 97.12%, Val-Class-Acc: {0: '99.81%', 1: '97.32%', 2: '83.46%'}, LR: 0.000100000\n",
      "Epoch 1258/2000, Train Loss: 0.000450288, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153350979, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.75%', 1: '97.29%', 2: '84.68%'}, LR: 0.000100000\n",
      "Epoch 1259/2000, Train Loss: 0.000444593, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158417165, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.79%', 1: '97.31%', 2: '83.80%'}, LR: 0.000100000\n",
      "Epoch 1260/2000, Train Loss: 0.000430173, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156968360, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.79%', 1: '97.24%', 2: '84.21%'}, LR: 0.000100000\n",
      "Epoch 1261/2000, Train Loss: 0.000462987, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160031819, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.79%', 1: '97.32%', 2: '83.73%'}, LR: 0.000100000\n",
      "Epoch 1262/2000, Train Loss: 0.000432238, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156929292, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.74%', 1: '97.41%', 2: '84.60%'}, LR: 0.000100000\n",
      "Epoch 1263/2000, Train Loss: 0.000422334, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158221240, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.78%', 1: '97.35%', 2: '84.43%'}, LR: 0.000100000\n",
      "Epoch 1264/2000, Train Loss: 0.000406196, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163282512, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.79%', 1: '97.31%', 2: '83.67%'}, LR: 0.000100000\n",
      "Epoch 1265/2000, Train Loss: 0.000404410, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159360888, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.77%', 1: '97.41%', 2: '84.62%'}, LR: 0.000100000\n",
      "Epoch 1266/2000, Train Loss: 0.000410213, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159900077, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.76%', 1: '97.40%', 2: '84.48%'}, LR: 0.000100000\n",
      "Epoch 1267/2000, Train Loss: 0.000425634, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158899119, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.77%', 1: '97.31%', 2: '85.08%'}, LR: 0.000100000\n",
      "Epoch 1268/2000, Train Loss: 0.000414949, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163663456, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.80%', 1: '97.29%', 2: '84.10%'}, LR: 0.000100000\n",
      "Epoch 1269/2000, Train Loss: 0.000401148, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163240847, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.79%', 1: '97.38%', 2: '84.23%'}, LR: 0.000100000\n",
      "Epoch 1270/2000, Train Loss: 0.000496894, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.168564933, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.84%', 1: '96.97%', 2: '84.01%'}, LR: 0.000100000\n",
      "Epoch 1271/2000, Train Loss: 0.118089107, Train-Class-Acc: {0: '98.00%', 1: '97.16%', 2: '96.69%'}, Val Loss: 0.127056951, Val Accuracy: 96.20%, Val-Class-Acc: {0: '99.03%', 1: '95.86%', 2: '83.65%'}, LR: 0.000100000\n",
      "Epoch 1272/2000, Train Loss: 0.010997305, Train-Class-Acc: {0: '99.69%', 1: '99.63%', 2: '99.78%'}, Val Loss: 0.129983843, Val Accuracy: 96.54%, Val-Class-Acc: {0: '99.68%', 1: '96.41%', 2: '81.82%'}, LR: 0.000100000\n",
      "Epoch 1273/2000, Train Loss: 0.003359597, Train-Class-Acc: {0: '99.92%', 1: '99.91%', 2: '99.97%'}, Val Loss: 0.141216377, Val Accuracy: 96.57%, Val-Class-Acc: {0: '99.75%', 1: '96.96%', 2: '79.90%'}, LR: 0.000100000\n",
      "Epoch 1274/2000, Train Loss: 0.001847090, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.140638541, Val Accuracy: 96.67%, Val-Class-Acc: {0: '99.81%', 1: '97.05%', 2: '80.19%'}, LR: 0.000100000\n",
      "Epoch 1275/2000, Train Loss: 0.001328778, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.140133900, Val Accuracy: 96.83%, Val-Class-Acc: {0: '99.82%', 1: '97.01%', 2: '81.77%'}, LR: 0.000100000\n",
      "Epoch 1276/2000, Train Loss: 0.001086719, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.137111628, Val Accuracy: 96.90%, Val-Class-Acc: {0: '99.74%', 1: '97.07%', 2: '82.63%'}, LR: 0.000100000\n",
      "Epoch 1277/2000, Train Loss: 0.000885033, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.139569462, Val Accuracy: 96.91%, Val-Class-Acc: {0: '99.72%', 1: '97.09%', 2: '82.71%'}, LR: 0.000100000\n",
      "Epoch 1278/2000, Train Loss: 0.000771598, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.140386636, Val Accuracy: 96.95%, Val-Class-Acc: {0: '99.71%', 1: '97.16%', 2: '82.92%'}, LR: 0.000100000\n",
      "Epoch 1279/2000, Train Loss: 0.000707929, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.143858907, Val Accuracy: 96.95%, Val-Class-Acc: {0: '99.71%', 1: '97.23%', 2: '82.68%'}, LR: 0.000100000\n",
      "Epoch 1280/2000, Train Loss: 0.000643377, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.144470031, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.73%', 1: '97.19%', 2: '83.00%'}, LR: 0.000100000\n",
      "Epoch 1281/2000, Train Loss: 0.000602945, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.143801620, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.70%', 1: '97.24%', 2: '83.25%'}, LR: 0.000100000\n",
      "Epoch 1282/2000, Train Loss: 0.000609842, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.150269904, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.79%', 1: '97.41%', 2: '82.43%'}, LR: 0.000100000\n",
      "Epoch 1283/2000, Train Loss: 0.000555319, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.148796796, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.76%', 1: '97.36%', 2: '82.66%'}, LR: 0.000100000\n",
      "Epoch 1284/2000, Train Loss: 0.000529611, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.148752442, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.74%', 1: '97.44%', 2: '82.84%'}, LR: 0.000100000\n",
      "Epoch 1285/2000, Train Loss: 0.000509816, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.146447072, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.69%', 1: '97.44%', 2: '83.31%'}, LR: 0.000100000\n",
      "Epoch 1286/2000, Train Loss: 0.000507252, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.149526532, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.76%', 1: '97.25%', 2: '83.16%'}, LR: 0.000100000\n",
      "Epoch 1287/2000, Train Loss: 0.000489709, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151658136, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.76%', 1: '97.38%', 2: '82.94%'}, LR: 0.000100000\n",
      "Epoch 1288/2000, Train Loss: 0.000472646, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151829828, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.75%', 1: '97.33%', 2: '83.03%'}, LR: 0.000100000\n",
      "Epoch 1289/2000, Train Loss: 0.000470849, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.150750266, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.74%', 1: '97.30%', 2: '83.52%'}, LR: 0.000100000\n",
      "Epoch 1290/2000, Train Loss: 0.000578614, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.156203786, Val Accuracy: 96.99%, Val-Class-Acc: {0: '99.83%', 1: '97.03%', 2: '83.13%'}, LR: 0.000100000\n",
      "Epoch 1291/2000, Train Loss: 0.000707311, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.147910762, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.30%', 1: '97.54%', 2: '84.73%'}, LR: 0.000100000\n",
      "Epoch 1292/2000, Train Loss: 0.002177692, Train-Class-Acc: {0: '99.93%', 1: '99.90%', 2: '99.99%'}, Val Loss: 0.147681186, Val Accuracy: 97.18%, Val-Class-Acc: {0: '99.58%', 1: '97.45%', 2: '84.65%'}, LR: 0.000100000\n",
      "Epoch 1293/2000, Train Loss: 0.000923960, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '100.00%'}, Val Loss: 0.154220779, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.79%', 1: '97.29%', 2: '83.82%'}, LR: 0.000100000\n",
      "Epoch 1294/2000, Train Loss: 0.000467699, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152142122, Val Accuracy: 97.18%, Val-Class-Acc: {0: '99.72%', 1: '97.42%', 2: '84.11%'}, LR: 0.000100000\n",
      "Epoch 1295/2000, Train Loss: 0.000449753, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156139984, Val Accuracy: 97.12%, Val-Class-Acc: {0: '99.80%', 1: '97.23%', 2: '83.78%'}, LR: 0.000100000\n",
      "Epoch 1296/2000, Train Loss: 0.000442011, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155567490, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.79%', 1: '97.26%', 2: '83.90%'}, LR: 0.000100000\n",
      "Epoch 1297/2000, Train Loss: 0.000426926, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155017074, Val Accuracy: 97.18%, Val-Class-Acc: {0: '99.73%', 1: '97.47%', 2: '83.91%'}, LR: 0.000100000\n",
      "Epoch 1298/2000, Train Loss: 0.000419103, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156040338, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.77%', 1: '97.45%', 2: '83.85%'}, LR: 0.000100000\n",
      "Epoch 1299/2000, Train Loss: 0.000426800, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154617434, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.74%', 1: '97.39%', 2: '84.29%'}, LR: 0.000100000\n",
      "Epoch 1300/2000, Train Loss: 0.000433760, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155869702, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.74%', 1: '97.43%', 2: '84.03%'}, LR: 0.000100000\n",
      "Epoch 1301/2000, Train Loss: 0.000412987, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156243745, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.77%', 1: '97.40%', 2: '84.05%'}, LR: 0.000100000\n",
      "Epoch 1302/2000, Train Loss: 0.000410143, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156359277, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.76%', 1: '97.40%', 2: '84.18%'}, LR: 0.000100000\n",
      "Epoch 1303/2000, Train Loss: 0.000406321, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161189364, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.82%', 1: '97.26%', 2: '83.74%'}, LR: 0.000100000\n",
      "Epoch 1304/2000, Train Loss: 0.000404311, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160343190, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.79%', 1: '97.45%', 2: '83.71%'}, LR: 0.000100000\n",
      "Epoch 1305/2000, Train Loss: 0.016475145, Train-Class-Acc: {0: '99.62%', 1: '99.54%', 2: '99.84%'}, Val Loss: 0.136274981, Val Accuracy: 96.84%, Val-Class-Acc: {0: '98.37%', 1: '96.86%', 2: '89.38%'}, LR: 0.000100000\n",
      "Epoch 1306/2000, Train Loss: 0.005684136, Train-Class-Acc: {0: '99.81%', 1: '99.74%', 2: '99.94%'}, Val Loss: 0.140762740, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.39%', 1: '97.45%', 2: '84.49%'}, LR: 0.000100000\n",
      "Epoch 1307/2000, Train Loss: 0.001047294, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.145959204, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.62%', 1: '97.38%', 2: '83.91%'}, LR: 0.000100000\n",
      "Epoch 1308/2000, Train Loss: 0.000669595, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.146367627, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.81%', 1: '97.05%', 2: '84.56%'}, LR: 0.000100000\n",
      "Epoch 1309/2000, Train Loss: 0.000616439, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.145362417, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.74%', 1: '97.19%', 2: '84.56%'}, LR: 0.000100000\n",
      "Epoch 1310/2000, Train Loss: 0.000497454, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.148479062, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.73%', 1: '97.43%', 2: '84.25%'}, LR: 0.000100000\n",
      "Epoch 1311/2000, Train Loss: 0.000594265, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.150241419, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.76%', 1: '97.40%', 2: '84.27%'}, LR: 0.000100000\n",
      "Epoch 1312/2000, Train Loss: 0.000473127, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.149889498, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.71%', 1: '97.51%', 2: '84.35%'}, LR: 0.000100000\n",
      "Epoch 1313/2000, Train Loss: 0.000452848, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152842969, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.78%', 1: '97.40%', 2: '84.22%'}, LR: 0.000100000\n",
      "Epoch 1314/2000, Train Loss: 0.000431005, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153795771, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.77%', 1: '97.42%', 2: '84.28%'}, LR: 0.000100000\n",
      "Epoch 1315/2000, Train Loss: 0.000469100, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153798296, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.73%', 1: '97.52%', 2: '84.35%'}, LR: 0.000100000\n",
      "Epoch 1316/2000, Train Loss: 0.000418881, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153786821, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.71%', 1: '97.51%', 2: '84.34%'}, LR: 0.000100000\n",
      "Epoch 1317/2000, Train Loss: 0.000408130, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153527127, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.76%', 1: '97.36%', 2: '84.63%'}, LR: 0.000100000\n",
      "Epoch 1318/2000, Train Loss: 0.000419134, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156655531, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.71%', 1: '97.57%', 2: '84.21%'}, LR: 0.000100000\n",
      "Epoch 1319/2000, Train Loss: 0.000420275, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153669157, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.66%', 1: '97.56%', 2: '84.66%'}, LR: 0.000100000\n",
      "Epoch 1320/2000, Train Loss: 0.000902679, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.161713766, Val Accuracy: 97.18%, Val-Class-Acc: {0: '99.86%', 1: '97.08%', 2: '84.58%'}, LR: 0.000100000\n",
      "Epoch 1321/2000, Train Loss: 0.002118044, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.155424320, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.47%', 1: '97.53%', 2: '85.36%'}, LR: 0.000100000\n",
      "Epoch 1322/2000, Train Loss: 0.055221344, Train-Class-Acc: {0: '98.62%', 1: '98.07%', 2: '98.74%'}, Val Loss: 0.139714460, Val Accuracy: 96.49%, Val-Class-Acc: {0: '98.31%', 1: '97.90%', 2: '82.99%'}, LR: 0.000100000\n",
      "Epoch 1323/2000, Train Loss: 0.008375286, Train-Class-Acc: {0: '99.75%', 1: '99.67%', 2: '99.90%'}, Val Loss: 0.136494758, Val Accuracy: 96.68%, Val-Class-Acc: {0: '99.44%', 1: '96.79%', 2: '82.91%'}, LR: 0.000100000\n",
      "Epoch 1324/2000, Train Loss: 0.001888699, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.129449388, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.61%', 1: '97.25%', 2: '85.88%'}, LR: 0.000100000\n",
      "Epoch 1325/2000, Train Loss: 0.000978161, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.131826777, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.67%', 1: '97.18%', 2: '85.26%'}, LR: 0.000100000\n",
      "Epoch 1326/2000, Train Loss: 0.000718523, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.133771085, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.68%', 1: '97.29%', 2: '84.93%'}, LR: 0.000100000\n",
      "Epoch 1327/2000, Train Loss: 0.000634029, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.133807325, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.63%', 1: '97.36%', 2: '85.47%'}, LR: 0.000100000\n",
      "Epoch 1328/2000, Train Loss: 0.000580331, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.137562981, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.68%', 1: '97.26%', 2: '85.10%'}, LR: 0.000100000\n",
      "Epoch 1329/2000, Train Loss: 0.000526051, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.138113017, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.69%', 1: '97.22%', 2: '85.20%'}, LR: 0.000100000\n",
      "Epoch 1330/2000, Train Loss: 0.000514767, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.138687845, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.68%', 1: '97.31%', 2: '85.24%'}, LR: 0.000100000\n",
      "Epoch 1331/2000, Train Loss: 0.000516489, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.140462642, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.69%', 1: '97.33%', 2: '85.09%'}, LR: 0.000100000\n",
      "Epoch 1332/2000, Train Loss: 0.000476949, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.141995226, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.71%', 1: '97.31%', 2: '85.02%'}, LR: 0.000100000\n",
      "Epoch 1333/2000, Train Loss: 0.000467817, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.147129113, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.79%', 1: '97.31%', 2: '84.49%'}, LR: 0.000100000\n",
      "Epoch 1334/2000, Train Loss: 0.000456201, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.143147084, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.72%', 1: '97.26%', 2: '85.25%'}, LR: 0.000100000\n",
      "Epoch 1335/2000, Train Loss: 0.000446522, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.144405863, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.73%', 1: '97.29%', 2: '85.11%'}, LR: 0.000100000\n",
      "Epoch 1336/2000, Train Loss: 0.000431523, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.143067633, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.70%', 1: '97.28%', 2: '85.78%'}, LR: 0.000100000\n",
      "Epoch 1337/2000, Train Loss: 0.000431714, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.145717442, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.75%', 1: '97.25%', 2: '85.36%'}, LR: 0.000100000\n",
      "Epoch 1338/2000, Train Loss: 0.000426495, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.147116574, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.74%', 1: '97.34%', 2: '85.01%'}, LR: 0.000100000\n",
      "Epoch 1339/2000, Train Loss: 0.000428537, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.146457957, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.70%', 1: '97.39%', 2: '85.25%'}, LR: 0.000100000\n",
      "Epoch 1340/2000, Train Loss: 0.000451257, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.147982905, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.72%', 1: '97.32%', 2: '85.30%'}, LR: 0.000100000\n",
      "Epoch 1341/2000, Train Loss: 0.000671398, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.146954744, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.73%', 1: '97.27%', 2: '85.79%'}, LR: 0.000100000\n",
      "Epoch 1342/2000, Train Loss: 0.000410683, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.150163829, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.81%', 1: '97.27%', 2: '84.94%'}, LR: 0.000100000\n",
      "Epoch 1343/2000, Train Loss: 0.000581728, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.149974839, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.77%', 1: '97.27%', 2: '85.27%'}, LR: 0.000100000\n",
      "Epoch 1344/2000, Train Loss: 0.000401900, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151655941, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.74%', 1: '97.40%', 2: '84.92%'}, LR: 0.000100000\n",
      "Epoch 1345/2000, Train Loss: 0.000399706, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151454665, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.77%', 1: '97.34%', 2: '85.17%'}, LR: 0.000100000\n",
      "Epoch 1346/2000, Train Loss: 0.000390780, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.150999268, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.73%', 1: '97.38%', 2: '85.38%'}, LR: 0.000100000\n",
      "Epoch 1347/2000, Train Loss: 0.001708349, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.170576687, Val Accuracy: 96.96%, Val-Class-Acc: {0: '98.30%', 1: '97.02%', 2: '90.28%'}, LR: 0.000100000\n",
      "Epoch 1348/2000, Train Loss: 0.014449351, Train-Class-Acc: {0: '99.58%', 1: '99.53%', 2: '99.86%'}, Val Loss: 0.136197136, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.60%', 1: '96.69%', 2: '86.69%'}, LR: 0.000100000\n",
      "Epoch 1349/2000, Train Loss: 0.001108661, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.143122924, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.69%', 1: '97.07%', 2: '86.52%'}, LR: 0.000100000\n",
      "Epoch 1350/2000, Train Loss: 0.000625009, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.147720904, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.73%', 1: '97.18%', 2: '85.26%'}, LR: 0.000100000\n",
      "Epoch 1351/2000, Train Loss: 0.000506767, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.147901567, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.69%', 1: '97.29%', 2: '85.59%'}, LR: 0.000100000\n",
      "Epoch 1352/2000, Train Loss: 0.000460815, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.149062518, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.74%', 1: '97.23%', 2: '85.57%'}, LR: 0.000100000\n",
      "Epoch 1353/2000, Train Loss: 0.000443562, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.150651419, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.71%', 1: '97.28%', 2: '85.51%'}, LR: 0.000100000\n",
      "Epoch 1354/2000, Train Loss: 0.000427337, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151461068, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.71%', 1: '97.34%', 2: '85.44%'}, LR: 0.000100000\n",
      "Epoch 1355/2000, Train Loss: 0.000417518, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151157330, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.72%', 1: '97.28%', 2: '85.69%'}, LR: 0.000100000\n",
      "Epoch 1356/2000, Train Loss: 0.000404281, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153298789, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.70%', 1: '97.43%', 2: '85.25%'}, LR: 0.000100000\n",
      "Epoch 1357/2000, Train Loss: 0.000407716, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.157876698, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.79%', 1: '97.31%', 2: '84.91%'}, LR: 0.000100000\n",
      "Epoch 1358/2000, Train Loss: 0.000402366, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151461395, Val Accuracy: 97.45%, Val-Class-Acc: {0: '99.64%', 1: '97.44%', 2: '86.92%'}, LR: 0.000100000\n",
      "Epoch 1359/2000, Train Loss: 0.000437356, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151825683, Val Accuracy: 97.40%, Val-Class-Acc: {0: '99.60%', 1: '97.39%', 2: '86.82%'}, LR: 0.000100000\n",
      "Epoch 1360/2000, Train Loss: 0.003269721, Train-Class-Acc: {0: '99.91%', 1: '99.87%', 2: '99.98%'}, Val Loss: 0.149461163, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.48%', 1: '97.52%', 2: '86.76%'}, LR: 0.000100000\n",
      "Epoch 1361/2000, Train Loss: 0.000755203, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.157531027, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.81%', 1: '97.32%', 2: '85.50%'}, LR: 0.000100000\n",
      "Epoch 1362/2000, Train Loss: 0.000426872, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158031664, Val Accuracy: 97.36%, Val-Class-Acc: {0: '99.72%', 1: '97.50%', 2: '85.44%'}, LR: 0.000100000\n",
      "Epoch 1363/2000, Train Loss: 0.000396024, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156595915, Val Accuracy: 97.39%, Val-Class-Acc: {0: '99.75%', 1: '97.39%', 2: '86.00%'}, LR: 0.000100000\n",
      "Epoch 1364/2000, Train Loss: 0.000519882, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.155096135, Val Accuracy: 97.44%, Val-Class-Acc: {0: '99.51%', 1: '97.53%', 2: '87.11%'}, LR: 0.000100000\n",
      "Epoch 1365/2000, Train Loss: 0.001330485, Train-Class-Acc: {0: '99.95%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.271548036, Val Accuracy: 95.84%, Val-Class-Acc: {0: '99.99%', 1: '95.01%', 2: '78.53%'}, LR: 0.000100000\n",
      "Epoch 1366/2000, Train Loss: 0.018988461, Train-Class-Acc: {0: '99.46%', 1: '99.27%', 2: '99.81%'}, Val Loss: 0.166178871, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.34%', 1: '97.53%', 2: '83.21%'}, LR: 0.000100000\n",
      "Epoch 1367/2000, Train Loss: 0.001552756, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.148840731, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.63%', 1: '96.92%', 2: '86.31%'}, LR: 0.000100000\n",
      "Epoch 1368/2000, Train Loss: 0.000657412, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.156479605, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.72%', 1: '97.49%', 2: '84.88%'}, LR: 0.000100000\n",
      "Epoch 1369/2000, Train Loss: 0.000533235, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154190803, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.68%', 1: '97.40%', 2: '85.25%'}, LR: 0.000100000\n",
      "Epoch 1370/2000, Train Loss: 0.000481163, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152568697, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.68%', 1: '97.42%', 2: '85.62%'}, LR: 0.000100000\n",
      "Epoch 1371/2000, Train Loss: 0.000466445, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155741354, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.71%', 1: '97.40%', 2: '85.37%'}, LR: 0.000100000\n",
      "Epoch 1372/2000, Train Loss: 0.000444642, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155740881, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.70%', 1: '97.39%', 2: '85.55%'}, LR: 0.000100000\n",
      "Epoch 1373/2000, Train Loss: 0.000429431, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158350134, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.74%', 1: '97.37%', 2: '85.31%'}, LR: 0.000100000\n",
      "Epoch 1374/2000, Train Loss: 0.000432969, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.157508111, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.69%', 1: '97.49%', 2: '85.46%'}, LR: 0.000100000\n",
      "Epoch 1375/2000, Train Loss: 0.000416137, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159290642, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.70%', 1: '97.49%', 2: '85.21%'}, LR: 0.000100000\n",
      "Epoch 1376/2000, Train Loss: 0.000399081, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159329201, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.71%', 1: '97.42%', 2: '85.47%'}, LR: 0.000100000\n",
      "Epoch 1377/2000, Train Loss: 0.000398652, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160144060, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.69%', 1: '97.51%', 2: '85.28%'}, LR: 0.000100000\n",
      "Epoch 1378/2000, Train Loss: 0.000393406, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160707846, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.69%', 1: '97.47%', 2: '85.49%'}, LR: 0.000100000\n",
      "Epoch 1379/2000, Train Loss: 0.000378775, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160333035, Val Accuracy: 97.37%, Val-Class-Acc: {0: '99.69%', 1: '97.50%', 2: '85.70%'}, LR: 0.000100000\n",
      "Epoch 1380/2000, Train Loss: 0.000465820, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159847159, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.31%', 1: '97.74%', 2: '86.36%'}, LR: 0.000100000\n",
      "Epoch 1381/2000, Train Loss: 0.009456799, Train-Class-Acc: {0: '99.72%', 1: '99.72%', 2: '99.94%'}, Val Loss: 0.200605409, Val Accuracy: 96.74%, Val-Class-Acc: {0: '99.68%', 1: '97.90%', 2: '78.68%'}, LR: 0.000100000\n",
      "Epoch 1382/2000, Train Loss: 0.003635085, Train-Class-Acc: {0: '99.88%', 1: '99.85%', 2: '99.96%'}, Val Loss: 0.171622755, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.81%', 1: '97.43%', 2: '83.48%'}, LR: 0.000100000\n",
      "Epoch 1383/2000, Train Loss: 0.000695662, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.161650778, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.57%', 1: '98.04%', 2: '83.94%'}, LR: 0.000100000\n",
      "Epoch 1384/2000, Train Loss: 0.000515678, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162893911, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.69%', 1: '97.74%', 2: '84.43%'}, LR: 0.000100000\n",
      "Epoch 1385/2000, Train Loss: 0.000439018, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164950549, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.71%', 1: '97.69%', 2: '84.33%'}, LR: 0.000100000\n",
      "Epoch 1386/2000, Train Loss: 0.000420006, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165291869, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.70%', 1: '97.60%', 2: '84.58%'}, LR: 0.000100000\n",
      "Epoch 1387/2000, Train Loss: 0.000409831, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164132129, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.68%', 1: '97.60%', 2: '84.95%'}, LR: 0.000100000\n",
      "Epoch 1388/2000, Train Loss: 0.000426454, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167231417, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.68%', 1: '97.59%', 2: '84.52%'}, LR: 0.000100000\n",
      "Epoch 1389/2000, Train Loss: 0.000419354, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168391815, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.73%', 1: '97.50%', 2: '84.87%'}, LR: 0.000100000\n",
      "Epoch 1390/2000, Train Loss: 0.000416828, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167417572, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.68%', 1: '97.57%', 2: '84.98%'}, LR: 0.000100000\n",
      "Epoch 1391/2000, Train Loss: 0.000398800, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170513740, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.68%', 1: '97.62%', 2: '84.76%'}, LR: 0.000100000\n",
      "Epoch 1392/2000, Train Loss: 0.000374266, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168477234, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.65%', 1: '97.62%', 2: '85.25%'}, LR: 0.000100000\n",
      "Epoch 1393/2000, Train Loss: 0.000385020, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171977194, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.75%', 1: '97.46%', 2: '84.81%'}, LR: 0.000100000\n",
      "Epoch 1394/2000, Train Loss: 0.012860700, Train-Class-Acc: {0: '99.73%', 1: '99.59%', 2: '99.71%'}, Val Loss: 0.241396614, Val Accuracy: 95.79%, Val-Class-Acc: {0: '98.04%', 1: '98.44%', 2: '76.08%'}, LR: 0.000100000\n",
      "Epoch 1395/2000, Train Loss: 0.008611330, Train-Class-Acc: {0: '99.75%', 1: '99.65%', 2: '99.69%'}, Val Loss: 0.130603362, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.49%', 1: '96.62%', 2: '86.74%'}, LR: 0.000100000\n",
      "Epoch 1396/2000, Train Loss: 0.000955448, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '99.99%'}, Val Loss: 0.138731975, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.77%', 1: '97.09%', 2: '86.00%'}, LR: 0.000100000\n",
      "Epoch 1397/2000, Train Loss: 0.000582110, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.141284580, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.71%', 1: '97.23%', 2: '86.02%'}, LR: 0.000100000\n",
      "Epoch 1398/2000, Train Loss: 0.000499413, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.142032997, Val Accuracy: 97.38%, Val-Class-Acc: {0: '99.67%', 1: '97.39%', 2: '86.28%'}, LR: 0.000100000\n",
      "Epoch 1399/2000, Train Loss: 0.000456491, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.146884413, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.69%', 1: '97.40%', 2: '85.61%'}, LR: 0.000100000\n",
      "Epoch 1400/2000, Train Loss: 0.000432918, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.147747009, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.72%', 1: '97.33%', 2: '85.90%'}, LR: 0.000100000\n",
      "Epoch 1401/2000, Train Loss: 0.000432669, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.144929226, Val Accuracy: 97.42%, Val-Class-Acc: {0: '99.66%', 1: '97.51%', 2: '86.26%'}, LR: 0.000100000\n",
      "Epoch 1402/2000, Train Loss: 0.000419862, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151819252, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.69%', 1: '97.41%', 2: '85.60%'}, LR: 0.000100000\n",
      "Epoch 1403/2000, Train Loss: 0.000394019, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153629742, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.69%', 1: '97.38%', 2: '85.53%'}, LR: 0.000100000\n",
      "Epoch 1404/2000, Train Loss: 0.000400202, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151782797, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.68%', 1: '97.43%', 2: '85.75%'}, LR: 0.000100000\n",
      "Epoch 1405/2000, Train Loss: 0.000411499, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156388614, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.72%', 1: '97.31%', 2: '85.46%'}, LR: 0.000100000\n",
      "Epoch 1406/2000, Train Loss: 0.000394930, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158295999, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.74%', 1: '97.26%', 2: '85.34%'}, LR: 0.000100000\n",
      "Epoch 1407/2000, Train Loss: 0.000372828, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159051659, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.73%', 1: '97.33%', 2: '85.37%'}, LR: 0.000100000\n",
      "Epoch 1408/2000, Train Loss: 0.000369667, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.157587010, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.73%', 1: '97.33%', 2: '85.68%'}, LR: 0.000100000\n",
      "Epoch 1409/2000, Train Loss: 0.000366981, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159042667, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.70%', 1: '97.36%', 2: '85.54%'}, LR: 0.000100000\n",
      "Epoch 1410/2000, Train Loss: 0.000359947, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159188947, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.69%', 1: '97.37%', 2: '85.52%'}, LR: 0.000100000\n",
      "Epoch 1411/2000, Train Loss: 0.000372707, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159723552, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.73%', 1: '97.32%', 2: '85.53%'}, LR: 0.000100000\n",
      "Epoch 1412/2000, Train Loss: 0.000365246, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160190430, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.69%', 1: '97.44%', 2: '85.54%'}, LR: 0.000100000\n",
      "Epoch 1413/2000, Train Loss: 0.000367830, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161735249, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.75%', 1: '97.31%', 2: '85.55%'}, LR: 0.000100000\n",
      "Epoch 1414/2000, Train Loss: 0.000355683, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164432522, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.76%', 1: '97.27%', 2: '85.29%'}, LR: 0.000100000\n",
      "Epoch 1415/2000, Train Loss: 0.027739670, Train-Class-Acc: {0: '99.47%', 1: '99.22%', 2: '99.50%'}, Val Loss: 0.161484480, Val Accuracy: 96.58%, Val-Class-Acc: {0: '99.73%', 1: '96.69%', 2: '80.91%'}, LR: 0.000100000\n",
      "Epoch 1416/2000, Train Loss: 0.004054349, Train-Class-Acc: {0: '99.89%', 1: '99.84%', 2: '99.93%'}, Val Loss: 0.147809161, Val Accuracy: 96.89%, Val-Class-Acc: {0: '99.80%', 1: '96.51%', 2: '84.06%'}, LR: 0.000100000\n",
      "Epoch 1417/2000, Train Loss: 0.001028069, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.148059975, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.64%', 1: '97.26%', 2: '83.87%'}, LR: 0.000100000\n",
      "Epoch 1418/2000, Train Loss: 0.000659425, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.151526181, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.79%', 1: '97.25%', 2: '83.94%'}, LR: 0.000100000\n",
      "Epoch 1419/2000, Train Loss: 0.000518670, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153906702, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.75%', 1: '97.37%', 2: '83.90%'}, LR: 0.000100000\n",
      "Epoch 1420/2000, Train Loss: 0.000462048, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151593563, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.67%', 1: '97.50%', 2: '84.48%'}, LR: 0.000100000\n",
      "Epoch 1421/2000, Train Loss: 0.001604330, Train-Class-Acc: {0: '99.95%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.149988965, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.17%', 1: '97.57%', 2: '85.99%'}, LR: 0.000100000\n",
      "Epoch 1422/2000, Train Loss: 0.002549642, Train-Class-Acc: {0: '99.91%', 1: '99.89%', 2: '99.99%'}, Val Loss: 0.154620855, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.68%', 1: '97.27%', 2: '85.10%'}, LR: 0.000100000\n",
      "Epoch 1423/2000, Train Loss: 0.000712336, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.154573904, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.69%', 1: '97.43%', 2: '84.97%'}, LR: 0.000100000\n",
      "Epoch 1424/2000, Train Loss: 0.000438412, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154965878, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.68%', 1: '97.54%', 2: '85.03%'}, LR: 0.000100000\n",
      "Epoch 1425/2000, Train Loss: 0.000413392, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158889307, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.76%', 1: '97.38%', 2: '84.75%'}, LR: 0.000100000\n",
      "Epoch 1426/2000, Train Loss: 0.000396084, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.157200638, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.69%', 1: '97.54%', 2: '84.91%'}, LR: 0.000100000\n",
      "Epoch 1427/2000, Train Loss: 0.000386710, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158174879, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.68%', 1: '97.54%', 2: '84.87%'}, LR: 0.000100000\n",
      "Epoch 1428/2000, Train Loss: 0.000376994, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160601776, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.74%', 1: '97.45%', 2: '84.71%'}, LR: 0.000100000\n",
      "Epoch 1429/2000, Train Loss: 0.000376612, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161928932, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.73%', 1: '97.49%', 2: '84.62%'}, LR: 0.000100000\n",
      "Epoch 1430/2000, Train Loss: 0.000375679, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162127803, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.73%', 1: '97.50%', 2: '84.77%'}, LR: 0.000100000\n",
      "Epoch 1431/2000, Train Loss: 0.000364628, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163101122, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.77%', 1: '97.45%', 2: '84.68%'}, LR: 0.000100000\n",
      "Epoch 1432/2000, Train Loss: 0.000376539, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160025769, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.68%', 1: '97.51%', 2: '85.21%'}, LR: 0.000100000\n",
      "Epoch 1433/2000, Train Loss: 0.000421097, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159538739, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.53%', 1: '97.68%', 2: '85.46%'}, LR: 0.000100000\n",
      "Epoch 1434/2000, Train Loss: 0.001830947, Train-Class-Acc: {0: '99.94%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.165978688, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.82%', 1: '97.15%', 2: '84.83%'}, LR: 0.000100000\n",
      "Epoch 1435/2000, Train Loss: 0.004085976, Train-Class-Acc: {0: '99.88%', 1: '99.83%', 2: '99.98%'}, Val Loss: 0.236055441, Val Accuracy: 96.16%, Val-Class-Acc: {0: '96.53%', 1: '96.11%', 2: '94.49%'}, LR: 0.000100000\n",
      "Epoch 1436/2000, Train Loss: 0.040456832, Train-Class-Acc: {0: '98.88%', 1: '98.48%', 2: '99.08%'}, Val Loss: 0.159848184, Val Accuracy: 96.35%, Val-Class-Acc: {0: '99.64%', 1: '96.38%', 2: '80.37%'}, LR: 0.000100000\n",
      "Epoch 1437/2000, Train Loss: 0.003575642, Train-Class-Acc: {0: '99.93%', 1: '99.88%', 2: '99.98%'}, Val Loss: 0.150044038, Val Accuracy: 96.83%, Val-Class-Acc: {0: '99.53%', 1: '96.95%', 2: '83.34%'}, LR: 0.000100000\n",
      "Epoch 1438/2000, Train Loss: 0.001257419, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.148979143, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.59%', 1: '97.35%', 2: '84.15%'}, LR: 0.000100000\n",
      "Epoch 1439/2000, Train Loss: 0.000738615, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.148009043, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.62%', 1: '97.20%', 2: '84.91%'}, LR: 0.000100000\n",
      "Epoch 1440/2000, Train Loss: 0.000587752, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152498424, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.69%', 1: '97.25%', 2: '84.65%'}, LR: 0.000100000\n",
      "Epoch 1441/2000, Train Loss: 0.000538287, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152766166, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.70%', 1: '97.18%', 2: '84.90%'}, LR: 0.000100000\n",
      "Epoch 1442/2000, Train Loss: 0.000489488, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151616056, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.68%', 1: '97.31%', 2: '84.95%'}, LR: 0.000100000\n",
      "Epoch 1443/2000, Train Loss: 0.000464329, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154494455, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.69%', 1: '97.31%', 2: '84.87%'}, LR: 0.000100000\n",
      "Epoch 1444/2000, Train Loss: 0.000447980, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155535618, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.70%', 1: '97.28%', 2: '84.84%'}, LR: 0.000100000\n",
      "Epoch 1445/2000, Train Loss: 0.000436278, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158110190, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.74%', 1: '97.36%', 2: '84.62%'}, LR: 0.000100000\n",
      "Epoch 1446/2000, Train Loss: 0.000417140, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154693921, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.68%', 1: '97.41%', 2: '85.00%'}, LR: 0.000100000\n",
      "Epoch 1447/2000, Train Loss: 0.000405477, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156832475, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.69%', 1: '97.37%', 2: '84.95%'}, LR: 0.000100000\n",
      "Epoch 1448/2000, Train Loss: 0.000402308, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158019134, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.70%', 1: '97.49%', 2: '84.90%'}, LR: 0.000100000\n",
      "Epoch 1449/2000, Train Loss: 0.000390799, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158910798, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.69%', 1: '97.47%', 2: '84.82%'}, LR: 0.000100000\n",
      "Epoch 1450/2000, Train Loss: 0.000398197, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.157079763, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.68%', 1: '97.49%', 2: '85.04%'}, LR: 0.000100000\n",
      "Epoch 1451/2000, Train Loss: 0.000385706, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161745006, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.75%', 1: '97.40%', 2: '84.72%'}, LR: 0.000100000\n",
      "Epoch 1452/2000, Train Loss: 0.000371957, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158146278, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.68%', 1: '97.46%', 2: '85.09%'}, LR: 0.000100000\n",
      "Epoch 1453/2000, Train Loss: 0.000368754, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160948427, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.70%', 1: '97.47%', 2: '84.91%'}, LR: 0.000100000\n",
      "Epoch 1454/2000, Train Loss: 0.000366059, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160969705, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.70%', 1: '97.45%', 2: '85.07%'}, LR: 0.000100000\n",
      "Epoch 1455/2000, Train Loss: 0.000358221, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159381536, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.68%', 1: '97.51%', 2: '85.19%'}, LR: 0.000100000\n",
      "Epoch 1456/2000, Train Loss: 0.000361884, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161520746, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.70%', 1: '97.47%', 2: '85.05%'}, LR: 0.000100000\n",
      "Epoch 1457/2000, Train Loss: 0.000349978, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162205636, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.69%', 1: '97.45%', 2: '84.93%'}, LR: 0.000100000\n",
      "Epoch 1458/2000, Train Loss: 0.000364649, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164261778, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.72%', 1: '97.38%', 2: '84.86%'}, LR: 0.000100000\n",
      "Epoch 1459/2000, Train Loss: 0.000375605, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162502742, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.68%', 1: '97.49%', 2: '85.26%'}, LR: 0.000100000\n",
      "Epoch 1460/2000, Train Loss: 0.000344390, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162904146, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.65%', 1: '97.53%', 2: '85.18%'}, LR: 0.000100000\n",
      "Epoch 1461/2000, Train Loss: 0.000361247, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166040578, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.68%', 1: '97.54%', 2: '84.96%'}, LR: 0.000100000\n",
      "Epoch 1462/2000, Train Loss: 0.000344289, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.169299957, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.74%', 1: '97.45%', 2: '84.66%'}, LR: 0.000100000\n",
      "Epoch 1463/2000, Train Loss: 0.042095352, Train-Class-Acc: {0: '98.88%', 1: '98.59%', 2: '99.33%'}, Val Loss: 0.161542742, Val Accuracy: 96.24%, Val-Class-Acc: {0: '99.78%', 1: '95.27%', 2: '82.38%'}, LR: 0.000100000\n",
      "Epoch 1464/2000, Train Loss: 0.006149877, Train-Class-Acc: {0: '99.85%', 1: '99.75%', 2: '99.95%'}, Val Loss: 0.149240514, Val Accuracy: 96.81%, Val-Class-Acc: {0: '99.67%', 1: '96.69%', 2: '83.38%'}, LR: 0.000100000\n",
      "Epoch 1465/2000, Train Loss: 0.001345718, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.150303869, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.65%', 1: '97.00%', 2: '84.01%'}, LR: 0.000100000\n",
      "Epoch 1466/2000, Train Loss: 0.000718287, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151339423, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.64%', 1: '97.18%', 2: '84.42%'}, LR: 0.000100000\n",
      "Epoch 1467/2000, Train Loss: 0.000605136, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154481104, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.66%', 1: '97.20%', 2: '84.68%'}, LR: 0.000100000\n",
      "Epoch 1468/2000, Train Loss: 0.000503248, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159673748, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.69%', 1: '97.18%', 2: '84.36%'}, LR: 0.000100000\n",
      "Epoch 1469/2000, Train Loss: 0.000466387, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159461163, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.69%', 1: '97.18%', 2: '84.66%'}, LR: 0.000100000\n",
      "Epoch 1470/2000, Train Loss: 0.000449837, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159762598, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.67%', 1: '97.27%', 2: '84.76%'}, LR: 0.000100000\n",
      "Epoch 1471/2000, Train Loss: 0.000444728, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163133548, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.69%', 1: '97.28%', 2: '84.43%'}, LR: 0.000100000\n",
      "Epoch 1472/2000, Train Loss: 0.000413951, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164397916, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.71%', 1: '97.28%', 2: '84.42%'}, LR: 0.000100000\n",
      "Epoch 1473/2000, Train Loss: 0.000405536, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162553024, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.68%', 1: '97.35%', 2: '84.77%'}, LR: 0.000100000\n",
      "Epoch 1474/2000, Train Loss: 0.000400894, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164647876, Val Accuracy: 97.18%, Val-Class-Acc: {0: '99.69%', 1: '97.30%', 2: '84.64%'}, LR: 0.000100000\n",
      "Epoch 1475/2000, Train Loss: 0.000408764, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163040208, Val Accuracy: 97.20%, Val-Class-Acc: {0: '99.68%', 1: '97.30%', 2: '84.88%'}, LR: 0.000100000\n",
      "Epoch 1476/2000, Train Loss: 0.000377731, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165609212, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.69%', 1: '97.34%', 2: '84.60%'}, LR: 0.000100000\n",
      "Epoch 1477/2000, Train Loss: 0.000389690, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164107442, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.64%', 1: '97.46%', 2: '85.09%'}, LR: 0.000100000\n",
      "Epoch 1478/2000, Train Loss: 0.001309977, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.163353850, Val Accuracy: 97.28%, Val-Class-Acc: {0: '99.65%', 1: '97.41%', 2: '85.40%'}, LR: 0.000100000\n",
      "Epoch 1479/2000, Train Loss: 0.000390772, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165749624, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.69%', 1: '97.38%', 2: '85.05%'}, LR: 0.000100000\n",
      "Epoch 1480/2000, Train Loss: 0.000366966, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167452123, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.69%', 1: '97.36%', 2: '84.99%'}, LR: 0.000100000\n",
      "Epoch 1481/2000, Train Loss: 0.000360502, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167763044, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.69%', 1: '97.40%', 2: '84.95%'}, LR: 0.000100000\n",
      "Epoch 1482/2000, Train Loss: 0.000366542, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.169119010, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.70%', 1: '97.33%', 2: '84.92%'}, LR: 0.000100000\n",
      "Epoch 1483/2000, Train Loss: 0.000363142, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170067828, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.69%', 1: '97.42%', 2: '84.81%'}, LR: 0.000100000\n",
      "Epoch 1484/2000, Train Loss: 0.000347958, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171105799, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.73%', 1: '97.35%', 2: '84.89%'}, LR: 0.000100000\n",
      "Epoch 1485/2000, Train Loss: 0.000349851, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171022378, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.70%', 1: '97.42%', 2: '84.94%'}, LR: 0.000100000\n",
      "Epoch 1486/2000, Train Loss: 0.000350549, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171587387, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.69%', 1: '97.47%', 2: '84.87%'}, LR: 0.000100000\n",
      "Epoch 1487/2000, Train Loss: 0.000345550, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171152476, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.69%', 1: '97.38%', 2: '85.18%'}, LR: 0.000100000\n",
      "Epoch 1488/2000, Train Loss: 0.000333060, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172534319, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.69%', 1: '97.43%', 2: '84.91%'}, LR: 0.000100000\n",
      "Epoch 1489/2000, Train Loss: 0.000334453, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170924767, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.68%', 1: '97.45%', 2: '85.37%'}, LR: 0.000100000\n",
      "Epoch 1490/2000, Train Loss: 0.000682074, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.172295325, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.67%', 1: '97.39%', 2: '85.20%'}, LR: 0.000100000\n",
      "Epoch 1491/2000, Train Loss: 0.000356152, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.173009540, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.70%', 1: '97.33%', 2: '85.20%'}, LR: 0.000100000\n",
      "Epoch 1492/2000, Train Loss: 0.000340190, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.169508405, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.60%', 1: '97.53%', 2: '85.70%'}, LR: 0.000100000\n",
      "Epoch 1493/2000, Train Loss: 0.013517480, Train-Class-Acc: {0: '99.65%', 1: '99.57%', 2: '99.85%'}, Val Loss: 0.151250049, Val Accuracy: 96.74%, Val-Class-Acc: {0: '99.74%', 1: '95.96%', 2: '84.82%'}, LR: 0.000100000\n",
      "Epoch 1494/2000, Train Loss: 0.001621858, Train-Class-Acc: {0: '99.97%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.154060167, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.63%', 1: '97.31%', 2: '85.51%'}, LR: 0.000100000\n",
      "Epoch 1495/2000, Train Loss: 0.000564003, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152437639, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.66%', 1: '96.99%', 2: '86.20%'}, LR: 0.000100000\n",
      "Epoch 1496/2000, Train Loss: 0.000435341, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158737213, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.71%', 1: '97.19%', 2: '85.15%'}, LR: 0.000100000\n",
      "Epoch 1497/2000, Train Loss: 0.000425358, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166834294, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.84%', 1: '96.95%', 2: '84.87%'}, LR: 0.000100000\n",
      "Epoch 1498/2000, Train Loss: 0.000397906, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164847523, Val Accuracy: 97.22%, Val-Class-Acc: {0: '99.75%', 1: '97.22%', 2: '85.05%'}, LR: 0.000100000\n",
      "Epoch 1499/2000, Train Loss: 0.000356896, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165297783, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.70%', 1: '97.37%', 2: '85.06%'}, LR: 0.000100000\n",
      "Epoch 1500/2000, Train Loss: 0.000357254, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166588924, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.73%', 1: '97.27%', 2: '85.13%'}, LR: 0.000100000\n",
      "Epoch 1501/2000, Train Loss: 0.006515941, Train-Class-Acc: {0: '99.82%', 1: '99.78%', 2: '99.96%'}, Val Loss: 0.176949885, Val Accuracy: 96.85%, Val-Class-Acc: {0: '99.72%', 1: '96.21%', 2: '85.10%'}, LR: 0.000100000\n",
      "Epoch 1502/2000, Train Loss: 0.002128487, Train-Class-Acc: {0: '99.94%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.155210940, Val Accuracy: 97.41%, Val-Class-Acc: {0: '99.48%', 1: '97.17%', 2: '88.17%'}, LR: 0.000100000\n",
      "Epoch 1503/2000, Train Loss: 0.000541190, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162995437, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.61%', 1: '97.44%', 2: '85.79%'}, LR: 0.000100000\n",
      "Epoch 1504/2000, Train Loss: 0.000410835, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167411918, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.67%', 1: '97.45%', 2: '85.49%'}, LR: 0.000100000\n",
      "Epoch 1505/2000, Train Loss: 0.000378950, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168085924, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.67%', 1: '97.41%', 2: '85.50%'}, LR: 0.000100000\n",
      "Epoch 1506/2000, Train Loss: 0.000360232, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.169575340, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.66%', 1: '97.48%', 2: '85.40%'}, LR: 0.000100000\n",
      "Epoch 1507/2000, Train Loss: 0.000353183, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171020624, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.66%', 1: '97.49%', 2: '85.38%'}, LR: 0.000100000\n",
      "Epoch 1508/2000, Train Loss: 0.000347339, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.173156165, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.70%', 1: '97.45%', 2: '85.20%'}, LR: 0.000100000\n",
      "Epoch 1509/2000, Train Loss: 0.000337170, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172594990, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.69%', 1: '97.48%', 2: '85.39%'}, LR: 0.000100000\n",
      "Epoch 1510/2000, Train Loss: 0.000358426, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.175376002, Val Accuracy: 97.30%, Val-Class-Acc: {0: '99.74%', 1: '97.41%', 2: '85.14%'}, LR: 0.000100000\n",
      "Epoch 1511/2000, Train Loss: 0.000327239, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.176785870, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.73%', 1: '97.47%', 2: '85.11%'}, LR: 0.000100000\n",
      "Epoch 1512/2000, Train Loss: 0.000323406, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.176917312, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.73%', 1: '97.40%', 2: '85.12%'}, LR: 0.000100000\n",
      "Epoch 1513/2000, Train Loss: 0.000322150, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.174125600, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.65%', 1: '97.51%', 2: '85.60%'}, LR: 0.000100000\n",
      "Epoch 1514/2000, Train Loss: 0.000322856, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.177163660, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.73%', 1: '97.45%', 2: '85.25%'}, LR: 0.000100000\n",
      "Epoch 1515/2000, Train Loss: 0.000323778, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.174839153, Val Accuracy: 97.34%, Val-Class-Acc: {0: '99.67%', 1: '97.46%', 2: '85.69%'}, LR: 0.000100000\n",
      "Epoch 1516/2000, Train Loss: 0.000314642, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.178571763, Val Accuracy: 97.33%, Val-Class-Acc: {0: '99.75%', 1: '97.41%', 2: '85.43%'}, LR: 0.000100000\n",
      "Epoch 1517/2000, Train Loss: 0.000302039, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.180589304, Val Accuracy: 97.31%, Val-Class-Acc: {0: '99.75%', 1: '97.43%', 2: '85.14%'}, LR: 0.000100000\n",
      "Epoch 1518/2000, Train Loss: 0.000307968, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.180729212, Val Accuracy: 97.32%, Val-Class-Acc: {0: '99.72%', 1: '97.47%', 2: '85.15%'}, LR: 0.000100000\n",
      "Epoch 1519/2000, Train Loss: 0.094147390, Train-Class-Acc: {0: '99.03%', 1: '99.18%', 2: '97.94%'}, Val Loss: 0.862928647, Val Accuracy: 90.26%, Val-Class-Acc: {0: '99.96%', 1: '86.57%', 2: '55.65%'}, LR: 0.000100000\n",
      "Epoch 1520/2000, Train Loss: 0.163242899, Train-Class-Acc: {0: '96.72%', 1: '94.29%', 2: '92.19%'}, Val Loss: 0.125309089, Val Accuracy: 95.67%, Val-Class-Acc: {0: '98.67%', 1: '96.77%', 2: '77.48%'}, LR: 0.000100000\n",
      "Epoch 1521/2000, Train Loss: 0.023808884, Train-Class-Acc: {0: '99.42%', 1: '99.01%', 2: '99.20%'}, Val Loss: 0.119752711, Val Accuracy: 96.50%, Val-Class-Acc: {0: '99.43%', 1: '97.17%', 2: '80.12%'}, LR: 0.000100000\n",
      "Epoch 1522/2000, Train Loss: 0.011793446, Train-Class-Acc: {0: '99.71%', 1: '99.59%', 2: '99.73%'}, Val Loss: 0.125659629, Val Accuracy: 96.57%, Val-Class-Acc: {0: '99.68%', 1: '96.80%', 2: '80.81%'}, LR: 0.000100000\n",
      "Epoch 1523/2000, Train Loss: 0.007219603, Train-Class-Acc: {0: '99.82%', 1: '99.78%', 2: '99.83%'}, Val Loss: 0.129229174, Val Accuracy: 96.59%, Val-Class-Acc: {0: '99.82%', 1: '96.31%', 2: '81.88%'}, LR: 0.000100000\n",
      "Epoch 1524/2000, Train Loss: 0.004500435, Train-Class-Acc: {0: '99.89%', 1: '99.87%', 2: '99.90%'}, Val Loss: 0.128137283, Val Accuracy: 96.84%, Val-Class-Acc: {0: '99.71%', 1: '96.85%', 2: '83.00%'}, LR: 0.000100000\n",
      "Epoch 1525/2000, Train Loss: 0.003004061, Train-Class-Acc: {0: '99.93%', 1: '99.91%', 2: '99.95%'}, Val Loss: 0.127638050, Val Accuracy: 96.87%, Val-Class-Acc: {0: '99.62%', 1: '96.92%', 2: '83.41%'}, LR: 0.000100000\n",
      "Epoch 1526/2000, Train Loss: 0.002360529, Train-Class-Acc: {0: '99.94%', 1: '99.93%', 2: '99.97%'}, Val Loss: 0.131161341, Val Accuracy: 96.79%, Val-Class-Acc: {0: '99.73%', 1: '96.65%', 2: '83.03%'}, LR: 0.000100000\n",
      "Epoch 1527/2000, Train Loss: 0.001895280, Train-Class-Acc: {0: '99.96%', 1: '99.94%', 2: '99.99%'}, Val Loss: 0.137801935, Val Accuracy: 96.70%, Val-Class-Acc: {0: '99.87%', 1: '96.65%', 2: '81.57%'}, LR: 0.000100000\n",
      "Epoch 1528/2000, Train Loss: 0.001510784, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '100.00%'}, Val Loss: 0.140277577, Val Accuracy: 96.69%, Val-Class-Acc: {0: '99.84%', 1: '96.78%', 2: '81.16%'}, LR: 0.000100000\n",
      "Epoch 1529/2000, Train Loss: 0.001327092, Train-Class-Acc: {0: '99.97%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.146704422, Val Accuracy: 96.60%, Val-Class-Acc: {0: '99.89%', 1: '96.67%', 2: '80.46%'}, LR: 0.000100000\n",
      "Epoch 1530/2000, Train Loss: 0.001175238, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.136469715, Val Accuracy: 96.78%, Val-Class-Acc: {0: '99.67%', 1: '96.99%', 2: '82.07%'}, LR: 0.000100000\n",
      "Epoch 1531/2000, Train Loss: 0.001073448, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.140314995, Val Accuracy: 96.78%, Val-Class-Acc: {0: '99.78%', 1: '96.92%', 2: '81.76%'}, LR: 0.000100000\n",
      "Epoch 1532/2000, Train Loss: 0.000921930, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.142175429, Val Accuracy: 96.80%, Val-Class-Acc: {0: '99.80%', 1: '96.94%', 2: '81.84%'}, LR: 0.000100000\n",
      "Epoch 1533/2000, Train Loss: 0.000790650, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.144794248, Val Accuracy: 96.82%, Val-Class-Acc: {0: '99.81%', 1: '96.94%', 2: '81.98%'}, LR: 0.000100000\n",
      "Epoch 1534/2000, Train Loss: 0.000719060, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.145561446, Val Accuracy: 96.87%, Val-Class-Acc: {0: '99.79%', 1: '96.95%', 2: '82.48%'}, LR: 0.000100000\n",
      "Epoch 1535/2000, Train Loss: 0.000664397, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.145120841, Val Accuracy: 96.87%, Val-Class-Acc: {0: '99.69%', 1: '97.02%', 2: '82.73%'}, LR: 0.000100000\n",
      "Epoch 1536/2000, Train Loss: 0.000598960, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.149945541, Val Accuracy: 96.85%, Val-Class-Acc: {0: '99.72%', 1: '97.03%', 2: '82.37%'}, LR: 0.000100000\n",
      "Epoch 1537/2000, Train Loss: 0.000616916, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151802861, Val Accuracy: 96.88%, Val-Class-Acc: {0: '99.77%', 1: '97.01%', 2: '82.43%'}, LR: 0.000100000\n",
      "Epoch 1538/2000, Train Loss: 0.000757321, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.155853961, Val Accuracy: 96.86%, Val-Class-Acc: {0: '99.85%', 1: '96.82%', 2: '82.50%'}, LR: 0.000100000\n",
      "Epoch 1539/2000, Train Loss: 0.000925909, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '100.00%'}, Val Loss: 0.153784182, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.76%', 1: '97.08%', 2: '82.71%'}, LR: 0.000100000\n",
      "Epoch 1540/2000, Train Loss: 0.000500621, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152811138, Val Accuracy: 96.92%, Val-Class-Acc: {0: '99.71%', 1: '97.09%', 2: '82.85%'}, LR: 0.000100000\n",
      "Epoch 1541/2000, Train Loss: 0.000468004, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156246159, Val Accuracy: 96.91%, Val-Class-Acc: {0: '99.78%', 1: '97.05%', 2: '82.63%'}, LR: 0.000100000\n",
      "Epoch 1542/2000, Train Loss: 0.000449025, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156236950, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.76%', 1: '97.23%', 2: '82.67%'}, LR: 0.000100000\n",
      "Epoch 1543/2000, Train Loss: 0.000437803, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154397396, Val Accuracy: 96.96%, Val-Class-Acc: {0: '99.68%', 1: '97.21%', 2: '83.01%'}, LR: 0.000100000\n",
      "Epoch 1544/2000, Train Loss: 0.000432638, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158495726, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.78%', 1: '97.19%', 2: '82.72%'}, LR: 0.000100000\n",
      "Epoch 1545/2000, Train Loss: 0.000412519, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.157579163, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.74%', 1: '97.25%', 2: '82.89%'}, LR: 0.000100000\n",
      "Epoch 1546/2000, Train Loss: 0.000415823, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158848406, Val Accuracy: 96.99%, Val-Class-Acc: {0: '99.68%', 1: '97.33%', 2: '82.84%'}, LR: 0.000100000\n",
      "Epoch 1547/2000, Train Loss: 0.000395721, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159557538, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.72%', 1: '97.36%', 2: '82.79%'}, LR: 0.000100000\n",
      "Epoch 1548/2000, Train Loss: 0.000386456, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158794735, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.69%', 1: '97.35%', 2: '82.99%'}, LR: 0.000100000\n",
      "Epoch 1549/2000, Train Loss: 0.000409929, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158254241, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.68%', 1: '97.31%', 2: '83.09%'}, LR: 0.000100000\n",
      "Epoch 1550/2000, Train Loss: 0.000383621, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160222093, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.68%', 1: '97.34%', 2: '82.96%'}, LR: 0.000100000\n",
      "Epoch 1551/2000, Train Loss: 0.000383084, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162934824, Val Accuracy: 96.97%, Val-Class-Acc: {0: '99.74%', 1: '97.32%', 2: '82.37%'}, LR: 0.000100000\n",
      "Epoch 1552/2000, Train Loss: 0.000357373, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162662213, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.71%', 1: '97.38%', 2: '82.78%'}, LR: 0.000100000\n",
      "Epoch 1553/2000, Train Loss: 0.007283086, Train-Class-Acc: {0: '99.80%', 1: '99.80%', 2: '99.94%'}, Val Loss: 0.167976717, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.67%', 1: '97.22%', 2: '82.70%'}, LR: 0.000100000\n",
      "Epoch 1554/2000, Train Loss: 0.000843385, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.150733044, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.82%', 1: '97.21%', 2: '84.11%'}, LR: 0.000100000\n",
      "Epoch 1555/2000, Train Loss: 0.000454183, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155657452, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.75%', 1: '97.27%', 2: '83.53%'}, LR: 0.000100000\n",
      "Epoch 1556/2000, Train Loss: 0.000395257, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155864535, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.69%', 1: '97.34%', 2: '83.56%'}, LR: 0.000100000\n",
      "Epoch 1557/2000, Train Loss: 0.000414658, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159682035, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.73%', 1: '97.30%', 2: '83.44%'}, LR: 0.000100000\n",
      "Epoch 1558/2000, Train Loss: 0.000366935, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162473937, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.75%', 1: '97.25%', 2: '83.20%'}, LR: 0.000100000\n",
      "Epoch 1559/2000, Train Loss: 0.000356816, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163388902, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.74%', 1: '97.25%', 2: '83.18%'}, LR: 0.000100000\n",
      "Epoch 1560/2000, Train Loss: 0.000348641, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162915846, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.71%', 1: '97.35%', 2: '83.22%'}, LR: 0.000100000\n",
      "Epoch 1561/2000, Train Loss: 0.000345339, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.169207072, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.82%', 1: '97.11%', 2: '82.79%'}, LR: 0.000100000\n",
      "Epoch 1562/2000, Train Loss: 0.000353134, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163621507, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.71%', 1: '97.33%', 2: '83.26%'}, LR: 0.000100000\n",
      "Epoch 1563/2000, Train Loss: 0.000341496, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168204691, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.76%', 1: '97.24%', 2: '82.91%'}, LR: 0.000100000\n",
      "Epoch 1564/2000, Train Loss: 0.000349387, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164068872, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.67%', 1: '97.43%', 2: '83.39%'}, LR: 0.000100000\n",
      "Epoch 1565/2000, Train Loss: 0.043435455, Train-Class-Acc: {0: '99.08%', 1: '98.78%', 2: '99.12%'}, Val Loss: 0.141994280, Val Accuracy: 96.67%, Val-Class-Acc: {0: '99.22%', 1: '96.88%', 2: '83.62%'}, LR: 0.000100000\n",
      "Epoch 1566/2000, Train Loss: 0.004973432, Train-Class-Acc: {0: '99.87%', 1: '99.80%', 2: '99.95%'}, Val Loss: 0.151599563, Val Accuracy: 96.64%, Val-Class-Acc: {0: '99.72%', 1: '96.70%', 2: '81.54%'}, LR: 0.000100000\n",
      "Epoch 1567/2000, Train Loss: 0.001820800, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.139679462, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.75%', 1: '97.07%', 2: '83.31%'}, LR: 0.000100000\n",
      "Epoch 1568/2000, Train Loss: 0.001075285, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.144976947, Val Accuracy: 96.99%, Val-Class-Acc: {0: '99.73%', 1: '97.12%', 2: '83.33%'}, LR: 0.000100000\n",
      "Epoch 1569/2000, Train Loss: 0.000766583, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.146062900, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.64%', 1: '97.37%', 2: '83.13%'}, LR: 0.000100000\n",
      "Epoch 1570/2000, Train Loss: 0.000618275, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.148959315, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.65%', 1: '97.38%', 2: '82.95%'}, LR: 0.000100000\n",
      "Epoch 1571/2000, Train Loss: 0.000540800, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154340221, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.67%', 1: '97.50%', 2: '82.50%'}, LR: 0.000100000\n",
      "Epoch 1572/2000, Train Loss: 0.000484223, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152291614, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.68%', 1: '97.39%', 2: '83.08%'}, LR: 0.000100000\n",
      "Epoch 1573/2000, Train Loss: 0.000449944, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152359671, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.65%', 1: '97.47%', 2: '83.19%'}, LR: 0.000100000\n",
      "Epoch 1574/2000, Train Loss: 0.000441376, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156301669, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.69%', 1: '97.41%', 2: '82.94%'}, LR: 0.000100000\n",
      "Epoch 1575/2000, Train Loss: 0.000411545, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155816080, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.69%', 1: '97.41%', 2: '83.21%'}, LR: 0.000100000\n",
      "Epoch 1576/2000, Train Loss: 0.000400153, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.157430517, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.68%', 1: '97.46%', 2: '83.08%'}, LR: 0.000100000\n",
      "Epoch 1577/2000, Train Loss: 0.000381770, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158967495, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.68%', 1: '97.47%', 2: '82.95%'}, LR: 0.000100000\n",
      "Epoch 1578/2000, Train Loss: 0.000375140, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160172069, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.69%', 1: '97.46%', 2: '82.98%'}, LR: 0.000100000\n",
      "Epoch 1579/2000, Train Loss: 0.000363770, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162585011, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.69%', 1: '97.45%', 2: '82.80%'}, LR: 0.000100000\n",
      "Epoch 1580/2000, Train Loss: 0.000357337, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161245762, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.68%', 1: '97.46%', 2: '83.04%'}, LR: 0.000100000\n",
      "Epoch 1581/2000, Train Loss: 0.000353473, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163041720, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.70%', 1: '97.41%', 2: '82.93%'}, LR: 0.000100000\n",
      "Epoch 1582/2000, Train Loss: 0.000354172, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164482520, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.68%', 1: '97.50%', 2: '82.78%'}, LR: 0.000100000\n",
      "Epoch 1583/2000, Train Loss: 0.000360794, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167231776, Val Accuracy: 96.97%, Val-Class-Acc: {0: '99.73%', 1: '97.26%', 2: '82.66%'}, LR: 0.000100000\n",
      "Epoch 1584/2000, Train Loss: 0.000361733, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164504135, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.67%', 1: '97.47%', 2: '82.99%'}, LR: 0.000100000\n",
      "Epoch 1585/2000, Train Loss: 0.000352006, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168209142, Val Accuracy: 96.99%, Val-Class-Acc: {0: '99.72%', 1: '97.34%', 2: '82.57%'}, LR: 0.000100000\n",
      "Epoch 1586/2000, Train Loss: 0.000346916, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165880878, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.69%', 1: '97.43%', 2: '83.15%'}, LR: 0.000100000\n",
      "Epoch 1587/2000, Train Loss: 0.000338242, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170023501, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.71%', 1: '97.39%', 2: '82.64%'}, LR: 0.000100000\n",
      "Epoch 1588/2000, Train Loss: 0.000333704, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.169597922, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.70%', 1: '97.37%', 2: '82.73%'}, LR: 0.000100000\n",
      "Epoch 1589/2000, Train Loss: 0.000323328, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166963323, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.67%', 1: '97.48%', 2: '83.14%'}, LR: 0.000100000\n",
      "Epoch 1590/2000, Train Loss: 0.000324585, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.169848889, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.67%', 1: '97.52%', 2: '82.88%'}, LR: 0.000100000\n",
      "Epoch 1591/2000, Train Loss: 0.000319463, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.169990177, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.68%', 1: '97.48%', 2: '82.95%'}, LR: 0.000100000\n",
      "Epoch 1592/2000, Train Loss: 0.000327361, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171501836, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.70%', 1: '97.35%', 2: '83.05%'}, LR: 0.000100000\n",
      "Epoch 1593/2000, Train Loss: 0.000318258, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170491697, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.68%', 1: '97.47%', 2: '83.17%'}, LR: 0.000100000\n",
      "Epoch 1594/2000, Train Loss: 0.000317521, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170969821, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.68%', 1: '97.49%', 2: '83.07%'}, LR: 0.000100000\n",
      "Epoch 1595/2000, Train Loss: 0.000325450, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172359257, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.69%', 1: '97.45%', 2: '83.07%'}, LR: 0.000100000\n",
      "Epoch 1596/2000, Train Loss: 0.000318651, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.175530085, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.71%', 1: '97.36%', 2: '82.95%'}, LR: 0.000100000\n",
      "Epoch 1597/2000, Train Loss: 0.000309360, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168075814, Val Accuracy: 97.17%, Val-Class-Acc: {0: '99.57%', 1: '97.67%', 2: '83.91%'}, LR: 0.000100000\n",
      "Epoch 1598/2000, Train Loss: 0.036733722, Train-Class-Acc: {0: '99.30%', 1: '99.02%', 2: '99.00%'}, Val Loss: 0.148848209, Val Accuracy: 96.66%, Val-Class-Acc: {0: '99.34%', 1: '97.11%', 2: '82.19%'}, LR: 0.000100000\n",
      "Epoch 1599/2000, Train Loss: 0.002874973, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.97%'}, Val Loss: 0.143994585, Val Accuracy: 96.73%, Val-Class-Acc: {0: '99.62%', 1: '96.84%', 2: '82.40%'}, LR: 0.000100000\n",
      "Epoch 1600/2000, Train Loss: 0.001205765, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.146069010, Val Accuracy: 96.77%, Val-Class-Acc: {0: '99.59%', 1: '96.86%', 2: '82.86%'}, LR: 0.000100000\n",
      "Epoch 1601/2000, Train Loss: 0.000766998, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.148925503, Val Accuracy: 96.79%, Val-Class-Acc: {0: '99.64%', 1: '96.89%', 2: '82.65%'}, LR: 0.000100000\n",
      "Epoch 1602/2000, Train Loss: 0.000592686, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.150802850, Val Accuracy: 96.80%, Val-Class-Acc: {0: '99.68%', 1: '96.92%', 2: '82.51%'}, LR: 0.000100000\n",
      "Epoch 1603/2000, Train Loss: 0.000510644, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.149296812, Val Accuracy: 96.96%, Val-Class-Acc: {0: '99.65%', 1: '97.32%', 2: '82.75%'}, LR: 0.000100000\n",
      "Epoch 1604/2000, Train Loss: 0.000439371, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152543767, Val Accuracy: 96.99%, Val-Class-Acc: {0: '99.65%', 1: '97.42%', 2: '82.64%'}, LR: 0.000100000\n",
      "Epoch 1605/2000, Train Loss: 0.000403667, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152621862, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.65%', 1: '97.40%', 2: '82.91%'}, LR: 0.000100000\n",
      "Epoch 1606/2000, Train Loss: 0.000386901, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152290158, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.64%', 1: '97.50%', 2: '83.01%'}, LR: 0.000100000\n",
      "Epoch 1607/2000, Train Loss: 0.000374950, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153058219, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.64%', 1: '97.49%', 2: '83.10%'}, LR: 0.000100000\n",
      "Epoch 1608/2000, Train Loss: 0.000370528, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156790550, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.67%', 1: '97.44%', 2: '82.84%'}, LR: 0.000100000\n",
      "Epoch 1609/2000, Train Loss: 0.000360144, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156533608, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.68%', 1: '97.45%', 2: '83.01%'}, LR: 0.000100000\n",
      "Epoch 1610/2000, Train Loss: 0.000355671, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161164495, Val Accuracy: 96.99%, Val-Class-Acc: {0: '99.71%', 1: '97.36%', 2: '82.61%'}, LR: 0.000100000\n",
      "Epoch 1611/2000, Train Loss: 0.000444050, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158924213, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.63%', 1: '97.52%', 2: '82.97%'}, LR: 0.000100000\n",
      "Epoch 1612/2000, Train Loss: 0.000336879, Train-Class-Acc: {0: '99.99%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.161278086, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.69%', 1: '97.46%', 2: '82.90%'}, LR: 0.000100000\n",
      "Epoch 1613/2000, Train Loss: 0.000972405, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '100.00%'}, Val Loss: 0.152841620, Val Accuracy: 96.96%, Val-Class-Acc: {0: '99.22%', 1: '97.45%', 2: '84.46%'}, LR: 0.000100000\n",
      "Epoch 1614/2000, Train Loss: 0.003999802, Train-Class-Acc: {0: '99.89%', 1: '99.86%', 2: '99.98%'}, Val Loss: 0.159887401, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.68%', 1: '97.33%', 2: '83.16%'}, LR: 0.000100000\n",
      "Epoch 1615/2000, Train Loss: 0.000389638, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161009902, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.74%', 1: '97.28%', 2: '83.12%'}, LR: 0.000100000\n",
      "Epoch 1616/2000, Train Loss: 0.000357595, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.158360794, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.64%', 1: '97.48%', 2: '83.47%'}, LR: 0.000100000\n",
      "Epoch 1617/2000, Train Loss: 0.000354189, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160315726, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.66%', 1: '97.48%', 2: '83.34%'}, LR: 0.000100000\n",
      "Epoch 1618/2000, Train Loss: 0.000332410, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161429611, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.67%', 1: '97.46%', 2: '83.34%'}, LR: 0.000100000\n",
      "Epoch 1619/2000, Train Loss: 0.000334102, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167671819, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.75%', 1: '97.35%', 2: '82.81%'}, LR: 0.000100000\n",
      "Epoch 1620/2000, Train Loss: 0.000327081, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162189048, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.65%', 1: '97.50%', 2: '83.40%'}, LR: 0.000100000\n",
      "Epoch 1621/2000, Train Loss: 0.000322959, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165144512, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.68%', 1: '97.45%', 2: '83.21%'}, LR: 0.000100000\n",
      "Epoch 1622/2000, Train Loss: 0.000314435, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166097913, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.67%', 1: '97.48%', 2: '83.22%'}, LR: 0.000100000\n",
      "Epoch 1623/2000, Train Loss: 0.000323183, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165942645, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.66%', 1: '97.51%', 2: '83.25%'}, LR: 0.000100000\n",
      "Epoch 1624/2000, Train Loss: 0.011199347, Train-Class-Acc: {0: '99.76%', 1: '99.74%', 2: '99.96%'}, Val Loss: 0.193329929, Val Accuracy: 96.41%, Val-Class-Acc: {0: '99.71%', 1: '96.08%', 2: '81.59%'}, LR: 0.000100000\n",
      "Epoch 1625/2000, Train Loss: 0.003480045, Train-Class-Acc: {0: '99.90%', 1: '99.87%', 2: '99.95%'}, Val Loss: 0.152558365, Val Accuracy: 97.19%, Val-Class-Acc: {0: '99.52%', 1: '97.53%', 2: '84.74%'}, LR: 0.000100000\n",
      "Epoch 1626/2000, Train Loss: 0.000779178, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.158069777, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.62%', 1: '97.45%', 2: '83.18%'}, LR: 0.000100000\n",
      "Epoch 1627/2000, Train Loss: 0.000545289, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161241203, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.68%', 1: '97.27%', 2: '83.29%'}, LR: 0.000100000\n",
      "Epoch 1628/2000, Train Loss: 0.000449358, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160688889, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.64%', 1: '97.41%', 2: '83.46%'}, LR: 0.000100000\n",
      "Epoch 1629/2000, Train Loss: 0.000388589, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164378056, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.66%', 1: '97.38%', 2: '83.38%'}, LR: 0.000100000\n",
      "Epoch 1630/2000, Train Loss: 0.000357755, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161270823, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.58%', 1: '97.55%', 2: '83.72%'}, LR: 0.000100000\n",
      "Epoch 1631/2000, Train Loss: 0.000355331, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164827522, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.66%', 1: '97.45%', 2: '83.61%'}, LR: 0.000100000\n",
      "Epoch 1632/2000, Train Loss: 0.000342161, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162655640, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.53%', 1: '97.65%', 2: '83.82%'}, LR: 0.000100000\n",
      "Epoch 1633/2000, Train Loss: 0.000353403, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166997725, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.65%', 1: '97.49%', 2: '83.54%'}, LR: 0.000100000\n",
      "Epoch 1634/2000, Train Loss: 0.000331078, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.169265537, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.65%', 1: '97.47%', 2: '83.43%'}, LR: 0.000100000\n",
      "Epoch 1635/2000, Train Loss: 0.000346012, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171310939, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.70%', 1: '97.40%', 2: '83.33%'}, LR: 0.000100000\n",
      "Epoch 1636/2000, Train Loss: 0.000313784, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.169998096, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.66%', 1: '97.48%', 2: '83.54%'}, LR: 0.000100000\n",
      "Epoch 1637/2000, Train Loss: 0.000314645, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168216659, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.62%', 1: '97.56%', 2: '83.73%'}, LR: 0.000100000\n",
      "Epoch 1638/2000, Train Loss: 0.000566542, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.173735777, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.67%', 1: '97.45%', 2: '83.44%'}, LR: 0.000100000\n",
      "Epoch 1639/2000, Train Loss: 0.000321884, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.174774171, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.72%', 1: '97.29%', 2: '83.42%'}, LR: 0.000100000\n",
      "Epoch 1640/2000, Train Loss: 0.000464320, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.171053687, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.67%', 1: '97.40%', 2: '83.75%'}, LR: 0.000100000\n",
      "Epoch 1641/2000, Train Loss: 0.000312130, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170760171, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.64%', 1: '97.50%', 2: '83.89%'}, LR: 0.000100000\n",
      "Epoch 1642/2000, Train Loss: 0.000293005, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172263564, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.65%', 1: '97.52%', 2: '83.67%'}, LR: 0.000100000\n",
      "Epoch 1643/2000, Train Loss: 0.000286160, Train-Class-Acc: {0: '99.99%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.176604959, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.70%', 1: '97.44%', 2: '83.34%'}, LR: 0.000100000\n",
      "Epoch 1644/2000, Train Loss: 0.000292230, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.179355598, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.76%', 1: '97.22%', 2: '83.24%'}, LR: 0.000100000\n",
      "Epoch 1645/2000, Train Loss: 0.000288563, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.176209817, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.68%', 1: '97.46%', 2: '83.47%'}, LR: 0.000100000\n",
      "Epoch 1646/2000, Train Loss: 0.000283501, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.176934110, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.72%', 1: '97.37%', 2: '83.50%'}, LR: 0.000100000\n",
      "Epoch 1647/2000, Train Loss: 0.000277289, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.177241006, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.70%', 1: '97.43%', 2: '83.50%'}, LR: 0.000100000\n",
      "Epoch 1648/2000, Train Loss: 0.014887734, Train-Class-Acc: {0: '99.85%', 1: '99.70%', 2: '99.83%'}, Val Loss: 0.324289971, Val Accuracy: 95.34%, Val-Class-Acc: {0: '97.91%', 1: '98.09%', 2: '73.77%'}, LR: 0.000100000\n",
      "Epoch 1649/2000, Train Loss: 0.054399509, Train-Class-Acc: {0: '98.89%', 1: '98.31%', 2: '98.19%'}, Val Loss: 0.149755575, Val Accuracy: 96.50%, Val-Class-Acc: {0: '99.18%', 1: '97.66%', 2: '79.69%'}, LR: 0.000100000\n",
      "Epoch 1650/2000, Train Loss: 0.004163710, Train-Class-Acc: {0: '99.91%', 1: '99.87%', 2: '99.96%'}, Val Loss: 0.153491588, Val Accuracy: 96.58%, Val-Class-Acc: {0: '99.64%', 1: '97.19%', 2: '79.73%'}, LR: 0.000100000\n",
      "Epoch 1651/2000, Train Loss: 0.001636937, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.149178334, Val Accuracy: 96.70%, Val-Class-Acc: {0: '99.59%', 1: '97.20%', 2: '81.08%'}, LR: 0.000100000\n",
      "Epoch 1652/2000, Train Loss: 0.001055774, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.153634993, Val Accuracy: 96.72%, Val-Class-Acc: {0: '99.65%', 1: '97.39%', 2: '80.29%'}, LR: 0.000100000\n",
      "Epoch 1653/2000, Train Loss: 0.000796066, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.154387071, Val Accuracy: 96.83%, Val-Class-Acc: {0: '99.66%', 1: '97.33%', 2: '81.49%'}, LR: 0.000100000\n",
      "Epoch 1654/2000, Train Loss: 0.000642604, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151513840, Val Accuracy: 96.97%, Val-Class-Acc: {0: '99.62%', 1: '97.43%', 2: '82.59%'}, LR: 0.000100000\n",
      "Epoch 1655/2000, Train Loss: 0.000575200, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155343697, Val Accuracy: 96.90%, Val-Class-Acc: {0: '99.66%', 1: '97.43%', 2: '81.80%'}, LR: 0.000100000\n",
      "Epoch 1656/2000, Train Loss: 0.000502093, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156493360, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.67%', 1: '97.35%', 2: '82.23%'}, LR: 0.000100000\n",
      "Epoch 1657/2000, Train Loss: 0.000450044, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159339842, Val Accuracy: 96.89%, Val-Class-Acc: {0: '99.68%', 1: '97.36%', 2: '81.82%'}, LR: 0.000100000\n",
      "Epoch 1658/2000, Train Loss: 0.000422686, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160039317, Val Accuracy: 96.92%, Val-Class-Acc: {0: '99.67%', 1: '97.39%', 2: '82.03%'}, LR: 0.000100000\n",
      "Epoch 1659/2000, Train Loss: 0.000398599, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159622924, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.66%', 1: '97.43%', 2: '82.49%'}, LR: 0.000100000\n",
      "Epoch 1660/2000, Train Loss: 0.000388839, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163025644, Val Accuracy: 96.92%, Val-Class-Acc: {0: '99.68%', 1: '97.36%', 2: '82.08%'}, LR: 0.000100000\n",
      "Epoch 1661/2000, Train Loss: 0.000371845, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165049669, Val Accuracy: 96.89%, Val-Class-Acc: {0: '99.69%', 1: '97.38%', 2: '81.68%'}, LR: 0.000100000\n",
      "Epoch 1662/2000, Train Loss: 0.000363413, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161514679, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.65%', 1: '97.50%', 2: '82.58%'}, LR: 0.000100000\n",
      "Epoch 1663/2000, Train Loss: 0.000356814, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168516362, Val Accuracy: 96.84%, Val-Class-Acc: {0: '99.70%', 1: '97.35%', 2: '81.34%'}, LR: 0.000100000\n",
      "Epoch 1664/2000, Train Loss: 0.000357342, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163405068, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.68%', 1: '97.42%', 2: '82.75%'}, LR: 0.000100000\n",
      "Epoch 1665/2000, Train Loss: 0.000350035, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163244455, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.66%', 1: '97.52%', 2: '82.77%'}, LR: 0.000100000\n",
      "Epoch 1666/2000, Train Loss: 0.000346661, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165089508, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.67%', 1: '97.46%', 2: '82.68%'}, LR: 0.000100000\n",
      "Epoch 1667/2000, Train Loss: 0.000334119, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170065368, Val Accuracy: 96.92%, Val-Class-Acc: {0: '99.70%', 1: '97.35%', 2: '82.04%'}, LR: 0.000100000\n",
      "Epoch 1668/2000, Train Loss: 0.000331576, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170574819, Val Accuracy: 96.91%, Val-Class-Acc: {0: '99.71%', 1: '97.30%', 2: '82.06%'}, LR: 0.000100000\n",
      "Epoch 1669/2000, Train Loss: 0.000326060, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.169488366, Val Accuracy: 96.95%, Val-Class-Acc: {0: '99.70%', 1: '97.34%', 2: '82.35%'}, LR: 0.000100000\n",
      "Epoch 1670/2000, Train Loss: 0.000328667, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168732755, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.67%', 1: '97.46%', 2: '82.55%'}, LR: 0.000100000\n",
      "Epoch 1671/2000, Train Loss: 0.000314704, Train-Class-Acc: {0: '99.99%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.168348415, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.69%', 1: '97.41%', 2: '82.81%'}, LR: 0.000100000\n",
      "Epoch 1672/2000, Train Loss: 0.000321537, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167974433, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.68%', 1: '97.43%', 2: '82.93%'}, LR: 0.000100000\n",
      "Epoch 1673/2000, Train Loss: 0.000304196, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.170601870, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.69%', 1: '97.39%', 2: '82.73%'}, LR: 0.000100000\n",
      "Epoch 1674/2000, Train Loss: 0.000306144, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172081235, Val Accuracy: 96.97%, Val-Class-Acc: {0: '99.70%', 1: '97.32%', 2: '82.63%'}, LR: 0.000100000\n",
      "Epoch 1675/2000, Train Loss: 0.000310735, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171200184, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.69%', 1: '97.40%', 2: '82.91%'}, LR: 0.000100000\n",
      "Epoch 1676/2000, Train Loss: 0.000308733, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172629032, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.68%', 1: '97.41%', 2: '82.79%'}, LR: 0.000100000\n",
      "Epoch 1677/2000, Train Loss: 0.000298496, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170713300, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.67%', 1: '97.44%', 2: '83.12%'}, LR: 0.000100000\n",
      "Epoch 1678/2000, Train Loss: 0.000303785, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172390197, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.68%', 1: '97.48%', 2: '82.97%'}, LR: 0.000100000\n",
      "Epoch 1679/2000, Train Loss: 0.000296134, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172064446, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.69%', 1: '97.39%', 2: '83.15%'}, LR: 0.000100000\n",
      "Epoch 1680/2000, Train Loss: 0.000291664, Train-Class-Acc: {0: '99.99%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.173334604, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.68%', 1: '97.42%', 2: '83.05%'}, LR: 0.000100000\n",
      "Epoch 1681/2000, Train Loss: 0.000296168, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.179097752, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.72%', 1: '97.31%', 2: '82.16%'}, LR: 0.000100000\n",
      "Epoch 1682/2000, Train Loss: 0.032079693, Train-Class-Acc: {0: '99.31%', 1: '99.17%', 2: '99.44%'}, Val Loss: 0.201202492, Val Accuracy: 96.07%, Val-Class-Acc: {0: '99.93%', 1: '95.64%', 2: '78.82%'}, LR: 0.000100000\n",
      "Epoch 1683/2000, Train Loss: 0.006778173, Train-Class-Acc: {0: '99.83%', 1: '99.69%', 2: '99.90%'}, Val Loss: 0.170160443, Val Accuracy: 96.50%, Val-Class-Acc: {0: '99.59%', 1: '96.48%', 2: '81.62%'}, LR: 0.000100000\n",
      "Epoch 1684/2000, Train Loss: 0.001754540, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.153280890, Val Accuracy: 96.71%, Val-Class-Acc: {0: '99.49%', 1: '96.80%', 2: '82.96%'}, LR: 0.000100000\n",
      "Epoch 1685/2000, Train Loss: 0.000951324, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.154206889, Val Accuracy: 96.79%, Val-Class-Acc: {0: '99.68%', 1: '96.71%', 2: '83.07%'}, LR: 0.000100000\n",
      "Epoch 1686/2000, Train Loss: 0.000664669, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153318812, Val Accuracy: 96.88%, Val-Class-Acc: {0: '99.61%', 1: '96.93%', 2: '83.51%'}, LR: 0.000100000\n",
      "Epoch 1687/2000, Train Loss: 0.000553154, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154822962, Val Accuracy: 96.97%, Val-Class-Acc: {0: '99.66%', 1: '97.11%', 2: '83.54%'}, LR: 0.000100000\n",
      "Epoch 1688/2000, Train Loss: 0.000474370, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156725285, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.67%', 1: '97.28%', 2: '83.58%'}, LR: 0.000100000\n",
      "Epoch 1689/2000, Train Loss: 0.000417477, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.159343296, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.67%', 1: '97.33%', 2: '83.38%'}, LR: 0.000100000\n",
      "Epoch 1690/2000, Train Loss: 0.000377447, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161093963, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.69%', 1: '97.32%', 2: '83.55%'}, LR: 0.000100000\n",
      "Epoch 1691/2000, Train Loss: 0.000363640, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163930816, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.69%', 1: '97.28%', 2: '83.74%'}, LR: 0.000100000\n",
      "Epoch 1692/2000, Train Loss: 0.000362157, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166228300, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.69%', 1: '97.34%', 2: '83.35%'}, LR: 0.000100000\n",
      "Epoch 1693/2000, Train Loss: 0.000353908, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166780081, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.68%', 1: '97.31%', 2: '83.41%'}, LR: 0.000100000\n",
      "Epoch 1694/2000, Train Loss: 0.000342712, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166736947, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.68%', 1: '97.35%', 2: '83.81%'}, LR: 0.000100000\n",
      "Epoch 1695/2000, Train Loss: 0.000325771, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170558053, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.69%', 1: '97.25%', 2: '83.29%'}, LR: 0.000100000\n",
      "Epoch 1696/2000, Train Loss: 0.000314903, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170555980, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.69%', 1: '97.35%', 2: '82.82%'}, LR: 0.000100000\n",
      "Epoch 1697/2000, Train Loss: 0.000328407, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.173439548, Val Accuracy: 96.95%, Val-Class-Acc: {0: '99.70%', 1: '97.24%', 2: '82.74%'}, LR: 0.000100000\n",
      "Epoch 1698/2000, Train Loss: 0.000321612, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.169762167, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.67%', 1: '97.41%', 2: '83.50%'}, LR: 0.000100000\n",
      "Epoch 1699/2000, Train Loss: 0.000315701, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172951225, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.69%', 1: '97.30%', 2: '82.85%'}, LR: 0.000100000\n",
      "Epoch 1700/2000, Train Loss: 0.000708066, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.167248628, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.61%', 1: '97.45%', 2: '83.89%'}, LR: 0.000100000\n",
      "Epoch 1701/2000, Train Loss: 0.000708571, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.173249943, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.69%', 1: '97.26%', 2: '83.37%'}, LR: 0.000100000\n",
      "Epoch 1702/2000, Train Loss: 0.000307998, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.174025522, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.68%', 1: '97.36%', 2: '83.17%'}, LR: 0.000100000\n",
      "Epoch 1703/2000, Train Loss: 0.000294910, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.172308404, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.65%', 1: '97.47%', 2: '83.58%'}, LR: 0.000100000\n",
      "Epoch 1704/2000, Train Loss: 0.000304245, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.179984396, Val Accuracy: 96.89%, Val-Class-Acc: {0: '99.72%', 1: '97.17%', 2: '82.26%'}, LR: 0.000100000\n",
      "Epoch 1705/2000, Train Loss: 0.000293560, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.176111028, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.69%', 1: '97.30%', 2: '83.29%'}, LR: 0.000100000\n",
      "Epoch 1706/2000, Train Loss: 0.000307348, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.178890598, Val Accuracy: 96.96%, Val-Class-Acc: {0: '99.70%', 1: '97.28%', 2: '82.64%'}, LR: 0.000100000\n",
      "Epoch 1707/2000, Train Loss: 0.004251926, Train-Class-Acc: {0: '99.88%', 1: '99.87%', 2: '99.98%'}, Val Loss: 0.169271741, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.79%', 1: '97.22%', 2: '83.14%'}, LR: 0.000100000\n",
      "Epoch 1708/2000, Train Loss: 0.000399477, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168047635, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.68%', 1: '97.34%', 2: '84.08%'}, LR: 0.000100000\n",
      "Epoch 1709/2000, Train Loss: 0.000311531, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170769024, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.69%', 1: '97.33%', 2: '83.75%'}, LR: 0.000100000\n",
      "Epoch 1710/2000, Train Loss: 0.000310572, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.176505049, Val Accuracy: 96.97%, Val-Class-Acc: {0: '99.71%', 1: '97.29%', 2: '82.70%'}, LR: 0.000100000\n",
      "Epoch 1711/2000, Train Loss: 0.000309931, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172992445, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.66%', 1: '97.45%', 2: '84.02%'}, LR: 0.000100000\n",
      "Epoch 1712/2000, Train Loss: 0.000874765, Train-Class-Acc: {0: '99.98%', 1: '99.96%', 2: '100.00%'}, Val Loss: 0.183161912, Val Accuracy: 96.98%, Val-Class-Acc: {0: '98.59%', 1: '97.27%', 2: '88.24%'}, LR: 0.000100000\n",
      "Epoch 1713/2000, Train Loss: 0.027549920, Train-Class-Acc: {0: '99.36%', 1: '99.15%', 2: '99.50%'}, Val Loss: 0.189492029, Val Accuracy: 96.62%, Val-Class-Acc: {0: '99.53%', 1: '97.81%', 2: '78.53%'}, LR: 0.000100000\n",
      "Epoch 1714/2000, Train Loss: 0.002618005, Train-Class-Acc: {0: '99.94%', 1: '99.93%', 2: '99.99%'}, Val Loss: 0.162648565, Val Accuracy: 96.85%, Val-Class-Acc: {0: '99.58%', 1: '97.14%', 2: '82.66%'}, LR: 0.000100000\n",
      "Epoch 1715/2000, Train Loss: 0.001043613, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.160612182, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.69%', 1: '97.07%', 2: '84.15%'}, LR: 0.000100000\n",
      "Epoch 1716/2000, Train Loss: 0.000646453, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164564937, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.65%', 1: '97.29%', 2: '84.08%'}, LR: 0.000100000\n",
      "Epoch 1717/2000, Train Loss: 0.000521435, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165480616, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.68%', 1: '97.25%', 2: '84.08%'}, LR: 0.000100000\n",
      "Epoch 1718/2000, Train Loss: 0.000432461, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168539457, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.70%', 1: '97.24%', 2: '83.58%'}, LR: 0.000100000\n",
      "Epoch 1719/2000, Train Loss: 0.000387822, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171765691, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.69%', 1: '97.29%', 2: '83.15%'}, LR: 0.000100000\n",
      "Epoch 1720/2000, Train Loss: 0.000365343, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170947863, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.69%', 1: '97.27%', 2: '83.72%'}, LR: 0.000100000\n",
      "Epoch 1721/2000, Train Loss: 0.000344936, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.170788486, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.69%', 1: '97.30%', 2: '83.97%'}, LR: 0.000100000\n",
      "Epoch 1722/2000, Train Loss: 0.000333488, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172104151, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.69%', 1: '97.31%', 2: '83.98%'}, LR: 0.000100000\n",
      "Epoch 1723/2000, Train Loss: 0.000325630, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.173185562, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.69%', 1: '97.27%', 2: '84.03%'}, LR: 0.000100000\n",
      "Epoch 1724/2000, Train Loss: 0.000320564, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.177974978, Val Accuracy: 96.96%, Val-Class-Acc: {0: '99.70%', 1: '97.24%', 2: '82.80%'}, LR: 0.000100000\n",
      "Epoch 1725/2000, Train Loss: 0.000313478, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.175192745, Val Accuracy: 97.12%, Val-Class-Acc: {0: '99.68%', 1: '97.34%', 2: '83.96%'}, LR: 0.000100000\n",
      "Epoch 1726/2000, Train Loss: 0.000309563, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.176226373, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.69%', 1: '97.30%', 2: '83.90%'}, LR: 0.000100000\n",
      "Epoch 1727/2000, Train Loss: 0.000302993, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.176099552, Val Accuracy: 97.12%, Val-Class-Acc: {0: '99.68%', 1: '97.35%', 2: '83.94%'}, LR: 0.000100000\n",
      "Epoch 1728/2000, Train Loss: 0.000298491, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.177714189, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.68%', 1: '97.31%', 2: '83.90%'}, LR: 0.000100000\n",
      "Epoch 1729/2000, Train Loss: 0.000407366, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.184433223, Val Accuracy: 96.89%, Val-Class-Acc: {0: '99.74%', 1: '97.07%', 2: '82.48%'}, LR: 0.000100000\n",
      "Epoch 1730/2000, Train Loss: 0.000346903, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.179667329, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.70%', 1: '97.21%', 2: '83.67%'}, LR: 0.000100000\n",
      "Epoch 1731/2000, Train Loss: 0.000286346, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.180782055, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.69%', 1: '97.23%', 2: '83.67%'}, LR: 0.000100000\n",
      "Epoch 1732/2000, Train Loss: 0.000283118, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.180365873, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.69%', 1: '97.29%', 2: '83.54%'}, LR: 0.000100000\n",
      "Epoch 1733/2000, Train Loss: 0.000280016, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.182921852, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.70%', 1: '97.23%', 2: '83.31%'}, LR: 0.000100000\n",
      "Epoch 1734/2000, Train Loss: 0.000279744, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.180968388, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.69%', 1: '97.30%', 2: '83.96%'}, LR: 0.000100000\n",
      "Epoch 1735/2000, Train Loss: 0.000276483, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.183565340, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.69%', 1: '97.25%', 2: '83.42%'}, LR: 0.000100000\n",
      "Epoch 1736/2000, Train Loss: 0.000322551, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.181442262, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.67%', 1: '97.33%', 2: '84.16%'}, LR: 0.000100000\n",
      "Epoch 1737/2000, Train Loss: 0.034577810, Train-Class-Acc: {0: '99.15%', 1: '98.89%', 2: '99.68%'}, Val Loss: 0.172300625, Val Accuracy: 96.80%, Val-Class-Acc: {0: '99.40%', 1: '97.85%', 2: '80.76%'}, LR: 0.000100000\n",
      "Epoch 1738/2000, Train Loss: 0.005573185, Train-Class-Acc: {0: '99.83%', 1: '99.79%', 2: '99.95%'}, Val Loss: 0.160947727, Val Accuracy: 96.71%, Val-Class-Acc: {0: '99.42%', 1: '96.90%', 2: '82.94%'}, LR: 0.000100000\n",
      "Epoch 1739/2000, Train Loss: 0.001492480, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '100.00%'}, Val Loss: 0.159424493, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.65%', 1: '97.25%', 2: '84.36%'}, LR: 0.000100000\n",
      "Epoch 1740/2000, Train Loss: 0.000792741, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.161752333, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.65%', 1: '97.35%', 2: '84.27%'}, LR: 0.000100000\n",
      "Epoch 1741/2000, Train Loss: 0.000558974, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168421432, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.68%', 1: '97.28%', 2: '84.12%'}, LR: 0.000100000\n",
      "Epoch 1742/2000, Train Loss: 0.000464543, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168277984, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.68%', 1: '97.28%', 2: '84.32%'}, LR: 0.000100000\n",
      "Epoch 1743/2000, Train Loss: 0.000412286, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172512831, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.68%', 1: '97.28%', 2: '84.26%'}, LR: 0.000100000\n",
      "Epoch 1744/2000, Train Loss: 0.000386999, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.172673159, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.68%', 1: '97.29%', 2: '84.45%'}, LR: 0.000100000\n",
      "Epoch 1745/2000, Train Loss: 0.000362587, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.175430565, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.68%', 1: '97.35%', 2: '84.29%'}, LR: 0.000100000\n",
      "Epoch 1746/2000, Train Loss: 0.000352244, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.175913668, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.68%', 1: '97.33%', 2: '84.34%'}, LR: 0.000100000\n",
      "Epoch 1747/2000, Train Loss: 0.000335107, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.177470802, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.69%', 1: '97.28%', 2: '84.33%'}, LR: 0.000100000\n",
      "Epoch 1748/2000, Train Loss: 0.000326299, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.179143873, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.70%', 1: '97.25%', 2: '84.30%'}, LR: 0.000100000\n",
      "Epoch 1749/2000, Train Loss: 0.000329159, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.183774417, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.72%', 1: '97.11%', 2: '83.99%'}, LR: 0.000100000\n",
      "Epoch 1750/2000, Train Loss: 0.000317538, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.180125213, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.69%', 1: '97.30%', 2: '84.42%'}, LR: 0.000100000\n",
      "Epoch 1751/2000, Train Loss: 0.000310535, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.180399992, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.69%', 1: '97.32%', 2: '84.31%'}, LR: 0.000100000\n",
      "Epoch 1752/2000, Train Loss: 0.000312500, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.181841369, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.70%', 1: '97.26%', 2: '84.28%'}, LR: 0.000100000\n",
      "Epoch 1753/2000, Train Loss: 0.000302409, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.181286898, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.69%', 1: '97.27%', 2: '84.46%'}, LR: 0.000100000\n",
      "Epoch 1754/2000, Train Loss: 0.000300382, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.182420885, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.69%', 1: '97.30%', 2: '84.37%'}, LR: 0.000100000\n",
      "Epoch 1755/2000, Train Loss: 0.000291032, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.183521447, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.69%', 1: '97.29%', 2: '84.28%'}, LR: 0.000100000\n",
      "Epoch 1756/2000, Train Loss: 0.000285708, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.184224349, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.69%', 1: '97.31%', 2: '84.32%'}, LR: 0.000100000\n",
      "Epoch 1757/2000, Train Loss: 0.000288445, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.186320606, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.70%', 1: '97.25%', 2: '84.07%'}, LR: 0.000100000\n",
      "Epoch 1758/2000, Train Loss: 0.000282689, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.185348593, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.69%', 1: '97.27%', 2: '84.27%'}, LR: 0.000100000\n",
      "Epoch 1759/2000, Train Loss: 0.000416214, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.192335078, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.79%', 1: '96.99%', 2: '83.84%'}, LR: 0.000100000\n",
      "Epoch 1760/2000, Train Loss: 0.061408673, Train-Class-Acc: {0: '98.67%', 1: '98.12%', 2: '98.61%'}, Val Loss: 0.167956595, Val Accuracy: 96.08%, Val-Class-Acc: {0: '99.87%', 1: '95.63%', 2: '79.24%'}, LR: 0.000100000\n",
      "Epoch 1761/2000, Train Loss: 0.005862302, Train-Class-Acc: {0: '99.86%', 1: '99.79%', 2: '99.95%'}, Val Loss: 0.165527537, Val Accuracy: 96.35%, Val-Class-Acc: {0: '99.55%', 1: '96.32%', 2: '80.96%'}, LR: 0.000100000\n",
      "Epoch 1762/2000, Train Loss: 0.001851133, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.158293300, Val Accuracy: 96.64%, Val-Class-Acc: {0: '99.68%', 1: '96.35%', 2: '82.93%'}, LR: 0.000100000\n",
      "Epoch 1763/2000, Train Loss: 0.000974832, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.156638247, Val Accuracy: 96.83%, Val-Class-Acc: {0: '99.62%', 1: '96.72%', 2: '83.73%'}, LR: 0.000100000\n",
      "Epoch 1764/2000, Train Loss: 0.000667268, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160242322, Val Accuracy: 96.83%, Val-Class-Acc: {0: '99.67%', 1: '96.77%', 2: '83.31%'}, LR: 0.000100000\n",
      "Epoch 1765/2000, Train Loss: 0.000541117, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161376649, Val Accuracy: 96.89%, Val-Class-Acc: {0: '99.69%', 1: '96.84%', 2: '83.54%'}, LR: 0.000100000\n",
      "Epoch 1766/2000, Train Loss: 0.000482042, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161381219, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.65%', 1: '97.20%', 2: '83.77%'}, LR: 0.000100000\n",
      "Epoch 1767/2000, Train Loss: 0.000436159, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162335294, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.68%', 1: '97.21%', 2: '83.99%'}, LR: 0.000100000\n",
      "Epoch 1768/2000, Train Loss: 0.000414265, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.162924386, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.67%', 1: '97.27%', 2: '84.00%'}, LR: 0.000100000\n",
      "Epoch 1769/2000, Train Loss: 0.000389031, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165982475, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.70%', 1: '97.24%', 2: '83.98%'}, LR: 0.000100000\n",
      "Epoch 1770/2000, Train Loss: 0.000375818, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166404735, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.71%', 1: '97.19%', 2: '84.04%'}, LR: 0.000100000\n",
      "Epoch 1771/2000, Train Loss: 0.000359443, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166919060, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.69%', 1: '97.27%', 2: '84.02%'}, LR: 0.000100000\n",
      "Epoch 1772/2000, Train Loss: 0.000350956, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168731452, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.70%', 1: '97.22%', 2: '83.86%'}, LR: 0.000100000\n",
      "Epoch 1773/2000, Train Loss: 0.000345127, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167058601, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.69%', 1: '97.28%', 2: '84.05%'}, LR: 0.000100000\n",
      "Epoch 1774/2000, Train Loss: 0.000336094, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171004351, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.71%', 1: '97.17%', 2: '83.67%'}, LR: 0.000100000\n",
      "Epoch 1775/2000, Train Loss: 0.000330884, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.169199016, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.69%', 1: '97.24%', 2: '84.05%'}, LR: 0.000100000\n",
      "Epoch 1776/2000, Train Loss: 0.000328367, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.168675824, Val Accuracy: 97.12%, Val-Class-Acc: {0: '99.69%', 1: '97.29%', 2: '84.10%'}, LR: 0.000100000\n",
      "Epoch 1777/2000, Train Loss: 0.000322313, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.172296439, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.71%', 1: '97.15%', 2: '83.80%'}, LR: 0.000100000\n",
      "Epoch 1778/2000, Train Loss: 0.000313911, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171175332, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.70%', 1: '97.23%', 2: '83.93%'}, LR: 0.000100000\n",
      "Epoch 1779/2000, Train Loss: 0.000316704, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171185033, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.70%', 1: '97.21%', 2: '84.04%'}, LR: 0.000100000\n",
      "Epoch 1780/2000, Train Loss: 0.000314288, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171550310, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.69%', 1: '97.23%', 2: '83.96%'}, LR: 0.000100000\n",
      "Epoch 1781/2000, Train Loss: 0.000303533, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171725243, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.69%', 1: '97.23%', 2: '84.12%'}, LR: 0.000100000\n",
      "Epoch 1782/2000, Train Loss: 0.000309198, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.173547042, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.70%', 1: '97.21%', 2: '83.91%'}, LR: 0.000100000\n",
      "Epoch 1783/2000, Train Loss: 0.000307435, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.169644339, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.65%', 1: '97.37%', 2: '84.34%'}, LR: 0.000100000\n",
      "Epoch 1784/2000, Train Loss: 0.000337738, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.173162398, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.69%', 1: '97.21%', 2: '84.10%'}, LR: 0.000100000\n",
      "Epoch 1785/2000, Train Loss: 0.000295521, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.173939562, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.69%', 1: '97.19%', 2: '84.06%'}, LR: 0.000100000\n",
      "Epoch 1786/2000, Train Loss: 0.000286434, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174391454, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.69%', 1: '97.25%', 2: '83.86%'}, LR: 0.000100000\n",
      "Epoch 1787/2000, Train Loss: 0.000292191, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174863040, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.70%', 1: '97.24%', 2: '83.98%'}, LR: 0.000100000\n",
      "Epoch 1788/2000, Train Loss: 0.000572299, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.203687642, Val Accuracy: 96.52%, Val-Class-Acc: {0: '99.93%', 1: '96.24%', 2: '80.97%'}, LR: 0.000100000\n",
      "Epoch 1789/2000, Train Loss: 0.002158994, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.99%'}, Val Loss: 0.173977002, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.73%', 1: '97.17%', 2: '83.97%'}, LR: 0.000100000\n",
      "Epoch 1790/2000, Train Loss: 0.000306983, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171417099, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.66%', 1: '97.31%', 2: '84.44%'}, LR: 0.000100000\n",
      "Epoch 1791/2000, Train Loss: 0.000296899, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.175402312, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.71%', 1: '97.22%', 2: '84.00%'}, LR: 0.000100000\n",
      "Epoch 1792/2000, Train Loss: 0.000286502, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174435427, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.69%', 1: '97.29%', 2: '84.33%'}, LR: 0.000100000\n",
      "Epoch 1793/2000, Train Loss: 0.000295049, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174895479, Val Accuracy: 97.12%, Val-Class-Acc: {0: '99.70%', 1: '97.23%', 2: '84.35%'}, LR: 0.000100000\n",
      "Epoch 1794/2000, Train Loss: 0.000275661, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.176096401, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.70%', 1: '97.28%', 2: '84.24%'}, LR: 0.000100000\n",
      "Epoch 1795/2000, Train Loss: 0.000273552, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.179189699, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.71%', 1: '97.17%', 2: '83.96%'}, LR: 0.000100000\n",
      "Epoch 1796/2000, Train Loss: 0.000297826, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.174168229, Val Accuracy: 97.18%, Val-Class-Acc: {0: '99.66%', 1: '97.35%', 2: '84.59%'}, LR: 0.000100000\n",
      "Epoch 1797/2000, Train Loss: 0.000280449, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.179864344, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.71%', 1: '97.15%', 2: '84.04%'}, LR: 0.000100000\n",
      "Epoch 1798/2000, Train Loss: 0.026360662, Train-Class-Acc: {0: '99.53%', 1: '99.46%', 2: '99.41%'}, Val Loss: 0.161975492, Val Accuracy: 96.50%, Val-Class-Acc: {0: '99.17%', 1: '97.02%', 2: '81.83%'}, LR: 0.000100000\n",
      "Epoch 1799/2000, Train Loss: 0.003658078, Train-Class-Acc: {0: '99.90%', 1: '99.88%', 2: '99.96%'}, Val Loss: 0.161842813, Val Accuracy: 96.83%, Val-Class-Acc: {0: '99.45%', 1: '97.06%', 2: '83.38%'}, LR: 0.000100000\n",
      "Epoch 1800/2000, Train Loss: 0.001173434, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.156286277, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.69%', 1: '96.71%', 2: '84.26%'}, LR: 0.000100000\n",
      "Epoch 1801/2000, Train Loss: 0.000686696, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.155697035, Val Accuracy: 96.96%, Val-Class-Acc: {0: '99.63%', 1: '96.82%', 2: '84.53%'}, LR: 0.000100000\n",
      "Epoch 1802/2000, Train Loss: 0.000498509, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154392929, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.63%', 1: '96.81%', 2: '84.75%'}, LR: 0.000100000\n",
      "Epoch 1803/2000, Train Loss: 0.000408646, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.157054079, Val Accuracy: 97.03%, Val-Class-Acc: {0: '99.66%', 1: '97.10%', 2: '84.14%'}, LR: 0.000100000\n",
      "Epoch 1804/2000, Train Loss: 0.000371442, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160548797, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.69%', 1: '97.24%', 2: '83.99%'}, LR: 0.000100000\n",
      "Epoch 1805/2000, Train Loss: 0.000343193, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164587202, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.72%', 1: '97.18%', 2: '83.94%'}, LR: 0.000100000\n",
      "Epoch 1806/2000, Train Loss: 0.000344881, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166361295, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.71%', 1: '97.21%', 2: '83.93%'}, LR: 0.000100000\n",
      "Epoch 1807/2000, Train Loss: 0.000327369, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165904873, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.68%', 1: '97.25%', 2: '84.04%'}, LR: 0.000100000\n",
      "Epoch 1808/2000, Train Loss: 0.000301552, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.168553788, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.70%', 1: '97.20%', 2: '84.01%'}, LR: 0.000100000\n",
      "Epoch 1809/2000, Train Loss: 0.000302046, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.170726186, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.71%', 1: '97.15%', 2: '83.92%'}, LR: 0.000100000\n",
      "Epoch 1810/2000, Train Loss: 0.000292826, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171466724, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.69%', 1: '97.23%', 2: '83.91%'}, LR: 0.000100000\n",
      "Epoch 1811/2000, Train Loss: 0.000286123, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171856389, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.68%', 1: '97.28%', 2: '83.87%'}, LR: 0.000100000\n",
      "Epoch 1812/2000, Train Loss: 0.000284813, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174105033, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.69%', 1: '97.26%', 2: '83.83%'}, LR: 0.000100000\n",
      "Epoch 1813/2000, Train Loss: 0.000278758, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174058150, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.69%', 1: '97.24%', 2: '83.96%'}, LR: 0.000100000\n",
      "Epoch 1814/2000, Train Loss: 0.000292670, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171428120, Val Accuracy: 97.12%, Val-Class-Acc: {0: '99.67%', 1: '97.30%', 2: '84.25%'}, LR: 0.000100000\n",
      "Epoch 1815/2000, Train Loss: 0.000274304, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174417742, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.68%', 1: '97.27%', 2: '83.99%'}, LR: 0.000100000\n",
      "Epoch 1816/2000, Train Loss: 0.000272929, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.177440533, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.69%', 1: '97.27%', 2: '83.66%'}, LR: 0.000100000\n",
      "Epoch 1817/2000, Train Loss: 0.000287305, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.177633780, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.69%', 1: '97.25%', 2: '84.09%'}, LR: 0.000100000\n",
      "Epoch 1818/2000, Train Loss: 0.000271563, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.178565938, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.69%', 1: '97.28%', 2: '83.83%'}, LR: 0.000100000\n",
      "Epoch 1819/2000, Train Loss: 0.000262963, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.179875470, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.69%', 1: '97.28%', 2: '83.60%'}, LR: 0.000100000\n",
      "Epoch 1820/2000, Train Loss: 0.000278220, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.181366308, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.69%', 1: '97.26%', 2: '83.60%'}, LR: 0.000100000\n",
      "Epoch 1821/2000, Train Loss: 0.000258842, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.181399885, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.69%', 1: '97.26%', 2: '83.71%'}, LR: 0.000100000\n",
      "Epoch 1822/2000, Train Loss: 0.000262373, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.181528356, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.69%', 1: '97.25%', 2: '83.77%'}, LR: 0.000100000\n",
      "Epoch 1823/2000, Train Loss: 0.000252491, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.178130023, Val Accuracy: 97.15%, Val-Class-Acc: {0: '99.65%', 1: '97.36%', 2: '84.35%'}, LR: 0.000100000\n",
      "Epoch 1824/2000, Train Loss: 0.004758759, Train-Class-Acc: {0: '99.90%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.182217287, Val Accuracy: 96.88%, Val-Class-Acc: {0: '98.54%', 1: '97.11%', 2: '88.08%'}, LR: 0.000100000\n",
      "Epoch 1825/2000, Train Loss: 0.007909255, Train-Class-Acc: {0: '99.75%', 1: '99.73%', 2: '99.89%'}, Val Loss: 0.152072296, Val Accuracy: 97.12%, Val-Class-Acc: {0: '99.31%', 1: '96.94%', 2: '87.14%'}, LR: 0.000100000\n",
      "Epoch 1826/2000, Train Loss: 0.000868738, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.165922397, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.64%', 1: '97.60%', 2: '84.37%'}, LR: 0.000100000\n",
      "Epoch 1827/2000, Train Loss: 0.000404615, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.161083552, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.66%', 1: '97.55%', 2: '84.95%'}, LR: 0.000100000\n",
      "Epoch 1828/2000, Train Loss: 0.000331427, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160772188, Val Accuracy: 97.29%, Val-Class-Acc: {0: '99.67%', 1: '97.47%', 2: '85.20%'}, LR: 0.000100000\n",
      "Epoch 1829/2000, Train Loss: 0.000307520, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164292688, Val Accuracy: 97.27%, Val-Class-Acc: {0: '99.69%', 1: '97.45%', 2: '84.95%'}, LR: 0.000100000\n",
      "Epoch 1830/2000, Train Loss: 0.000290750, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165488249, Val Accuracy: 97.26%, Val-Class-Acc: {0: '99.69%', 1: '97.44%', 2: '84.92%'}, LR: 0.000100000\n",
      "Epoch 1831/2000, Train Loss: 0.000291807, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.169499523, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.69%', 1: '97.51%', 2: '84.53%'}, LR: 0.000100000\n",
      "Epoch 1832/2000, Train Loss: 0.000280200, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.168994856, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.69%', 1: '97.44%', 2: '84.66%'}, LR: 0.000100000\n",
      "Epoch 1833/2000, Train Loss: 0.000269437, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.169578597, Val Accuracy: 97.23%, Val-Class-Acc: {0: '99.68%', 1: '97.42%', 2: '84.76%'}, LR: 0.000100000\n",
      "Epoch 1834/2000, Train Loss: 0.000285421, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.170606247, Val Accuracy: 97.25%, Val-Class-Acc: {0: '99.69%', 1: '97.42%', 2: '84.88%'}, LR: 0.000100000\n",
      "Epoch 1835/2000, Train Loss: 0.067288265, Train-Class-Acc: {0: '98.83%', 1: '98.16%', 2: '98.00%'}, Val Loss: 0.145854049, Val Accuracy: 96.14%, Val-Class-Acc: {0: '99.32%', 1: '95.26%', 2: '83.69%'}, LR: 0.000100000\n",
      "Epoch 1836/2000, Train Loss: 0.006864033, Train-Class-Acc: {0: '99.82%', 1: '99.79%', 2: '99.92%'}, Val Loss: 0.155027043, Val Accuracy: 96.48%, Val-Class-Acc: {0: '99.62%', 1: '96.47%', 2: '81.36%'}, LR: 0.000100000\n",
      "Epoch 1837/2000, Train Loss: 0.002356026, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.147619151, Val Accuracy: 96.69%, Val-Class-Acc: {0: '99.62%', 1: '96.97%', 2: '81.55%'}, LR: 0.000100000\n",
      "Epoch 1838/2000, Train Loss: 0.001299956, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.148954642, Val Accuracy: 96.63%, Val-Class-Acc: {0: '99.64%', 1: '96.99%', 2: '80.86%'}, LR: 0.000100000\n",
      "Epoch 1839/2000, Train Loss: 0.000940002, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.148525825, Val Accuracy: 96.63%, Val-Class-Acc: {0: '99.64%', 1: '96.93%', 2: '81.03%'}, LR: 0.000100000\n",
      "Epoch 1840/2000, Train Loss: 0.000766934, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152117679, Val Accuracy: 96.63%, Val-Class-Acc: {0: '99.69%', 1: '96.94%', 2: '80.84%'}, LR: 0.000100000\n",
      "Epoch 1841/2000, Train Loss: 0.000618349, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151260322, Val Accuracy: 96.73%, Val-Class-Acc: {0: '99.67%', 1: '97.08%', 2: '81.33%'}, LR: 0.000100000\n",
      "Epoch 1842/2000, Train Loss: 0.000533705, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152153352, Val Accuracy: 96.87%, Val-Class-Acc: {0: '99.64%', 1: '97.45%', 2: '81.52%'}, LR: 0.000100000\n",
      "Epoch 1843/2000, Train Loss: 0.000480733, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151530467, Val Accuracy: 96.90%, Val-Class-Acc: {0: '99.66%', 1: '97.32%', 2: '82.20%'}, LR: 0.000100000\n",
      "Epoch 1844/2000, Train Loss: 0.000429057, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.151123650, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.64%', 1: '97.36%', 2: '82.36%'}, LR: 0.000100000\n",
      "Epoch 1845/2000, Train Loss: 0.000397844, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153215032, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.66%', 1: '97.32%', 2: '82.38%'}, LR: 0.000100000\n",
      "Epoch 1846/2000, Train Loss: 0.000373711, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154809674, Val Accuracy: 96.91%, Val-Class-Acc: {0: '99.68%', 1: '97.29%', 2: '82.26%'}, LR: 0.000100000\n",
      "Epoch 1847/2000, Train Loss: 0.000359159, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153072133, Val Accuracy: 96.99%, Val-Class-Acc: {0: '99.65%', 1: '97.36%', 2: '82.89%'}, LR: 0.000100000\n",
      "Epoch 1848/2000, Train Loss: 0.000345261, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.154333294, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.65%', 1: '97.40%', 2: '82.79%'}, LR: 0.000100000\n",
      "Epoch 1849/2000, Train Loss: 0.000345685, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156103717, Val Accuracy: 96.99%, Val-Class-Acc: {0: '99.68%', 1: '97.34%', 2: '82.83%'}, LR: 0.000100000\n",
      "Epoch 1850/2000, Train Loss: 0.000345178, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156626240, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.68%', 1: '97.37%', 2: '82.93%'}, LR: 0.000100000\n",
      "Epoch 1851/2000, Train Loss: 0.000322459, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.158124301, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.67%', 1: '97.37%', 2: '82.82%'}, LR: 0.000100000\n",
      "Epoch 1852/2000, Train Loss: 0.000312512, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.158416326, Val Accuracy: 97.02%, Val-Class-Acc: {0: '99.67%', 1: '97.41%', 2: '82.94%'}, LR: 0.000100000\n",
      "Epoch 1853/2000, Train Loss: 0.000319954, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.158505915, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.67%', 1: '97.37%', 2: '83.17%'}, LR: 0.000100000\n",
      "Epoch 1854/2000, Train Loss: 0.000306071, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.159161537, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.68%', 1: '97.36%', 2: '83.21%'}, LR: 0.000100000\n",
      "Epoch 1855/2000, Train Loss: 0.000299083, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.162237625, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.68%', 1: '97.31%', 2: '82.81%'}, LR: 0.000100000\n",
      "Epoch 1856/2000, Train Loss: 0.000294918, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.160746152, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.67%', 1: '97.39%', 2: '83.19%'}, LR: 0.000100000\n",
      "Epoch 1857/2000, Train Loss: 0.000287797, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.165551773, Val Accuracy: 96.92%, Val-Class-Acc: {0: '99.69%', 1: '97.29%', 2: '82.29%'}, LR: 0.000100000\n",
      "Epoch 1858/2000, Train Loss: 0.000287272, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.162324113, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.67%', 1: '97.39%', 2: '83.22%'}, LR: 0.000100000\n",
      "Epoch 1859/2000, Train Loss: 0.000283541, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.164783960, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.69%', 1: '97.31%', 2: '82.82%'}, LR: 0.000100000\n",
      "Epoch 1860/2000, Train Loss: 0.000287586, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.163756548, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.65%', 1: '97.45%', 2: '83.15%'}, LR: 0.000100000\n",
      "Epoch 1861/2000, Train Loss: 0.000283543, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.165917331, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.68%', 1: '97.34%', 2: '82.92%'}, LR: 0.000100000\n",
      "Epoch 1862/2000, Train Loss: 0.000292819, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.169329633, Val Accuracy: 96.89%, Val-Class-Acc: {0: '99.69%', 1: '97.27%', 2: '82.07%'}, LR: 0.000100000\n",
      "Epoch 1863/2000, Train Loss: 0.000273136, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.167697965, Val Accuracy: 96.99%, Val-Class-Acc: {0: '99.67%', 1: '97.40%', 2: '82.60%'}, LR: 0.000100000\n",
      "Epoch 1864/2000, Train Loss: 0.000273288, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.169583084, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.70%', 1: '97.27%', 2: '82.41%'}, LR: 0.000100000\n",
      "Epoch 1865/2000, Train Loss: 0.000266567, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.172569398, Val Accuracy: 96.87%, Val-Class-Acc: {0: '99.70%', 1: '97.29%', 2: '81.78%'}, LR: 0.000100000\n",
      "Epoch 1866/2000, Train Loss: 0.000266047, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174012234, Val Accuracy: 96.84%, Val-Class-Acc: {0: '99.71%', 1: '97.21%', 2: '81.77%'}, LR: 0.000100000\n",
      "Epoch 1867/2000, Train Loss: 0.000262429, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174000810, Val Accuracy: 96.88%, Val-Class-Acc: {0: '99.71%', 1: '97.21%', 2: '82.05%'}, LR: 0.000100000\n",
      "Epoch 1868/2000, Train Loss: 0.000261247, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174449606, Val Accuracy: 96.89%, Val-Class-Acc: {0: '99.70%', 1: '97.27%', 2: '82.00%'}, LR: 0.000100000\n",
      "Epoch 1869/2000, Train Loss: 0.009100510, Train-Class-Acc: {0: '99.82%', 1: '99.75%', 2: '99.92%'}, Val Loss: 0.170556365, Val Accuracy: 96.87%, Val-Class-Acc: {0: '98.91%', 1: '98.15%', 2: '82.76%'}, LR: 0.000100000\n",
      "Epoch 1870/2000, Train Loss: 0.003526919, Train-Class-Acc: {0: '99.88%', 1: '99.86%', 2: '99.97%'}, Val Loss: 0.156897673, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.49%', 1: '96.78%', 2: '85.54%'}, LR: 0.000100000\n",
      "Epoch 1871/2000, Train Loss: 0.000613011, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.163260986, Val Accuracy: 96.89%, Val-Class-Acc: {0: '99.61%', 1: '96.92%', 2: '83.69%'}, LR: 0.000100000\n",
      "Epoch 1872/2000, Train Loss: 0.000399700, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165062164, Val Accuracy: 96.88%, Val-Class-Acc: {0: '99.62%', 1: '96.94%', 2: '83.45%'}, LR: 0.000100000\n",
      "Epoch 1873/2000, Train Loss: 0.000359587, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164777670, Val Accuracy: 96.92%, Val-Class-Acc: {0: '99.64%', 1: '96.89%', 2: '83.83%'}, LR: 0.000100000\n",
      "Epoch 1874/2000, Train Loss: 0.000329869, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167500859, Val Accuracy: 96.88%, Val-Class-Acc: {0: '99.69%', 1: '96.82%', 2: '83.53%'}, LR: 0.000100000\n",
      "Epoch 1875/2000, Train Loss: 0.000309880, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167327559, Val Accuracy: 96.94%, Val-Class-Acc: {0: '99.67%', 1: '96.88%', 2: '83.90%'}, LR: 0.000100000\n",
      "Epoch 1876/2000, Train Loss: 0.000302058, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168189292, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.67%', 1: '96.91%', 2: '83.76%'}, LR: 0.000100000\n",
      "Epoch 1877/2000, Train Loss: 0.000288773, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.168837639, Val Accuracy: 96.95%, Val-Class-Acc: {0: '99.68%', 1: '96.94%', 2: '83.79%'}, LR: 0.000100000\n",
      "Epoch 1878/2000, Train Loss: 0.000281569, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.169512401, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.69%', 1: '96.99%', 2: '83.82%'}, LR: 0.000100000\n",
      "Epoch 1879/2000, Train Loss: 0.000276387, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.170940164, Val Accuracy: 96.99%, Val-Class-Acc: {0: '99.69%', 1: '97.06%', 2: '83.74%'}, LR: 0.000100000\n",
      "Epoch 1880/2000, Train Loss: 0.000270351, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.170162256, Val Accuracy: 96.97%, Val-Class-Acc: {0: '99.66%', 1: '96.97%', 2: '83.97%'}, LR: 0.000100000\n",
      "Epoch 1881/2000, Train Loss: 0.000272239, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.172541715, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.70%', 1: '97.06%', 2: '83.71%'}, LR: 0.000100000\n",
      "Epoch 1882/2000, Train Loss: 0.002428286, Train-Class-Acc: {0: '99.92%', 1: '99.91%', 2: '99.99%'}, Val Loss: 0.259282939, Val Accuracy: 95.99%, Val-Class-Acc: {0: '99.98%', 1: '95.38%', 2: '78.73%'}, LR: 0.000100000\n",
      "Epoch 1883/2000, Train Loss: 0.005301325, Train-Class-Acc: {0: '99.85%', 1: '99.82%', 2: '99.95%'}, Val Loss: 0.156334769, Val Accuracy: 97.24%, Val-Class-Acc: {0: '99.39%', 1: '96.67%', 2: '88.75%'}, LR: 0.000100000\n",
      "Epoch 1884/2000, Train Loss: 0.000532274, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168206743, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.71%', 1: '97.14%', 2: '84.40%'}, LR: 0.000100000\n",
      "Epoch 1885/2000, Train Loss: 0.000336267, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166291312, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.64%', 1: '97.17%', 2: '84.85%'}, LR: 0.000100000\n",
      "Epoch 1886/2000, Train Loss: 0.000306071, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167736167, Val Accuracy: 97.12%, Val-Class-Acc: {0: '99.66%', 1: '97.14%', 2: '84.80%'}, LR: 0.000100000\n",
      "Epoch 1887/2000, Train Loss: 0.000299017, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171766832, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.70%', 1: '97.16%', 2: '84.01%'}, LR: 0.000100000\n",
      "Epoch 1888/2000, Train Loss: 0.000284912, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.170971495, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.66%', 1: '97.18%', 2: '84.32%'}, LR: 0.000100000\n",
      "Epoch 1889/2000, Train Loss: 0.000289372, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.173499586, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.69%', 1: '97.20%', 2: '84.02%'}, LR: 0.000100000\n",
      "Epoch 1890/2000, Train Loss: 0.000268388, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.173950590, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.68%', 1: '97.17%', 2: '84.06%'}, LR: 0.000100000\n",
      "Epoch 1891/2000, Train Loss: 0.000260698, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.175412741, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.72%', 1: '97.19%', 2: '84.14%'}, LR: 0.000100000\n",
      "Epoch 1892/2000, Train Loss: 0.000274720, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.177742056, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.74%', 1: '97.14%', 2: '83.98%'}, LR: 0.000100000\n",
      "Epoch 1893/2000, Train Loss: 0.001027244, Train-Class-Acc: {0: '99.97%', 1: '99.96%', 2: '99.99%'}, Val Loss: 0.177670535, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.71%', 1: '97.27%', 2: '84.48%'}, LR: 0.000100000\n",
      "Epoch 1894/2000, Train Loss: 0.000318482, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.175379906, Val Accuracy: 97.21%, Val-Class-Acc: {0: '99.67%', 1: '97.43%', 2: '84.59%'}, LR: 0.000100000\n",
      "Epoch 1895/2000, Train Loss: 0.000269437, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.178207196, Val Accuracy: 97.14%, Val-Class-Acc: {0: '99.71%', 1: '97.33%', 2: '84.06%'}, LR: 0.000100000\n",
      "Epoch 1896/2000, Train Loss: 0.000256255, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.179273747, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.70%', 1: '97.29%', 2: '84.04%'}, LR: 0.000100000\n",
      "Epoch 1897/2000, Train Loss: 0.000251548, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.178445562, Val Accuracy: 97.13%, Val-Class-Acc: {0: '99.68%', 1: '97.30%', 2: '84.25%'}, LR: 0.000100000\n",
      "Epoch 1898/2000, Train Loss: 0.000256339, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.177874366, Val Accuracy: 97.16%, Val-Class-Acc: {0: '99.66%', 1: '97.37%', 2: '84.37%'}, LR: 0.000100000\n",
      "Epoch 1899/2000, Train Loss: 0.000243709, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.181923593, Val Accuracy: 97.11%, Val-Class-Acc: {0: '99.72%', 1: '97.25%', 2: '84.07%'}, LR: 0.000100000\n",
      "Epoch 1900/2000, Train Loss: 0.102175429, Train-Class-Acc: {0: '98.69%', 1: '98.07%', 2: '97.70%'}, Val Loss: 0.240388196, Val Accuracy: 94.58%, Val-Class-Acc: {0: '99.67%', 1: '93.38%', 2: '74.03%'}, LR: 0.000100000\n",
      "Epoch 1901/2000, Train Loss: 0.020548254, Train-Class-Acc: {0: '99.53%', 1: '98.94%', 2: '99.31%'}, Val Loss: 0.142642095, Val Accuracy: 96.23%, Val-Class-Acc: {0: '99.66%', 1: '95.78%', 2: '81.18%'}, LR: 0.000100000\n",
      "Epoch 1902/2000, Train Loss: 0.004523282, Train-Class-Acc: {0: '99.91%', 1: '99.87%', 2: '99.93%'}, Val Loss: 0.144356908, Val Accuracy: 96.30%, Val-Class-Acc: {0: '99.59%', 1: '96.05%', 2: '81.28%'}, LR: 0.000100000\n",
      "Epoch 1903/2000, Train Loss: 0.002323781, Train-Class-Acc: {0: '99.95%', 1: '99.95%', 2: '99.98%'}, Val Loss: 0.139905126, Val Accuracy: 96.62%, Val-Class-Acc: {0: '99.49%', 1: '96.99%', 2: '81.52%'}, LR: 0.000100000\n",
      "Epoch 1904/2000, Train Loss: 0.001505324, Train-Class-Acc: {0: '99.97%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.148294119, Val Accuracy: 96.62%, Val-Class-Acc: {0: '99.64%', 1: '97.14%', 2: '80.33%'}, LR: 0.000100000\n",
      "Epoch 1905/2000, Train Loss: 0.001100496, Train-Class-Acc: {0: '99.98%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.146235602, Val Accuracy: 96.69%, Val-Class-Acc: {0: '99.63%', 1: '97.09%', 2: '81.07%'}, LR: 0.000100000\n",
      "Epoch 1906/2000, Train Loss: 0.000891715, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.140529288, Val Accuracy: 96.77%, Val-Class-Acc: {0: '99.53%', 1: '97.09%', 2: '82.38%'}, LR: 0.000100000\n",
      "Epoch 1907/2000, Train Loss: 0.000765891, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.145156564, Val Accuracy: 96.87%, Val-Class-Acc: {0: '99.65%', 1: '97.27%', 2: '82.10%'}, LR: 0.000100000\n",
      "Epoch 1908/2000, Train Loss: 0.000669807, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.142484854, Val Accuracy: 96.91%, Val-Class-Acc: {0: '99.54%', 1: '97.25%', 2: '83.06%'}, LR: 0.000100000\n",
      "Epoch 1909/2000, Train Loss: 0.000590906, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.145935726, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.63%', 1: '97.38%', 2: '82.81%'}, LR: 0.000100000\n",
      "Epoch 1910/2000, Train Loss: 0.000530113, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.146729690, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.65%', 1: '97.32%', 2: '82.93%'}, LR: 0.000100000\n",
      "Epoch 1911/2000, Train Loss: 0.000475395, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.150116300, Val Accuracy: 97.01%, Val-Class-Acc: {0: '99.68%', 1: '97.41%', 2: '82.78%'}, LR: 0.000100000\n",
      "Epoch 1912/2000, Train Loss: 0.000438255, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.148314386, Val Accuracy: 96.99%, Val-Class-Acc: {0: '99.66%', 1: '97.26%', 2: '83.19%'}, LR: 0.000100000\n",
      "Epoch 1913/2000, Train Loss: 0.000418571, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.148146308, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.64%', 1: '97.42%', 2: '83.26%'}, LR: 0.000100000\n",
      "Epoch 1914/2000, Train Loss: 0.000381976, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.148754679, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.65%', 1: '97.36%', 2: '83.43%'}, LR: 0.000100000\n",
      "Epoch 1915/2000, Train Loss: 0.000371753, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.153268322, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.68%', 1: '97.38%', 2: '83.27%'}, LR: 0.000100000\n",
      "Epoch 1916/2000, Train Loss: 0.000346996, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.152704395, Val Accuracy: 97.05%, Val-Class-Acc: {0: '99.66%', 1: '97.35%', 2: '83.44%'}, LR: 0.000100000\n",
      "Epoch 1917/2000, Train Loss: 0.000336223, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.154612902, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.68%', 1: '97.31%', 2: '83.40%'}, LR: 0.000100000\n",
      "Epoch 1918/2000, Train Loss: 0.000338430, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.152228974, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.62%', 1: '97.49%', 2: '83.63%'}, LR: 0.000100000\n",
      "Epoch 1919/2000, Train Loss: 0.000331251, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.157052809, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.69%', 1: '97.33%', 2: '83.42%'}, LR: 0.000100000\n",
      "Epoch 1920/2000, Train Loss: 0.000317157, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.156440461, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.69%', 1: '97.30%', 2: '83.67%'}, LR: 0.000100000\n",
      "Epoch 1921/2000, Train Loss: 0.000304497, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.157166106, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.68%', 1: '97.37%', 2: '83.61%'}, LR: 0.000100000\n",
      "Epoch 1922/2000, Train Loss: 0.000300302, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.157985534, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.69%', 1: '97.32%', 2: '83.69%'}, LR: 0.000100000\n",
      "Epoch 1923/2000, Train Loss: 0.000295364, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.157342090, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.68%', 1: '97.32%', 2: '83.82%'}, LR: 0.000100000\n",
      "Epoch 1924/2000, Train Loss: 0.000296484, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.158994374, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.68%', 1: '97.35%', 2: '83.58%'}, LR: 0.000100000\n",
      "Epoch 1925/2000, Train Loss: 0.000286953, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.160625726, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.69%', 1: '97.30%', 2: '83.68%'}, LR: 0.000100000\n",
      "Epoch 1926/2000, Train Loss: 0.000283167, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.161140987, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.68%', 1: '97.35%', 2: '83.68%'}, LR: 0.000100000\n",
      "Epoch 1927/2000, Train Loss: 0.000295134, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.160713046, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.66%', 1: '97.42%', 2: '83.59%'}, LR: 0.000100000\n",
      "Epoch 1928/2000, Train Loss: 0.000288341, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.161783365, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.69%', 1: '97.35%', 2: '83.54%'}, LR: 0.000100000\n",
      "Epoch 1929/2000, Train Loss: 0.000273343, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.165011895, Val Accuracy: 97.04%, Val-Class-Acc: {0: '99.70%', 1: '97.29%', 2: '83.34%'}, LR: 0.000100000\n",
      "Epoch 1930/2000, Train Loss: 0.000273551, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.162687222, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.68%', 1: '97.37%', 2: '83.60%'}, LR: 0.000100000\n",
      "Epoch 1931/2000, Train Loss: 0.000268160, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.162658865, Val Accuracy: 97.09%, Val-Class-Acc: {0: '99.69%', 1: '97.34%', 2: '83.74%'}, LR: 0.000100000\n",
      "Epoch 1932/2000, Train Loss: 0.000304549, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.165331924, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.70%', 1: '97.29%', 2: '83.57%'}, LR: 0.000100000\n",
      "Epoch 1933/2000, Train Loss: 0.000261168, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.164810217, Val Accuracy: 97.08%, Val-Class-Acc: {0: '99.69%', 1: '97.31%', 2: '83.66%'}, LR: 0.000100000\n",
      "Epoch 1934/2000, Train Loss: 0.000257274, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.166106153, Val Accuracy: 97.07%, Val-Class-Acc: {0: '99.70%', 1: '97.31%', 2: '83.57%'}, LR: 0.000100000\n",
      "Epoch 1935/2000, Train Loss: 0.000259211, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.167133125, Val Accuracy: 97.06%, Val-Class-Acc: {0: '99.70%', 1: '97.29%', 2: '83.53%'}, LR: 0.000100000\n",
      "Epoch 1936/2000, Train Loss: 0.000269866, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.165987925, Val Accuracy: 97.10%, Val-Class-Acc: {0: '99.69%', 1: '97.31%', 2: '83.81%'}, LR: 0.000100000\n",
      "Epoch 1937/2000, Train Loss: 0.000261216, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.164825482, Val Accuracy: 97.12%, Val-Class-Acc: {0: '99.66%', 1: '97.42%', 2: '83.84%'}, LR: 0.000100000\n",
      "Epoch 1938/2000, Train Loss: 0.039631765, Train-Class-Acc: {0: '99.24%', 1: '99.04%', 2: '99.23%'}, Val Loss: 0.155210181, Val Accuracy: 96.53%, Val-Class-Acc: {0: '99.63%', 1: '96.82%', 2: '80.57%'}, LR: 0.000100000\n",
      "Epoch 1939/2000, Train Loss: 0.003049379, Train-Class-Acc: {0: '99.94%', 1: '99.92%', 2: '99.97%'}, Val Loss: 0.167868357, Val Accuracy: 96.52%, Val-Class-Acc: {0: '99.85%', 1: '96.79%', 2: '79.48%'}, LR: 0.000100000\n",
      "Epoch 1940/2000, Train Loss: 0.001317111, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '99.99%'}, Val Loss: 0.158950841, Val Accuracy: 96.61%, Val-Class-Acc: {0: '99.64%', 1: '96.80%', 2: '81.30%'}, LR: 0.000100000\n",
      "Epoch 1941/2000, Train Loss: 0.000823518, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167649368, Val Accuracy: 96.53%, Val-Class-Acc: {0: '99.72%', 1: '96.84%', 2: '80.05%'}, LR: 0.000100000\n",
      "Epoch 1942/2000, Train Loss: 0.000644372, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.166731031, Val Accuracy: 96.59%, Val-Class-Acc: {0: '99.68%', 1: '96.93%', 2: '80.47%'}, LR: 0.000100000\n",
      "Epoch 1943/2000, Train Loss: 0.000531977, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168169556, Val Accuracy: 96.56%, Val-Class-Acc: {0: '99.68%', 1: '96.90%', 2: '80.30%'}, LR: 0.000100000\n",
      "Epoch 1944/2000, Train Loss: 0.000469536, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168076008, Val Accuracy: 96.59%, Val-Class-Acc: {0: '99.69%', 1: '96.88%', 2: '80.57%'}, LR: 0.000100000\n",
      "Epoch 1945/2000, Train Loss: 0.000416559, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.164913082, Val Accuracy: 96.62%, Val-Class-Acc: {0: '99.65%', 1: '96.95%', 2: '80.83%'}, LR: 0.000100000\n",
      "Epoch 1946/2000, Train Loss: 0.000381213, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167063290, Val Accuracy: 96.70%, Val-Class-Acc: {0: '99.67%', 1: '97.19%', 2: '80.77%'}, LR: 0.000100000\n",
      "Epoch 1947/2000, Train Loss: 0.000356799, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167984270, Val Accuracy: 96.75%, Val-Class-Acc: {0: '99.66%', 1: '97.33%', 2: '80.79%'}, LR: 0.000100000\n",
      "Epoch 1948/2000, Train Loss: 0.000333224, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.167611121, Val Accuracy: 96.78%, Val-Class-Acc: {0: '99.67%', 1: '97.31%', 2: '80.99%'}, LR: 0.000100000\n",
      "Epoch 1949/2000, Train Loss: 0.000318344, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171259114, Val Accuracy: 96.79%, Val-Class-Acc: {0: '99.69%', 1: '97.38%', 2: '80.77%'}, LR: 0.000100000\n",
      "Epoch 1950/2000, Train Loss: 0.000308744, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.170462646, Val Accuracy: 96.81%, Val-Class-Acc: {0: '99.68%', 1: '97.39%', 2: '81.01%'}, LR: 0.000100000\n",
      "Epoch 1951/2000, Train Loss: 0.000299888, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174762110, Val Accuracy: 96.77%, Val-Class-Acc: {0: '99.70%', 1: '97.33%', 2: '80.69%'}, LR: 0.000100000\n",
      "Epoch 1952/2000, Train Loss: 0.000292812, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174416122, Val Accuracy: 96.78%, Val-Class-Acc: {0: '99.68%', 1: '97.36%', 2: '80.79%'}, LR: 0.000100000\n",
      "Epoch 1953/2000, Train Loss: 0.000297413, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171992516, Val Accuracy: 96.83%, Val-Class-Acc: {0: '99.68%', 1: '97.38%', 2: '81.20%'}, LR: 0.000100000\n",
      "Epoch 1954/2000, Train Loss: 0.000280243, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174128152, Val Accuracy: 96.79%, Val-Class-Acc: {0: '99.69%', 1: '97.30%', 2: '81.07%'}, LR: 0.000100000\n",
      "Epoch 1955/2000, Train Loss: 0.000277517, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.173878355, Val Accuracy: 96.83%, Val-Class-Acc: {0: '99.68%', 1: '97.34%', 2: '81.30%'}, LR: 0.000100000\n",
      "Epoch 1956/2000, Train Loss: 0.000269236, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.175620851, Val Accuracy: 96.81%, Val-Class-Acc: {0: '99.69%', 1: '97.34%', 2: '81.12%'}, LR: 0.000100000\n",
      "Epoch 1957/2000, Train Loss: 0.000271426, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.176982683, Val Accuracy: 96.79%, Val-Class-Acc: {0: '99.69%', 1: '97.36%', 2: '80.85%'}, LR: 0.000100000\n",
      "Epoch 1958/2000, Train Loss: 0.000263655, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.175571252, Val Accuracy: 96.82%, Val-Class-Acc: {0: '99.68%', 1: '97.36%', 2: '81.21%'}, LR: 0.000100000\n",
      "Epoch 1959/2000, Train Loss: 0.000264187, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171550700, Val Accuracy: 96.91%, Val-Class-Acc: {0: '99.65%', 1: '97.45%', 2: '81.88%'}, LR: 0.000100000\n",
      "Epoch 1960/2000, Train Loss: 0.000275744, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.171075657, Val Accuracy: 96.94%, Val-Class-Acc: {0: '99.58%', 1: '97.58%', 2: '82.08%'}, LR: 0.000100000\n",
      "Epoch 1961/2000, Train Loss: 0.008610645, Train-Class-Acc: {0: '99.77%', 1: '99.77%', 2: '99.96%'}, Val Loss: 0.149779846, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.59%', 1: '97.45%', 2: '82.80%'}, LR: 0.000100000\n",
      "Epoch 1962/2000, Train Loss: 0.000627676, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.156787190, Val Accuracy: 96.98%, Val-Class-Acc: {0: '99.63%', 1: '97.48%', 2: '82.58%'}, LR: 0.000100000\n",
      "Epoch 1963/2000, Train Loss: 0.000357666, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160442200, Val Accuracy: 96.96%, Val-Class-Acc: {0: '99.67%', 1: '97.43%', 2: '82.34%'}, LR: 0.000100000\n",
      "Epoch 1964/2000, Train Loss: 0.000307162, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.166654653, Val Accuracy: 96.89%, Val-Class-Acc: {0: '99.68%', 1: '97.44%', 2: '81.52%'}, LR: 0.000100000\n",
      "Epoch 1965/2000, Train Loss: 0.000289192, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.166730802, Val Accuracy: 96.90%, Val-Class-Acc: {0: '99.68%', 1: '97.41%', 2: '81.80%'}, LR: 0.000100000\n",
      "Epoch 1966/2000, Train Loss: 0.000282258, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.168165299, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.66%', 1: '97.49%', 2: '81.82%'}, LR: 0.000100000\n",
      "Epoch 1967/2000, Train Loss: 0.000273130, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.168705731, Val Accuracy: 96.96%, Val-Class-Acc: {0: '99.66%', 1: '97.50%', 2: '82.09%'}, LR: 0.000100000\n",
      "Epoch 1968/2000, Train Loss: 0.000268781, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171825226, Val Accuracy: 96.90%, Val-Class-Acc: {0: '99.69%', 1: '97.42%', 2: '81.69%'}, LR: 0.000100000\n",
      "Epoch 1969/2000, Train Loss: 0.000276098, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.171862626, Val Accuracy: 96.93%, Val-Class-Acc: {0: '99.68%', 1: '97.42%', 2: '82.00%'}, LR: 0.000100000\n",
      "Epoch 1970/2000, Train Loss: 0.000258427, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.170447088, Val Accuracy: 97.00%, Val-Class-Acc: {0: '99.66%', 1: '97.53%', 2: '82.38%'}, LR: 0.000100000\n",
      "Epoch 1971/2000, Train Loss: 0.000266717, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.178296949, Val Accuracy: 96.86%, Val-Class-Acc: {0: '99.76%', 1: '97.29%', 2: '81.45%'}, LR: 0.000100000\n",
      "Epoch 1972/2000, Train Loss: 0.000254536, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.175202849, Val Accuracy: 96.90%, Val-Class-Acc: {0: '99.70%', 1: '97.41%', 2: '81.70%'}, LR: 0.000100000\n",
      "Epoch 1973/2000, Train Loss: 0.000252483, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.174834362, Val Accuracy: 96.94%, Val-Class-Acc: {0: '99.69%', 1: '97.38%', 2: '82.18%'}, LR: 0.000100000\n",
      "Epoch 1974/2000, Train Loss: 0.000277886, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.175635153, Val Accuracy: 96.99%, Val-Class-Acc: {0: '99.68%', 1: '97.41%', 2: '82.54%'}, LR: 0.000100000\n",
      "Epoch 1975/2000, Train Loss: 0.000960710, Train-Class-Acc: {0: '99.97%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.214168665, Val Accuracy: 96.53%, Val-Class-Acc: {0: '99.96%', 1: '96.17%', 2: '81.09%'}, LR: 0.000100000\n",
      "Epoch 1976/2000, Train Loss: 0.093635764, Train-Class-Acc: {0: '98.26%', 1: '97.56%', 2: '97.98%'}, Val Loss: 0.153955500, Val Accuracy: 96.35%, Val-Class-Acc: {0: '99.62%', 1: '96.18%', 2: '81.11%'}, LR: 0.000100000\n",
      "Epoch 1977/2000, Train Loss: 0.006821865, Train-Class-Acc: {0: '99.86%', 1: '99.80%', 2: '99.92%'}, Val Loss: 0.160343075, Val Accuracy: 96.56%, Val-Class-Acc: {0: '99.61%', 1: '96.74%', 2: '81.21%'}, LR: 0.000100000\n",
      "Epoch 1978/2000, Train Loss: 0.002672025, Train-Class-Acc: {0: '99.96%', 1: '99.95%', 2: '99.99%'}, Val Loss: 0.161323963, Val Accuracy: 96.57%, Val-Class-Acc: {0: '99.65%', 1: '96.87%', 2: '80.66%'}, LR: 0.000100000\n",
      "Epoch 1979/2000, Train Loss: 0.001568208, Train-Class-Acc: {0: '99.98%', 1: '99.97%', 2: '100.00%'}, Val Loss: 0.158926791, Val Accuracy: 96.59%, Val-Class-Acc: {0: '99.70%', 1: '96.95%', 2: '80.35%'}, LR: 0.000100000\n",
      "Epoch 1980/2000, Train Loss: 0.001116612, Train-Class-Acc: {0: '99.99%', 1: '99.98%', 2: '100.00%'}, Val Loss: 0.157251430, Val Accuracy: 96.60%, Val-Class-Acc: {0: '99.71%', 1: '96.87%', 2: '80.67%'}, LR: 0.000100000\n",
      "Epoch 1981/2000, Train Loss: 0.000889909, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.157199883, Val Accuracy: 96.73%, Val-Class-Acc: {0: '99.66%', 1: '97.31%', 2: '80.57%'}, LR: 0.000100000\n",
      "Epoch 1982/2000, Train Loss: 0.000754913, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160320179, Val Accuracy: 96.72%, Val-Class-Acc: {0: '99.69%', 1: '97.34%', 2: '80.30%'}, LR: 0.000100000\n",
      "Epoch 1983/2000, Train Loss: 0.000624920, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.160488576, Val Accuracy: 96.67%, Val-Class-Acc: {0: '99.60%', 1: '97.40%', 2: '80.07%'}, LR: 0.000100000\n",
      "Epoch 1984/2000, Train Loss: 0.000544667, Train-Class-Acc: {0: '99.99%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.167116428, Val Accuracy: 96.61%, Val-Class-Acc: {0: '99.65%', 1: '97.35%', 2: '79.43%'}, LR: 0.000100000\n",
      "Epoch 1985/2000, Train Loss: 0.000484173, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168177811, Val Accuracy: 96.62%, Val-Class-Acc: {0: '99.63%', 1: '97.38%', 2: '79.53%'}, LR: 0.000100000\n",
      "Epoch 1986/2000, Train Loss: 0.000449483, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.168553626, Val Accuracy: 96.64%, Val-Class-Acc: {0: '99.63%', 1: '97.39%', 2: '79.75%'}, LR: 0.000100000\n",
      "Epoch 1987/2000, Train Loss: 0.000415995, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.173678858, Val Accuracy: 96.59%, Val-Class-Acc: {0: '99.66%', 1: '97.31%', 2: '79.39%'}, LR: 0.000100000\n",
      "Epoch 1988/2000, Train Loss: 0.000394819, Train-Class-Acc: {0: '100.00%', 1: '99.99%', 2: '100.00%'}, Val Loss: 0.174949062, Val Accuracy: 96.60%, Val-Class-Acc: {0: '99.65%', 1: '97.35%', 2: '79.35%'}, LR: 0.000100000\n",
      "Epoch 1989/2000, Train Loss: 0.000370350, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.175037685, Val Accuracy: 96.63%, Val-Class-Acc: {0: '99.66%', 1: '97.31%', 2: '79.75%'}, LR: 0.000100000\n",
      "Epoch 1990/2000, Train Loss: 0.000356752, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.175197812, Val Accuracy: 96.66%, Val-Class-Acc: {0: '99.65%', 1: '97.34%', 2: '79.96%'}, LR: 0.000100000\n",
      "Epoch 1991/2000, Train Loss: 0.000342537, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.177894228, Val Accuracy: 96.65%, Val-Class-Acc: {0: '99.67%', 1: '97.33%', 2: '79.82%'}, LR: 0.000100000\n",
      "Epoch 1992/2000, Train Loss: 0.000332388, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.178286578, Val Accuracy: 96.65%, Val-Class-Acc: {0: '99.69%', 1: '97.27%', 2: '79.91%'}, LR: 0.000100000\n",
      "Epoch 1993/2000, Train Loss: 0.000340726, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.179607379, Val Accuracy: 96.64%, Val-Class-Acc: {0: '99.70%', 1: '97.24%', 2: '79.83%'}, LR: 0.000100000\n",
      "Epoch 1994/2000, Train Loss: 0.000319735, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.176908248, Val Accuracy: 96.70%, Val-Class-Acc: {0: '99.62%', 1: '97.43%', 2: '80.16%'}, LR: 0.000100000\n",
      "Epoch 1995/2000, Train Loss: 0.000313985, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.179563433, Val Accuracy: 96.68%, Val-Class-Acc: {0: '99.68%', 1: '97.34%', 2: '79.95%'}, LR: 0.000100000\n",
      "Epoch 1996/2000, Train Loss: 0.000305515, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.184281347, Val Accuracy: 96.61%, Val-Class-Acc: {0: '99.71%', 1: '97.24%', 2: '79.46%'}, LR: 0.000100000\n",
      "Epoch 1997/2000, Train Loss: 0.000315193, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.184155538, Val Accuracy: 96.63%, Val-Class-Acc: {0: '99.76%', 1: '97.19%', 2: '79.68%'}, LR: 0.000100000\n",
      "Epoch 1998/2000, Train Loss: 0.000294952, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.180751091, Val Accuracy: 96.69%, Val-Class-Acc: {0: '99.68%', 1: '97.32%', 2: '80.11%'}, LR: 0.000100000\n",
      "Epoch 1999/2000, Train Loss: 0.000293548, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.184700973, Val Accuracy: 96.62%, Val-Class-Acc: {0: '99.71%', 1: '97.21%', 2: '79.70%'}, LR: 0.000100000\n",
      "Epoch 2000/2000, Train Loss: 0.000297534, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.182898811, Val Accuracy: 96.67%, Val-Class-Acc: {0: '99.66%', 1: '97.34%', 2: '80.00%'}, LR: 0.000100000\n",
      "\n",
      "Final model saved to Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_final.pth\n",
      "\n",
      "Training complete. \n",
      "\n",
      "Top 5 Models Sorted by Validation Accuracy: \n",
      "Epoch 214/2000, Train Loss: 0.004808446, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.094864418, Val Accuracy: 97.95%, Val-Class-Acc: {0: '99.66%', 1: '97.34%', 2: '80.00%'}, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_214.pth\n",
      "Epoch 216/2000, Train Loss: 0.004818549, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.095839721, Val Accuracy: 97.94%, Val-Class-Acc: {0: '99.66%', 1: '97.34%', 2: '80.00%'}, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_216.pth\n",
      "Epoch 52/2000, Train Loss: 0.025370944, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.058782248, Val Accuracy: 97.94%, Val-Class-Acc: {0: '99.66%', 1: '97.34%', 2: '80.00%'}, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_52.pth\n",
      "Epoch 288/2000, Train Loss: 0.003964437, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.106312231, Val Accuracy: 97.90%, Val-Class-Acc: {0: '99.66%', 1: '97.34%', 2: '80.00%'}, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_288.pth\n",
      "Epoch 220/2000, Train Loss: 0.004858088, Train-Class-Acc: {0: '100.00%', 1: '100.00%', 2: '100.00%'}, Val Loss: 0.102364999, Val Accuracy: 97.90%, Val-Class-Acc: {0: '99.66%', 1: '97.34%', 2: '80.00%'}, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_220.pth\n",
      "\n",
      "\n",
      "Epoch 214/2000, Train Loss: 0.0048, Val Loss: 0.0949, Val Accuracy: 97.95%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_214.pth\n",
      "Epoch 216/2000, Train Loss: 0.0048, Val Loss: 0.0958, Val Accuracy: 97.94%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_216.pth\n",
      "Epoch 52/2000, Train Loss: 0.0254, Val Loss: 0.0588, Val Accuracy: 97.94%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_52.pth\n",
      "Epoch 288/2000, Train Loss: 0.0040, Val Loss: 0.1063, Val Accuracy: 97.90%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_288.pth\n",
      "Epoch 220/2000, Train Loss: 0.0049, Val Loss: 0.1024, Val Accuracy: 97.90%, Model Path: Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\EWC_CIL\\Period_2\\1st_try\\BiGRUWithAttentionEWC_epoch_220.pth\n",
      "\n",
      "class_gru_model with ewc (current_model): \n",
      "BiGRUWithAttention(\n",
      "  (gru): GRU(7, 64, num_layers=4, batch_first=True, bidirectional=True)\n",
      "  (attention_fc): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "\n",
      "unique_classes = [0 1 2]\n",
      "num_classes = 3\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001 # For the optimizer # lr=0.00005\n",
    "weight_decay=0.0 # 1e-5 # For the optimizer\n",
    "use_scheduler = False\n",
    "lambda_ewc=40 #<<<<<<<<<<<<0.4\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttentionEWC' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/EWC_CIL/Period_2/1st_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the current period model (and load weights from previous period's best model)\n",
    "current_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "period_1_epoch = 1987 # Epoch of the chosen Period 1 model\n",
    "ewc_sample_tag = \"All\" # Options: \"All\" or \"100\" (must match the saved file)\n",
    "best_model_dir = os.path.normpath(os.path.join('Class_Incremental_CL', f\"Classif_Bi_Dir_GRU_Model/Trained_models/EWC_CIL/Period_1_weights_with_ewc/EWC_with_{ewc_sample_tag}_samples\"))\n",
    "best_model_path = os.path.normpath(os.path.join(best_model_dir, f\"{model_name}_epoch_{period_1_epoch}_ewc_{ewc_sample_tag}.pth\"))\n",
    "#-------- OR ---------\n",
    "# best_model_path = r\"Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1987.pth\"\n",
    "#----------------------------------------------------------------------\n",
    "# Initialize the list to store results across runs\n",
    "track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "prev_checkpoint_path = os.path.normpath(best_model_path)\n",
    "prev_checkpoint = torch.load(prev_checkpoint_path, map_location=device, weights_only=True)\n",
    "required_keys = ['model_state_dict', 'ewc_fisher', 'ewc_params']\n",
    "for key in required_keys:\n",
    "    if key not in prev_checkpoint:\n",
    "        raise KeyError(f\"Checkpoint {prev_checkpoint} is missing required key: '{key}'\")\n",
    "prev_model_dict = prev_checkpoint['model_state_dict']\n",
    "ewc_fisher_dict = prev_checkpoint['ewc_fisher'] # Should be on CPU\n",
    "ewc_params_dict = prev_checkpoint['ewc_params'] # Should be on CPU\n",
    "print(f\"Loaded previous period checkpoint from: \\n\\t{prev_checkpoint_path}\")\n",
    "# print(f\"\\nprev_checkpoint: \\n{prev_checkpoint}\\n\")\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "#----------------------------------------<<<<<<<<<<<<<<<\n",
    "# --- !! START INSPECTION HERE !! ---\n",
    "inspect_fisher_info(ewc_fisher_dict, label=f\"Loaded Fisher Values ({ewc_sample_tag} Samples)\")\n",
    "# --- !! END INSPECTION !! ---\n",
    "#----------------------------------------<<<<<<<<<<<<<<<\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# --- Transfer Compatible Weights from Previous Period Model to Current Period Model ---\n",
    "print(\"Transferring compatible weights to the new model...\")\n",
    "current_model_dict = current_model.state_dict()\n",
    "# Filter the loaded state dict: Keep only layers that exist in the current model AND have matching shapes\n",
    "# Update only parameters with matching shapes (skip final fc if dimensions differ)\n",
    "filtered_prev_state_dict = {\n",
    "    k: v for k, v in prev_model_dict.items()\n",
    "    if k in current_model_dict and v.size() == current_model_dict[k].size()\n",
    "}\n",
    "if not filtered_prev_state_dict:\n",
    "     print(\"Warning: No compatible weights found to transfer. The new model will start from random initialization (except layers possibly initialized by default).\")\n",
    "else:\n",
    "    # Load the filtered weights into the new model.\n",
    "    # `strict=False` allows loading a partial state dict (ignoring missing keys like the final FC layer)\n",
    "    missing_keys, unexpected_keys = current_model.load_state_dict(filtered_prev_state_dict, strict=False)\n",
    "    print(f\"  Weights loaded. Keys missing in loaded dict (expected: fc layer): {missing_keys}\")\n",
    "    print(f\"  Keys in loaded dict but not in model (should be empty): {unexpected_keys}\")\n",
    "# Ensure the model is on the correct device *after* loading state dict\n",
    "current_model.to(device)\n",
    "print(f\"\\nCurrent Period Model Structure: \\n{current_model}\\n\")\n",
    "#-------------------------------------------------------------------------\n",
    "# # --- Transfer Compatible Weights from Previous Period Model to Current Period Model ---\n",
    "# current_model_dict = current_model.state_dict()\n",
    "# # Filter the loaded state dict: Keep only layers that exist in the current model AND have matching shapes\n",
    "# # Update only parameters with matching shapes (skip final fc if dimensions differ)\n",
    "# prev_model_dict = {\n",
    "#     k: v for k, v in prev_model_dict.items() \n",
    "#     if k in current_model_dict and v.size() == current_model_dict[k].size()\n",
    "# }\n",
    "# current_model_dict.update(prev_model_dict)\n",
    "# current_model.load_state_dict(current_model_dict)\n",
    "# # Ensure the model is on the correct device *after* loading state dict\n",
    "# current_model.to(device)\n",
    "# print(f\"\\nCurrent Period Model Structure: \\n{current_model}\\n\")\n",
    "#-------------------------------------------------------------------------\n",
    "# --- Instantiate EWC Object for Training ---\n",
    "# Use the Fisher matrix and optimal parameters loaded from the Previous Period checkpoint\n",
    "print(\"Instantiating EWC object using loaded state...\")\n",
    "ewc_object = EWC(fisher=ewc_fisher_dict, params=ewc_params_dict)\n",
    "# The fisher/params tensors are currently on CPU (as saved).\n",
    "# The EWC.penalty method handles moving the param tensors to the model's device during calculation.\n",
    "#-------------------------------------------------------------------------\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(current_model.parameters(), lr=learning_rate, weight_decay=weight_decay) # lr=0.00005\n",
    "scheduler = None\n",
    "if use_scheduler:\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    scheduler_name = scheduler.__class__.__name__\n",
    "    print(f\"Using {scheduler_name} scheduler.\\n\")\n",
    "\n",
    "# raise Exception(\"Stop here!\") # <<<-----------------------------------------\n",
    "\n",
    "train_and_validate_ewc(\n",
    "    model=current_model,\n",
    "    output_size=output_size,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_val=X_val, y_val=y_val,\n",
    "    scheduler=scheduler,\n",
    "    use_scheduler=use_scheduler,\n",
    "    ewc=ewc_object, # Pass the EWC object\n",
    "    lambda_ewc=lambda_ewc, # Pass the EWC strength\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    model_saving_folder=model_saving_folder,\n",
    "    model_name=model_name, # Use base name for saved files in this period\n",
    "    stop_signal_file=stop_signal_file\n",
    ")\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model with ewc (current_model): \\n{current_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "\n",
    "for var in [\n",
    "    \"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\",\n",
    "    \"Number_features\", \"unique_classes\", \"num_classes\",\n",
    "    \"current_model\", \"ewc_object\",\n",
    "    \"prev_checkpoint\", \"prev_model_dict\", \"prev_checkpoint_path\",\n",
    "    \"period_1_epoch\", \"ewc_sample_tag\", \"best_model_dir\",\n",
    "    \"filtered_prev_state_dict\", \"current_model_dict\",\n",
    "    \"ewc_fisher_dict\", \"ewc_params_dict\"\n",
    "]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n",
    "# --- Force garbage collection ---\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in [\n",
    "    \"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\",\n",
    "    \"Number_features\", \"unique_classes\", \"num_classes\",\n",
    "    \"current_model\", \"ewc_object\",\n",
    "    \"prev_checkpoint\", \"prev_model_dict\", \"prev_checkpoint_path\",\n",
    "    \"period_1_epoch\", \"ewc_sample_tag\", \"best_model_dir\",\n",
    "    \"filtered_prev_state_dict\", \"current_model_dict\",\n",
    "    \"ewc_fisher_dict\", \"ewc_params_dict\"\n",
    "]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n",
    "# --- Force garbage collection ---\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 2 --> Training and saving in __*'2nd_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 2.0, alpha = 0.4) ---> Val acc = 97.94 %\n",
    "### Val-Class-Acc: {0: '99.68%', 1: '97.81%', 2: '84.10%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2]\n",
      "num_classes = 3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[1], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.4          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 2.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_2/2nd_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "best_model_path = r\"Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1987.pth\"\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "# teacher_checkpoint = torch.load(\"teacher_model.pth\", map_location=device)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 2 --> Training and saving in __*'3rd_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 2.0, alpha = 0.3) ---> Val acc = 98.35 %\n",
    "### Val-Class-Acc: {0: '99.55%', 1: '98.63%', 2: '85.32%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2]\n",
      "num_classes = 3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[1], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.3          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 2.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_2/3rd_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "best_model_path = r\"Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\Baseline\\Period_1\\1st_try\\BiGRUWithAttention_epoch_1987.pth\"\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "# teacher_checkpoint = torch.load(\"teacher_model.pth\", map_location=device)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'1st_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 2.0, alpha = 0.5) ---> Val acc = 93.27 %\n",
    "### Val-Class-Acc: {0: '64.82%', 1: '97.99%', 2: '93.35%', 3: '94.49%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.5          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 2.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/1st_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "best_model_path = r\"Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\KL_Div_Distillation_CIL\\Period_2\\3rd_try\\BiGRUWithAttention_epoch_1033.pth\"\n",
    "#----------------------------------------------------------------------\n",
    "# Initialize the list to store results across runs\n",
    "track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'2nd_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 2.0, alpha = 0.4) ---> Val acc = 93.10 %\n",
    "### Val-Class-Acc: {0: '66.98%', 1: '96.91%', 2: '86.08%', 3: '95.65%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.4          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 2.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/2nd_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'3rd_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 2.0, alpha = 0.3) ---> Val acc = 93.84 %\n",
    "### Val-Class-Acc: {0: '70.58%', 1: '96.55%', 2: '84.78%', 3: '95.99%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.3          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 2.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/3rd_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'4th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 3.0, alpha = 0.3) ---> Val acc = 93.71 %\n",
    "### Val-Class-Acc: {0: '72.03%', 1: '98.08%', 2: '94.74%', 3: '94.11%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.3          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 3.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/4th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "best_model_path = r\"Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\KL_Div_Distillation_CIL\\Period_2\\3rd_try\\BiGRUWithAttention_epoch_1033.pth\"\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'5th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 2.5, alpha = 0.3) ---> Val acc = 93.22 %\n",
    "### Val-Class-Acc: {0: '71.81%', 1: '97.38%', 2: '90.61%', 3: '93.89%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.3          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 2.5  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/5th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'6th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.5, alpha = 0.3) ---> Val acc = 94.08 %\n",
    "### Val-Class-Acc: {0: '75.45%', 1: '96.81%', 2: '97.90%', 3: '95.05%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.3          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 1.5  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/6th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'7th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.0, alpha = 0.3) ---> Val acc = 95.33 %\n",
    "### Val-Class-Acc: {0: '83.02%', 1: '97.36%', 2: '89.90%', 3: '96.20%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.3          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 1.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/7th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'8th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.5, alpha = 0.5) ---> Val acc = 93.40 %\n",
    "### Val-Class-Acc: {0: '68.89%', 1: '97.65%', 2: '93.12%', 3: '94.13%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.5          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 1.5  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/8th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'9th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.0, alpha = 0.5) ---> Val acc = 93.90 %\n",
    "### Val-Class-Acc: {0: '74.07%', 1: '95.42%', 2: '84.46%', 3: '96.23%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.5          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 1.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/9th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Class_Incremental_CL\\\\Classif_Bi_Dir_GRU_Model\\\\Trained_models\\\\KL_Div_Distillation_CIL\\\\Period_2\\\\3rd_try\\\\BiGRUWithAttention_epoch_1033.pth'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1589,\n",
       "  'train_loss': 3.9481144844993628,\n",
       "  'train_classwise_accuracy': {0: '62.57%',\n",
       "   1: '97.03%',\n",
       "   2: '95.69%',\n",
       "   3: '94.30%'},\n",
       "  'val_loss': 0.1866158771488635,\n",
       "  'val_accuracy': 0.9321806167400881,\n",
       "  'val_classwise_accuracy': {0: '69.45%',\n",
       "   1: '97.57%',\n",
       "   2: '90.70%',\n",
       "   3: '94.58%'},\n",
       "  'learning_rate': 0.0001,\n",
       "  'model_path': 'Class_Incremental_CL\\\\Classif_Bi_Dir_GRU_Model\\\\Trained_models\\\\KL_Div_Distillation_CIL\\\\Period_3\\\\5th_try\\\\BiGRUWithAttention_epoch_1589.pth'},\n",
       " {'epoch': 1949,\n",
       "  'train_loss': 1.0451876429259679,\n",
       "  'train_classwise_accuracy': {0: '74.15%',\n",
       "   1: '97.02%',\n",
       "   2: '96.04%',\n",
       "   3: '95.26%'},\n",
       "  'val_loss': 0.1530346570429823,\n",
       "  'val_accuracy': 0.9408171806167401,\n",
       "  'val_classwise_accuracy': {0: '75.20%',\n",
       "   1: '97.16%',\n",
       "   2: '97.98%',\n",
       "   3: '94.98%'},\n",
       "  'learning_rate': 0.0001,\n",
       "  'model_path': 'Class_Incremental_CL\\\\Classif_Bi_Dir_GRU_Model\\\\Trained_models\\\\KL_Div_Distillation_CIL\\\\Period_3\\\\6th_try\\\\BiGRUWithAttention_epoch_1949.pth'},\n",
       " {'epoch': 1946,\n",
       "  'train_loss': 0.7673279963552656,\n",
       "  'train_classwise_accuracy': {0: '80.99%',\n",
       "   1: '97.11%',\n",
       "   2: '96.08%',\n",
       "   3: '96.01%'},\n",
       "  'val_loss': 0.12623137767356923,\n",
       "  'val_accuracy': 0.9533458149779735,\n",
       "  'val_classwise_accuracy': {0: '82.55%',\n",
       "   1: '97.97%',\n",
       "   2: '89.83%',\n",
       "   3: '96.16%'},\n",
       "  'learning_rate': 0.0001,\n",
       "  'model_path': 'Class_Incremental_CL\\\\Classif_Bi_Dir_GRU_Model\\\\Trained_models\\\\KL_Div_Distillation_CIL\\\\Period_3\\\\7th_try\\\\BiGRUWithAttention_epoch_1946.pth'},\n",
       " {'epoch': 1961,\n",
       "  'train_loss': 2.4670009588106163,\n",
       "  'train_classwise_accuracy': {0: '68.02%',\n",
       "   1: '96.93%',\n",
       "   2: '95.84%',\n",
       "   3: '94.28%'},\n",
       "  'val_loss': 0.1839815555427568,\n",
       "  'val_accuracy': 0.9340176211453745,\n",
       "  'val_classwise_accuracy': {0: '69.19%',\n",
       "   1: '98.13%',\n",
       "   2: '92.40%',\n",
       "   3: '94.27%'},\n",
       "  'learning_rate': 0.0001,\n",
       "  'model_path': 'Class_Incremental_CL\\\\Classif_Bi_Dir_GRU_Model\\\\Trained_models\\\\KL_Div_Distillation_CIL\\\\Period_3\\\\8th_try\\\\BiGRUWithAttention_epoch_1961.pth'},\n",
       " {'epoch': 1999,\n",
       "  'train_loss': 0.9389921405450551,\n",
       "  'train_classwise_accuracy': {0: '72.03%',\n",
       "   1: '97.00%',\n",
       "   2: '96.10%',\n",
       "   3: '94.72%'},\n",
       "  'val_loss': 0.16761538281314697,\n",
       "  'val_accuracy': 0.9389867841409691,\n",
       "  'val_classwise_accuracy': {0: '73.77%',\n",
       "   1: '97.26%',\n",
       "   2: '88.54%',\n",
       "   3: '95.77%'},\n",
       "  'learning_rate': 0.0001,\n",
       "  'model_path': 'Class_Incremental_CL\\\\Classif_Bi_Dir_GRU_Model\\\\Trained_models\\\\KL_Div_Distillation_CIL\\\\Period_3\\\\9th_try\\\\BiGRUWithAttention_epoch_1999.pth'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_across_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'10th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.0, alpha = 0.2) ---> Val acc = 95.63 %\n",
    "### Val-Class-Acc: {0: '87.58%', 1: '97.00%', 2: '87.27%', 3: '96.69%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.2          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 1.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/10th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'11th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.0, alpha = 0.1) ---> Val acc = 96.41 %\n",
    "### Val-Class-Acc: {0: '89.79%', 1: '96.68%', 2: '85.81%', 3: '97.90%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.1          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 1.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/11th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'12th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 0.5, alpha = 0.3) ---> Val acc = 96.13 %\n",
    "### Val-Class-Acc: {0: '86.92%', 1: '97.55%', 2: '86.37%', 3: '97.45%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.3          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 0.5  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/12th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'13th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 0.3, alpha = 0.3) ---> Val acc = 96.84 %\n",
    "### Val-Class-Acc: {0: '91.41%', 1: '98.34%', 2: '82.61%', 3: '97.31%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.3          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 0.3  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/13th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'14th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 0.3, alpha = 0.1) ---> Val acc = 97.40 %\n",
    "### Val-Class-Acc: {0: '93.17%', 1: '97.79%', 2: '89.81%', 3: '98.17%'} <<<<<<<<<<<<< Choice for Period 4 (Look at outputs for best model path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.1          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 0.3  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/14th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3 --> Training and saving in __*'15th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 0.3, alpha = 0.5) ---> Val acc = 96.50 %\n",
    "### Val-Class-Acc: {0: '91.10%', 1: '97.29%', 2: '87.62%', 3: '97.33%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3]\n",
      "num_classes = 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[2], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.5          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 0.3  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_3/15th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'1st_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 2.0, alpha = 0.5) ---> Val acc = 96.11 %\n",
    "### Val-Class-Acc: {0: '87.24%', 1: '97.13%', 2: '94.85%', 3: '97.15%', 4: '94.75%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.5          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 2.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/1st_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "best_model_path = r\"Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\KL_Div_Distillation_CIL\\Period_3\\14th_try\\BiGRUWithAttention_epoch_1945.pth\"\n",
    "#----------------------------------------------------------------------\n",
    "# Initialize the list to store results across runs\n",
    "track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'2nd_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 2.0, alpha = 0.4) ---> Val acc = 95.75 %\n",
    "### Val-Class-Acc: {0: '86.03%', 1: '96.75%', 2: '94.21%', 3: '96.52%', 4: '95.64%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.4          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 2.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/2nd_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'3rd_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 2.0, alpha = 0.3) ---> Val acc = 95.81 %\n",
    "### Val-Class-Acc: {0: '84.12%', 1: '97.56%', 2: '93.17%', 3: '96.01%', 4: '95.70%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.3          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 2.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/3rd_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'4th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 2.0, alpha = 0.1) ---> Val acc = 95.82 %\n",
    "### Val-Class-Acc: {0: '89.32%', 1: '97.60%', 2: '92.37%', 3: '96.57%', 4: '95.14%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.1          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 2.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/4th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'5th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 0.3, alpha = 0.1) ---> Val acc = 95.87 %\n",
    "### Val-Class-Acc: {0: '91.25%', 1: '95.92%', 2: '90.46%', 3: '97.99%', 4: '97.67%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.1          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 0.3  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/5th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'6th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 0.3, alpha = 0.3) ---> Val acc = 95.60 %\n",
    "### Val-Class-Acc: {0: '88.35%', 1: '96.82%', 2: '91.27%', 3: '96.79%', 4: '96.29%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.3          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 0.3  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/6th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'7th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 0.3, alpha = 0.5) ---> Val acc = 95.69 %\n",
    "### Val-Class-Acc: {0: '87.60%', 1: '96.36%', 2: '91.58%', 3: '96.45%', 4: '98.40%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.5          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 0.3  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/7th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'8th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.0, alpha = 0.1) ---> Val acc = 96.13 %\n",
    "### Val-Class-Acc: {0: '91.73%', 1: '96.37%', 2: '91.85%', 3: '97.03%', 4: '98.88%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.1          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 1.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/8th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'9th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.0, alpha = 0.3) ---> Val acc = 96.00 %\n",
    "### Val-Class-Acc: {0: '85.98%', 1: '97.72%', 2: '92.65%', 3: '96.47%', 4: '98.02%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.3          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 1.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/9th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'10th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.0, alpha = 0.5) ---> Val acc = 95.70 %\n",
    "### Val-Class-Acc: {0: '85.29%', 1: '96.96%', 2: '92.79%', 3: '97.08%', 4: '95.35%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.5          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 1.0  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/10th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'11th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.5, alpha = 0.5) ---> Val acc = 95.53 %\n",
    "### Val-Class-Acc: {0: '87.09%', 1: '96.88%', 2: '92.77%', 3: '96.55%', 4: '93.91%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.5          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 1.5  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/11th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'12th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.5, alpha = 0.3) ---> Val acc = 95.51 %\n",
    "### Val-Class-Acc: {0: '85.74%', 1: '96.89%', 2: '92.56%', 3: '96.63%', 4: '94.14%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.3          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 1.5  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/12th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 4 --> Training and saving in __*'13th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.5, alpha = 0.1) ---> Val acc = 96.03 %\n",
    "### Val-Class-Acc: {0: '90.59%', 1: '97.35%', 2: '93.29%', 3: '96.98%', 4: '94.46%'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number_features = 7\n",
      "unique_classes = [0 1 2 3 4]\n",
      "num_classes = 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 'trend': Categorized trend values based on the detected phases:\n",
    "    - 0: No trend\n",
    "    - 1: Moderate negative trend\n",
    "    - 2: Very strong negative trend\n",
    "    - 3: Moderate positive trend\n",
    "    - 4: Very strong positive trend\n",
    "\"\"\"\n",
    "with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, Number_features = process_and_return_splits(\n",
    "        with_indicators_file_path = list_period_files_full_path[3], # Change \n",
    "        downsampled_data_minutes = downsampled_data_minutes,\n",
    "        exclude_columns = exclude_columns,\n",
    "        lower_threshold = lower_threshold,\n",
    "        upper_threshold = upper_threshold,\n",
    "        reverse_steps = reverse_steps,\n",
    "        sequence_length = sequence_length,\n",
    "        sliding_interval = sliding_interval,\n",
    "        trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends : {0, 1, 2, 3, 4}\n",
    "        # trends_to_keep = {0, 1, 2, 3, 4}  # Default keeps all trends\n",
    "    )\n",
    "\n",
    "print(f\"\\nNumber_features = {Number_features}\")\n",
    "\n",
    "unique_classes = np.unique(y_val)\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"unique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "stable_classes = unique_classes[1:-1]  # Exclude first and last elements\n",
    "input_size = Number_features  # Number of features\n",
    "hidden_size = 64  # Number of GRU units\n",
    "output_size = num_classes # Must be dynamic, up to 5  # Number of trend classes (0, 15, 25, -15, -25)\n",
    "num_layers = 4  # Number of GRU layers\n",
    "dropout = 0.0\n",
    "learning_rate = 0.0001\n",
    "alpha = 0.1          # Weight for distillation loss\n",
    "# --- Modified Knowledge Distillation using KL divergence ---\n",
    "temperature = 1.5  # Set temperature hyperparameter (adjust as needed)\n",
    "# ---- ---- ---- #\n",
    "num_epochs= 2000 # Number of epochs/ go through entire data\n",
    "batch_size= 64 # How many sequences passed at once to the model\n",
    "model_name = 'BiGRUWithAttention' # Name of the model to use for saving\n",
    "best_results = [] # Initialize this outside the training function or at the beginning of training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Define a global stop signal\n",
    "stop_signal_file = os.path.normpath(os.path.join('Class_Incremental_CL', 'Classif_Bi_Dir_GRU_Model/stop_training.txt'))  # Create this file to stop training\n",
    "model_saving_folder = os.path.normpath(os.path.join('Class_Incremental_CL', \"Classif_Bi_Dir_GRU_Model/Trained_models/KL_Div_Distillation_CIL/Period_4/13th_try\"))\n",
    "ensure_folder(model_saving_folder)\n",
    "\n",
    "# Instantiate the student model\n",
    "student_model = BiGRUWithAttention(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "\n",
    "# Instantiate and load the teacher model\n",
    "teacher_model = BiGRUWithAttention(input_size, hidden_size, output_size - 1, num_layers, dropout).to(device)\n",
    "#-------------------------------------------------------------------------\n",
    "# best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "# best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# # Initialize the list to store results across runs\n",
    "# track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "teacher_checkpoint_path = os.path.normpath(best_model_path)\n",
    "teacher_checkpoint = torch.load(teacher_checkpoint_path, map_location=device, weights_only=True)\n",
    "# print(f\"\\n{teacher_checkpoint}\\n\")\n",
    "teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "del teacher_checkpoint\n",
    "gc.collect()\n",
    "print(f\"Loaded teacher model from: \\n\\t{teacher_checkpoint_path}\")\n",
    "print(f\"\\n{teacher_model}\\n\")\n",
    "\n",
    "# Define the loss function, optimizer and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer: only train parameters of the student model (LoRA parameters and any unfrozen ones).\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate) # lr=0.00005\n",
    "# optimizer = optim.Adam(class_gru_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9, patience=10)\n",
    "\n",
    "train_and_validate_KL_Div(student_model, teacher_model, stable_classes, output_size, criterion, optimizer, \n",
    "                          X_train, y_train, X_val, y_val, scheduler, False, num_epochs, batch_size, \n",
    "                          alpha, temperature, model_saving_folder, model_name, stop_signal_file)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Append only the best result (already at index 0)\n",
    "track_across_runs.append(best_results[0])\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "for res in best_results:        \n",
    "    print(f\"Epoch {res['epoch']}/{num_epochs}, \"\n",
    "            f\"Train Loss: {res['train_loss']:.4f}, \" \n",
    "            f\"Val Loss: {res['val_loss']:.4f}, \"\n",
    "            f\"Val Accuracy: {res['val_accuracy'] * 100:.2f}%, \"\n",
    "            f\"Model Path: {res['model_path']}\")      \n",
    "print(f\"\\nclass_gru_model (student_model): \\n{student_model}\")\n",
    "\n",
    "print(f\"\\nunique_classes = {unique_classes}\")\n",
    "print(f\"num_classes = {num_classes}\")\n",
    "# del unique_classes, num_classes\n",
    "for var in [\"X_train\", \"y_train\", \"X_val\", \"y_val\", \"X_test\", \"y_test\", \"Number_features\", \"unique_classes\", \"num_classes\"]:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_path = Class_Incremental_CL\\Classif_Bi_Dir_GRU_Model\\Trained_models\\KL_Div_Distillation_CIL\\Period_4\\8th_try\\BiGRUWithAttention_epoch_1962.pth\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------\n",
    "best_overall = max(track_across_runs, key=lambda res: res['val_accuracy'])\n",
    "best_model_path = best_overall['model_path']\n",
    "#----------------------------------------------------------------------\n",
    "# Initialize the list to store results across runs\n",
    "track_across_runs = []\n",
    "#----------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "print(f\"best_model_path = {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------------------------------------------------------------------------------------\n",
    "## Summary:\n",
    "## ---------\n",
    "### Period 1 --> Training and saving in __*'1st_try'*__ (BiGRUWithAttention, num_layers = 4) ---> Val acc = 98.35 %\n",
    "### Val-Class-Acc: {0: '98.10%', 1: '97.81%'}\n",
    "## ---------\n",
    "### Period 2 --> Training and saving in __*'3rd_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 2.0, alpha = 0.3) ---> Val acc = 98.35 %\n",
    "### Val-Class-Acc: {0: '99.55%', 1: '98.63%', 2: '85.32%'}\n",
    "## ---------\n",
    "### Period 3 --> Training and saving in __*'14th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 0.3, alpha = 0.1) ---> Val acc = 97.40 %\n",
    "### Val-Class-Acc: {0: '93.17%', 1: '97.79%', 2: '89.81%', 3: '98.17%'}\n",
    "## ---------\n",
    "### Period 4 --> Training and saving in __*'8th_try'*__ (BiGRUWithAttention, num_layers = 4, temperature = 1.0, alpha = 0.1) ---> Val acc = 96.13 %\n",
    "### Val-Class-Acc: {0: '91.73%', 1: '96.37%', 2: '91.85%', 3: '97.03%', 4: '98.88%'}\n",
    "## ----------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
